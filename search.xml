<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Algorithms, Part 1]]></title>
    <url>%2F2019%2F03%2F10%2FAlgorithms-Part-1%2F</url>
    <content type="text"><![CDATA[Princeton Algorithm course on coursera. Part 1 Cover: Disjoint set Analysis of Algorithms Stack and Queue Elementary Sorts Mergesort Quicksort Priority Queue Elementary Symbol Tables BST Hash Table Learning Purpose: Being familiar with Java. Having fun with algorithms. Reference Books: Algorithms, 4th Edition Computer Science: An Interdisciplinary Approach Week 1Why study algorithms“Great algorithms are the poetry of computation.” — Francis Sullivan “Algorithms + Data Structures = Programs.” — Niklaus Wirth Union-FindSteps to developing a usable algorithm Model the problem. Find an algorithm to solve it. Fast enough? Fits in memory? If not, figure out why. Find a way to address the problem. Iterate until satisfied. dynamic connectivityGiven a set of N objects. Union command: connect two objects Find/conneted query: is there a path connecting the two objects? Connectivity example Q. Is there a path connecting p and q? Some common understandings: Reflexive: p is connected to p itself. Symmetric: if p is connected to q, then q is connected to p. Transitive: if p is connected to q and q is connected to r, then p is connected to r. Connected components. Maximal set of objects that are mutually connected. e.g. ​ Goal. Design efficient data structure for union-find. Number of objects N can be huge. Number of operations M can be huge. Find queries and union commands may be intermixed. 12345678// APIpublic class UF &#123; UF(int N) // initialize union-find data structure with N objects (0 to N-1) void union(int p, int q) // add connection between p and q boolean connected(int p, int q) // are p and q the same component? int find(int p) //component identifier for p (0 to N-1) int count() // number of components&#125; quick findData structure Integer array id[] of size N. Interpretation: p and q are connected iff they have the same id. Find: Check if p and q have the same id Union: To merge components containing p and q, change all entries whose id equals id[p] to id[q]. Costly. 12345678910111213141516171819202122public class QuickFindUF&#123; private int[] id; public QuickFindUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; public boolean connected(int p, int q) &#123; return id[p] == id[q]; &#125; public void union(int p, int q) &#123; int pid = id[p]; int qid = idp[q]; for (int i = 0; i &lt; id.length; i++) if (id[i] == pid) id[i] = qid; &#125;&#125; algorithm initialize union find quick-find N N 1 N union commands on N object: quadratic time. Much too slow. Quadratic algorithms don’t scale with technology. quick unionData structure Integer array id[] of size N. Interpretation: id[i] is parent of i. Root of i is id[id[id[…id[i]…]]]. Each root represents the connected components. Find: Check if p and q have the same root. Union: To merge components containing p and q, set the id of p’s root to the id of q’s root. (path compression) 12345678910111213141516171819202122232425262728public class QuickUnionUF&#123; private int[] id; public QuickUnionUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; private int root(int i) &#123; while (i != id[i]) i = id[i]; return i; &#125; public boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int i = root(p); int j = root(q); id[i] = j; &#125;&#125; Worst case: algorithm initialize union find Quick-union N N N Quick-union defect Trees can get tall Find too expensive (could be N array accesses). improvementsImprovement 1: weighting Weighted quick-union Modify quick-union to avoid tall trees. Keep track of size of each tree (number of objects). Balance by linking root of smaller tree to root of larger tree. Data structure： Same as quick-union, but maintain extra array sz[i] to count number of objects in the tree rooted at i. Find: Identical to quick-union. return root(p) == root(q) Union: Modify quick-union to: Link root of samller tree to root of larger tree. Update the sz[] array. 12345int i = root(p);itn j = root(q);if (i == j) return;if (sz[i] &lt; sz[j]) &#123; id[i] = j; sz[j] += sz[i]; &#125;else &#123; id[j] = i; sz[i] += sz[j]; &#125; Proposition: Depth of any node x is at most $lg N$ algorithm initialize union find Weighted QU N lg N Lg N Improvement 2: path compressionQuick union with path compression: Just after computing the root of p, set the id of each examined node to point to that root. Two-pass implementation: add second loop to root() to set the id[] of each examined node to the root. Simpler one-pass variant: Make every other node in path point to its grandparent (thereby halving path length). 12345678910// variantprivate int root(int i)&#123; while (i != id[i]) &#123; id[i] = id[id[i]] i = id[i] &#125; return i;&#125; Weighted QU + path compression: worst-case time is N + M lg* N (lg * is an iterate function, plz refer to slide for more information) applications Percolation Games (Go, Hex) Dynamic connectivity Least common ancestor Equivalence of finite state automata Hoshen-Kopelman algorithm in physics Hinley-Milner polymorphic type inference Kruskal’s minimum spanning tree algorithm Compiling equivalence statements in Fortran Morphological attribute openings and closings Matlab’s bwlabel() function in image processing Subroutine of many other algorithms Programming Assignment 1Problem: Programming Assignment 1 Code is on my Github page: Percolation Missing the optional task of running time analysis, but I don’t want to do it again because this task is somewhat discouraging for some beginners I think. Analysis of AlgorithmsobservationsAnalytic Engine Reasons to analyze algorithms Predict performance Compare algorithms Provide guarantees Understand theoretical basis Primary practical reason: avoid performance bugs. Discrete Fourier transform N-body simulation Scientific method Observe Hypothesize Predict Verify Validate Principles Experiments must be reproducible Hypotheses must be falsifiable 3-sum problem Standard plot on running time Log-log scale strategy Doubling hypothesis: run program, doubling the size of the input. System independent effects Algorithm Input data System dependent effects Hardware: CPU, memory, cache Software: compiler, interpreter, garbage collector System: operating system, network, other apps mathematical modelsTotal running time: sum of cost * frequency for all operations General concepts 1-sum problem 2-sum problem tilde notation Estimating a discrete sum order-of-growth classification1, log N, N, N lgN, N^2, N^3, 2^N Recurence Easy concepts theory of algorithmsBest case: Lower bound on cost Determined by “easiest” input Provides a goal for all inputs Worst case: Upper bound on cost Determined by “most difficult” input Provides a way to predict performance Average case: Expected cost for random input Need a model for “random” input Provides a way to predict performance Actual data Need to understand input to effectively process it Approach 1: design for the worst case Approach 2: randomize, depend on probailistic guarantee Goals Establish “difficulty” of a problem Develop “optimal” algorithms Approach Suppress details in analyze “to within a constant factor” Eliminate variability in input model by focusing on the worst case Algorithm design approach Start Develop an algorithm Prove a lower bound Gap? Lower the upper bound (discover a new algorithm) Raise the lower bound (more difficult) memoryBit Byte Megabyte (MB) Gigabyte (GB) Old machine: We used to assume a 32-bit machine with 4 byte pointers Modern machine: We now assume a 64-bit machine with 8 byte pointers Typical memory usage for objects in Java Object overhead: 16 bytes Reference: 8 bytes Padding: Each object uses a multiple of 8 bytes Week 2Stacks and QueuesFundamental data types. Value: collection of objects Operations: insert, remove, iterate, test if empty Intent is clear when we insert Which item do we remove Modular programming: Seperate interface and implementation Benefits. Client can’t know details of implementation Implementation can’t know details of client needs Design: creates modular, reusable libraries Performance: useoptimized implementation where it matters stacksLIFO, examine the item most recently added. push, pop API. 1234567public class StackOfStrings&#123; StackOfStrings() // create an empty stack void push(String item) //insert a new string onto stack String pop() // remove and return the string most recently added boolean isEmpty() // is the stack empty? int size() // number of strings on the stack&#125; Linked-list representation 12345// inner classprivate class Node &#123; String item; Node next;&#125; Pop: Push: Array implementation Use array s[] to store N items on stack. push(): add new item at s[N]. pop(): remove item from s[N-1]. Defect: Stack overflows when N exceeds capacity. Full implementation: 12345678910111213141516public class FixedCapacityStackOfStrings &#123; private String[] s; private int N = 0; public FixedCapacityStackOfStrings(int capacity) &#123; s = new String[capacity]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void push(String item) &#123; s[N++] = item; &#125; public String pop() &#123; return s[--N]; &#125;&#125; Stack considerations: Overflow and underflow Underflow: throw exception if pop from an empty stack. Overflow: use resizing array for array implementation. Null items: We allow null items to be inserted. Loitering: Holding a reference to an object when it is no longer needed. To avoid the problem caused by loitering, we need to remove the pointer and free the memory: 1234567// the version avoids "loitering" garbage collector can reclaim memory only// if no outstanding referencespublic String pop() &#123; String item = s[--N]; s[N] = null; return item;&#125; resizing arraysProblem. Requiring client to provide capacity does not implement API First try: push(): increase size of array s[] by 1. pop(): decrease size of array s[] by 1. Too expensive Need to copy all item to a new array. Inserting first N items takes time proportional to 1+2+…+N Repeated doubling: If the array is full, create a new array of twice the size, and copy items 1234567891011121314public ResizingArrayStackOfStrings()&#123; s = new String[1]; &#125;public void push(String item) &#123; if (N == s.length) resize(2 * s.length); s[N++] = item;&#125;private void resize(int capacity) &#123; String[] copy = new String[capacity]; for (int i = 0; i &lt; N; i++) copy[i] = s[i]; s = copy;&#125; Efficient solution for shrinking an array: halve size of array s[] when array is one-quarter full. Invariant: Array is between 25% and 100% full. Amortized analysis: Average running time per operation over a worst-case sequence of operations. Proposition: Starting from an empty stack, any sequence of M push and pop operations takes time proportional to M. Tradeoffs: Linked-list implementation Every operation takes constant time in the worst case. Uses extra time and space to deal with the links. Resizing-array implementation. Every operation takes constant amortized time. Less wasted space. queuesFIFO, examine the item least recently added. enqueue, dequeue API: 1234567public class QueueOfStrings &#123; QueueOfStrings(); // create an empty queue void enqueue(String item); // insert a new string onto queue String dequeue(); // remove and return the string least recently added boolean isEmpty(); // is the queue empty? int size(); // number of strings on the queue&#125; Linked-list representation Maintain pointer to first and last nodes in a linked list; Insert/remove from opposite ends Enqueue: Array implementation of a queue Use array q[] to store items in queue. enqueue(): add new item at q[tail]. dequeue(): remove item from q[head]. Update head and tail modulo the capacity Add resizing array. genericsJava generics Avoid casting in client. Discover type mismatch errors at compile-time instead of run-time. 123456Stack&lt;Apple&gt; s = new Stack&lt;Apple&gt;();Apple a = new Apple();Orange b = new Orange();s.push(a);s.push(b); // compile-time errora = s.pop(); Guilding principles: Welcome compile-time errors; avoid run-time errors. Full implementation (Linked-list version): 12345678910111213141516171819202122232425262728public class Stack&lt;Item&gt;&#123; private Node first = null; private class Node &#123; Item item; Node next; &#125; public boolean isEmpty() &#123; return first == null; &#125; public void push(Item item) &#123; Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; &#125; public Item pop() &#123; Item item = first.item; first = first.next; return item; &#125;&#125; Wrapper type. Each primitive type has a wrapper object type. Ex: Integer is wrapper type for int. Autoboxing: Automatic case between a primitive type and its wrapper. Syntactic sugar: Behind-the-scenes casting. Bottom line: Client code can use generic stack for any type of data. iteratorsDesign challenge: Support iteration over stack items by client, without revealing the internal representation of the stack. Java solution: Make stack implement the Iterable interface. An Iterable has a method that returns an Iterator. Iterable interface: 1234public interface Iterable&lt;Item&gt;&#123; Iterator&lt;Item&gt; iterator();&#125; An Iterator has methods hasNext() and next(). Iterator interface: 123456public interface Iterator&lt;Item&gt;&#123; boolean hasNext(); Item next(); void remove(); // optional&#125; “foreach” statement: 12for (String s : stack) StdOut.println(s); Equivalent code: 123456Iterator&lt;String&gt; i = stack.iterator();while(i.hasNext())&#123; String s = i.next(); StdOut.println(s);&#125; Example: Stack iterator: linked-list implementation 12345678910111213141516171819202122import java.util.Iterator;public class Stack&lt;Item&gt; implements Iterable&lt;Item&gt;&#123; ... public Iterator&lt;Item&gt; iterator() &#123; return new ListIterator(); &#125; private class ListIterator implements Iterator&lt;Item&gt; &#123; private Node current = first; public boolean hasNext() &#123; return current != null; &#125; public void remove() &#123; /* not supported */ &#125; public Item next() &#123; Item item = current.item; current = current.next; return item; &#125; &#125;&#125; Bag API Main application: Adding items to a collection and iterating (when order doesn’t matter). 1234567public class Bag&lt;Item&gt; implements Iterable&lt;Item&gt;&#123; Bag(); // create an empty bag void add(Item x); // insert a new item onto bag int size(); // number of items in bag Iterator&lt;Item&gt; iterator(); // iterator for all items in bag&#125; applicationsWhy not simply use Java collections library? “Performance” Lesson: Don’t use a library until you understand its API or you can tolerate the defect of the efficiency. Stack applications: Parsing in a compiler. Java virtual machine. Undo in a word processor. Back button in a Web browser. PostScript language for printers Implementing function calls in a compiler. Dijkstra’s two-stack algorithm: Value: push onto the value stack. Operator: push onto the operator stack. Left parenthesis: ignore. Right parenthesis: pop operator and two values; push the result of applying that operator to those values onto the operand stack. Programming Assignment 2Problem: Programming Assignment 2 Code is on my Github page: Kdtree Missing bonus memory challenge task. (I think it’s easy) Elementary Sortsrules of the gameGoal: Sort any type of data. Q. How can sort() know how to compare data of type Double, String, and java.io.File without any information about the type of an item’s key? Callback = reference to executable code. Client passes array of objects to sort() function. The sort() function calls back object’s compareTo() method as needed. Comparable interface (built in to Java) 1234public interface Comparable&lt;Item&gt;&#123; public int compareTo(Item that);&#125; Object implementation: 12345678910111213public class File implements Compareble&lt;File&gt;&#123; ... public int compareTo(File b) &#123; ... return -1; ... return +1; ... return 0; &#125;&#125; Sort implementation 123456789public static void sort(Comparable[] a)&#123; int N = a.length; for (int i = 0; i &lt; N; i++) for (int j = i; j &gt; 0; j--) if (a[j].compareTo(a[j-1]) &lt; 0) exch(a, j, j-1); else break;&#125; Total order A total order is a binary relation ≤ that satisfies Antisymmetry: if v ≤ w and w ≤ v, then v = w. Transitivity: if v ≤ w and w ≤ x, then v ≤ x. Totality: either v ≤ w or w ≤ v or both. Comparable API implement compareTo() so that v.compareTo(w) Is a total order. Returns a negative integer, zero, or positive integer if v is less than, equal to, or greater than w, repectively. Throws an exception if incompatible types (or either is null). 12345678910111213141516171819202122public class Date implements Comparable&lt;Date&gt;&#123; private final int month, day, year; public Date(int m, int d, int y) &#123; month = m; day = dl year = yl &#125; public int compareTo(Date that) &#123; if (this.year &lt; that.year) return -1; if (this.year &gt; that.year) return +1; if (this.month &lt; that.month) return -1; if (this.month &gt; that.month) return +1; if (this.day &lt; that.day) return -1; if (this.day &gt; that.day) return +1; return 0; &#125;&#125; Two useful sorting abstractions Less: Is item v less than w? 12private static boolean less(Comparable v, Comparable w)&#123; return v.compareTo(w) &lt; 0; &#125; Exchange: Swap item in array a[] at index i with the one at index j. 123456private static void exch(Comparable[] a, int i, int j)&#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; selection sortIn iteration i, find index min of smallest remaining entry. Swap a[i] and a[min]. 123456789101112131415161718192021public class Selection&#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; i &lt; N; j++) if (less(a[j], a[min])) min = j; exch(a, i, min) &#125; &#125; private static boolean less(Comparable v, Comparable w) &#123; /* as before */ &#125; private static void exch(Comparable[] a, int i, int j) &#123; /* as before */ &#125;&#125; insertion sortIn iteration i, swap a[i] with each larger entry to its left. 12345678910111213141516171819public class Insertion&#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) for (int j = i; j &gt; 0; j--) if (less(a[j], a[j-1])) exch(a, j, j-1); else break; &#125; private static boolean less(Comparable v, Comparable w) &#123; /* as before */ &#125; private static void exch(Comparable[] a, int i, int j) &#123; /* as before */ &#125;&#125; Def: An inversion is a pair of keys that are out of order. Def: An array is partially sorted if the number of inversions is ≤ cN. Proposition: For partially-sorted arrays, insertion sort runs in linear time. Pf: Number of exchanges equals the number of inversions. shellsortIdea: Move entries more than one position at a time by h-sorting the array. How to h-sort an array? Insertion sort, with stride length h. Useful in practice: Fast unless array size is huge. Tiny, fixed footprint for code (used in embedded systems). Hardware sort prototype. shufflingShuffle sort Generate a random real number for each array entry. Sort the array. Proposition: Shuffle sort produces a uniformly random permutation of the input array, provided no duplicate values. Goal: Rearrange array so that result is a uniformly random permutation in linear time. Knuth shuffle In iteration i, pick integer r between 0 and i uniformly at random. Swap a[i] and a[r]. Proposition: Knuth shuffling algorithm produces a uniformly random permutation of the input array in linear time. 12345678910111213public class StdRandom&#123; ... public static void shuffle(Object[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int r = StdRandom.uniform(i + 1); // between 0 and i exch(a, i, r); &#125; &#125;&#125; online poker: easily cracked Bottom line: Shuffling a deck of cards is hard! convex hullThe convex hull of a set of N points is the smallest perimeter fence enclosing the points. Equivalent definitions: Smallest convex set containing all the points. Smallest area convex polygon enclosing the points. Convex polygon enclosing the points, whose vertices are points in set. Convex hull output: Sequence of vertices in counterclockwise order. Convex hull application: motion planning Robot motion planning: Find shortest path in the plane from s to t that avoids a polygonal obstacle. Fact: Shortest path is either straight line from s to t or it is one of two polygonal chains of convex hull. Farthest pair problem: Given N points in the plane, find a pair of points with the largest Euclidean distance between them. Graham scan: Choose point p with smallest y-coordinate. Sort points by polar angle with p. Consider points in order; discard unless it create a ccw turn. Implementation: Define a total order, comparing by y-coordinate. Define a total order for each point p. (polar angle) Computational geometry to determine counterclockwise for triple. Mergesort to sort efficiently. Implementing ccw: CCW: Given three points a, b, and c, is a-&gt;b-&gt;c a counterclockwise turn? (is c to the left of the ray a-&gt;b) A good strategy involves computing areas (high school compitation knowledge) To show respectations: Week 5Balanced Search Trees2-3 search treesAllow 1 or 2 keys per node 2-node: one key, two children 3-node: two keys, three children Perfect balance: Every path from root to null link has same length Symmetric order: Inorder traversal yields keys in ascending order Search Compare search key against keys in node Find interval containing search key Follow associated link (recursively) Insert into a 2-node at bottom Search for key, as usual Replace 2-node with 3-node Splitting a 4-node is a local transformation: constant number of operations Invariants: Maintain symmetric order and perfect balance Pf: Each transformation maintains symmetric order and perfect balance Tree height: Always $lg N$ red-black BSTsLeft-leaning RB tree Idea: Represent 2-3 tree as a BST Use “internal” left-leaning links as “glue” for 3-nodes A BST such that: No node has two red links connected to it Every path from root to null link has the same number of black links Red links lean left 2-3 tree and RB BST are coresponding as following: Search for red-black BST is the same as the general BST Representation: 12345678910111213141516private static final boolean RED = true;private static final boolean BLACK = false;private class Node&#123; Key key; Value val; Node left, right; boolean color; // color of parent link&#125;private boolean isRed(Node x)&#123; if (x == null) return false; return x.color == RED;&#125; Left rotation: Orient a (temporarily) right-leaning red link to lean left 12345678910private Node rotateLedt(Node h)&#123; assert isRed(h.right); Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; return x;&#125; Invariants: Maintains symmetric order and perfect black balance Right rotation is similar. Color flip: Recolor to split a (temporary) 4-node 123456789private void flipColors(Node h)&#123; assert !isRed(h); assert isRed(h.left); assert isRed(h.right); h.color = RED; h.left.color = Black; h.right.color = Black;&#125; Insertion in a LLRB tree Basic strategy: Maintain 1-1 correspondence with 2-3 trees by applying elementary red-black BST operations Warmup 1: Insert into a tree with exactly 1 node Warmup 2: Insert into a tree with exactly 2 nodes (3 cases) Case 2: Insert into a 3-node at the bottom Do standard BST insert; color new link red Rotate to balance the 4-node (if needed) Flip colors to pass red link up one level Rotate to make lean left (if needed) Repeat case 1 or case 2 up the tree (if needed) Java implementation Reduce one case to another 1234567891011121314private Node put(Node h, Key key, Value val)&#123; if (h == null) return new Node(key, val, RED); int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else if (cmp == 0) h.val = val; if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h; if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); return h; &#125; B-trees (Bayer-McCreight, 1972)File system model: Page: Contiguous block of data Probe: First access to a page Property: Time required for a probe is much larger than time to access data within a page Cost model: Number of probes Goal: Access data using minimum number of probes B-tree: Generalize 2-3 trees by allowing up to M-1 key-link pairs per node At least 2 key-link pairs at root At least M/2 key-link pairs in other nodes External nodes contain client keys Internal nodes contain copies of keys to guide search Searching in a B-tree: Start at root Find interval for search key and take corresponding link Search terminates in external node Insertion in a B-tree: Search for new key Insert at bottom Split nodes with M key-link pairs on the way up the tree Red-black trees are widely used as system symbol tables Java: java.util.TreeMap, java.util.TreeSet C++ STL: map, multimap, multiset Linux kernel: completely fair scheduler, linux/rbtree.h Emacs: conservative stack scanning B-tree variants: B+ tree, B* tree, B# tree, … B-trees (and variants) are videly used for file systems and databases Windows: NTFS Mac: HFS, HFS+ Linux: ReiserFS, XFS, Ext3FS, JFS Databases: Oracle, DB2, Ingres, SQL, PostgreSQL Geometric Applications of BSTsApplications: CAD, games, movies, virtual reality, databases, … 1d range search Insert key-value pair Search for key k Delete key k Range search: find all keys between $k_1$ and $k_2$ Range count: number of keys between $k_1$ and $k_2$ Implementations: data structure insert range count range search unordered array 1 N N ordered array N log N R + log N goal log N log N R + log N N = number of keys R = number of keys that match BST implementation: Proposition: Running time proportional to log N. Pf: Nodes examined = search path to lo + search path to hi. line segment intersectionOrthogonal line segment intersection search Quadratic algorithm: Check all pairs of line segments for intersection. Nondegeneracy assumption: All x- and y- coordinates are distinct. Sweep-line algorithm: Sweep vertical line from left to right X-coordinates define events. H-segment (left endpoint): insert y-coordinate into BST. H-segment (right endpoint): remove y-coordinate from BST. When hit a vertical line segment, do a 1-d search Proposition: The sweep-line algorithm takes time proportional to N log N + R to find all R intersections among N orthogonal line segments. Pf. Put x-coordinates on a PQ (or sort). N log N Insert y-coordinates into BST N log N Delete y-coordinates from BST N log N Range searches in BST N log N + R Bottom line: Sweep line reduces 2d orthogonal line segment intersection search to 1d range search kd treesExtension of ordered symbol-table to 2d keys Insert a 2d key Delete a 2d key Search for a 2d key Range search: find all keys that lie in a 2d range Range count: number of keys that lie in a 2d range Geometric interpretation: Keys are point in the plane Find/count points in a given h-v rectangle Grid implementation: Divide space into M-by-M grid of squares Create list of points contained in each square Use 2d array to directly index relevant square Insert: add(x, y) to list for corresponding square Range search: examine only squares that intersect 2d range query Space-time tradeoff Space: $M^2+N$ Time: 1 + $N/M^2$ per square examined, on average Choose grid square size to tune performance Too small: waste space Too large: too many points per square It’s fast, simple solution for evenly-distributed points Problem: Clustering a well-knwon phenomenon in geometric data Lists are too long, even though average length is short Need data structure that adapts gracefully to data 2d tree construction Recursively partition plane into two halfplanes. Data structure: BST, but alternate using x- and y- coordinates as key. Search gives rectangle containing point Insert further subdivides the plane Range search in a 2d tree Goal: Find all points in a query axis-aligned rectangle. Check if point in node lies in given rectangle Recursively search left/bottom (if any could fall in rectangle) Recursively search right/top (if any could fall in rectangle) Nearest neighbor search in a 2d tree Goal: Find closest point to query point Check distance from point in node to query point Recursively search left/bottom (if it could contain a closer point) Recursively search right/top (if it could contain a closer point) Organize method so that it begins by searching for query point Kd tree Recursively partition k-dimensional space into 2 halfspaces Efficient, simple data structure for processing k-dimensional data Widely used Apapts well to high-dimensional and clustered data Discovered by an undergrad in an algorithms class! N-body simulation Build 3d-tree with N particles sa nodes Store center-of-mass of subtree in each node. To compute total force acting on a particle, traverse tree, but stop as soon as distance from particle to subdivision is sufficiently large. interval search trees1d interval search: Data structure to hold set of (overlapping) intervals Insert an interval (lo, hi). Search for an interval (lo, hi). Delete an interval (lo, hi). Interval intersection query: given an interval (lo, hi), find all intervals (or one interval) in data structure that intersects (lo, hi). API 123456public class IntervalST IntervalST() void put(Key lo, Key hi, Value val) Value get(Key lo, Key hi) void delete(Key lo, Key hi) Iterable&lt;Value&gt; intersects(Key lo, Key hi) Interval search trees Create BST, where each node stores an interval (lo, hi). Use left endpoint as BST key. Store max endpoint in subtree rooted at node. To insert an interval (lo, hi): Insert into BST, using lo as the key. Update max in each node on search path. To search for any one interval that intersects query interval (lo, hi): If interval in node intersects query interval, return it. Else if left subtree is null, go right. Else if max endpoint in left subtree is less than lo, go right. Else go left. Case 1. If search goes right, then no intersection in left. Case 2. If search goes left, then there is either an intersection in left subtree or no intersections in either Pf. Suppose no intersection in left. Since went left, we have lo ≤ max. Then for any interval (a,b) in right subtree of x, hi &lt; c ≤ a, no intersection in right. rectangle intersectionOrthogonal rectangle intersection search Goal: Find all intersections among a set of N orthogonal rectangles Quadratic algorithm: Check all pairs of rectangles for intersection Non-degeneracy assumption: All x- and y- coordinates are distinct. Design-rule checking: Certain wires cannot intersect Certain spacing needed between different types of wires Debugging = orthogonal rectangle intersection search Sweep-line algorithm (similar to previous one) X-coordinates of left and right endpoints define events. Maintain set of rectangles that intersect the sweep line in an interval search tree (using y-intervals of rectangle). Left endpoint: interval search for y-interval of rectangle; insert y-interval. Right endpoint: remove y-interval. Bottom line: Sweep line reduces 2d orthogonal rectangle intersection search to 1d interval search. Summary Of Geometric Applications of BSTs Programming Assignment 5Problem: Programming Assignment 5 Code is on my Github page: Kdtree Missing the optional task of running time analysis because it’s optional. Week 6]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Network and Deep Learning, Course Notes]]></title>
    <url>%2F2019%2F03%2F08%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Neural Network and Deep Learning, Course Notes Goal: 理解驱动深度学习的主要技术趋势 能够搭建、训练并运用全连接的深层网络 了解如何实现高效的（向量化）神经网络 理解神经网络架构中的关键参数 课时2.1学习神经网络编程的基础知识 正向传播过程和反向传播过程forward, backward 二分类问题 计算机保存一张图片要用三个矩阵，分别表示三个通道 矩阵向量化：变成特征向量，如果是64*64的矩阵。则向量化后向量的维度是64*64*3 用m表示训练样本数 设计矩阵用列向量堆叠的方式会好很多： X.shape 标签的向量化矩阵是1*m的，其中m表示样本数。Y.shape = (1, m) 课时2.2logistic regression 给定x，希望计算出y的预测值 y = P(1|x) $$\hat{y} = w^{T}x+b$$ 由于y的值不在0-1之间，希望要把它进行概率归一化 需要使用sigmoid函数 $$\hat{y} = \sigma(w^{T}x+b)$$ $$\sigma(z)=\frac{1}{1+e^{-z}}$$ 如果z是很大的负数，则概率接近于0。如果z是很大的正数，则概率接近于1 预测函数里的b项是intercepter $$\theta$$是列向量，用$$\theta_{0}$$来表示常数项b。然后在样本项x中引入一个1即可 课时2.3loss funciton 和 cost function不一样 表示第i个样本的预测值$$\hat{y}^{(i)} = \sigma(w^{T}x^{(i)}+b)$$ $$\sigma(z)=\frac{1}{1+e^{-z}}$$ 用上标指明数据样本 在logistic中使用的损失函数loss function：$$L(\hat{y},y) = -(ylog\hat{y}+(1-y)log(1-\hat{y}))$$ 选修视频中会讲为什么这么选损失函数 cost function: $$J(w,b) = \frac{1}{m}\sum_{i=1}^{m}L(\hat{y,y})$$ loss funtion应用于单个训练样本，计算单个样本的损失程度 cost function是成本函数，计算整个训练集的总体损失 目标是找w，b，使得cost function尽量小 课时2.4梯度下降法 训练和学习w和b 凸函数可以更好地进行梯度下降 对logistic回归而言，几乎任何初始化值都是可行的 minimize J(w,b) 梯度下降的过程： $$w := w-\alpha\frac{dJ(w)}{dw}$$ $$\alpha$$表示学习速率。之后会讲如何选择learning rate 在表示上，用dw表示导数项 $$w := w - \alpha dw$$ 梯度表示切线斜率 后面的课讲导数和微积分 课时2.5讲导数 课时2.6讲导数 课时2.7Computation Graph计算图 前向传播用来计算神经网路的输出，反向传播用来计算出对应的梯度或导数 根据运算符优先级计算 课时2.8计算图的导数计算 链式法则计算导数的反向传播 chain rule 在编程的时候，就用dvar表示目标输出对于var的导数 分析梯度就是给变量一个微小增量，看目标输出变量的变化情况 课时2.9logistic回归中的梯度下降法 表示输出$$\hat{y} = a = \sigma(z)$$ $$z = w^{T}x+b$$ 步骤：w1,w2,x1,x2,b $$z = w_{1}x_{1}+w_{2}x_{2}+b$$ 计算输出 $$\hat{y} = a = \sigma(z)$$ 计算概率输出，也即计算激活函数值 $$L(a,y)$$ 计算损失函数 需要做的是修正w和b，从而减少损失函数L 课时2.10m个样本的梯度下降 $$a^{(i)}=\hat{y}^{(i)}=\sigma(z^{i})=\sigma(w^{T}x^{(i)}+b)$$ 累加器，全局成本函数cost function，然后对训练样本数做平均，计算完后，做全局更新 这节课还没讲向量化。向量化之后就会好很多。 后面的视频会讲向量化 课时2.11向量化 numpy：z = np.dot(w,x) 向量化版本比非向量化版本快很多 numpy可以自己执行并行化 课时2.12讲了logistic的向量化 recap了一下 对于正向传播，每个样本都需要计算激活函数值，sigmoid激活到0-1之间 课时2.13-2.14设计矩阵列堆叠，也是横向堆叠 一次性计算所有z： 构建一个1*m的矩阵 $$Z = np.dot(w.T,X)+b$$ numpy会将b自动广播为一个行向量 然后计算a：激活函数值 无论是正向传播还是反向传播，向量化都可以加速计算 $$dZ = A-Y$$ $$dw = \frac{1}{m}XdZ^{T}$$ $$db = \frac{1}{m}np.sum(dZ)$$ 迭代次数的for没有办法去掉 课时2.15axis表示竖向 课时2.16python numpy broadcasting tricks来排除问题，简化程序 建议不要用(5,)或(n,)这种秩为1的结构 用(5,1)，不要用(5,) 用assert(a.shape == (5,1))来保证不出错，检查矩阵维度 图片属于非结构化数据？ 神经元节点先计算线性函数再算激活函数 课时3.1神经网络概览 表示：用[1] [2]来表示神经网络的各个层 课时3.2神经网络的表示 输入层，隐藏层，输出层 $$a^{[0]}$$表示输入层的激活值 $$a^{[1]}{1} a^{[1]}{2}$$表示隐藏层的激活值 $$a^{[1]}$$是一个多维列向量 计算网络的层数的时候不管输入层 课时3.3计算神经网络的输出 recat表示方法：上标表示神经网路的层数，下标表示第几个神经元 向量化表示：把w的转置进行行堆叠，作为左乘矩阵，然后输入向量x是特征列堆叠，得到一个列向量，b向量也是一个列向量 把激活函数值也可以堆叠成列向量 $$z^{[1]} = W^{[1]}x+b^{[1]}$$ $$a^{[1]}=\sigma(z^{[2]}) $$ 课时3.4多个例子中的向量化（举例） $$a^{2}$$表示第二层神经元中的第一个样本激活值 数据输入X还是进行列向量堆叠，同样将Z，a都进行列向量堆叠 以A为例，由于是列堆叠，横向看表示不同的样本的激活值。纵向看是同一个样本在同一层中不同神经元上的激活值。纵向different hidden unions，横向different training examples。 课时3.5向量化的直观解释 多样本向量化的解释 把X(列堆叠成的输入向量)看成是$$A^{[0]}$$ 然后就可以完全向量化表示了 课时3.6使用不同的激活函数 之前一直用的是$$\sigma$$激活函数，但有时候其他的激活函数的效果会更好 $$z^{[1]}=W^{[1]}x+b^{[1]}$$ $$a^{[1]} = \sigma(z^{[1]})$$ tanh函数总是比sigmoid函数表现好，即双曲正弦函数 $$tanh(z) = \frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$$ 实际上tanh函数是sigmoid函数平移后的结果 tanh函数的一个好处是有数据中心化的效果 Ag说tanh函数几乎在任何场合下都比sigmoid函数表现优越 例外是在输出层，二分类问题中可能会在输出层用到sigmoid函数来进行激活 有时候在激活函数上面加上上标用来表示不同层的激活函数是不同的 sigmoid函数和tanh函数的共同缺点是梯度可能消失 另外一个比较受欢迎的激活函数是纠正线性单元：ReLU，Rectifier linear unit $$a = max(0,z)$$ 讲了选择激活函数的经验法则： 如果输出值时0或1，即如果做二元分类，那么sigmoid函数比较适合做输出层的激活函数，然后其他单元用ReLU做激活函数。这种组合也变成了现在默认的激活函数选择方案。ReLU有一个修正版本：leaky ReLU：当z为负数时，给予一个比较小的导数，而不是令导数为0。使用ReLU的一个好处也是训练神经网络速度会更快，主要原因是ReLU没有导数接近于0这种效应，所以学习速率不会被减慢 Ag在这节课严重批判了sigmoid函数 课时3.7讲了一下为什么总是要用非线性激活函数，这个问题机器学习课老师也讲了 因为非线性函数激活理论上可以用来拟合任意非线性可分问题 课时3.8激活函数的导数 backpropagation 导数的表示：$$g^{‘}(z)$$叫做g prime of z 课时3.9据说是激动人心的一个课时。。。 实现back propagation / gradient descent 表示： 参数： $$n^{[0]}, n^{[1]}, n^{[2]}$$ 分别表示输入量个数，隐藏单元个数，输出单元个数 损失函数cost function： $$J(W^{[1]},b^{[1]}, W^{[2]}, b^{[2]}) = \frac{1}{m}\sum{L(y,\hat{y})}$$ 训练参数就用梯度下降 在训练神经网络的时候，随机初始化参数很重要 Update: $$ W^{[1]} = W^{[2]} - \alpha dW^{[1]}$$ $$ b^{[1]} = b^{[2]} - \alpha db^{[1]}$$ 关于dW和db的含义，之前讲过的，就不重复了 正向传播：反正就是计算线性函数，计算激活值，然后从前面向后面逐层传递 反向传播：计算导数 然后np中keepdims = true这个参数的作用是防止numpy输出秩为1的矩阵：(n,)这种，而是命令它保持维度，输出(n,1)这样的 如果不调用keepdims参数，则要用reshape来调整维度 课时3.10(选修)看看反向传播的灵感来源 由流程图推导出梯度公式 这个视频中有一个等式写错了，当然可能是我钻牛角尖了才觉得它错了，在01:19 课时3.11如何初始化参数 随机初始化 全0初始化会导数symmetric的问题，无论训练时间多长，每个神经元的权重参数都是一样的，这样的话，多个隐藏神经元就没有啥用了 solution: $$W^{[1]} = np.random.randn(…)*0.01$$ b不会导致对称问题，所以是可以把b初始化成0的 将权重乘一个很小的系数是为了防止激活函数的参数绝对值比较大，而导致梯度平缓的问题，也叫做饱和 课时4.1看这一章的收获还是非常大的，对向量化的概念有了更加深入的理解 深度神经网络 目标是把学习的综合起来，build your own deep neural network 做一个编程大作业 logistic regression —- shallow model denotion: 用L表示层数 用$$n^{[i]}$$表示第i个层上的单元数量 $$a^{[l]} = g^{[l]}(z^{[l]})$$表示l层中的的激活函数 $$W^{[l]}$$表示 课时4.2深层网络中的前向传播和反向传播 前向传播公式： $$Z^{[n+1]}=W^{[n+1]}a^{[n]}+b^{[n+1]}$$ $$A^{[n+1]}=g^{[n+1]}(Z^{[n]})$$ 这边02:26的地方一个公式又写错了 Z是一层上单个样本的所有Z，然后所有样本竖向堆叠而成的 正向传播中用for loop没问题 防止程序bug的方法是想办法检查矩阵的维度 课时4.3核对矩阵的维数 是拿出一张纸，然后确保各个地方计算的矩阵维度没有问题 $$W^{[l]}$$的维度是$$(n^{[l]}, n^{[l-1]})$$ a和z的维度是相同的 聚合所有样本之后的向量化： $$Z^{[1]} = W^{[1]}X+b^{[1]}$$ 其中Z是所有小z的列堆叠，每个小z代表一个样本在一个层上所有输出的堆叠向量，W维度不变，而X变成了所有输入向量的列堆叠，b也随之广播成了列堆叠 和之前的比一下： $$z^{[l]}$$和$$a^{[l]}$$的维度原来都是$$(n^{[l]},1)$$ 后来变成了$$(n^{[l]},m)$$。是把所有样本进行列堆叠而成的结果 课时4.4为什么深度神经网络表现得比浅层神经网络好？ 深度网络的前几层学习低层次的特征，在后面几层，就会把简单的特征结合起来，去探测更加复杂的东西 deep learning: great brand 课时4.5搭建深度网络块 把过程中计算得到的a，z之类的缓存起来 课时4.6正向传播和反向传播的具体实现过程 课时4.7参数和超参数 超参数：比如学习速率和迭代次数、隐藏层数、隐藏单元数、激活函数]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Network, Course Notes]]></title>
    <url>%2F2019%2F03%2F08%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Convolutional Neural Network, Course Notes 课时1.1计算机视觉 分为两个任务： Image Classification和Object Detection 另外还有一个Neural Style Transfer 标准全连接网络连接所有输入和神经元 难以用数据的方式来解决过拟合的问题 课时1.2边缘检测实例 edge detection filter/kernel convolve，卷积核/过滤器 用*表示卷积运算，在原图上进行element wise product，结果求和 卷积后得到的图片可以理解为另一张图片 python conv_forward函数。tensorflow tf.nn.conv2d Keras Conv2d 后面讲了为什么卷积可以进行边缘检测 课时1.3进一步讲了边缘检测 区分正边和负边，亮到暗和暗到亮 不同的filter可以过滤出不同的边缘 有一些公认的filter：Sobel， Scharr filter里的数字也可以learn出来，当参数训练，甚至可以识别不同的角度的edges 课时1.4Padding 划重点 一个n*n的原图，用f*f的kernel做卷积，得到的结果是(n-f+1)*(n-f+1) 不做Padding原图会缩小，因为边缘上的像素点被触碰到的概率远小于中间像素点，可能会丢失边缘信息 解决方案是在做conv前做pad padding amout: p 让2p-f+1为0，这样conv后图像就不会缩小了 如果选择padding amount：对于Valid conv，不做padding；对于Same conv，padding到无损 在conv kernel中有一个central pixel会方便-&gt;选择奇数filter 课时1.5卷积步长 strided conv 带卷积步长时的输入输出维度关系： n*n输入，f*f filter，padding p，stride s。得到的输出维度将会是(n+2p-f)/s+1方阵，如果商不是整数，就向下取整，这么做是限制卷积核不会移到原图之外 cross -correction 和 conv：不同领域的不同叫法 课时1.6如何在3D图像上做卷积 在RGB图像上做卷积，假设输入是6*6*3，其中三个数字分别表示height, width和channel。卷积核也是height, width和channel，channel必须匹配 这节课讲的有点慢，一点点东西讲了一整节课 Multiple filters： 把最后得到的卷积图像叠加 维度总结：n*n*channels的输入图像，f*f*channels的kernel，得到的是(n-f+1)*(n-f+1)的图像，用多个kernel，这样输出结果的通道数可以表征需要检测的特征数 课时1.7单层卷积神经网络 在卷积层实际应用的时候，也是需要增加一个偏执项 Ng在这一节2:10左右又有一个地方讲错了 和之前神经网络相似，卷积层也是先做线性运算，然后做激活 卷积层的representation： convolutional layer $$f^{[l]}$$表示卷积核的大小filter size $$p^{[l]}$$表示padding $$s^{[l]}$$表示步幅stride $$n^{[l-1]}{H} * n^{[l-1]}{W} * n^{[l-1]}_{C}$$表示l-1层的高度维度，宽度维度，以及通道数，输出的通道数由filter数量来决定 别的公式就不打算写了，感觉Ng一直是在炒冷饭，一个representation讲了真TM久 在做batch或mini batch的时候把第一个维度改成number of samples，后面再和上面一样就行了 课时1.8卷积神经网络实例 深层卷积神经网络 在卷积最后输出进行flatten，平滑处理成一个列向量，然后再经过最后一层输出激活进行预测 设计神经网络的时候，设置参数比较麻烦 一个典型的深层卷积神经网络至少有三层，一个conv层，一个pool层，一个FC层(全连接) 课时1.9pooling layers max pooling，有超参数，但是没有要学习的参数 之前卷积计算维度的公式同样适用于最大池化 average pooling 目前来说，maxpooling比average pooling更加常用 很少把padding作为超参数 课时1.10卷积神经网络实例 在文献中有两类约定：一类是把一次conv和一次pool当做一个卷积层，另外=一类则是分别计算 就是讲了一下深层卷积神经网络的整体架构，卷积，池化，全连接这些 通常高度宽度维度会逐渐减小，而通道数会逐渐增加 还有种卷积神经网络的架构是若干的卷积层加上一个池化层 Ng说如何构建高效的网络需要看别人的文献，学习他们的做法 课时1.11为什么使用卷积 想象一下一张输入图片的size如果特别大，用传统方法的话需要训练的参数矩阵就会特别大，但是用卷积的话，参数只在卷积核里面，就很小了 卷积核参数少的原因是：参数共享，即在图片的不同区域可以使用相同的参数，如果图片的不同部分有相似特征，那么用相同的特征检测器(conv kernel)来提取特征效果就比较好。另一个原因是稀疏连接：输出矩阵中呃某一个元素与原始图片的一小部分稀疏连接，其他部分对这个输出没有影响。 卷积神经网络善于捕捉平移不变 最后又讲了如何在实际任务中构建卷积神经网络，这TM的不是已经在上一节课里讲过了么 通过本周课程学会了整个卷积神经网络的各个基本模块 下周会讲卷积神经网路的实例，用来学习人家是怎么设置超参数和构建网络的 课时2.1一些神经网络的实例探究 LeNet-5 AlexNet VGG ResNet：残差网络，Residual Network Inception Network 课时2.2经典神经网络架构：LeNet-5, AlexNet, VGGNet LeNet-5: 识别手写数字。在那个年代，还没有padding和softmax，所以算是比较古老的一个神经网络模型。用的sigmoid激活和tanh，还没有用ReLU。这个网络比较神奇的一点是在做pooling之后还做了非线性激活 AlexNet: 用RGB图片做输入，与LeNet网络结构相似，但是AlexNet大很多，另外就是AlexNet用了ReLU作为激活函数，还有个另外的层：Local Response Normalization Layer。现在应用不多。而且研究者也发现这个层没啥用。 VGG-16: 简化了网络结构，名字里的16指示这个网络包含16个卷积层和全连接层 课时2.3残差网络 ResNets 深度神经网络是比较难训练的，因为有梯度爆炸和梯度消失的问题 这节课讲Skip Connection，通过某一层获取激活，然后马上反馈给另外一层 用跳远链接Skip Connection来训练ResNet，有时深度超度100 ResNet由残差块组成，Residual Block 残差网络的short cut 插入的残差块应该是某一层的激活值，插入到另一层的线性输出之后，激活之前 Plain Network加上Skip Connection就可以变成Residual Network 每个Skip Connection会创建一个Residual Block 对于Plain Network而言，实际上网络层数越多，训练准确率先下降后上升，与理论有差距。但是对ResNet而言，网络越深，训练准确率就越低 课时2.4为什么ResNet表现这么好？ $$a^{[l+2]} = g(z^{[l+2]}+a^{[l]})$$ 残差跳远连接的好处是如果中间的神经元失活了，通过残差仍然可以将前层的激活值传递下去 残差快学习恒等式是很容易的 有一个key point是残差跳远连接的输入维度应该保持一致，这也成为限制卷积层构造的原因之一。如果维度不一致，那么在构造残差块的时候还需要再引入一个矩阵 课时2.51*1的卷积层 网络中的网络 1*1的卷积网络在深度channel输入上有用：比如1*1*32的filter对原输入上同一个位置但不同通道的数据进行element wise product，这样的一个卷积层可以理解为一次全连接 举个例子讲，如何把一个28*28*192的输入shrink成一个28*28*32的输出？ 可以用32个filter，每个filter都是1*1*192的，相当于每个filter在原输入上做全连接，然后把所有的filter进行堆叠，就得到了32个通道的输出了。理解1*1卷积只是增加了非线性函数激活，允许网络学习更复杂的特征 课时2.6Inception Network 代替人工来决定是否要加某些层 用1*1卷积核可以减小计算成本 使用1*1卷积核的策略是把原来的输入先压缩，完成压缩操作的层叫做bottleneck layer 大幅缩小数据规模是否会影响网络的性能？如果bottlenect layer选择合适就不会出现这个问题 课时2.7完整的Inception Network的结构 把输入经过各个层处理，然后最后做Channel Concat进行堆叠 GoogLeNet Inception名字来源于盗梦空间和小李子。。。 课时2.8使用开源代码 通过阅读他人论文来复现是非常非常难的 这节课就教了一下怎么用Google找到开源代码和下载 课时2.9迁移学习Transfer Learning 在别人训练好的网络权重的基础上再进行训练，这样效率会高很多 计算机视觉数据集：ImageNet，MS COCO，Pascal Transfer选择把输出层的激活改成自己的激活函数，冻结网络层的前层参数 另一个加速训练的策略是把固定的前层封装成一个函数，将输入映射到固定层的最后一层，然后保存起来，这样就不用每次都计算固定的值了 计算机视觉是经常用到transfer learning的一个领域 课时2.10数据扩充，数据增强，data augmentation 对计算机视觉领域而言，最大的一个问题就是缺少训练数据 数据增强的常用方法有：垂直镜像对称，随机裁剪，旋转rotation，剪切shearing，色彩转换color shifting(在通道上加减值)，实际应用中颜色转换是根据某种概率分布来做的 对RGB有不同的采样方式，一种是PCA主成分分析，PCA颜色增强。在AlexNet论文里有实现PCA的方法 实现数据增强：用一个CPU线程或多个CPU线程加载数据和实现distortion，然后传递给其他线程 课时2.11计算机视觉研究现状 如果没有足够多的数据就要做hand-engineering 另一种解决数据量小的问题的技术是Transfer Learing，也就是上一节课里讲到的 后面讲了实际工业领域的几个tricks 课时3.1Object localization目标定位 先有图像分类，然后有classification with localization，再有detection Classification：bounding box，红框中心点(bx, by), bh, bw，训练集还需要上面的数据 输出标签包含多种信息：是否属于要检测的目标，输出要检测目标的bx, by, bh, bw, c1, c2, c3，表示输出哪一类，这个的话输出层就不只是一个神经元了，不同的神经元可以用不同的激活函数，计算不同的损失 课时3.2landmark detection 特征点检测 比如要检测眼角，可以在输出层加两个entry，来表征眼角信息 检测关键点也是计算机图形模块的一个重要部分，比如脸部扭曲等 课时3.3Object detection 对象检测 示例是基于滑动窗口的目标检测算法，sliding windows detection 滑动窗口算法缺点是计算cost，与stride有关系，又是一个trade off 这个想法好天真啊，我也是醉了，难道这就是目标检测吗 课时3.4卷积的滑动窗口实现 把FC层转成Conv层，想法也比较简单，就是用很多个filters去conv就行了 讲义内容借鉴了OverFeat论文 可以发现滑动窗口中有很多计算是重复的 trick就是在跑conv的时候实际不是把裁剪下来的输入，而是把整个都输入，然后分部分标记。在整张输入图片上做卷积，然后对输出进行滑动裁剪就行了 这个卷积滑动窗口的缺点是可能bounding box不太准确 课时3.5 Bounding Box预测 YOLO算法的思想大概是把输入图像分割成一个个的grid，然后再每个grid跑图像识别的算法，判断一个物体是否属于这个格子，看的是这个物体的中心点是否在这个格子里面，实际用的时候会用19*19\这样的精细划分 如何编码边界坐标？ 课时3.6抑制交并比intersection over union IoU交并比函数是个评价函数，计算交集和并集之比，一般约定，如果IoU大于0.5，那么预测正确，当然阈值是可以人为设定的 课时3.7非最大值抑制 Non-max suppression 可以确保每个对象只识别一次 先丢弃所有低概率边框预测结果 然后跑一个while，每次选出最高概率的box预测，丢弃所有和这个box有高IoU值的预测结果 课时3.8Anchor box 让一个格子检测出多个对象 思想是预先定义几个不同shape的Anchor boxes 输出y的值由这几个Anchor boxes分别的预测结果堆叠 课时3.9YOLO network 把之前几节课讲的综合起来放到一个网络来实现 课时3.10RPN网络，区域生成网络 R-CNN：区域卷积网络，在少数窗口上跑CNN来做预测，找窗口的方法是用图像分割的技巧，segmentation，R-CNN的问题是太慢了，F-R-CNN是用卷积实现滑动窗口，也就是在之前的情况下做了一点点优化，还是不如YOLO，just for fun 课时4.1什么是人脸识别 face recognition 百度Andrew Ng，林元庆哈哈哈哈 人脸识别和活体检测配合使用 face verification是验证是否匹配，是一对一的问题，face recognition是一对多的问题，比验证问题难很多 课时4.2One-shot learning problem: 只有一个训练样例 学习一个似然函数Similarity function，一个差异函数d，拿到两张图片后用这个差异函数去比对输入 课时4.3Siamese network 是一个编码网络，当两张图片是同一个人的时候，编码相似度要很大，对应的范数小 课时4.4triplet loss function 引入一个margin防止恒等于0的输出，margin parameter：拉大了正样本和负样本之间的距离 引入损失函数为范数差的形式 将训练样本以三元组的形式进行分组，需要有同一个人的很多图片 选择训练样本的原则是使两个范数尽可能相似，这样的数据才有训练意义(学难学的东西才能有成长) 课时4.5面部验证和二分类 想法比较简单，感觉这节课就没啥东西 课时4.6神经风格迁移(编程作业里面) neural style transfer C表示图像内容，S表示图像风格，G表示生成的图像 课时4.7深度神经网络到底在学什么 找到最大化激活隐藏单元的图片块 课时4.8代价函数 评价函数用于评价生成的图像的好坏 代价函数可以分为内容代价和风格代价 内容代价用来度量生成图像的内容和原来图像的内容有多相似，风格同理 提出神经风格迁移的作者提出用两个超参数 在做梯度下降的时候更新的实际上是图像的像素值 随机初始化的图像时白噪声图像 课时4.9内容代价函数 content cost component 课时4.10风格损失函数style cost function 把图像的style定义为不同通道之间的互相关系 什么时候两个通道之间有高度互相关性呢？correlation，不同块之间的激活特征高度重合，那么是高度correlated，否则不然 style matrix风格矩阵 Frobenius范数 课时4.11一维和三维的卷积 心电图处理的是一维数据，时间序列 一维的卷积思想比较简单 CT：3D数据块 3D volume，3D filter 完结了]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Neural Networks, Course Notes]]></title>
    <url>%2F2019%2F03%2F08%2F%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Princeton Algorithm course on coursera. Part 1 超参数调试、正则化及优化 课时1.1训练/开发/测试集 内容涉及hyperparameter tuning, set up date decisions: layers hidden units learning rates activation functions go round the cycle many times 总的数据分为几个部分，一部分是训练数据，一部分是简单的交叉验证集，这部分有时候也被称为development set(dev set)，最后一部分作为测试集 通过训练数据训练模型，通过验证集验证模型的效果，然后最后再测试集上进行评估 验证集的目的是验证哪种算法有效 在大数据时代，验证集和测试集不需要那么多数据，比如100万条数据，可能只需要1万条用来验证，1万条用来测试就可以了 建议保证验证集和测试集的数据来自于同一分布，因为训练模型需要很大的数据量，可能的结果就是训练集和测试/验证集不是来源于同一数据分布。这条是经验法则 有时候没有测试集，只有训练集和验证集，这样的话训练集还是训练集，但是验证集有时候就被称为测试集了 课时1.2偏差、方差 bias and variance trade-off 方差高：过拟合 偏差高：欠拟合 train set error dev set error 数据在训练样本上表现好，在验证集上表现得很差：高方差 数据在训练集上表现差，在验证集上表现差：高偏差 数据在训练集上表现差，在验证集上表现特别差：高方差且高偏差 高偏差直观表现在没有比较好地拟合数据，高方差表现在局部拟合效果太好，表现太灵活 课时1.3机器学习基础 basic recipe for machine learning 评估的步骤： 看看模型的是否高偏差，如果高偏差，就要试着评估一下模型在训练集上的表现。解决方法是用新的网络，用更深层的网络，训练更长的时间 偏差降低到一定程度后，再检查方差有没有问题，就要查看验证集性能。如果方差高，解决方法是：获取更多的数据，正则化 一直试一直试，知道找到一个低偏差和低方差的模型框架framework 现在有工具和方法来只降低bias和variance的一方，而不会显著影响另一方，这也是深度学习现在能流行的重要原因之一 课时1.4正则化Regularization 解决高方差(过度拟合)的问题 正则化的方法是在cost function里面加上一个正则项 L2正则化：$$\frac{\lambda}{2m}||w||_{2}^{2}$$，欧几里得二范数 为什么不加b？因为W一般是高维的矩阵，加上他的正则项之后一般已经可以解决过拟合的问题了，就不需要加b了 L2正则化也是最常见的正则化方式 如果用L1正则化，W会是稀疏的 $$\lambda$$称为正则化参数 通常用验证集(交叉验证)来选择这个参数。python中lambda是保留字，用lambd即可 深度神经网络中的正则项是所有层正则项之和 矩阵(非向量)的2范数称为Frobenium Norm，下标用F，而不用2，区别于2范数。鉴于大家不可的原因，才有了这个规定。。。。 正则项的引入会到dW的计算带上一个正则项导数，然后用新的dW来进行反向传播和权值更新 引入正则项会引起权值递减(weight decay)。所以有时候L2正则化也被称为weight decay 课时1.5为什么正则项可以防止过拟合 添加正则项有助于防止权值矩阵的权重过大 说实话关于正则化的解释我没有怎么看懂，这部分还需查询其他相关资料以及看看知乎才行 课时1.6Dropout 有多种实现Dropout的方法： Inverted dropout：反向随机失活 对于l=3，设置d3 = np.random.rand(a3.shape[0],a3.shape[1])&lt;keep_prop 最后那个项表示保留某个神经元的概率，这个最后返回一个boolean矩阵 然后a3 = np.multiply(a3,d3)就可以过滤掉那些false的神经元 最后a3 /= keep_prop，是为了保证再计算z4的时候其期望值不变，这部分视频里没有解释得比较清楚 反向随机失活也是现在深度学习领域最常用的dropout方法 在测试阶段的话，就不要用dropout了，然后一个trick是在a/=keep_drop这一步cache住dropout之前的值，这样在测试的时候就不用浪费时间再去多算一遍了，是用空间换时间 课时1.7理解dropout intuition 从之前的经验来理解的话dropout可以减小神经网络复杂度，从而减小过拟合的可能性。从另一个角度来看，即从单个神经元的角度来看，dropout减少了单个神经元的输入特征，这意味了这个神经元不能依赖于某个特定的特征，因为它们都可能被随机清除 dropout的效果类似于L2正则化 强调一下不同层的keep_prop设定可以不同，如果是参数密集的层，keep_prop可以设得相对小一点。0.5/0.7。如果某一层不用担心过拟合的问题，可以设置keep_prop为1 通常输入层不去做dropout。另外的话一个原则是如果算法不会出现过拟合，就不要用dropout。在CV中会经常用到dropout，但是在其他领域使用相对较少 使用dropout带来的后果是cost function不再有显式定义，所以很难double check，这样我们就失去了调试工具，所以Ag给出的一个经验是在调试back propagation看梯度下降的时候先关闭dropout，然后等调试好了再开启dropout 课时1.8其他正则化方法 这就涉及图像处理之类的知识了，比如图片的翻转，随机裁剪 数据扩增可以作为正则化手段之一 另一种方法叫做early stopping 因为训练集误差通过 梯度下降可以一直递减，但是验证集误差可能是先递减后递增，early stopping选择在某个迭代次数之后停止 Orthogonalization正交化：独立处理cost function优化的问题和减小过拟合的问题 early stopping也存在缺点：会变成一个trade-off问题，因为模型在训练集上训练的效果可能不佳 不同人会用不同的dropout方法，Ag说他喜欢用L2正则化，后果是计算量会很大 课时1.9归一化输入，可以有效加快训练速度。normalize input 归一化输入有两步： 零均值化(移动训练数据，直到零均值化) 归一化方差，也就是做一次scaling 为什么要归一化输入特征：归一化函数可以让cost function看起来更加匀称，然后可能学习速率就更容易选择，归一化之前可能学习速率要很小才行 如果输入特征的scale不太一致，归一化就比较有用，如果是相似的scale，那么归一化可能也没啥用，但是也没啥坏处 课时1.10梯度消失和梯度爆炸 vanishing/exploding gradients 这个主要是深层神经网络会遇到的问题 这两个问题可以通过合适的随机权重初始化来解决 课时1.11深层神经网络权重初始化 vanishing and exploding gradients 直接理解：输入特征越多的话，希望W的scale小一点，因为z是累加值 合适的做法是： $$W^{[l]}=np.random.randn(shape)*np.sqrt(\frac{1}{n^{[l-1]}})$$ 这边有个引用方差的问题，Ag说Relu激活可以选的引用方差源是$$\frac{2}{n}$$ 不过这个貌似是经验法则了，我目前任然不太理解，或许这个也是一个超参数吧 后面讲了如何选择这些引用方差是有相关paper证明的，就总结一下： relu: $$np.sqrt(\frac{2}{n})$$。最常用 tanh: $$np.sqrt(\frac{1}{n})$$。被称为Xavier初始化 方差参数是一个另外需要tune的hyperparameter。不过这个超参数的调优的优先级比较低，因为常常效果不明显 课时1.12梯度的数值逼近 是为了做梯度检验 在做梯度检验的时候，多用双边误差而少用单边误差 课时1.13梯度检验 帮助发现反向传播中存在的bug gradient checking -&gt; grad check 做梯度检验就是做一个loop，然后对每个d的element做双边误差检验 check：计算欧式距离，然后用向量长度做归一化 -&gt; into ratio 给出一个标准：一般10^-7量级是没啥问题的；如果是10^-5就要稍微小心了；10^-3量级，那基本就是有bug了 Ag说梯度检验帮他发现了很多bug 课时1.14关于梯度检验的实操技巧 不要在训练的时候用梯度检验，只有在debug的时候需要进行梯度检验，检验完成后就可以关闭梯度检验了 如果梯度检验出错，那么要检查所有项 在做梯度检验的时候记住还有正则项，因为正则项也会带来梯度 梯度检验不能和dropout一起用，这一点在dropout的时候已经说过了，dropout和梯度有点不太兼容，所以一般都是先做好bg，做好gc，然后再去做dropout 课时2.1优化算法 mini-batch 每个batch的X用$$X^1$$表示 epoch: 一代 课时2.2batch gradient descent的具体实现 SGD：每次一个样本 batch gradient descent：一次全部样本 分别是mini-batch的两个极端情况 在mini batch的时候一个epoch是整个数据集，即所有batch都进行过一遍梯度下降，称为一代 课时2.3指数加权平均，快于梯度下降 exponentially weighted averages 统计学中也叫指数移动加权平均 $$V_{t}=\beta V_{t-1}+(1-\beta)\theta_{t}$$ 其中$$\beta$$为加权参数，$$\beta$$很大的时候可以看到曲线很平滑，因为平滑的天数很多，很小的时候噪声很大，起伏很大，能更好地拟合数据，但是缺乏泛化能力 通常$$\beta$$取某个中间值会更好 课时2.4指数加权平均的本质 从计算和内存的角度讲，指数加权平均是一个非常高效的算法 课时2.5指数加权平均中的偏差修正 目的是让平均数计算更精确 需要进行偏差修正的原因是初始化会被放小很多 在预测初期，指数加权平均很难预测正确 修正策略是用$$\frac{V_{t}}{1-\beta^{t}}$$来修正 偏差修正能让模型在早期的时候表现更出色 课时2.6动量梯度下降 momentum 出现这个方法的原因是传统梯度下降会有摆动，从而限制了学习速率不能太快 区别在于权值更新的时候用动量值去更新，动量的计算就是根据指数加权平均来算 在动量梯度下降里，常用的$$\beta$$是0.9，也就是平均了过去十天的迭代梯度 在这个方法里，偏差修正不常用，因为迭代十次之后可以认为是度过了迭代初期 现在有两种动量梯度下降的公式，其中一种要注意scale，一种则不需要，因为是线性加权(指数加权平均) 课时2.7RMSprop root mean square prop 这个和动量梯度下降相似，都是在全值更新策略那一步做了修改 目的同样是减小无关方向上的摆动 这个方向主要是利用微分，而上个方法主要是利用指数加权平均，这样就比较好理解了 均方根 在保证数值稳定的时候会在分母的地方加上一个小项，防止出现爆炸的值 课时2.8Adam优化算法，结合Momentum和RMSprop 实现：初始化方均根项和动量项都为0 可以使用偏差修正 这是一种非常常用的优化算法，被证明了泛化能力强，能适用于不同的神经网络 超参数：学习速率，$$\beta_{1} = 0.9, \beta_{2} = 0.999, \epsilon = 10e(-8)$$ 课时2.9learning rate decay 学习率衰减 decay rate是另一个需要tune的超参数 衰减公式有多种选择 课时2.10局部最优问题 local optima 成本函数的零梯度点是鞍点 problem of plateaus 课时3.1调试处理 调试优先级 随机取点而不要用grid 由粗到细的策略 课时3.2选择合适的scale 线性指标和对数指标 学习速率用对数指标来采样 $$\beta$$是另一个比较麻烦的超参数，表示指数加权参数 也不能用线性取值，考虑$$1-\beta$$ 在某些区域取值需要密集，有些区域取值要松散 课时3.3超参数训练实践 每间隔几个月要重新调一次超参数 两种基本策略：一种是babysit一个module，另一种是训练多个模型 由拥有的计算资源决定，如果有多个网络 课时3.4normalization 归一化 batch normalization 数据归一化normalization的作用是把狭长的数据变成圆的东西 归一化是用均值和方差来进行归一化 对于深层神经网络，问题在于是否能归一化中间的激活值，从而使后面的权重系统矩阵训练得更快 上面的是batch normalization 对隐藏层的z计算均值和方差，然后做归一化就行了，归一化成0均值和1方差 我们所指的normalization指的是输入数据的归一化，batch normalization指的是对所有层的z进行归一化 但是隐藏单元可能不希望归一化成0均值和1方差，这个可以自由设定 课时3.5应用batch normalization 每个神经元上对应着两步：计算z和计算a 实际上framework会帮我们做好batch normalization而不需要手动去实现 $$\beta和\gamma$$是用来进行均值和方差缩放的系数 在batch normalization中，因为要处理均值和缩放，所以在计算线性函数的时候偏执项基本没用，因为BN的时候会把偏差均衡掉，bias的作用由$$\gamma$$来体现 带BN的反向传播部需要计算db，原因之前已经讲过了 课时3.6BN为什么能加速训练模型训练 这个问题的直观理解是tranfer上的问题，在一类集上如果分类表现得很好，在另一类集上可能就表现得不那么好，解决的方法是进行BN，在同样的scale上处理这个问题，改变数据分布，叫做covariate shift 中间隐藏值的分布可能会出现变化，BN的作用就是减小这部分的变化，使得后面的权重矩阵鲁棒性更强，因为BN说不管你前面的数据分布怎么变化，我可以让这一层的均值和方差保持不变，它限制了前层参数更新对后层的影响 BN和dropout的相似之处在于在每个层的神经元上增加了噪音 BN有轻微正则化的效果 课时3.7测试时的BN 注意一个样本的均值是对样本中的所有数据而言的，但是很多个batch的均值就是用到指数加权平均了，当然这只是建议做法，估算均值完全是怎么想怎么做 课时3.8Softmax回归 之前是二分分类 binary classification 多分类的概率问题 多个输出单元，显示各个类的概率 Softmax分类在没有隐藏层的情况下能够给出线性分类边界区分各个类 带隐藏层和激活函数可以有非线性决策边界 课时3.9深入学习Softmax分类 hardmax Softmax把概率映射变得更加温和 如果C=2，那么Softmax就变成了logistic regression 怎么训练Softmax的神经网络： Softmax的损失函数 最大似然估计 课时3.10深度学习框架 使用一些框架可以提高效率 课时3.11Tensorflow 123456789101112131415161718import numpy as npimport tensorflow as tfcoefficients = np.array([[1.],[-10.],[25.]])w = tf.Variable(0,dtype=tf.float32)x = tf.placeholder(tf.float32, [3,1])# cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)cost = x[0][0]*w**2+x[1][0]*w+x[2][0]tf = tf.train.GradientDescentOptimizer(0.01).minimize(cost)init = tf.global_initilizer()session = tf.Sessions()session.run(init)print(session.run(w))session.run(train, feed_dict=[x:coefficients]) #one iterationprint(session.run(w)) tensorflow重载了运算符，写公式可以更简单一点 placeholder是一个之后要赋值的变量，这种方式便于把数据加入cost function 创建session，session初始化和session.run是常用表达 常用with语句来写这三条常用表达 第二个课到此完结了！]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Operating System Lab]]></title>
    <url>%2F2019%2F03%2F08%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E5%AE%9E%E9%AA%8C%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Operating System Lab Notes 同步互斥和Linux内核模块涉及知识点：系统调用，pthread线程库，共享变量，原子操作，进程和线程，同步与互斥，多线程，内核模块 内核模块是在内核空间运行的，而应用程序运行在用户空间，内核空间和用户空间是操作系统重要的两个概念 内核符号表：存放所有模块可以访问的那些符号以及相应地址的特殊的表，模块的连接就是将模块插入内核的过程，模块声明的任何全局符号都成为内核符号表的一部分。内核符号表根据系统符号表从内核空间中获取符号的地址，可以从/proc/kallsytms中以文本方式读取，数据格式为： 内存地址 属性 符号名称 所属模块 模块依赖 ksyms命令可以显示内核和模块符号表的信息，可以读/proc/kallsyms文件 Linux为了便于管理管理，用task_struct结构来表示一个进程，每个进程都有自己独立的task_struct。包含这个进程的所有资源。 task_struct与内核栈： task_struct和内核栈放在同一个4K空间中 状态转换： volatile long state long exit_state 前者表示进程的可运行性，后者表示进程退出时的状态 kernel thread： 用内核模块编程创建一个kernel thread，这个内核线程定时统计当前系统中进程的状态，然后通过printk打印出来 系统调用系统调用是内核提供的，功能强大的一系列函数。他们在内核中实现，并通过一定的方式呈现给用户，是用户和内核交互的一个接口 user mode和kernel mode，处于user mode的用户态程序只有通过中断门gate陷入trap到系统内核中去，才能执行一些具有特权的内核函数 Intel CPU提供了实模式、保护模式，这是硬件层面上的概念，实模式只能进行20位寻址，只能访问1M内存空间，电脑刚启动的时候就是处于这种模式，所以才需要什么grub引导，另一种模式是保护模式，保护模式又分为4个特权态，其中我们所说的软件层面的用户态和内核态就是其中的两个特权态，内核态和用户态分别适用自己的堆栈。模式切换一般应该指的是用户态和内核态的切换。 虚存机制的存在提供了进程隔离和地址映射，每个进程的虚拟地址空间又可以分为用户空间和内核空间，在用户态下只能访问用户空间，在内核态下既能访问用户空间又能访问内核空间。因为只有一个运行的内核，所有进程的内核空间都映射到单一内核地址空间，在内核态下，进程可以访问到其他进程的地址空间 上下文就是一个环境，对进程而言，就是各个变量和数据、所有的寄存器变量、进程打开的文件、内存信息等，上下文可以分为： 用户级上下文：正文、数据、用户栈以及共享存储区 寄存器上下文：通用寄存器、程序寄存器IP、状态寄存器、栈指针 系统级上下文：进程控制块task_struct、内存管理信息、内核栈等 模式切换相比于进程切换要容易和省时得多 段页机制：两级地址转换，段地址偏移地址，逻辑地址、线性地址和物理地址，普通应用程序面对的只是逻辑地址，其他地址转换全由操作系统和硬件接管 逻辑地址转换为线性地址：选择子选择描述符，描述符描述了一个特定的段，然后再在此段基址上加上偏移量换算成32位线性地址 线性地址转换为物理地址：在分页机制中完成，i386机器采用两级分页，它在物理地址上的页帧和线性地址上的页面建立一一映射，线性地址被分为三部分：前两部分每部分10位分别作为页目录和页表的索引，最后一个部分12位寻址4K空间作为一个页帧内的索引。 系统调用表保存着所有系统调用的函数指针，以便进行索引调用 系统调用是一类特殊的中断，属于软中断，系统调用对应着中断向量表中的一项，也就是说中断的概念还要牛逼 一刷原理部分没有看懂，后面的实践模块也就没有进行下去，需要再去学些东西才行，汇编源码那部分有点难理解，关于堆栈切换，寄存器那块 进程创建进程、线程原理+三个实验 操作系统通过进程调度来调度每个进程，并且通过虚拟内存机制来保护每个进程自己独立的内存地址空间，这样一个进程崩溃就不会对其他进程产生影响 linux内核用task_struct来描述进程 task_struct有越来越臃肿的趋势，一方面，进程必须知道/控制它所拥有的所有系统资源；另一方面，内核越来越复杂，进程相关的信息也越来越多 早期linux内核把内核栈和task_struct放在同一个4K页面里，这样的话，当程序在内核态下，就可以通过栈指针获取当前进程的task_struct，进程管理方便，但是可能4K页面容不下整个内核栈以及task_struct。后面的内核试图增大这部分空间，把这部分空间从4K增加到8K，也就是从原来的一个页面增加到了两个页面，以及把原本task_struct的位置替换为thread_info，而把指向task_struct的指针存放到这个thread_info里面 进程状态转化：volatile long state以及long exit_state，分别表示进程的可运行性以及进程退出时候的状态，linux为其定义了一系列的宏： TASK_RUNNING: 正占用CPU的进程或在RUNNING队列中的进程，只有处于该状态的进程才能参与实际调度 TASK_INTERRUPTIBLE: 处于等待资源状态的进程，允许被中断 TASK_UNINTERRUPTIBLE: 处于等待资源状态的进程，不允许被中断 TASK_STOPPED: 进程被暂停，收到某些信号后会进入该状态 TASK_TRACED: 进程被跟踪，调试的时候 TASK_ZOMBIE: 正在终止的进程，是进程结束运行前的一个过渡状态，此时已经释放了内存、文件等资源，但是在内核中仍然保留一些这个进程的数据结构(比如task_struct)等待父进程回收 EXIT_DEAD: 进程消亡前的最后一个状态 TASK_NONINTERACTIVE: 表示是非交互式进程 进程标志位：和状态位不同，标志位是为了对每个进程运行进行更细粒度的控制，即一些flags 进程调度：task_struct里面定义了几种调度策略的宏，调度器根据每个进程的调度策略给予不同的优先级，进程有着动态的调度优先级 进程权限，ID这部分讲了一些特殊标志位的问题 进程与虚拟存储、进程的地址空间、内存分布：分页式内存管理，MMU内存管理单元完成从虚拟地址到物理地址的映射，linux系统和i386体系结构下，每个进程都有固定的4G虚拟地址空间。MMU和进程页表机制能够把虚拟地址转换为物理地址进行访问，如果虚拟地址和物理地址没有建立映射，就会触发缺页中断，然后操作系统会试图去建立一个映射，对进程来说，整个地址转换的过程都是透明的。虚拟地址的优点： 每次进程被装载入内存的地址可能是不同的，对程序员而言，根本不需要关心这个 每个进程有独自的地址空间，通过地址转换机制，可以有效地实现地址隔离和共享 task_struct可以链接到很多属于该进程的资源，比如mm_struct, fs_struct, files_struct等，分别管理进程内存、进程使用的文件系统、进程操作的所有文件 进程产生： 讲了fork, clone以及内核线程、exec系统调用、exit系统调用等 /proc文件系统/proc文件系统是一个虚拟文件系统，只存在于内存中，而不占用外存空间，从内核动态读取系统信息，主要有两个用途： 只读文件，用于读取系统信息 可写文件，用于向内核传递参数用strings或cat可以访问/proc里面的相关文件 /proc下很多以10进制为标题的目录，他们记录的是系统中正在运行的每个用户级进程的信息，数字表示进程号pid，/proc/self是当前进程目录的符号链接，这个目录下存放很多进程相关文件，比如/proc/self/status存放PCB信息 /proc/sys目录是一个特殊的目录，它支持直接使用文件系统的写操作，向内核传递参数 在内核编程/调试中，经常需要内核释放出一些状态信息给应用层 在/proc文件系统中创建文件：123#include &lt;linux/proc_fs.h&gt;struct proc_dir_entry* create_proc_entry(const char* name, mode_t mode, struct proc_dir_entry* parent); 参数说明： name: 要创建的文件名，可以包含多级目录 mode: 要创建的文件的属性 parent: 这个文件的父目录 如果只需创建一个只读文件，可以用下面这个更方便的函数:123456struct proc_dir_entry* create_proc_read_entry(const char* name, mode_t mode, struct proc_dir_entry* parent, read_proc_t* read_proc, void* data); 参数说明： name: 要创建的文件名 mode: 要创建的文件属性 parent: 这个文件的父目录 read_proc: 当用户读这个proc文件的时候，内核调用的函数 这个函数和前面的区别是在调用之后会给文件挂接上read_proc函数，而前面的函数没有挂接，要手动挂接读写函数 创建符号链接：1234struct proc_dir_entry* proc_symlink(const char* name, struct proc_dir_entry* parent, const char* dest); 参数说明： name: 要创建的文件名 parent: 这个文件的父目录 dest: 符号链接的目标文件 可以把这个函数理解为ln -s dest parent/name 创建目录：123struct proc_dir_entry* proc_mkdir(const char* name, struct proc_dir_entry* parent); 参数说明： name: 要创建的文件名 parent: 这个目录的父目录 删除文件或目录123void remove_proc_entry(const char* name, struct proc_dir_entry* parent); 参数说明： name: 要删除的文件或目录名 parent: 所在的父目录 需要注意的是该函数不会递归删除目录，然后内存需要手动释放 读写回调： 1234struct proc_dir_entry* entry;entry-&gt;read_proc = read_proc_foo;entry-&gt;write_proc = write_proc_foo; 实现读写函数的原型并注册回调即可，具体细节见本章第一个实验 后面的一些比如用seq_file编程接口、/proc文件系统的操作实验等感觉都比较高阶了，以后再来细学，现在是把基础的部分学完了 内核模块内核模块操作工具：lsmod,insmod,rmmod 模块是在内核空间上运行的程序，实际上是一种目标对象文件，没有链接，不能独立运行，但是其代码可以在运行时链接到系统中作为内核的一部分运行或从内核中取下，从而可以动态扩充内核的功能。模块机制的完整叫法是动态可加载内核模块(Loadable Kernel Module)或LKM。 内核模块的优点： 使得内核更加紧凑和灵活 修改内核时，不必全部重新编译整个内核，可节省不少时间，避免人工操作的错误。系统中如果需要使用新模块，只要编译响应模块然后使用特定用户空间的程序将模块装入即可 模块可以不依赖于某个固定的硬件平台 模块的目标代码一旦被链接到内核，它的作用和静态链接的内核目标代码完全等价 内核模块带来的问题： 由于内核所占用的内存是不会被换出的，所以链接进内核的模块会给整个系统带来一定的性能和内存利用方面的损失 装入内核的模块就称为了内核的一部分，可以修改内核中的其他部分，因此模块的使用不当会导致系统崩溃 为了让内核模块能访问所有内核资源，内核必须维护符号表，并在装入和卸载模块时修改符号表 模块会要求利用其他模块的功能，所以，内核要维护模块之间的依赖性 模块和内核处于同类的地址空间，所以模块编程和内核编程其实是等同的 在实现模块程序的时候有几个注意点： #define MODULE 声明是一个模块 int init_module(void) 向内核模块注册模块所提供的功能，内核符号表 void cleanup_module(void) 注销所有由模块提供的功能 内核模块和应用程序的比价： 为了保护内核不受应用程序干扰，多用户操作系统都实现了对硬件资源的授权访问，这种授权访问机制得益于CPU内部实现不同的操作保护级别，linux使用了两级保护级别 内核符号表： 是公开的，可以通过/proc/kallsyms以文本方式读取，格式为： 内存地址 属性 符号名称 所属模块 内核符号表处于内核代码段的_ksymtab部分，其开始地址和结束地址是c编译器所产生的两个符号来指定：startksymtab和stopksymtab 内核符号表的存在也引出了模块依赖的问题 跟模块有关的数据结构存放在include/linux/module.h里面，每个模块信息都由一个模块对象描述，所有module对象由一个链表链接在一起，kernel/module.c里有模块相关系统调用的实现 insmod所做的事： 从命令行参数读入要链接的模块名，通常是扩展名为.ko，elf格式的文件 确定模块对象代码所在位置，通常这个文件在lib/modules的某个子目录里 计算存放模块代码、模块名和module对象所需内存大小 在用户空间分配内存区 调用init_module，注册模块实现功能 释放用户态内存 模块实用工具集modutils，在加载linux内核的时候就被装入了，其包含的功能有： lsmod: 和cat /proc/modules等价 ksyms: 显示内核符号和模块符号表的信息，可以读取/proc/kallsyms文件 modprobe: 自动根据模块之间的依赖性插入模块的程序]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improve Neural Network, Programming Assignments]]></title>
    <url>%2F2019%2F03%2F08%2F%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[Improve Neural Network, Programming Assignments 第一周编程作业assignment1Initialization 之前那种随机权重初始化的方法已经work out了，一个好的初始化可以；加快梯度收敛，减小训练误差 zero initialization: break symmetry。导致的结果是对称性破坏，每层的所有神经元学习一样的东西，这就相当于每层只有一个神经元，这样的话，神经网络和简单logistic regression比起来就毫无优越性 random initialization: 破坏对称性。如果是scale(*10)随机初始化，可能导致的结果是起始梯度爆炸 He initialization: 改变乘子，适用于ReLU的随机初始化。这个可以明显看到train set上的准确率和test set上的准确率好了很多 随机初始化式用来破坏神经元的对称性，保证不同层的不同神经元可以学习到不同的特征。并且要注意到不要把权重初始化过大，否则cost初始值会爆炸，然后He initialization在ReLU激活时表现非常好 assignment2Regularization L2 正则化： 解决过拟合的问题，在数据集较小的情况下，模型可也许能很好地拟合训练样本，但是缺少泛化能力 非正则化模型的锐化程度比较严重，对于噪声数据集会明显表现出overfitting 在算正则损失项的时候，主要要把每一层的正则损失加起来 加上正则项后，反向传播也要改写过，就在dW后面加上一个正则项导数就行了，比较简单 使用$$\lambda=0.7$$做尝试，可以发现测试准确率提升到了93%，成功拯救法国队 绘图也可以看到，加上正则项后明显减小了过拟合程度 需要注意的是，正则化系数是需要tuning的超参数，正则项带来的效应是weight decay dropout： shutdown neurons对正向传播和反向传播没有贡献 没有dropout的话可能会出现有神经元过度依赖于某个输入特征 在做dropout的时候每层的筛选矩阵D要与当前层的激活A维度保持一直，然后element wise乘法就可以筛选神经元了 dropout的反向传播：只要在对应的dA上作用D就行了，比较简单，主要要保证预测输出scale过，也就是dA=dA/keep_prob 这边我要吐槽一下这个作业的一个bug了，百分比算错，减法都不会算，应该是14%，具体哪里自己去找 结果可以看到是dropout之后模型在测试集上表现的准确率达到了95%，不过在训练集上却只有93%哈哈哈 关于dropout一个常见的问题是在训练和测试的时候都用了dropout，实际上应该只在训练集上用dropout，从而提升模型的泛化能力，在测试集的时候再随机dropout的话就有点玄学了啊 assignment3grad check 梯度检验 梯度检验是建立在forward propagation是100%正确的基础上的，否则就是扯淡，如果是cost function都没算对，那还做啥梯度检验 检验的话就是用gradapprox去校准计算的grad值 学到的东西：numpy计算范数：numpy.linalg.norm()，貌似默认计算2范数 后面就是高维输入的梯度检验 区别在于高维梯度校验需要把每层的需要校验的梯度先处理一下，方法是从字典里面拿出来，然后连接在一起，然后一起校验 这部分高维梯度检验做的有点迷糊，以后还需要再深入学习 第二周编程作业assignmentOptimization methods GD: gradient descent 对于m个sample同时进行梯度下降也称为batch gradient descent SGD: GD的一个变种，stochastic gradient descent，等价于mini batch中batch size为1的情况 SGD在大样本量的情况下迭代更快，但是会有更多的震荡 mini-batch gradient descent steps：先shuffle，保证每次取的batch中的样本都比较随机，但是需要注意是shuffle要同时对X和Y做，否则就错了。然后做partition，因为样本数不一定被mini batch size整除，最后一个样本可能size会相对小 partition：12first_mini_batch_X = shuffled_X[:, 0 : mini_batch_size]second_mini_batch_X = shuffled_X[:, mini_batch_size : 2 * mini_batch_size] 只要注意处理一下最后一个batch的size就行了 怎么做shuffle：123permutation = list(np.random.permutation(m))shuffled_X = X[:, permutation]shuffled_Y = Y[:, permutation].reshape((1,m)) 怎么做sample：12345678910111213mnini_batches = []mini_batch_X = shuffled_X[:,mini_batch_size*k:mini_batch_size*(k+1)]mini_batch_Y = shuffled_Y[:,mini_batch_size*k:mini_batch_size*(k+1)]mini_batch = (mini_batch_X, mini_batch_Y)mini_batches.append(mini_batch)if m % mini_batch_size != 0: mini_batch_X = shuffled_X[:,mini_batch_size*(k+1):] mini_batch_Y = shuffled_Y[:,mini_batch_size*(k+1):] mini_batch = (mini_batch_X, mini_batch_Y) mini_batches.append(mini_batch) Momentum，动量梯度下降： 动量梯度下降利用之前梯度下降的方向来使Update更加平滑 怎么写注释：1234567891011121314"""Initializes the velocity as a python dictionary with: - keys: "dW1", "db1", ..., "dWL", "dbL" - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.Arguments:parameters -- python dictionary containing your parameters. parameters['W' + str(l)] = Wl parameters['b' + str(l)] = blReturns:v -- python dictionary containing the current velocity. v['dW' + str(l)] = velocity of dWl v['db' + str(l)] = velocity of dbl""" 动量梯度下降，动量项用指数加权平均来更新，防止爆炸，然后参数项用类似之前的法则去更新即可，如果有必要就进行一下bias correction就行了 需要注意的一点是，速度项初始化为0，所以算法需要迭代几次之后才能把速度项build起来，然后迈更大的步子，$$\beta$$是动量系数，如果在意初值太小，可以做偏差校正，但是貌似不那么重要 然后下面给出一个经验性法则：$$\beta$$取值在0.8-0.999之间，通常0.9是一个比较常用取值 用动量梯度下降需要tune两个超参数：动量系数$$\beta$$和学习速率$$\alpha$$ Adam: Adam是最有效的优化算法之一，它结合了RMSprop和Momentum的思想 它计算了前层所有梯度的指数加权平均，然后做bias correction。另外就是计算前层梯度的均方指数加权平均，同时也做了偏差校正。然后用前面两项去做Update 做矩阵初始化时候的奇技淫巧：1np.zeros_like(parameters["W" + str(l + 1)]) 再做adam的时候v和s分别做出一个字典来存 后面貌似都比较简单，就是给的代码模板里面有bug，真的想吐槽 第二周作业完结 第三周编程作业assignmentTensorFlow tutorial 在这个编程作业中所要做的东西： 初始化参数 创建session 训练算法 构建一个神经网络 TensorFlow的整体步骤： 创建Tensor 写定义这些Tensor的操作 初始化Tensor 创建会话session 跑session 也就是说在define lost的时候是不会evaluate的，在init=tf.global_variables_initilizer()这句话中才会evaluate。然后再session.run的时候才会真正做好初始化 在没有run之前，给出的结果都是tensor，例如12345a = tf.constant(2)b = tf.constant(10)c = tf.multiply(a,b)print(c)# output: Tensor("Mul:0", shape=(), dtype=int32) 要计算tensor需要：12sess = tf.Session()print(sess.run(c)) 然后是placeholder，这是一个可以在后面指定值的对象，通过feed_dict来指定，例如： 12345# Change the value of x in the feed_dictx = tf.placeholder(tf.int64, name = 'x')print(sess.run(2 * x, feed_dict = &#123;x: 3&#125;))sess.close() 在run的时候feed data就行了 然后后面开始真正的练习了 先是计算线性函数 然后计算sigmoid，tf有内置的sigmoid, softmax placeholder更可以看成是一种参数传递的方法 然后是用tf内置函数计算了sigmoid激活和交叉熵损失的cost function，算是对placeholder的概念更加熟悉了，也明白了tf其实有很多高度封装的API 再后面试one hot，也就是热位编码器 one_hot热位编码是把行向量变成了矩阵，暂时不知道有啥用，不过矩阵的确是稀疏的 后面是用0和1进行初始化，就是用tf.ones和tf.zeros，接受参数是shape，vector形式的即可 再后面就算是一个大作业了，用TensorFlow构建一个神经网络 分为两大步：构建计算图和run 开始的时候要把label行向量one hot化成矩阵 然后做initialization，这部分有些API没有怎么看懂，因为同样道理，封装程度有点高 再后面就是前向传播，但是用tensorflow进行前向传播的时候要记住要停止在最后一层的激活之前，因为最后一层的激活是tensorflow计算损失的一个参数，这一步是在计算损失的时候做的。但不得不说的是tensorflow在做tensor运算的时候代码风格也TM太丑了，如果不是有运算符重载就要被我骂死了 再做完前向传播后就需要计算cost了，一行代码就搞定了 再后面就是计算反向传播，所有反向传播和权值更新都被封装好了 计算完cost后需要创建一个optimier对象，例如： 12optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)_ , c = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;) 然后吐槽一下model的参数说明写错了 最后就是构建整个模型和训练测试，可以发现训练集上的准确率接近于100%，但是测试集上的准确率却只有71%，这TM的明显是过拟合了，加上regularization和dropout就行了]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Covolutional Neural Network, Programming Assignments]]></title>
    <url>%2F2019%2F03%2F08%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[Covolutional Neural Network, Programming Assignments 第一周编程作业搭建卷积神经网络模型及应用 assignment1搭建卷积神经网络 conv层的函数： zero padding conv window conv forward conv backward pool层的函数： pool forward create mask distribute value pool backward 先写zero padding，它的好处是不会缩减图片的尺寸，以及保留图片的边缘信息 后面是单次conv是一次conv forward，其中要注意的是conv forward里面有两个channel信息，其中一个chanel其实表示的是filter的个数 pooling layer的反传也要计算，是因为计算前层的反传的时候会用到，因此pooling反传不可忽略。pooling layer反传策略基本上是创建一个mask译码，然后去filter无关项，把有用的项向前层反传，比如max pooling则把最大值反传，average pooling则把平均值反传 assignment2用tensorflow框架搭建卷积神经网络 第二周编程作业assignment1学习使用Keras，能够运行在Tensorflow和CNTK之上 Keras相比于Tensorflow，是更高层次的深度学习框架 Keras写出来的还蛮简洁的 assignment2Residual Networks 残差网络 在任务中，我们将完成：实现残差网络的基本模块，用所有模块组件一个先进的残差网络来做图像分类 shortcut || skip connection Indentity block和Convolutional block 前者用在输入输出维度一致的情况下，后者在skip connection的时候加上了卷积，用在输入输出维度不一致的情况下]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux System Programming]]></title>
    <url>%2F2019%2F03%2F08%2FLinux%E7%B3%BB%E7%BB%9F%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Linux System Programming GCC使用讲解如何使用GCC编译器GCC支持的源文件后缀名： .c: C语言源文件 .C .cc .cxx: C++源文件 .m: Object-C源文件 .i: 经过预处理后的C源文件 .ii: 经过预处理后的C++源文件 .s .S: 汇编语言源文件 .h: 预处理文件（头文件） .o: 目标文件 .a: 存档文件 gcc编译程序的流程: 源文件-&gt;预处理-&gt;编译-&gt;汇编-&gt;链接-&gt;可执行文件 filename.c-&gt;预处理器-&gt;编译器-&gt;汇编器-&gt;链接器-&gt;excutefile Linux的可执行文件并不像Windows一样有明显的exe后缀名，只需向其分配x(可执行)权限即可1sudo chmod u+x excutefile 可以使用gcc在编译的任何阶段结束，然后检查该阶段的输出(important) gcc做了哪些工作： 首先gcc会调用预处理程序cpp，由它负责在源程序上展开定义的宏(#include &lt;stdio.h&gt;) 使用-E参数可以使gcc在预处理结束后停止编译：1gcc -E hello.c -o hello.i 第二步，将hello.i编译为目标代码，gcc默认将.i文件看成是预处理后的C语言源代码，因此它会跳过预处理，开始编译过程。1gcc -c hello.i -o hello.o .o后缀已经是二进制目标文件代码了，使用-c参数是禁止链接，不使用这个参数会自动链接 第三步，gcc链接器将目标文件链接成一个可执行文件，然后一个大致编译流程结束 gcc编译模块化程序： 如果一个程序包含多个源文件，那么需要模块化编译 举个栗子：1gcc hello_print.c hello_main.c -o hello 上面这一句可以看成是执行了下面三句：123gcc -c hello_print.c -o hello_print.ogcc -c hello_main.c -o hello_main.ogcc hello_print.o hello_main.o -o hello 即两次编译出目标文件和最后一次链接 GDB使用讲解GDB调试器的使用，可以帮助找出程序中的错误和漏洞等 GDB概述 GDB是GNU开发组织发布的一个强大的UNIX/Linux下程序的调试工具。这个工具功能强大，GDB能帮助用户完成下面四方面的任务 启动程序时，可以根据用户自定义的要求随心所欲运行程序 可以让被调试的程序在用户指定的调试断点处停住(断点可以是条件表达式) 当程序停住时，可以检查此时程序中发生的事 动态地改变程序的执行环境实例： 123456789101112131415161718//gdb.c#include &lt;stdio.h&gt;int func(int n)&#123; int sum = 0, i; for(i = 0;i&lt;m)&#123; sum+=i; &#125; return sum;&#125;int main(void)&#123; int i; long result = 0; for(i = 1;i &lt; 100;i++) result += i; pritnf("result[1-100] = %ld \n", result); printf("result[1-250] = %d \n", func(250));&#125; 以gdb可调试模型进行编译1gcc -g gdb.c -o testgdb 启动gdb进行调试1gdb testgdb 键入l命令相当于list，从第一行开始list源代码默认显示10行，继续输入回车显示后面的内容break 16命令在16行设置断点程序输出：1Breakpoint 1 at 0x?????????: file gdb.c, line 16 break func命令在函数func入口处设置断点 info break查看断点信息 r命令运行程序，会停在断点处 输入n可以单条语句执行，next的缩写 c命令继续运行程序，就是一直执行，直到碰到断点 p命令可以打印某个变量，后面跟上变量名即可 bt命令查看函数堆栈 finish命令退出函数 q命令退出gdb gdb主要调试C/C++程序，要调试的话，在编译时要把调试信息加到可执行文件中，使用编译器cc/gcc/g++的-g参数即可。不加-g会看不到函数名和变量名，代替它们的全是运行时的内存地址 Makefile使用讲解Makefile的使用。Makefile带来的好处就是自动化编译。一旦写好，只要一个make命令，整个工程就可以完全编译，极大地提高了软件开发效率 12345678test: prog.o code.o gcc prog.o code.o -o testprog.o: prog.c code.h gcc -c prog.c -o prog.ocode.o: code.c code.h gcc -c code.c -o code.oclean: rm -f *.o test make程序利用Makefile中的数据，生成遍历以test为根节点的树。Makefile的基本写法如下： 12目标文件: 依赖文件列表至少一个tab的位置 要执行的命令 make clean命令会自动执行makefile里写的clean makefile还可以定义和使用宏，宏也称为变量，更加方法写makefile 定义宏格式为：1macroname = macrotest 使用宏格式为：1$(marcroname) 文件IO（一）介绍Linux系统的文件IO，讲解基本API，包括open，close，read，write等 系统调用：操作系统给用户程序提供的一组“特殊接口”，用户程序可以通过这组接口来获得操作系统提供的特殊服务 文件描述符：对内核而言，所有打开文件都由文件描述符引用。文件描述符是一个非负整数。当打开一个现存文件或创建一个新文件时，内核向进程返回一个文件描述符。 在POSIX程序中，整数0，1，2应该被换成符号常数 STDIN_FILENO(标准输入，默认是键盘) STDOUT_FILENO(标准输出，默认是屏幕) STDERR_FILENO(标准错误输出，默认是屏幕) 这些文件都定义在头文件&lt;unistd.h&gt;中，文件描述符的范围是0~OPEN_MAX。 大多数Linux文件IO只需要用到open, read, write, lseek以及close open需要包含的头文件12345#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;//函数原型int open(const str* pathname, int oflag), [mode]); 功能：打开文件，成功则返回文件描述符，错误则返回-1 pathname: 打开或创建文件的全路径名。 oflag：文件选项，可以选择O_RDONLY只读打开，O_WRONLY只写打开，O_RDWR读写打开中的一个或多个常数，O_APPEND追加到文件末尾，O_CREAT若文件不存在则创建它。使用此选项时，需要同时说明第三个参数。 mode：创建新文件才用到 用open创建一个文件： 12345678910111213141516171819#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;fcntl.h&gt;#define FILE_PATH "./test.txt"int main(void)&#123; int fd; if ((fd = open(FILE_PATH, O_RDWR | O_CREAT | O_EXCL, 0666)) &lt; 0) &#123; printf("open error\n"); exit(-1); &#125; else &#123; printf("open success\n"); &#125; return 0;&#125; read需要包含头文件123#include &lt;unistd.h&gt;//函数原型ssize_t read(int fd, void * buf, size_t count); 功能：从打开的文件中读取数据，返回实际读到的字节数，已读到文件末尾返回0，出错返回-1，返回值表示有符号整数(signed int)。fd：要读取文件的描述符，buf：得到的数据在内存中位置的首地址。count：期望本次能读到的最大字节数，size_t表示unsigned int write需要包含头文件123#include &lt;unistd.h&gt;//函数原型ssize_t write(int fd, const void* buf, size_t count); 功能：向打开的文件写数据，返回写入字节数，出错返回-1 返回-1的常见原因是磁盘空间已满，超过了一个给定进程的文件长度 参数：fd：要写入文件的文件描述符，buf：要写入文件的数据在内存中存放首地址，count：期望写入数据的最大字节数 read和write样例1234567891011121314151617181920#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;unistd.h&gt;int main(void)&#123; char buf[100]; int num = 0; // 获取键盘输入，还记得POSIX的文件描述符吗？ if ((num = read(STDIN_FILENO, buf, 10)) == -1) &#123; printf ("read error"); error(-1); &#125; else &#123; // 将键盘输入又输出到屏幕上 write(STDOUT_FILENO, buf, num); &#125; return 0;&#125; close需要包含头文件123#include &lt;unistd.h&gt;//函数原型int close(int filedes); 功能：关闭一个已打开的文件，参数：需要关闭文件的文件描述符 当一个进程终止的时候，它所有的打开文件都由内核自动关闭。很多程序都使用这一功能而不显式调用close。但是 to be perfect，我们还是最好手动关闭文件。 lseek每次打开文件都由一个当前文件偏移量，是一个非负整数，用以度量从文件开始处计算的字节数。当打开一个文件时，除非指定O_APPEND参数，不然偏移量设为0 需要包含头文件1234#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;//函数原型off_t lseek(int filesdes, off_t offset, int whence); 功能：设置文件内容读写位置，返回新的文件偏移量或者返回-1表示出错。off_t相当于signed int whence是SEEK_SET, 那么该文件的位移量设置为据文件开始处offset个字节 whence是SEEK_CUR, 那么该文件的位移量设置为当前值加offset。offset可为正或负 whence是SEEK_CUR, 那么该文件的位移量设置为当前值加offset。offset可为正或负 selectread函数可以监控一个文件描述符（如键盘）是否有输入，当键盘没有输入，read会阻塞，是同步函数。想同时监控多个设备需要使用异步函数select 需要包含头文件12#include &lt;sys/select.h&gt;int select(int maxfd, fd_set \* readset, fd_set \* writeset, fd_set \* exceptset, const struct timeval \* timeout); 失败返回-1，成功返回readset，writeset，exceptset中所有。参数太复杂了，用到在看吧，监控多个终端（或文件）我感觉不太用的到。 文件IO（二）讲解stat基本使用，目录操作 stat的使用系统调用stat的作用是获取文件的各个属性 需要包含的头文件12345#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;unistd.h&gt;//函数原型int stat(const char \* path, struct stat \* buf); 功能：查看文件或目录属性。将参数path所指的文件属性，复制到参数buf所指结构中 struct stat定义如下：123456789101112131415struct stat &#123; dev_t st_dev; ino_t st_ino; mode_t st_mode; nlink_t st_nlink; uid_t st_uid; gid_t st_gid; dev_t st_rdev; off_t st_size; blksize_t st_blksize; blkcnt_t st_blocks; time_t st_atime; time_t st_mtime; time_t st_ctime;&#125;; st_ino: 节点号 st_mode: 文件类型和文件访问权限被编码在该字段中 st_nlink: 硬链接数 st_uid: 属主的用户ID st_gid: 所属组的组ID st_rdev: 设备文件的主、次设备号 st_size: 文件的大小 st_mtime: 文件最后被修改时间 文件类型的判定根据st_mode字段来判断文件的类型，用来获取文件类型和文件访问权限。 文件类型宏定义： S_ISREG():普通文件 S_ISDIR():目录文件 S_ISCHR():字符设备文件 S_ISBLK():块设备文件 S_ISFIFO():有名管道文件 S_ISLNK():软链接文件 S_ISSOCK():套接字文件 文件权限判定根据st_mode字段可以判断文件的权限类型，同样需要一组由系统提供的宏来完成解码 S_ISUID():执行时，设置用户ID S_ISGID():执行时，设置组ID S_ISVTX():保存正文 S_IRWXU():拥有者读写执行权限 S_IRUSR():拥有者读权限 S_IWUSR():拥有者写权限 S_IXUSR():拥有者执行权限 S_IRWXG():用户组的读写执行权限 S_IRGRP():用户组的执行权限 S_IWGRP():用户组的写权限 S_IXGRP():用户组的执行权限 S_IRWXO():其它读写执行权限 S_IROTH():其它读权限 S_IWOTH():其它写权限 S_IXOTH():其它执行权限 目录操作打开目录： 需要包含的头文件：1234#include &lt;sys/types.h&gt;#include &lt;dirent.h&gt;//函数原型DIR * opendir(const char * name); 功能：用来打开参数name指定的目录，并返回DIR*状态的数据流，失败返回NULL 读取目录：1struct dirent * readdir(DIR * dir); 功能：返回参数dir目录流的下一个子条目，错误返回NULL12345678//成功时返回的结构体struct dirent&#123; int_t d_ino; off_t d_off; unsigned short d_reclen; unsigned char d_type; char d_name[256];&#125; 其中d_name字段存放子条目名称 关闭目录：12//函数原型int closedir(DIR * dir); 功能：closedir关闭dir所指的目录流，成功返回0，错误返回-1 多进程（一）进程状态 R(TASK_RUNNING)，可执行状态，只有该状态的进程才可能在CPU上运行，同一时刻可能有多个进程处于可执行状态，这些进程的task_struct结构(PCB)被放入对应的CPU可执行队列中，在这里统称RUNNING和READY都是可执行状态。 S(TASK_INTERRUPTIBLE)，可中断的睡眠状态，处于这个状态中的进程因为等待某某事件发生(比如等待socket连接、等待信号量)而被挂起，这些进程的task_struct结构被放入等待队列中。通过ps命令可以看到一般情况下，进程列表中的绝大多数进程都处于该状态。 D(TASK_UNINTERRUPTIBLE)，不可中断的睡眠状态，它存在的意义是，内核中某些处理流程是不可打断的 T(TASK_STOPPED or TASK_TRACED)，暂停状态或跟踪状态，向进程发送一个SIGSTOP信号，它就会响应该信号而进入T状态，向进程发送一个SIGCONT信号，可以让其从TASK_STOPPED状态恢复到TASK_RUNNING状态。当进程正在被跟踪时，它处于TASK_TRACED这个特殊的状态 Z(TASK_DEAD-EXIT_ZOMBIE)，进程在退出过程中，处于TASK_DEAD状态。在退出过程中，进程占用的所有资源会被回收，除了task_struct这个结构外，所以这个结构变成了一个空壳，被称为僵尸 X(TASK_DEAD-EXIT_DEAD)，进程即将被销毁， 进程标志获取进程标志号PID的API：getpid和getppid，需要包含的头文件： 12#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt; 函数原型1pid_t getpid(void) 功能是获取当前进程的ID，返回调用进程的进程ID 函数原型1pid_t getppid(void) 获取父进程ID，返回值：调用进程的父进程ID 示例：12345678910111213#include &lt;sys/types.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(void)&#123; pid_t pid = getpid(); pid_t ppid = getppid(); printf ("pid = %d\n", pid); printf ("ppid = %d\n", ppid); return 0;&#125; Linux下C进程内存布局text： 代码段。存放的是程序的全部代码（指令） initialized data(data段)和unintialized data(bss段)共同组成数据段。其中data段存放的是已初始化全局变量和已初始化static局部变量，bss段存放未初始化全局变量和未初始化static局部变量，其内容不来源于二级制可执行文件的数据部分。bss段存放的全是0，将bss段清0是系统在加载二进制文件后，开始执行程序前完成的，由一段内核代码完成。这段代码就是exec调用。 malloc从堆(heap)中分配空间，stack存放的是动态局部变量，主要用在函数调用的时候 获取和设置环境变量： 1#include &lt;stdlib.h&gt; 返回字符指针，该指针指向变量名为name的环境变量的字符串1char *getenv(const char* name); 将环境变量=环境变量值形式的字符串增加到环境变量列表中，如果变量已存在，则更新旧值 1int putenv(const char* str); fork系统调用fork调用后，子进程的代码是父进程代码完全相同的一个拷贝。不仅仅是text段，子进程的全部进程空间(包括：text/data/bss/heap/stack/command line/environment variables)都是父进程空间的一个完全拷贝。fork为子进程分配了空间，并拷贝了父进程的相关内容给子进程，然后fork在内核数据结构中创建并初始化子进程的PCB，子进程首次被OS调度时，执行的第一条代码在fork内部，但是在应用程序开来，子进程执行的第一条代码是fork返回，于是就可以理解为什么fork调用一次却返回两次了，因为子进程没有调用fork，只有父进程调用了。这个是个很神奇的东西。而且fork两次返回的返回值不同，在父进程中返回的是子进程的pid，子进程的返回值为0。在fork之后是子进程先执行还是父进程先执行取决于操作系统的调度策略，应用程序是无法控制的。子进程出生后，子进程和父进程的进程空间是不相互干扰的。 多进程（二）这节课讲一个另外的进程相关系统调用exec 文件描述符： 节点表：可以看成结构体数组，数组中的每一个元素对应一个物理文件 文件表：也看作结构体数组，三个重要字段： file status flag: 记录文件被打开来读的，还是写的。记录的是open调用的第二个参数 current file offset: 记录文件的当前读写位置指针 v-node ptr: 该字段是指针，指向右侧表的第一个元素，从而关联了物理文件 文件描述符表：每个进程有一张，可以视为指针数组，该表的第一个元素指向文件表的一个元素 open调用执行的操作：新建一个i节点表元素，让其打开对应的物理文件，新建一个文件表的元素，根据open参数设置相关字段，在文件描述符表中，寻找一个尚未使用的元素，在该元素中填入一个指针值，让其指向刚才建立的文件表元素，将元素下标作为open返回值返回。 父进程fork调用创建子进程后，父子进程共享文件描述符，指向同一个文件表和同一个物理文件。对于程序员而言，如果子进程不打算用父进程打开的文件，应该在fork调用返回的时候显式调用close来关闭文件。 父子进程同步：wait调用 在之前的例子里面，为了确保先执行子进程再执行父进程，方法是在父进程中调用sleep让父进程睡觉两秒钟，但是实际上不能保证子进程一定在父进程前面执行，在负载很重的系统中，有可能让父进程睡觉了两秒子进程还没有开始执行。wait用来确保100%进程同步。 需要包含的头文件： 1234#include &lt;sys/types.h&gt;#include &lt;sys/wait.h&gt;//函数原型pid_t wait(int *status); 功能是等待进程结束。若成功则返回子进程ID号，出错则返回-1。status存放进程结束状态 wait函数用于父进程阻塞，直到一个子进程结束 即用1wait(&amp;status) == pid 条件即可检查子进程是否结束了，其中右值pid是fork调用的返回值，在父进程里pid应该是其fork出的子进程ID号 多进程（三）进程的消亡： exit函数和_exit函数 IO流和IO库缓存]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Operating System]]></title>
    <url>%2F2019%2F03%2F08%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E7%B2%BE%E9%AB%93%E4%B8%8E%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Operating System Book Notes. 计算机系统概述顶层看，计算机由处理器，存储器和输入/输出部件组成，每类部件有多个模块： 处理器与存储器交换数据需要用两个内部寄存器：存储器地址寄存器MAR，确定下一次读写的存储器地址，存储器缓冲寄存器MBR存放要写入存储器的数据或从存储器中总读取的数据。同理，输入输出地址寄存器确定一个特定的输入输出设备，输入输出缓冲寄存器存放要写入或写出的数据，数据交换通过系统总线来实现。 处理器寄存器分为用户可见寄存器和控制和状态寄存器。 用户可见寄存器分为数据寄存器和地址寄存器，数据寄存器也存在一些限制，比如浮点数运算使用专用的寄存器，而整数运算使用其他寄存器 地址寄存器存放数据和指令的内存地址或者存放用于计算完整地址或有效地址的部分地址。例如变址寄存器，变址寻址是常用的寻址方式，它通过给基值加一个索引来获得有效地址。 段指针，对于分段寻址方式，存储器被划分为段，一个存储器引用由一个特定段号和段内的偏移量组成 栈指针：对用户可见的栈进行寻址，则需要一个专门的寄存器指向栈顶 控制和状态寄存器：程序计数器PC，包含将取指令的地址，指令寄存器（IR），包含最近取的指令内容，还包括一个或一组寄存器，通常称为程序状态字，包含状态信息，PSW通常包含条件码和其他状态信息，如中断允许/禁止位和内核/用户态 条件码：如算术运算后，会设置一个条件码，可以作为条件分支运算的一部分被测试 指令的执行：一个单一的指令需要的处理称为一个指令周期。两个步骤分别称为取指阶段和执行阶段。在指令周期开始时，处理器从存储器取一条指令，程序计数器PC保存下一次要取的指令地址，取到的指令被放到指令寄存器中，处理器解释并执行相应的操作。操作分为： 处理器-存储器：数据可以从处理器传送到存储器，或者从存储器传送到处理器 处理器-I/O：处理器和I/O模块之间的数据传送，数据可以输出到外部设备，或者从外部设备输入数据 数据处理：处理器可以执行很多与数据处理相关的算术操作或逻辑操作 控制：指令转移等 指令I/O操作，可以直接与处理器交换数据。处理器还允许I/O模块直接与内存发生数据交换，I/O模块对存储器发出读命令或写命令，免去处理器负责数据交换的任务。这个操作称为直接内存存取DMA。 中断所有计算机都提供了允许其他米快（I/O，存储器）中断处理器正常处理过程的机制 分类： 程序中断：指令执行的结果，如除法溢出，非法访问等 时钟中断：处理器内部计时器产生 I/O中断：I/O控制器产生 硬件故障中断：如掉电和存储器奇偶错误 利用中断功能，处理器可以在I/O操作的执行过程中执行其他命令 用户程序不需要管中断，处理器和操作系统负责挂起用户程序，然后再同一个地方恢复执行 指令周期：在允许中断的情况下，处理器会检查中断信号，如果有，则挂起当前程序的执行，由中断处理程序去处理中断，这个程序是操作系统的一部分，当中断处理程序完成后，处理器在中断点恢复对用户程序的执行。 中断处理程序需要执行额外的指令确定中断的性质 中断处理的事件：包括处理器硬件中的事件和软件事件 硬件包括：设备控制器或其他系统硬件产生一个中断，处理器结束当前指令的执行，处理器发送中断应答信号，处理器将PSW和PC压入控制栈，根据中断，处理器重新加载新的PC值，然后到软件部分，保存剩余的状态信息，中断处理程序处理中断，处理完后恢复处理状态信息，恢复老PSW和PC值 多个中断：一个程序可能从一条通信线中接收数据并打印结果 处理中断有两种方法：一是正在处理一个中断时，禁止再发生中断，意思是处理器对任何新的中断请求信号不予理睬。如果期间发生了中断，通常中断保持挂起，再次允许中断时，处理器再检查。这种方法的缺点是不考虑优先级 第二种方法是定义中断优先级，允许高优先级的中断打断低优先级的中断处理程序的运行，是一种嵌套中断的方式 多道程序设计：对于单道程序而言，如果完成I/O操作的时间远远大于I/O调用期间用户代码的执行时间，则在大部分时间处理器是空闲的，解决这个问题的方法是允许多道用户程序同时处于活动状态。 存储器层次结构存储器的设计目标可以归纳为：多大的容量，多快的速度，多贵的价格，trade-off 问题： 存取时间越快，每一个位的价格越高 容量越大，每一个位的价格越低 容量越大，存取速度越慢 为了解决这些问题，存储器的层次结构被提出 关键在于低层访问频率递减，也是告诉缓存和虚拟内存的关键内容 这部分看不太懂，之后再细看 高速缓存设计动机：处理器在取指令时至少访问一次存储器，通常要多次访问，因为涉及取数据和存数据，处理器执行指令的速度回收到存储周期的限制。理想情况下，内存的构造技术可以采用与处理器中的寄存器相同的构造技术，这样主存的存储周期才能跟得上处理器周期。但这样成本太高，解决方法是利用局部性原理，即在处理器和内存之间提供一个小容量而速度快的存储器，称作高速缓存。 高速缓存的原理： 高速缓存使访问速度接近现有最快的存储器，维持一个相对容量大而速度慢的内存和一个容量较小且速度较快的高速缓存，高速缓存包含一部分内存数据的副本，当处理器视图读取存储器中一个字节或字时，要检查一下它是不是在高速缓存中，如果不在，则由固定数目的字节组成一块内存数据线被读入高速缓存，然后该字节或字从高速缓存传递给处理器。注意是一块。 高速缓存中有C个存储槽slot或line，每个槽有一个标签，以标识当前存储的是哪个块。标签通常是地址中较高的若干位，标识以这些位开始的所有地址。 高速缓存设计的关键性问题：高速缓存大小，块大小，映射函数，替换算法，写策略 块大小：当块大小从很小增加到很大时，由于局部性原理，命中率会增加，局部性原理指的是位于被访问字附近的数据在近期被访问到的概率比较大。但是，当块变得更大时，新取的数据会把原先告诉缓存中的那些块移除，反而降低命中率，所以这里也有一个trade-off 当一个新块被读入高速缓存中时，由应设函数确定这个块将占据哪个高速缓存单元。映射函数的关键在于设计可以增大命中率的替换算法，其次，如果映射函数越灵活，则完成相应功能的电路设计更复杂。合理的替换策略是替换高速缓存汇总最长时间未被访问的块。叫做最近最少使用LRU算法。标识最近最少使用块需要由硬件支持。 另外如果高速缓存中某个块的内容被修改，则需要在它被换出高速缓存之前把它写会内存。写策略规定何时发生存储器写操作，极端情况是每当块被更新后就发生写操作；另一种极端情况是只有当块被替换时才发生写操作。后一种策略减少了存储器写操作的次数，但是使内存处于一种过时的状态，会妨碍多处理器操作以及I/O模块的直接内存存取。 I/O通信技术有三种：可编程I/O，中断驱动I/O，直接内存存取DMA 可编程I/O：处理器在执行程序时遇到一个与I/O有关的指令时，通过给相应的I/O模块发命令来执行这个指令。I/O模块来完成，不会中断处理器，指令集：控制，状态是，传送。这种技术的问题是处理器总是处于没有用的繁忙之中。因为处理器需要时刻检查I/O模块的状态，是否完成是否就绪。 中断驱动I/O：处理器给模块发送I/O命令，然后继续做其它任务，当I/O模块准备好与处理器交换数据时，它打断处理器的执行并请求服务。从I/O模块的角度来看看工作原理，对于输入操作，I/O模块从处理器中接收一个READ命令，然后开始从相关的外围设备读数据。一旦数据被读入该模块的数据寄存器，模块通过控制线给处理器发送一个中断信号，然后等待直到处理器请求该数据，当处理器发出请求后，模块把数据放到数据总线上，然后准备下一次的I/O操作。 从处理器的角度看看原理：输入操作，处理器发出一个READ命令，然后保存当前程序的上下文，离开当前程序，去做其它事情，在CPU时间片空闲阶段检查中断，当发生来自I/O模块的中断时，处理器保存上下文并执行中断操作 中断驱动比可编程更加高效 直接内存存取：中断驱动中处理器需要主动干预在存储器和I/O模块之间的数据传送，并且任何数据传送都必须完全通过处理器。当发生大量的数据移动时，需要用一种更有效的技术：直接内存存取DMA，当处理器要读或写一块数据时，它给DMA模块产生一条命令，然后自己管自己干别的事，DMA模块负责处理I/O，完成后，DMA发一个中断信号给处理器，只有在开始和结束的时候处理器才参与 操作系统概述操作系统由一开始的批处理系统演变成高级的多任务，多用户系统 实现用户与操作系统之间的接口，操作系统需要提供一些系统程序，其中一部分称作实用工具 早期串行处理计算机：调度和准备时间的问题，计算机很可能长期处于闲置状态 简单批处理系统：简单批处理的中心思想是用一个监控程序软件，通过这类操作系统，用户不再直接访问机器，用户把卡片或磁带中的作业提供给计算机操作员，由他把这些任务组成一批，将整个批放在输入设备上供监控程序使用。监控程序来完成调度。 多个程序（进程）之间的切换是多道程序设计的模式（multiprogramming）或多任务处理（multitasking），也是现代操作系统的主要方案 多道批处理系统必须依赖某些计算机硬件功能，对多道程序设计有用的最显著的辅助功能是支持I/O中断和直接存储器访问DMA的硬件，处理器可以发出一个I/O指令，指挥设备控制器进行I/O操作，当设备控制器在执行I/O操作时，处理器可以干别的事情。当I/O完成时，处理器被中断，控制权移交给中断处理程序，然后操作系统把控制权交给另一个作业。 多道程序需要保留在内存中，所以需要内存管理 如果多个作业都要运行，那么需要调度算法 多个用户分享处理器时间，因而该技术成为分时，多个用户可以通过终端同时访问系统，由操作系统控制每个用户程序以很短的时间为单位交替执行，批处理和分时都用到了多道程序设计，主要区别在于批处理多道程序设计充分利用处理器，分时的目标是减少相应时间 进程： 多种定义，比如：一个正在执行的程序。计算机中正在运行的程序的一个实例。可以分配给处理器并由处理器执行的一个实体。由单一的顺序的执行线程，一个当前状态和一组相关的系统资源所描述的活动单元。 计算机系统发展的三条主线：多道批处理操作、分时和实时事物系统，它们在时间安排和同步中所产生的问题推动了进程概念的发展。 错误： 不正确的同步：常常会出现一个进程必须挂起，等待系统中其他地方某一事件。不正确的信号机制可能会导致信号丢失或收到重复信号 失败的互斥：常常有多个用户或程序试图同时使用一个共享资源的情况。必须有某种互斥机制，以保证一次只允许一个例程进行处理。如果互斥机制设计不好就会出问题 不确定的程序操作：程序调度顺序可能会影响某个特定程序的输出 死锁：两个或多个程序互相挂起等待 内存管理： 如果处理器在很多进程间切换，很难把它们紧密压入内存中，因此引进了分页系统。在分页系统中，进程由许多固定大小的块组成，这些块称做页。程序通过虚地址(virtual address)访问字，虚地址由页号和页中偏移量组成。进程每一页可以放在内存中任何地方，分页系统提供了程序中使用的虚地址和内存中的实地址或物理地址之间的动态映射。 一个进程的所有页都保留在磁盘中，当进程执行时，一部分页在内存中。如果需要访问的某一页不在内存中，存储管理硬件可以检测到，然后安排载入这个缺页。这个配置称为虚拟内存。 虚拟存储器方案中的寻址方式：存储器由内存和低速的辅助存储器组成。地址映射器位于处理器和内存之间。程序使用虚地址访问，虚地址将映射成真实的内存地址，如果访问的虚地址不在实际内存中，实际内存的一部分会换到外存中。然后换入所需要的数据块。在过程中，产生地址访问的进程必须被挂起。 调度和资源管理： 公平性 有差别的响应性：例如，一个进程正在等待使用一个IO设备，操作系统会尽可能迅速地调度这个进程，从而释放这个设备以方便其他进程使用 有效性：期望获得最大吞吐量和最小的响应时间 微软操作系统概述： 1993年第一版Windows NT发布，是一个32位操作系统，具有支持老的DOS和Windows应用程序的能力。 2001年发布了XP，同年发布了64位版本的XP 单用户多任务：多个窗口之间可以自由切换 体系结构：软件的模块化结构 Windows的内核态组件： 执行体：操作系统基础服务，例如内存管理、进程和线程管理、安全、I/O和进程间通信 内核：内核是操作系统中唯一不可抢占或分页的一部分 硬件抽象层HAL：将硬件相关特性抽象成API，对对称多处理SMP提供支持 设备驱动：扩展执行体 窗口和图形系统：实现图形用户界面函数(GUI函数)执行体API： I/O管理器 高速缓存管理器 对象管理器 即插即用管理器 电源管理器 安全访问监控程序 虚拟内存管理器 进程/线程管理器 配置管理器 本地过程调用 Unix操作系统： 操作系统提供了直接和硬件交互的原子例程(primitive routine) Linux可加载模块loadable module，两个重要特性： 动态链接：当内核已经在内存中并正在运行时，内核模块可以被加载和链接到内核。模块也可以在任何时刻被断开链接，从内存中移出 可堆栈模块：当被高层模块访问时，它们作为库；当被低层模块访问时它们作为客户 内核组件介绍： 信号：内核通过信号通知进程 系统调用：进程通过系统调用来请求系统服务 进程和调度器 虚拟内存 文件系统 网络协议 字符设备驱动 块设备驱动 网络设备驱动 陷阱和错误 物理内存 中断 进程操作系统用PCB进程控制块来管理进程，描述进程的状态和资源所有权，使操作系统进行进程控制 进程的两个基本的元素是程序代码和代码相关联的数据集。在进程执行时，任意给定一个时间，进程都可以唯一地表征为以下元素： 标识符：跟进程相关的唯一标识符 状态 优先级 程序计数器 内存指针：包括程序代码和进程相关数据的指针，还有和其他进程共享内存块的指针 上下文数据：进程执行时处理器的寄存器中的数据 I/O状态信息：显式I/O请求、分配给进程的I/O设备和被进程使用的文件列表等 记账信息：处理器时间总和、使用的时钟数总和、时间限制、记账号等 前述列表信息存放在PCB中，PCB由操作系统创建和管理，PCB是操作系统能够支持多进程和提供多处理的关键之一。 当操作系统为另一个进程的显式请求创建一个进程时，这个动作称为进程派生 五状态模型： 运行态：该进程正在执行 就绪态：进程做好了准备，只要有机会既可以开始执行 阻塞/等待态：进程在某些事件发生前不能执行，如I/O操作完成 新建态：刚刚出创建的进程 退出态：操作系统从可执行进程组中释放出的进程 进程状态转换： 空-&gt;新建：创建执行一个程序的新进程 新建-&gt;就绪 就绪-&gt;运行：需要选择一个新进程运行时，操作系统选择一个处于就绪态的进程 运行-&gt;退出：如果当前正在运行的进程表示自己已经完成或取消，则它被操作系统终止 运行-&gt;就绪：CPU重新调度 运行-&gt;阻塞：如果进程请求它必须等待的某些事件，则进入阻塞态 阻塞-&gt;就绪：当所等待的事件发生后，处于阻塞态的进程转换到就绪态 就绪-&gt;退出：父进程终止子进程 阻塞-&gt;退出 大型操作系统阻塞队列中的进程数会非常多，常见的做法是一个事件对应一个阻塞队列，这样此事件发生时就将该事件阻塞队列中的事件全部划到就绪队列中 进程控制结构：属性的集合称为进程控制块PCB。程序、数据、栈和属性的集合称做进程映像。 进程映像保存在外存中，如果操作系统要管理进程，其进程映像至少要有一部分位于内存中，为执行进程，整个进程映像必须载入内存中或至少载入虚拟内存中。 进程属性：可以把进程控制块信息分成三类： 进程标识信息 处理器状态信息 进程控制信息 其他则是一些零零碎碎的知识点，非通用，比如Unix进程描述 线程、SMP和微内核关于进程，有两个独立概念：资源所有权和执行权。导致了线程的出现。 操作系统分派单位称为线程或轻量级进程(LWP,Light Weight Process)，拥有资源所有权的单位通常仍称做进程或任务。 单线程进程模型包括：进程控制块PCB，用户栈，用户地址空间，内核栈 多线程进程模型包括：进程控制块PCB，用户地址空间，线程包括：线程控制块，用户栈和内核栈 线程的优点有： 在一个已有进程中创建一个新线程比创建一个新进程耗时少 终止一个线程比终止一个进程花费时间少 同一进程内线程间切换比进程间切换花费时间少 线程提高了不同的执行程序间通信的效率 使用用户级线程而不是内核级线程的优点： 线程管理数据结构都在一个进程的用户栈地址空间中(应该大于用户栈概念吧)，线程切换不需要内核态特权，节省了状态转换的开销 调度可以是应用程序相关的，可以让应用程序来调度管理，不同的应用程序可以自主选择不同的调度算法，不过缺点就是不懂OS的人编不好多线程的应用程序了 兼容性好，内核无关 缺点： 一个线程阻塞和引起整个进程都阻塞 不能算真正的多线程，只是应用程序级别的多线程而已，因为上层进程还是只能指派给一个处理器 某些操作系统组合用户级线程和内核级线程来实现，线程调度和同步在应用程序用户态下完成，这样节省了模式切换的额外开支，然后把用户级线程映射到内核级线程，从而能指派给多个处理器，实现内核级别的多线程，达到整体最佳。 并发性：互斥和同步不论是单处理器多道程序设计技术还是多处理技术亦或是分布式系统，都需要解决并发的问题： 全局资源的共享充满了危险：如果两个进程都使用同一个全局变量，不同的读写顺序可能会影响最后结果 操作系统难以对资源进行最优分配：死锁 定位程序设计错误困难 共享内存区的问题：在单处理器系统的情况下，出现问题的原因是中断可能会在进程中任何地方停止指令的执行；在多处理器系统的情况下，当两个进程同时执行并试图访问同一个全局变量时，也会引发问题。这两类问题的解决方案是相同的：控制对共享资源的访问 操作系统关注的问题： 处操作系统必须能够记住各个活跃进程 操作系统必须为每个活跃进程分配和释放各种资源，资源包括：处理器时间，存储器，文件，I/O设备 操作系统必须保护每个进程的数据和物理资源，避免其他进程的无意干涉 一个进程的功能和输出结果必须与执行速度无关 进程交互： 进程之间互相了解的程度不同，可以是完全不知道对方的存在，可以通过共享数据来合作，可以直接知道彼此的存在 进程间的资源竞争会引发是哪个问题，一个是如何互斥，一个是死锁，一个是饥饿 互斥条件： 必须强制互斥，在与相同资源或共享对象的临界区有关的所有进程中，一次只允许一个进程进入临界区 一个在非临界区停止的进程不能干涉其他进程 绝不允许出现需要访问临界区的进程被无限延迟的情况。即不会产生死锁或饥饿 当没有进程在临界区时，任何需要进入临界区的进程必须能够立即进入 对相关进程的执行速度和处理器数目没有任何要求和限制 一个进程驻留在临界区中的时间必须是有限的 互斥的硬件支持： 在单处理器机器中，并发进程是交替执行的，不能重叠，也就是多道程序，一个进程将一直运行直到发生系统调用或被中断，所以要保证互斥，只要保证一个进程不被中断就行了。策略是在进程进入临界区之间禁用中断，在离开临界区后启用中断。多处理器的机器中这种方法会失效。 在硬件级别上，处理器设计者弄了一些机器指令来保证一些动作的原子性，如在一个取指周期对一个存储器单元的读或者读和测试，在该指令执行过程中，其他指令访问内存将被阻止]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Network and Deep Learning, Programming Assignments]]></title>
    <url>%2F2019%2F03%2F08%2F%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%2F</url>
    <content type="text"><![CDATA[Neural Network and Deep Learning, Programming Assignments 第二周编程作业assignment1学习numpy和iPython notebook 学习np.exp, np.log, np.reshape的使用 如果x = (x1, x2, …xn)是行向量，那么np.exp会按元素进行指数运算 也可以使用np.exp?来快速获取关于该函数的帮助 后面用numpy写了sigmoid函数以及计算sigmoid函数的原始梯度，比较简单 然后是矩形的形状变换：np.shape, np.reshape() 三个维度的图像的reshape:1v = image.reshape((image.shape[0]*image.shape[1],image.shape[2])) 然后讲了归一化技巧，normalize 行归一化，这里需要使用一个新的np函数 12345678910111213141516171819202122# GRADED FUNCTION: normalizeRowsdef normalizeRows(x): """ Implement a function that normalizes each row of the matrix x (to have unit length). Argument: x -- A numpy matrix of shape (n, m) Returns: x -- The normalized (by row) numpy matrix. You are allowed to modify x. """ ### START CODE HERE ### (≈ 2 lines of code) # Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True) x_norm = np.linalg.norm(x,ord = 2, axis = 1, keepdims = True) # Divide x by its norm. x = x/x_norm ### END CODE HERE ### return x 说明一下np.linalg.norm中的ord参数原为order，即表示范数的阶数 这个函数可以计算总共8阶范数 再后面就是讲了numpy的广播机制，看到过无数次了 以softmax激活函数为例，练习了这个广播机制如何使用 后面就不讲numpy了，开始练向量化vectorization 然后注意一下np.dot执行的是矩阵和矩阵或者矩阵和向量之间的乘法，而np.multiply或者*执行的是矩阵的按元素乘法 后面就是写损失函数，要写L1损失和L2损失 trick: 用np.dot(x,x)可以用来计算按元素平方 assignment2做一个能够识别猫的简单神经网络 将学会： 初始化参数 计算损失函数和梯度 使用一个优化算法(梯度下降) h5py包用来处理 H5 file training set说明：一共208张训练的图片，每张图片被展开成一个行向量，一起拼接成一个矩阵 testing set说明：一共49个测试样本，每个样本也是被展开成一个行向量，一起拼接成一个矩阵 在读取到的数据样本后面加上_orig表示后面还要处理 读取到的每个训练样本都是一个64*64*3的矩阵，表示一张图片，其中3表示共有3个颜色通道 然后后面就简单练习一下可视化图片，提供numpy矩阵的维度特征，reshape，reshape之后就获得了列堆叠的二维向量，列数表示样本数，行数表示一个样本的特征数 这边有必要说一个reshape的trick 下面代码可以将X展平成列堆叠，当然X.shape[0]需要是样本总数才行，-1表示从原矩形剩下维度推测并进行展平，比较实用的一个技巧，不用麻烦自己去算剩下的维chu度1X_flatten = X.reshape(X.shape[0], -1).T 对于图像数据集，做归一化处理的更简便方法是同时除255 总结一下数据集预处理所做的工作：导入数据，找出数据的维度特征，然后进行reshape，然后再进行归一化处理 然后后面开始正式写神经网络了，要做的工作如下： 初始化模型的参数 通过最小化损失来学习模型参数 使用学习到的参数来做预测 分析结果并进行总结 先写了一个向量化的sigmoid函数 写了参数初始化函数，这边比较值得注意的一个点是np.zeros函数接受的shape为元组格式，千万不要自作聪明传了两个数字进去 前向和反向传播 写propagate来计算损失函数和梯度 把progage算法贴一下，还是比较有价值的，其中计算了前向传播和反向传播梯度1234567891011121314151617181920212223242526272829303132333435363738394041424344# GRADED FUNCTION: propagatedef propagate(w, b, X, Y): """ Implement the cost function and its gradient for the propagation explained above Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of size (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples) Return: cost -- negative log-likelihood cost for logistic regression dw -- gradient of the loss with respect to w, thus same shape as w db -- gradient of the loss with respect to b, thus same shape as b Tips: - Write your code step by step for the propagation. np.log(), np.dot() """ m = X.shape[1] # number of samples # FORWARD PROPAGATION (FROM X TO COST) ### START CODE HERE ### (≈ 2 lines of code) A = sigmoid(np.dot(w.T,X)+b) # compute activation cost = 1/m*np.sum(Y*A+(1-Y)*np.log(1-A)) # compute cost ### END CODE HERE ### # BACKWARD PROPAGATION (TO FIND GRAD) ### START CODE HERE ### (≈ 2 lines of code) dw = 1/m*np.dot(X,(A-Y).T) db = 1/m*np.sum(A-Y) ### END CODE HERE ### assert(dw.shape == w.shape) assert(db.dtype == float) cost = np.squeeze(cost) assert(cost.shape == ()) grads = &#123;"dw": dw, "db": db&#125; return grads, cost 优化： 要做的事情： 计算当前参数的cost和gradient（使用之前写的propogate函数） 使用梯度下降法更新参数 把优化optimazation函数也贴一下，总体也算是比较有用的 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061# GRADED FUNCTION: optimizedef optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False): """ This function optimizes w and b by running a gradient descent algorithm Arguments: w -- weights, a numpy array of size (num_px * num_px * 3, 1) b -- bias, a scalar X -- data of shape (num_px * num_px * 3, number of examples) Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples) num_iterations -- number of iterations of the optimization loop learning_rate -- learning rate of the gradient descent update rule print_cost -- True to print the loss every 100 steps Returns: params -- dictionary containing the weights w and bias b grads -- dictionary containing the gradients of the weights and bias with respect to the cost function costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve. Tips: You basically need to write down two steps and iterate through them: 1) Calculate the cost and the gradient for the current parameters. Use propagate(). 2) Update the parameters using gradient descent rule for w and b. """ costs = [] for i in range(num_iterations): # Cost and gradient calculation (≈ 1-4 lines of code) ### START CODE HERE ### grads, cost = propagate(w, b, X, Y) ### END CODE HERE ### # Retrieve derivatives from grads dw = grads["dw"] db = grads["db"] # update rule (≈ 2 lines of code) ### START CODE HERE ### w = w - learning_rate * dw b = b - learning_rate * db ### END CODE HERE ### # Record the costs if i % 100 == 0: costs.append(cost) # Print the cost every 100 training examples if print_cost and i % 100 == 0: print ("Cost after iteration %i: %f" %(i, cost)) params = &#123;"w": w, "b": b&#125; grads = &#123;"dw": dw, "db": db&#125; return params, grads, costs 下面就是写预测(假设)函数predict了，用m来表示训练样本数，比较简单 最后就是集成前面所有写的函数到一个model里面了 最后测试了一下模型，发现在训练集上的准确率是99%多，但是在测试集上的准确率只有70%，题目也说了这个logistic回归这个东西的准确率本身就不高，也就是说写了这么多就是玩玩而已的 训练集准确率上升而测试集准确率下降称为overfit 总结来说cost函数不是越小越好，因为可能是overfit的情况 在深度学习中，通常是选择学习率使得代价函数尽可能小，然后选择用其他的策略来解决overfit的问题 从这次编程作业中学习到的东西： 数据集预处理是很重要的 分开写每个函数：initialize(),propogate(),optimize(),然后model(),改变学习速率learning_rate可以改变算法性能 第三周编程作业带有一个隐藏层的平面数据分类 构建具有单隐藏层的2分类神经网络 值得注意的一点是里面那个神经网络的结构图和实际构建的图是有出入的，数据规模是不一样的 使用非线性激活函数 计算交叉熵损失 实现前向和后向传播 数据格式： X: 2*400，表示的是每个数据有两个特征，一共有400个训练样本 Y：表示数据标签，规模是1*400，400个训练样本 X:(x1, x2) Y: red为0，blue为1 然后后面先做了简单logistic回归，再做单隐层神经网络 sklearn有内置做logisdic回归的函数 logistic regression准确率只有47%左右，因为数据集不是线性可分的，表现不佳 后面试神经网络模型 Recap一下： Steps： 定义神经网络结构 初始化模型参数 循环：完成前向传播，计算损失函数，完成后向传播获得梯度，更新参数(梯度下降) 先是定义各个层神经元结构，输入层几个，隐藏层几个，输出层几个 然后做初始化 方法是在初始化函数里对权值W做高斯随机初始化，然后偏执b初始化为0 真TM的坑，numpy的zeros函数接受参数是两个，random.randn接受的参数是元祖，这TM是哪个白痴设计的 后面开始前向传播 np.tanh函数可以直接用，它是内置在numpy里面的 从字典中取出元素： parameters[“..”] 然后用正向传播的方法计算了逐层的输出 np.squeeze函数 后面计算了cost function，简单用一下np.log和sum，进行向量化计算就行了 cache：缓存着各层神经元的线性输出值和激活值 反向传播的难点在于公式，如果公式知道了，反向传播也就很容易了 当然模板好在有公式可以套用，写起来就简单了 然后后面就是写Optimize函数了，梯度下降更新参数 最后写完了所有函数就是integratge into a complete model了 这边说一下我遇到的一个大坑，我在W初始化的时候W2忘记乘上一个小的系数了，最后导致在计算sigmoid的时候exp里面的参数特别大，但是我后来乘上0.01那个数还是特别大就不知道是怎么回事。因为如果那个值特别大的话，可能导致的结果是梯度消失，但numpy报错，说明那个已经大得离谱了，已经超时计算机表示范围了 第四周编程作业其中assignment1实现深层神经网络，然后assignment2应用此神经网络进行图像分类 assignment1实现构建深度神经网络的所有函数 使用非线性激活单元如ReLU 创建一个容易使用的神经网络类(编程中的代码规范问题) 表示：用[l]上标表示第l层的参数，用(i)表示第i个样本的对应值，用下标i表示某一层的某一个神经元单元 dnn_utils提供了必要的函数，是作者提供的 testCase提供了一些测试样例，用来评估整个网络的正确性 Outline： 对2层和L层神经网络implement initialization 完成前向传递模块，包括：线性，ReLU激活，整合，完成整个前向传播过程，然后最后用sigmoid来处理输出 计算cost function 完成反向传播模块，包括：线性，梯度导数，整合，完成整个反向传播过程 最后更新参数 后面正式开始写了 先是完成两层和多层神经网络参数初始化 注意在多层神经网络中，各层的神经元数被存放在layer_dims中。模板给的实现方法很简介，我特别喜欢 前向传播模块： 公式：$$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$$ 前向传播模块它只做了一步，没有一下子全部传播完，就是计算了一次传播，并把中间值：前层激活，当前层W，b缓存起来。然后另开一个函数去计算当前层的激活 关于激活函数，除了计算出当前层的激活值外，还缓存当前层激活和Z linear_activation_forward函数：接受前层激活，W，b和激活函数，计算传播并缓存中间量。LINEAR-&gt;ACTIVATION layer。缓存分为线性缓存和激活缓存 这部分代码我也比较喜欢，它把线性前传和缓存分开成一个单独的函数，总的就有两个函数，看起来比较舒服，不会是一个很长的函数的 然后对于L层深度神经网络，就是把上面的linear_activation_forward前传L-1次，模块化去实现，真的特别棒，这边需要稍微注意一下的一个point是完成L层前向传播的时候注意字典索引，每层的W和b是不同的 后面计算cost function，简单交叉熵损失 输入的是预测的概率向量(1,numofex)，以及给定的训练样本标签 后面计算后向传播，跟前面的前向传播类似，也是完成一层的后传，然后再完成L层后传。用来计算损失函数相对于parameters的各个梯度。三步走：线性后传，线性到激活(同层激活函数导数计算)，整体总和完成L-1次后传 第一个是线性后向传递，接受参数是损失函数对当前Z的计算导数，以及前传中获得的缓存cache，记录A,W,b，要返回dA,dW,db。这里要注意的一个点是在计算db的时候记得在np.sum里面加上选项keepdims=True，不加的话返回结果会是一个纯量，或者类似于(n,)这种形式，但是要求返回的是(1,1)的ndarry格式数据，这里也体现出了keepdims选项还是非常重要的 后面就是完成线性-&gt;激活后传，也就是在前面加上激活函数对原变量的导数项而已，没什么麻烦的，然后原作者已经把sigmoid和relu的导数分别封装成函数了，这种代码风格也非常棒。参数：dA，缓存项，以及激活函数值。这部分代码真的写得非常棒，值得学习，我估计得到积累很久才能写出这样水平的代码 后面就是写L层后传了，这个和L层前传不一样的地方是L层后传的初始化参数需要计算出来：1dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) # derivative of cost with respect to AL 这里就出现一个大坑了，L后传的整合函数里面涉及到前面一个shape的问题，在linear_back的地方，有个db在计算的时候需要制定axis=1和keepdims=True，如果不指定axis=1，前面测试不会出错，但是但这里，所有样本堆叠测试的时候就会出现shape不匹配的问题，所以这个给我的教训是任何时候要注意shape，在任何时候记住有axis和keepdims这两个选项！！！ 后面简单写一个更新参数的函数，比较简单，update W和b就行了 assignment2本课程的最后一个作业，用assignment1里完成的各个模块搭建一个完整的神经网络。要求搭建一个2层的和一个深层的 给定数据集包含了猫和非猫的数据，猫标签为1，非猫标签为0 每张图片的shape是(num_px,num_px,3)，3表示有3个通道 一共有209张训练的图片和50张测试的图片 在训练之前，需要对每张图片的数据进行标准化(列向量化)，也即flattern，标准化意味着把RGB值归一化到0-1之间，除以255即可。最后train的数据就是列向量堆叠，每一列代表一张图片，test也类似 通用方法学： 初始化参数/定义超参数 循环迭代若干次：前向传播，计算损失，反向传播，更新参数 使用训练好的模型来进行预测 关于浅层神经网络，需要注意的一点是在训练集上的准确率几乎到了100%，但是到测试集上只有72%，但是至少比logistic regression要好 5层神经网络在测试集上的准确率达到了80% 在下一节课中会讲如何系统选取超参数来提升神经网络的表现： learning_rate, layers_dims, num_iterations, and others 到此为此，第一个课的所有编程作业已经完成，接下来学习如何选择神经网路的参数，后面再学卷积神经网络，进度还算不错]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Paper Reading Notes, Hand Pose Estimation]]></title>
    <url>%2F2019%2F03%2F08%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0(%E6%89%8B%E5%8A%BF)%2F</url>
    <content type="text"><![CDATA[Paper Reading Notes. Learning to Estimate 3D Hand Pose from Single RGB Images(ICCV 2017)三个网络，一个用来抓取手部位置，类似于Object Localization，然后用一个网络定位2D手部关键点位置，然后根据2D关键点位置恢复出3D坐标 论文借鉴和使用了human pose estimation的一些方法 Hand pose representation: 用相对坐标系和平移的方法 HandSegNet: 将2D手部检测问题转化为一个分割问题，得到hand mask，然后提取手部和正则化 PoseNet: 对手部每个节点预测出一个二维热图，用encode-decoder结构 PosePrior: 得到21个节点的分布热图后，要推算出3D位置，首先要处理视角不变的问题(坐标变换) 最后再多个测试集上测试，一个符号语言识别数据集，来证明模型的泛化能力 它的数据获取还真的挺麻烦的，算是比较大的一项工作，先是用Mixamo对人物动作进行建模，然后用blender进行渲染成完整的3D图像(包含深度信息) 数据集说明数据集和POSE DATASET 1.1 数据集提供了41258个训练数据和2728个测试数据，每个样本提供： RGB图像(320*320 pixels) 深度图像(320*320 pixels) Segmentation masks(320*320 pixels)，包括background, person, three class for each finger and one for each palm 每个hand有21个keypoints(不知道uv coordinates是什么意思) 本征相机矩阵(这个应该是做视角无关的)Intrinsic Camera Matrix K Keypoints available: 0: left wrist, 1-4: left thumb [tip to palm], 5-8: left index, …, 17-20: left pinky,21: right wrist, 22-25: right thumb, …, 38-41: right pinky Segmentation masks available: 0: background, 1: person,2-4: left thumb [tip to palm], 5-7: left index, …, 14-16: left pinky, 17: palm,18-20: right thumb, …, right palm: 33 提供了Python版本和Matlab版本，函数是相同的 Open Source Code的文件结构： /: Root folder /view_samples.py: Script that shows basic use of the data for Python /evaluation/: Contains the split used for evaluation of our algorithm /evaluation/anno_training.pickle: Data structure for Python users containing keypoint annotations and camera matrices K /evaluation/color/: Color images /evaluation/depth/: 16Bits Depth maps, where the 8 top bits are stored in red and the lower 8 bits are stored in green channel /evaluation/mask/: Segmentation masks /training/: Contains the split used for training of our algorithm(子目录结构和/evaluation/一样) 数据表示：用所有关键点来描述手的3D坐标，做了简单normalization来做scale—invariant，s与相邻关键点之间的距离有关，就是把所有相邻距离都变成了单位长度，这么做是不是有点天真。。。 然后在3D空间的话相当于做了一个平移，文章用的是手掌关键点做root point 然后讲了怎么做3D的估计： 先做手势分割，这部分用的是别人提出的网络结构 然后做2D关键点检测，这部分用的是类似于最naive的MINIST的那种方法，score map，做likelihood match，这部分貌似也是用的前人成果 用姿态先验网络做3D手势估计 跑的结果的eval我放在QQ文件里面 整理一下代码结构： util是利用到的一个通用脚本文件，包含了绘制函数，构建网络的函数等等，net文件夹下面的是一个完整网络结构以及一个姿态后验估计网络代码(估计是最后一个网络的一部分) run.py这个脚本跑了一个前向，读取data目录下的图片，输入网络做前馈 run里用ColorHandPose3DNetwork来构建整个网络 后面整个逻辑就是把image_list里的图片依次取出来，resize，跑scoremap，跑crop，然后绘图，这个run.py逻辑反正很简单 网络架构部分就是说先做了分割segment，然后检测2D关键点位置，然后估计最可能的3D位置，最后上采样 后面就是几个子部分，做分割、检测2D手部关键点、姿态后验+视角变换网络根据给定的输出预测最可能的3D位置 视角变换网络做了一个旋转估计 另外还做了标准坐标系到真实xyz的变换，实际上的话后验估计的网络都是转化为左手情况并在标准坐标系下去做估计的，所以需要转换为人们可以认知的xyz，旋转也是同理，视角那部分做了旋转估计，才能进行norm，不过之后还是要旋转回去的 另外的train代码反正就是训练神经网络的，网络内部结构也不好说，很多都是经验之说 还有就是现在有很多成果做了2D到3D的lifting，但是他们做的大部分都是body pose estimation，但是手部不一样，有自遮挡等等问题，并且可获得的数据量小，硬做的效果肯定不好 RGB compared to depth? RGB会丢失很多空间维度上的信息，比如关节之前的互相关性等 只用单视角RGB做2D到3D首先要解决的一个问题是scale歧义，所以他们训练的一部分是推知一个scale invariance的结构，也就是做个归一化。。。用了相对3D坐标来做平移无关 handsegment这部分网络的功能是提取出一整只手，从而可以做各种变换包括resize，从而简化网络的训练，这部分网络是很有必要的，并且手部分割再怎么做也做不出花来 posenet做出一个key point score map，用来做2D关键点检测，用编码译码的概率模型 postprior后验网络用来学习并预测相对，归一化的3D坐标，然后要说的就是这个网络不是直接预测实际3D坐标，而是做了一个变换，预测它在另一个坐标框架中的位置信息，并并行运行一个网络用来估计视角变换之类的信息，然后它会做一个对称变换，转换成都是左手的情况来做，预测旋转矩阵和做视角估计是一样的，如果非要说提升的话，视角估计这部分倒是有提升的空间 引入这个frame的效果是更容易做视角估计，因为分离的xyz会有三个方向，很容易会造成说难以学习到旋转矩阵，后面的实验也进行了这个测试 好吧论文里与历史比较这部分写的有点扯淡了(没有可以比较的对象，强行扯了一个出来) 数据集的话提供了所有关键点的3D坐标，并提供了一个视角矩阵，估计就是用这个来做2D lifting to 3D的，包括视角估计/旋转矩阵的估计，并根据前层网络输出的score map并行估计数据在一个frame里的位置信息，结合这两部分的内容，最终还原出真实xyz信息 就这样了，别的也没了，感觉想法很简单啊，唯一说要有创新的就是引入了那个frame，很好地去解决了视角的问题，用的还是传统的监督学习策略，而且对数据集有很高的要求，不是一般的高，但是模型效果到底有多好真的很难说，因为前面没有人做过相关的研究，作为第一个吃螃蟹的，只能说作者们开辟了一条新的路 Dense 3D Regression for Hand Pose Estimation三个手势数据集：MSRA,NYU,ICVL 这篇文章说只用图像的深度信息变得越来越流行了 holistic regression直接把深度图的信息投射为3D参数比如关节角度和坐标等，这样就绕过了2D这一步，然后讲了这个策略的很多缺点，简而言之就是鲁棒性差 用CNN做2D的手势估计取得了巨大的成功 文章还是用了2D和3D结合方法去做，2D用的是FCN 深度图的意思是从一个视角看过去物体表面的距离，是CG的一个概念吧 这篇文章讲了现在做hand pose estimation的一个趋势是几乎全部都用深度图像，理由是传感器的普及。然后说传统的方法是把深度图像转换为3D体元表示，去做回归或者直接做检测，但是缺点是计算量特别大，所以作者打算绕过这一步，做所谓的dense regression 它做了一种参数重定义的策略，并且这种策略可以做到变换无关 现在比较常见的有两种，一种是two stage，先做2D关节点检测，再到3D，一种是直接回归3D，直接回归的好处是可以利用关节点之间的相互关系，并且现在表现好的也是one stage的 文章同时利用了深度图像的2D和3D信息 Depth-Based 3D Hand Pose Estimation: From Current Achievements to Future Goals分析不同CNN结构对于手的形状、关节可见度、视角和关节点分布的影响 3D测定体积的表示方法比2D CNN效果好很多 泛化能力依然比较弱(对于没有见过的手的形状效果依然不好) 大多数成功的方法把估计estimation任务当做一个学习任务，用随机森林或者CNN的方法。研究发现很多工业上现在用的系统用近邻匹配并且取得了很好的效果，但这种方法缺点也是明显的：泛化能力弱并且很吃数据，这些方法主要的问题是要scaling，合成数据的方法可以用来解决部分难点，但是 challenge的主要难度在于变化的视角、变化的手形、遮挡的问题，挑战指的是HIM2017，challenge有三个方面：单帧的手势估计、追踪以及手与物体的交互，paper主要关心的点是可见和不可见物体、关节可见度以及视角的分布 从21个手部关节的深度图中推测出3D位置，challenge的所有图片都提供了bounding box，所以不需要做定位，追踪tracking不是我们需要关心的问题 用于评价的数据来源于两个数据集：BigHand2.2M和FHAD，BigHand2.2M的特点是有许多个视角，FHAD的特点是有人和物体的交互动作 有做2D CNN以及用3D表示并投射到3D空间的，也有直接做3D CNN的，有做3D CNN估计空间每个体元关节点出现概率的 另外还有两种策略：Detection Based和Regression Based，基于检测的方法对于每个关节点生成一个概率密度图。而基于回归的方法则是把每个关节点映射到合适的位置上 看一下参考文献1，结合Region Ensemble Network 15和Deep Prior 29 层次模型：分层次分区域，然后fusion detection based策略比regression based策略好 层次结构的方法可以很有效地去解决遮挡的问题，层次貌似和RCN和REN有点像 区分multi-stage策略和层次化方法：multi-stage每次都是处理一整个手，每次在上面添加不同层次的信息，和2D-3D的做法比较像，然后层次化的方法就是每次处理手的不同部分 用depth图像的好处是可以解决很多RGB图像中遇到的歧义 Cross-model Deep Variational Hand Pose Estimation据说这篇文章强到能根据任意格式的输入图片进行3D还原并且能够进行逆过程 隐藏空间的统计学模型 半监督 这个隐藏空间latent space可以用来根据RGB图像直接估计3D hand pose，也可以不做修改地用到depth image上去 这篇文章说的是从图像中恢复手的3D configuration在VR/AR中有重要应用 从单目RGB图片来做恢复更具有挑战，相比于用depth image，用RGB做的还还有很大的研究空间 intro里讲的是它把2D关键点、图像和3D手势等根据隐藏表示嵌入到模型里，然后用独立译码器来重建 用depth做的策略有变化的自动编码器VAE和生成对抗网络GAN，但是要基于两个副本，一个用3D关节点做VAE，一个用depth image做GAN。需要一个结合两者的映射函数做fusion 文章在VAE的基础上做了延伸，算是一种通用的、泛化能力强的结构 手部姿态估计这个问题可以分为实时追踪和根据单帧图像进行分类的问题 一些基于深度图像的方法学习自定义的特征并预测关节点位置和3D关节角度，利用深度信息，可以转换为3D多视角或者是体元表示，作者表示他们的模型主要亮点是根据RGB去做estimate，但也可以用在depth image上，因为有latent space，Crossing-nets是和作者做的工作最相近的一篇文章(用的是VAE+GAN)，区别在于Crossing-nets需要做VAE和GAN之间的一个映射函数，而作者做的是仅仅基于VAE的，不需要映射，并且只要一个隐藏空间模型，Crossing-nets仅仅报告基于depth image做的实验结果。作者说他们做的效果可以和depth的state-of-art方法几乎持平，而在mere RGB的方法里是遥遥领先(当然一共也没几个做mere RGB的)，好的作者说现在仅仅做RGB到3D的只有17年ICCV的那一篇，哪一篇是multi-stage的，做图像分割，做2D关键点检测以及2D lifting to 3D 模型结构是成对的编码器和译码器(VAE)，辅助成对的编码译码器可以帮助做正则化，提升模型泛化能力，模型允许一种形态modality的输入，比如RGB和3D关节点，并允许输出RGB,2D和3D 看了intro和related work，感觉这篇论文TM的真的是太强了，不过作者也承认说是在历史的基础(VAE)上来做的，所以可以看到VAE有很大的潜力 因为手部自由度特别大，直接建模是不太可能的，所以很多论文是将其降维到低维子空间，然而用低维数据进行后验估计对数据集本身会提出要求，并且通过降维获取这样的数据集基本是不可能的 前面部分基本思路讲完了，就是说把不同的modality输入给编码器，然后这些特征有选择地去构造共享隐藏空间shared latent space，看做一种映射，然后译码器再从隐藏空间取出特征进行译码，并进行姿态估计，done，想法真的naive，不过就是这么厉害 后面开始讲各部分的实现细节和训练、比较等等，总的来说这个算是个拼凑的工作 实验：评估训练算法的效果以及得到的结果隐藏空间。通过三个不同的输入特征做：2D关键点位置，RGB图像以及深度图像，在实验中探究不同特征的结合的效果，预测3D关节位置。 相比于之前直接做3D坐标回归的文章，所用的编码器译码器size小很多 哇，这篇论文的代码是部分开源的。。。给了一个训练好的模型，以及一些评估脚本，然后就没了，github连注释都懒得写 半监督 半监督 半监督 纯依赖RGB的话只有最初的那篇文章，下面这篇都是引入了RGB-D来train，虽然最后并没有用D map 这篇文章要说缺点的话还是依赖数据，下面这篇倒是没有那么依赖，transfer比较简单 不知道这篇论文对RHD这个数据集算是批评还是褒扬，它说RHD视角变换多，噪声多 生成性能：可以生成连续样本 Weakly-supervised 3D Hand Pose Estimation from Monocular RGB Images仅用单目RGB来做的问题在于大量的深度信息歧义性，现在的一些方法需要有标注的3D坐标信息 作者打算用RGB-D的图片来train，但对于predict仅用RGB来预测3D坐标信息，这样就减轻了3D标注的负担(这部分工作量是相当大的) depth regularizer 手部姿态估计的作用在人机交互和虚拟现实中的作用巨大 标注的问题：2D信息标注可以直接从RGB图像中获得，而3D信息标注则完全需要人工 现在很多从2D图片提取3D信息的方法并不是广泛可用 作者们提出的这个depth regularizer其实也算是improvement of baselines 合成数据集和真实数据集的gap仍然存在 以前的3D标注是expensive和time-comsuming的 它也是用cascaded网络结构，之前16还是17年那篇也是cascaded，包括一个2D姿态估计网络和一个3D回归网络 depth regularizer是用来解决合成数据集和真实世界数据集之间的gap的 其实就是把3D label的loss替换成了这个depth map的loss，而depth map是容易获得的，就是想证明这个depth map提供的loss是可靠的 作者的工作： 弱监督：降低label的成本 端到端的适应模型：从完全标准到弱标注。depth regularizer提升准确率。 实验 21个关键点 2D姿态估计网络CPN：convolutional pose machine 3D回归网络3D regression network a depth regularier只在训练的时候用到 测试的时候只用2D网络和3D网络 它在训练的每个batch里的图片同时用了合成数据集和真实数据集(这个不知道为啥了)，难道只是为了解决那个gap吗 弱监督学习是先用RHD预训练模型，然后再RHD和STB混合训练 全监督是两个训练集分别单独训练 2D 姿态估计网络用编码译码结构网络，类似于VAE，输出21个关节的confidentce location 3D regression network: 作用是从2D热图中推测每个关节的深度信息，作者说他和传统2D lifting to 3D的区别在于它提取了其他的图像特征来防止歧义(同一个2D姿态可能对应多个3D手势) 最后测试的时候发现全监督模型+depth regularizer比所有state of art都好，但是迁移到另一个真实世界的数据集的时候效果出奇得差，这也验证了作者之前说的gap问题 所以这篇论文其实也间接指出了16年那篇论文的问题，就是数据集迁移的问题，我倒是没有注意16那篇有没有说在其他数据集(真实数据集上的评价效果) 现在貌似都在两个数据集上训练和评价，一个RHD合成数据集，一个STB真实世界数据集]]></content>
      <tags>
        <tag>Paper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac删除launchpad中无法正常删除的图标]]></title>
    <url>%2F2018%2F11%2F24%2FMac%E5%88%A0%E9%99%A4launchpad%E4%B8%AD%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%88%A0%E9%99%A4%E7%9A%84%E5%9B%BE%E6%A0%87%2F</url>
    <content type="text"><![CDATA[如何删除launchpad里一些无法正常删除的程序图标 一般launchpad里面应用可以通过两种方式删除： 用访达，在用户家目录的应用程序目录下找到对应的程序，直接删除即可。 直接进launchpad，按住option，点按应用，选择”x”删除即可。 但有些第三方应用无法用这两种方式删除，具体来说，有些应用不会出现在应用程序目录下，但却留在launchpad里面，还删不掉，超级恶心，已经两次碰到过这个问题了，就介绍一下删除这些应用的方法，以防日后的不测。 launchpad这个东西设计比较辣鸡，有很多bug，但总的来说找应用还算方便，但有了Alfrad，就不怎么打开launchpad了。有时候在总可能因为一些奇怪的操作，把一些应用或者文档弄到了launchpad里面，删不掉。出于强迫症，还是想让他变得干干净净的。 第一步，找到com.apple.dock.launchpad文件夹打开访达，按command+shift+G，在地址栏输入/private/var/folders，如下图所示： 然后再folders目录下找到一个名字为com.apple.dock.launchpad的文件夹，我的是在./6l/…/0/目录下。 获取数据库路径在这个文件夹下面继续走，找到名字为db的文件，它就是我们想要修改的数据库，右键这个文件，获取它的路径，如下图所示： 右键-&gt;显示简介 然后把路径复制下来 操作数据库获取数据库路径之后，打开终端，进入到上面的路径，如下图所示： 按照下面的格式输入命令删除第三方应用(或文档)即可1sqlite3 db &quot;delete from apps where title=&apos;应用名称&apos;;&quot;&amp;&amp;killall Dock 然后就可以把这些应用都删掉了 这里有几点要注意一下： 每次删除应用会重启一次dock，屏幕会黑一下，但马上就会好，不用担心。 直接操作数据库比较危险，因此应用名称记得一定要输准确，名字输错(输了一个不存在的应用程序)，可能会把文件夹都展开。 另外再说一点，launchpad还有个bug就是有时候会出现空的文件夹，这些空文件夹也不能用正常手段删除，一个简便可行的方法是把一个应用拖进这个文件夹，然后再拖出来，这个空文件夹就会自动消失。]]></content>
      <tags>
        <tag>Mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java笔记]]></title>
    <url>%2F2018%2F11%2F24%2FJava%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[参考菜鸟教程、实验楼、ZJU翁凯MOOC然后做的一些比较入门级的笔记 javac命令后面跟的是java文件的文件名，例如HelloWorld.java。该命令用于将.java源文件编译为class字节码文件，如：javac HelloWorld.java 运行javac命令后，如果成功编译没有错误的话，会出现一个HelloWorld.class的文件 java后面跟的是java文件中的类名字，例如HelloWorld就是类名，如：java HelloWorld java命令后面不要加.class java分为三个体系： JavaSE：平台标准版 JavaEE：平台企业版 JavaME：平台微型版 java程序员不需要管内存管理，支持类之间的单继承和接口之间的多继承。支持动态绑定 可移植性强，是解释型的，Java程序在Java平台上被编译为字节码格式，然后可以在实现这个Java平台的任何系统中运行，Java平台的解释器对这些字节码进行解释执行，执行中需要的类再联结阶段被载入到运行环境中。 高性能，接近于C++。是多线程的，提供多线程之间的同步机制，关键字synchronized 基础语法对象：对象是类的一个实例，有状态和行为。 类：类是一个模板，它描述一类对象的行为和状态。 方法：方法就是行为，一个类可以有很多方法。逻辑运算、数据修改以及所有动作都是在方法中完成的。 实例变量：每个对象都有独特的实例变量，对象的状态由这些实例变量的值决定。即实例变量是属于对象的。 注意事项： 大小写敏感，Hello和hello是不同的。 类名： 对于所有的类来说，类名的首字母应该大写。如果类由若干单词组成，那么每个单词的首字母应该大写，例如MyFirstClass。 方法名： 所有方法名应该以小写字母开头。如果方法名含有若干单词，则后面的每个单词首字母大写。 源文件名： 源文件名必须和类名相同。当保存文件的时候，应该使用类名作为文件名保存，文件后缀名必须为.java（如果文件名和类名不同会导致编译错误）。 主方法入口： 所有的java程序由public static void main(String []args)方法开始执行 Java标识符：不能是关键字 修饰符：分两类： 访问控制修饰符：default，public，protected，private 非访问控制修饰符：final，abstract，strictfp 变量：局部变量、类变量（静态变量）、成员变量（非静态变量） 数组：数组是储存在堆上的对象，可以保存多个同类型变量。 枚举：enum FreshJuiceSize{SMALL, MEDIUM, LARGE} 用.访问运算符访问枚举成员 利用继承的方法可以重用已存在的类的属性和方法，而不用重写这些代码。被继承的类称为超类（super class），派生类称为子类（subclass） 接口：可以理解为对象间相互通信的协议。接口在继承中很重要 接口只定义派生要用到的方法，方法的具体实现还是取决于派生类 支持的面向对象特性：多态，继承，封装，抽象，类，对象，实例，方法，重载 一个类可以包含局部变量（在方法，构造方法或者语句块中定义的变量，方法结束后自动销毁），成员变量（定义在类中，方法体之外，在创建对象的时候实例化，成员变量可以被类中的方法、构造方法和特定类的语句块访问）类变量（声明在类中，方法体之外，必须声明为static类型） 构造方法：每个类都有构造方法，如果没有显式指定，Java编译器会为该类提供一个默认构造方法。在创建对象时，至少要调用一个构造方法，构造方法的名称必须与类同名，一个类可以有多个构造方法（可以在一个构造方法里滴啊用另一个构造方法） 创建对象：三步： 声明：声明一个对象，包括对象名称和对象类型 实例化：用关键字new创建一个对象 初始化：使用new创建对象时，会调用构造方法初始化对象 访问实例变量可以用.运算符或者调用类中的方法 源文件声明规则一个源文件只能有一个public类 一个源文件可以有多个非public类 源文件的名称应该和public类的类名保持一致。 如果一个类定义在某个包中，那么package应该在源文件首行 如果源文件有import语句，应该放在package语句和类定义之前。如果没有package语句，那么import语句应该在源文件中最前面。import语句和package语句对源文件中定义的所有类都有效。在同一源文件中，不能给不同的类不同的包声明。 包：包主要用来对类和接口分类 import语句提供一个合理路径，使得编译器可以找到某个类 Java数据类型两大数据类型：内置数据类型和引用数据类型 八种基本类型 byte类型8位，主要用来替代int char类型是一个单一的16位Unicode字符，最小\u0000(即0)，最大值是\uffff(即65535) 引用类型： 类似于指针，指向一个对象，指向对象的变量是引用变量，在声明时被指定为一个特定类型。默认值null boolean类型不支持类型转换 强制类型转换，自动类型转换 Java变量类型在Java语言中，所有变量在使用前必须声明。 Java支持的变量类型有： 类变量：独立于方法之外的变量，用static修饰 实例变量：独立于方法之外的变量，没有static修饰 局部变量：类的方法中的变量 Java局部变量局部变量声明再方法、构造方法或者语句块中。 局部变量在方法、构造方法或者语句块被执行时候创建，当它们执行完后，变量会自动销毁。 访问修饰符不能用于修饰局部变量。 局部变量只在声明它的方法、构造方法或语句块中可见。 局部变量是在栈上分配的。 局部变量没有默认值，所以局部变量被声明后，它的作用域就限制在这个方法中。 Java实例变量实例变量声明在一个类中，但在方法、构造方法和语句块之外。 当一个对象被实例化之后，每个实例变量的值就跟着被确定。 实例变量在对象被创建的时候创建，在对象被销毁的时候销毁。 实例变量的值至少被一个方法、构造方法或者语句块引用，使得外部能够通过这些方式获取实例变量信息。 实例变量可以声明在使用前或者使用后，这是因为在创建对象的时候总是会先去初始化那些实例变量。 访问修饰符可以修饰实例变量。 实例变量对于类中的方法、构造方法或者语句块是可见的。一般情况下应该把实例变量设为私有，是封装的基本理念。可以通过访问修饰符使实例变量对子类可见。 实例变量具有默认值。数值型变量的默认值是0，布尔型变量的默认值是false，引用型变量的默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定。 在静态方法或者其他类中要访问实例变量需要用完全限定名。 Java类变量类变量也称为静态变量，在类中用static关键字声明，但必须在构造方法和语句块之外。 无论一个类创建了多少个对象，类只拥有类变量一份拷贝。 静态变量除了被声明为常量外很少使用。常量是指声明为public/private，final和static类型的变量。常量初始化后不可改变。 静态变量储存在静态存储区。经常被声明为常量，很少单独使用static声明变量。 静态变量在第一次被访问时创建，在程序结束时销毁。 与实例变量具有相似的可见性。但为了对类的使用者可见，大多数静态变量声明为public类型。 默认值和实例变量相似。数值型变量默认值是0，布尔型默认值是false，引用类型默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定。也可以在静态语句块中初始化。 静态变量通过ClassName.VariableName的方式访问。 类变量被声明为public static final类型时，类变量名称一般建议使用大写字母。 Java修饰符Java语言的修饰符主要分为： 1、访问修饰符 2、非访问修饰符 Java支持4种不同的访问权限 default（缺省）：在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。 private：在同一类内可见。使用对象：变量、方法。不能修饰类 public：对所有类可见。使用对象：类、接口、变量、方法 protected：对同一包内的类和所有子类可见。使用对象：变量、方法。不能修饰类 final方法：final方法可以被子类继承，但是不能被子类修改。 声明final方法的主要目的是防止该方法的内容被修改。 final类：不能被继承 abstract：抽象类，类似于接口类，声明抽象类的唯一目的是将来对该类进行扩充。抽象方法，是一种没有任何实现的方法，该方法的实现由子类提供。抽象方法不能被声明为final和static。任何继承抽象类的子类必须实现父类的所有抽象方法，除非该子类也是抽象类，这个就类似于C++中的纯虚函数了。也即抽象类中的抽象方法在抽象类中只需要提供声明，不需要提供实现，而需要在继承它的子类中实现对应的抽象方法。 synchronized修饰符： 这个关键字声明的方法同一时间只能被一个线程访问。 Java运算符大的可以分为：算术运算符，关系运算符，位运算符，逻辑运算符，赋值运算符，其他运算符。 ?:条件运算符，三元运算符。其他没什么好说的 instanceof运算符：用于操作对象实例，检查对象是否是一个特定类型（类类型或接口类型） 循环控制只说新出现的： Java增强for循环： Java5引入了一种主要用于数组的增强型for循环。 格式如下： for(声明语句:表达式) { //代码句子 } 声明语句：声明新的局部变量，变量类型必须和数组元素的类型匹配。作用域限定在循环语句块。 表达式：要访问的数组名，或者返回值为数组的方法。 break关键字： 主要用在循环语句或者switch语句中，用来跳出整个语句块。 continue关键字： 不说了 包裹类型：封包和解包以Character为例 Character：是char的包裹类型，处理char型对象，方法有： 1、isLetter()：判断是否是一个字母 2、isDigit()：判断是否是一个数字字符 3、isWhitespace()：判断是否是一个空格 4、isUpperCase()：判断是否是大写字母 5、isLowerCase()：判断是否是小写字母 6、toUpperCase()：指定字母的大写形式 7、toLowerCase()：指定字母的小写形式 8、toString()：返回字符的字符串形式，字符串的长度仅为1 Java String类在Java中字符串属于对象，Java提供了String类来创建和操作字符串 创建字符串： 1String greeting = "cainiao"; 在代码中遇到字符串常量时，编译器会使用该值创建一个String对象，可以使用关键字和构造方法来创建String对象。 String类不可修改 用于获取有关对象的信息的方法称为访问器方法。 String类的一个访问器方法是length()方法，返回字符串对象包含的字符数 12String site = "www.runoob.com";int len = site.length(); 连接字符串： 1string1.concat(string2); 返回string2连接string1的新字符串。也可以对字符串常量使用concat()方法。如： 1"我的名字是".concat("Runoob"); 更常用的是用’+’运算符来连接字符串： 1"Hello," + " runoob" + "!"; 创建格式化字符串： 使用静态方法format()可以生成格式化字符串 12String fs;fs = String.format("sdfasdfasdf"); //因为是静态方法，直接用类名调用即可 String方法： 1、chaAt():返回指定索引处的char值 2、compateTo():把这个字符串和另一个对象或者字符串比较，按字典序 3、concat():连接字符串 4、equals():将此字符串与指定的对象比较 5、length():返回此字符串的长度 6、toLowerCase():小写化 7、toUpperCase():大写化 8、trim():返回字符串的副本，忽略前导空白和尾部空白 其实java这些类很多方法和python十分类似，学习成本不高 StringBuffer和StringBuilder类当对字符串进行修改的时候，需要使用StringBuffer和StringBuilder类 和String类不同，StringBuffer和StringBuilder类的对象能被多次修改，并且不产生新的未使用对象 StringBuilder不是线程安全的，不能同步访问，但是StringBuilder相较于StringBuffer有速度优势，所以多数情况下建议使用StringBuilder类。但在应用程序要求线程安全的情况下，必须使用StringBuilder类。这个类的方法如下： Append：将指定的字符串追加到此字符序列 reverse：将此字符串序列用反转形式取代 delete：移除此序列的字符串中的字符，原型为public delete(int start, int end) Insert：将int参数的字符串表示形式插入序列中，原型为public insert(int offset, in i) replace：用String字符串替换此序列的子字符串中的字符，原型为replace(int start, int end, String str) Capacity：返回当前容量 charAt：获取此序列指定索引处的char值 indexOf：返回第一次出现的指定字符串在该字符串中的索引，有两种重构，indexOf(str)和indexOf(String str, int fromIndex)。第一种从头开始找，第二种从指定索引出开始找，返回第一次出现的指定子字符串在该字符串中的索引 length：返回长度 toString：返回序列中数据的字符串表示形式 Java数组Java语言提供的数组是用来存储固定大小的同类型元素 声明数组变量： 12dataType[] arrayRefVar; //首选方法dataType arrayReVar[] //效果相同，但不是首选 后面一种风格是C/C++风格，Java程序员建议使用第一种风格 创建数组： 1arrayReVar = new dataType[arraySize]; 上面语法语句做了两件事： 用dataType[arraySize]创建了一个数组 把新创建的数组的引用赋值给变量arrayReVar（Java对象变量是引用） 当然数组声明和创建可以用一条语句来完成： 1dataType[] arrayReVar = new dataType[arraySize]; 也可以直接初始化： 1dataType[] arrayRefVar = &#123;value0, value1, ..., valuek&#125;; 数组的元素是通过引用访问的。索引从0开始，一直到arrayRefVar.length-1 处理数组： 通常使用基本循环或者foreach循环（也成为增强型for循环，之前提到过，也能从目录直接导引过去，是从JDK 1.5开始引进的） 增强型for循环的优点在于可以不使用下标的情况下遍历数组 12345678910public class TestArray&#123; public static void main(String[] args)&#123; double[] myList = &#123;1.9, 2.9, 3.4, 3.5&#125;; //打印所有元素 for(double element:myList)&#123; System.out.println(element); &#125; &#125;&#125; 输出结果为： 12341.92.93.43.5 数组作为函数参数（传引用）： 123456789public static void printArray(int[] array)&#123; for(int i = 0; i &lt; array.length; i++)&#123; System.out.print(array[i] + " "); &#125;&#125;//调用printArray(new int[]&#123;3, 1, 2, 6, 4, 2&#125;); 数组作为函数返回值： 12345678public static int[] reverse(int[] list)&#123; int[] result = new int[list.length]; for(int i = 0, j = result.length - 1; i &lt; list.length; i++, j--) result[j] = list[i]; return result;&#125;//result数组作为函数的返回值 多维数组（数组的数组）： 12345678String str[][] = new String[3][4]; //二维数组是一个特殊的一维数组，每一个元素都是一维数组//分配空间type arrayName = new type[arraylength1][arraylength2];int a[][] = new int[2][3];//引用num[1][0]; Arrays类java.util.Arrays类能方便操作数组，它提供的方法都是静态的 功能有： 给数组赋值：通过fill方法 对数组排序：通过sort方法，按升序 比较数组：通过equals方法比较数组中元素值是否相等 查找数组元素：通过binarySearch方法能对排序好的数组进行二分查找法操作 函数原型： 1234public static int binarySearch(Object[] a, Object key);public static boolean equals(long[] a, long[] a2);public static void fill(int[] a, int val);public static void sort(Object[] a); 日期和时间Java.util包提供了Date类来封装当前的日期和时间。Date类提供两个构造函数来实例化Date对象。 第一个构造函数使用当前日期和时间来初始化对象： 12Date()Date(long millisec) Date对象的方法： after：若调用此方法的对象在指定日期之前返回true，否则返回false。 before：和上面的反一下 clone：返回此对象的副本 compareTo：比较当前调用此方法的Date对象和指定日期。相等则返回0。 equals：子类重载，判断调用此方法的Date对象和指定日期是否相等，相等则返回true，否则返回false。 getTime：返回1970年1月1日00:00:00 GMT以来此Date对象表示的毫秒数 hashCode：返回此对象的哈希码值 setTime：用自1970年1月1日00:00:00 GMT以来time毫秒数来设置时间和日期 toString：把此Date对象转换为下面格式的String：dow mon dd hh:mm:ss zzz yyyy 其中dow是一周中的某一天(Sun, Mon, Tue, Wed, Thu, Fri, Sat) 日期比较： 1、使用getTime方法获取两个日期（自1970年1月1日经历的毫秒数值），然后比较这两个值 2、使用方法before(), after()和equals()。 3、使用compareTo方法，它是由comparable接口定义的，Date类实现了这个接口 SimpleDateFormat格式化日期： 这是一个以语言环境敏感的方式来格式化和分析日期的类。SimpleDateFormat允许用户选择任何自定义日期时间格式来运行。 这个还挺好用的 格式化转换需要格式，在创建对象的时候指定格式 休眠： Sleep()使当前线程进入停滞状态（阻塞当前线程），让出CPU的使用，不是让当前线程独自占用CPU资源，以留时间给其他线程执行的机会。 Calendar类： 设置和获取日期数据的特定部分： 是一个抽象类，在实际使用时实现特定的子类的对象，方法是使用getInstance方法 12Calendar c = Calendar.getInstance(); //默认是当前日期c.set(2009, 6, -1, 12); 正则表达式正则表达式定义了字符串的模式 可以用来搜索、编辑或处理文本 正则表达式不仅限于某一种语言 java.util.regex类包括下面的类： Pattern类：pattern对象是一个正则表达式的编译表示。Pattern类没有公用构造方法。要创建Pattern对象，必须首先调用公用静态编译方法，返回一个Pattern对象，该方法接受一个正则表达式作为它的第一个参数 Matcher类：对输入字符串进行解释和匹配操作的引擎。和Pattern类一样，Matcher没有公用构造，需要调用Pattern对象的matcher方法来获取一个Matcher对象 PatternSystaxException：非强制异常类，表示一个正则表达式模式中的语法错误 这部分和所有其他的正则表达式一样，特别复杂，等待学习 Java方法System.out.println() println()是一个方法 System是系统类 out是标准输出对象 方法是语句的集合，在一起执行一个功能 方法命名规则：第一个单词以小写字母作为开头，后面的单词用大写字母开头写，不用连接符。如：addPerson 123456修饰符 返回值类型 方法名(参数类型 参数名)&#123; ... 方法体 ... return 返回值;&#125; 方法包含一个方法头和一个方法体。方法的所有部分包括： 修饰符：可选，告诉编译器如何调用该方法。定义了该方法的访问类型 返回值类型：方法可能有返回值 方法名：方法的实际名称。方法名和参数表共同构成方法签名 参数类型：参数像一个占位符。方法被调用时，传递值给参数。这个值被称为实参或变量。参数列表是指方法的参数类型、顺序和参数的个数。参数可选，方法可以无参 方法体：方法体包含具体的语句，定义该方法的功能 方法调用：根据方法是否返回值来选择 值传递参数：和引用传递不同，对象变量存的是对象引用，也正是因为有引用，才支持了Java的垃圾回收机制 变量作用域： 变量作用域是程序中该变量可以被引用的部分 方法内定义的变量称为局部变量 局部变量的作用域从声明开始，直到包含它的块结束 局部变量必须声明后才可以使用 方法参数范围涵盖整个方法。参数实际上是一个局部变量 for循环的初始化部分声明的变量，其作用范围在整个循环 循环体内声明的变量其适用范围是从它声明到循环体结束。 所以在for里面int i可以省内存 命令行参数：如果希望运行一个程序的时候再传递给它消息，就要靠命令行参数给main函数实现。 构造方法：当一个对象被创建的时候，构造方法用来初始化该对象。构造方法和它所在类的名字相同，但构造方法没有返回值（可以有参数列表） 通常用构造方法给一个类的实例变量赋初值，或者执行其他步骤来创建一个完整对象。 不定义也有默认构造方法，它把所有成员初始化为0 可变参数typeName… parameterName 在方法声明中，在指定参数类型后加一个省略号(…)。 一个方法中只能指定一个可变参数，它必须是方法的最后一个参数。任何普通参数必须在它之前声明。 finalize()方法： 类似于析构函数，它在对象呗垃圾收集器析构（回收）之前被调用，这个方法叫做finalize()，它用来清除回收对象。 例如，可以使用finalize来确保一个对象打开的文件夹被关闭了。 在finalize()方法里，用户需要制定对象被销毁时要执行的操作 1234protected void finalize()&#123; //source code&#125; 关键字protected是一个限定符，它确保finalize方法不会被该类外的代码调用 Java的垃圾回收可以由JVM自动完成，如果选择手动回收垃圾，就可以用上面的方法 System.gc()：显式调用Java垃圾收集器 Java流(Stream)、文件(File)和IOJava.io包几乎包含了所有操作输入、输出需要的类。流类代表了输入源和输出目标 Java.io包中的流支持很多格式，比如：基本类型、对象、本地化字符集等 一个流可以理解为一个数据的序列。输入流表示从一个源读取数据，输出流表示向一个目标写数据 Java为I/O提供了强大的灵活的支持，使得其广泛应用于文件IO和网络编程中 读取控制台输入： Java控制台输入由System.in完成 获得一个绑定到控制台的字符流： 1BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); BufferedReader对象创建后，可以用read()方法从控制台读取一个字符，或者用readLine()方法读取一个字符串 每次调用read方法，它从输入流读取一个字符并把该字符作为整数值返回。流结束的时候返回-1。 从控制台读取字符串： 从标准输入读取一个字符串需要使用BufferedReader的readLine方法 它的一般格式是： 1String readLine() throws IOException JDK 5以后的版本也可以使用Java Scanner类来获取控制台输入，也是更简单的方法 控制台输出; print和println：这些方法都由类PrintStream定义，System.out是该类对象的一个引用 PrintStream实现write的最简单格式为： 1void write(int byteval) 下面演示使用write输出字符”A”和换行符： 12345678910import java.io.*public class WriteDemo&#123; public static void main(String args[])&#123; int b; b = 'A'; System.out.write(b); System.out.write('\n'); &#125;&#125; 注意write方法不经常使用，因为print和println方法用起来更方便 读写文件： 流被定义为一个数据序列。输入流用于从源读取数据，输出流用于向目标写数据 文件输入输出流： FileInputStream: 该流用于从文件读取数据，它的对象可以用关键字new来创建 可以使用字符串类型的文件名来创建一个输入流对象来读取文件： 1InputStream f = new FileInputStream("C:/java/hello"); 也可以用一个文件对象来创建一个输入流对象来读取文件，首先要用File()方法来创建一个文件对象： 12File f = new File("C:/java/hello");InputStream out new FileInputStream(f); 创建文件输入流之后，就可以使用下面的方法来操作流了： Close：关闭文件输入流并释放与此流有关的所有系统资源。抛出IOException异常 finalize：清除与该文件的连接。确保在不再引用文件输入流时调用其close方法。抛出IOException异常 read：从InputStream对象读取指定字节数据。返回整数值，表示下一字节数据。结尾则返回-1 read重载：read(byte[] r) 从输入流读取r.length长度的字节。返回读取的字节数，文件结尾则返回-1 available：不受阻塞地读流 FileOutputStream： 该流在打开文件进行输出前，如果目标文件不存在，那么该流会创建该文件 123OutputStream f = new FileOutputStream("C:/hava/hello");File f = new File("C:/java/hello");OutputStream f = new FileOutputStream(f); 流操作： Close：关闭此文件输出流并释放与此流有关的所有系统资源。抛出IOException异常 finalize：清除与该文件的连接，确保不再引用文件输入流时调用其close方法。抛出IOException异常 write：把指定字节写到输出流中 write(byte[] w)：重载，把指定数组中w.length长度的字节写到OutputStream中 在读写的时候注意一下数据编码即可，不要出现乱码 创建目录： File类中有两个方法创建文件夹： mkdir()方法创建一个文件夹，成功则返回true，失败则返回false。 mkdirs()方法创建一个文件夹和它的所有父文件夹 读取目录： 创建一个File对象并且如果它是一个目录，那么调用isDirectory方法会返回true 可以调用该对象上的list方法，来提取它包含的文件和文件夹列表 删除目录： 可以使用java.io.File.delete方法 需要保证该目录下没有其他文件才能正确删除，否则删除失败 可以用上面的这些类和方法来实现展示目录结构、递归删除目录的功能 1234567891011121314151617181920212223//一级展开目录:/tmpimport java.io.*;public class main&#123; //data public static void main(String[] args)&#123; String dirname = "/tmp"; File f1 = new File(dirname); if(f1.isDirectory())&#123; System.out.println("Directory: " + dirname); String[] s1 = f1.list(); for(String s:s1)&#123; File f = new File(dirname + "/" + s); if(f.isDirectory()) System.out.println(s + " is a directory!"); else System.out.println(s + " is a file!"); &#125; &#125; else System.out.println(dirname + " is not a directory!"); &#125;&#125; Java Scanner类java.util.Scanner是Java5之后出现的新特性，可以直接通过Scanner类来获取用户的输入，而不用前面那些复杂的IO类（前面那些IO类主要是为了了解和学习） 1Scanner s = new Scanner(System.in); Scanner类的next和nextLine方法可以获取输入字符串，在读取之前需要使用hasNext和hasNextLine来判断是否还有输入的数据 next方法的核心代码： 1234if(scan.hasNext())&#123; System str1 = scan.next(); System.out.println("输入的数据为: " + str1);&#125; nextLine方法的核心代码基本类似 next和nextLine的区别： next(): 一定要读取到有效字符后才可以结束输入 对输入有效字符之前遇到的空白，next方法会自动将其去掉 只有输入有效字符后才能将后面输入的空白作为分隔符或者结束符 next不能得到带有空格的字符串 nextLine(): 以Enter为结束符，也就是说nextLine方法返回的是输入回车之前的所有字符 可以获得空白 如果要读入int或float类型的数据，在Scanner类中也有对应支持，输入之前可以用hasNextXxx()方法检测数据类型，判断用户的输入char是否可以转换为小数或者整数格式 Java 异常处理异常指的是程序中的一些错误，并不是所有错误都是异常，错误有时候是可以避免的。 异常引发的原因有多种，通常包含： 用户输入了非法数据 要打开的文件不存在 网络通信时连接中断，或者JVM内存溢出 程序员需要掌握三种类型异常： 检查性异常：用户错误或问题引起的异常，是程序员无法预见的，比如打开一个不存在的文件 运行时异常：运行异常是可能被程序员避免的异常。运行时异常可以在编译时被忽略 错误：错误不是异常，而是脱离程序员控制的问题。比如当栈溢出时，一个错误就发生了，它们在编译时是检查不到的。 Exception类： 所有异常都是从java.lang.Exception类继承的子类 捕获异常可以用try catch代码块： 12345try&#123; //程序代码&#125;catch(ExceptionName e1)&#123; //catch块&#125; 多重捕获： 1234567try&#123; //程序代码&#125;catch(ExceptionName1)&#123; &#125;catch(ExceptionName2)&#123; &#125; 当try中的保护代码块发生一个异常时，try后面的catch块就会检查是不是要捕获的异常，如果异常发生在catch块，异常会传递到该catch块 throws/throw关键字： 如果一个方法没有捕获到一个检查性异常，那么该方法使用throws关键字来声明异常，然后在方法实现体里面用throw抛出异常 finally关键字用在创建try代码块后面执行的代码块，无论是否发生异常，finally代码块中的代码总是被执行，在finally代码块中，可以运行清理类型等收尾善后性质的语句。格式如下： 123456789try&#123; //程序代码&#125;catch(异常类型1 异常变量名1)&#123; //程序代码&#125;catch(异常类型2 异常变量名2)&#123; //程序代码&#125;finally&#123; //程序代码&#125; 其他关于异常没有什么好说的，日常写很少用到，用到再查就可以了 Java面向对象Java继承允许创建分等级层次的类 类的继承格式： 1234567class 父类&#123; &#125;class 子类 extends 父类&#123; &#125; 继承用来解决代码重复的问题 1234567891011121314151617public class Animal&#123; private String name; //动物的名字 private int id; //动物身份标签 public Animal(String myName, int myid)&#123; name = myName; id = myid; &#125; public void eat()&#123; System.out.println(name + "正在吃"); &#125; public void sleep()&#123; System.out.println(name + "正在睡"); &#125; public void introduction()&#123; System.out.println("大家好！我是" + id + "号" + name + "."); &#125;&#125; 这个animal类可以作为其他动物类的父类 12345678910111213//企鹅类public class Penguin extends Animal&#123; public Penguin(String myName, int myid)&#123; super(myName, myid); //调用父类构造函数 &#125;&#125;//老鼠类public class Mouse extends Animal&#123; public Mouse(String myName, int myid)&#123; super(myName, myid); &#125;&#125; 继承的特性： 子类拥有父类非private属性，方法（）实际上子类也有父类的private属性和方法，只不过被隐藏了 子类可以拥有自己的属性和方法，即子类可以对父类进行扩展 子类可以用自己的方式实现父类的方法，这个称为重载 Java的继承是单继承，但是可以多重继承，单继承就是一个子类只能继承一个父类，多重继承就是祖宗关系 提高了类之间的耦合性（这个是继承带来的坏处，耦合度高会造成代码间联系太过紧密，代码独立性差） 继承可以用extends和implements这两个关键字来实现，且所有类都是继承于java.lang.Object，这个Object是所有类的祖宗，当一个类没有继承关键字，则默认继承Object，这个特性在C++里面是没有的 1234567891011121314//extendspublic class Animal&#123; private String name; private int id; public Animal(Stirng myName, String myid)&#123; //初始化属性值 &#125; public void eat()&#123;&#125; public void sleep()&#123;&#125;&#125;public class Penguin extends Animal&#123; &#125; implements关键字主要用来实现接口，可以同时继承多个接口： 1234567891011public interface A&#123; public void eat(); public void sleep();&#125;public interface B&#123; public void show();&#125;public class C implements A, B&#123;&#125; super和this关键字： super关键字可以通过这个来实现对父类成员的访问，用来引用当前对象的父类 this关键字：指向自己的引用 12345678910111213141516171819202122232425class Animal&#123; public void eat()&#123; System.out.println("animal : eat"); &#125;&#125;class Dog extends Animal&#123; //overload public void eat&#123;&#125;&#123; System.out.println("dog : eat"); &#125; public void eatTest()&#123; this.eat(); //this自调用 super.eat(); //调用父类方法 &#125;&#125;public class Test&#123; public static void main(String[] args)&#123; Animal a = new Animal(); a.eat(); //父类吃 Dog d = new Dog(); d.eatTest(); //调用子类吃和父类吃 &#125;&#125; final关键字： 可以把类定义为不能继承的，即是最终类；或者用于修饰方法，表示该方法不能被子类重写，主要用作保护 12final class 类名&#123;&#125;修饰符(public/private/default/protected) final 返回值类型 方法名()&#123;&#125; 构造器： 子类不继承父类的构造器，只是调用。如果父类的构造器带有参数，必须在子类的构造器中显式通过super关键字调用父类的构造器并给出参数。 如果父类是默认构造器，那么在子类构造器中可以不用管父类构造 Java重写(Override)与重载(Overload)重写(Override)： 重写是子类对父类允许访问的方法的实现过程进行重新编写，返回值和形参都不变。重写的好处是子类可以个性化定制属于自己的方法。 12345678910111213141516171819202122class Animal&#123; public void move()&#123; System.out.println("动物可以移动"); &#125;&#125;class Dog extends Animal&#123; public void move()&#123; System.out.println("狗可以跑和走"); &#125;&#125;public class TestDog&#123; public static void main(String args[])&#123; Animal a = new Animal(); //Animal对象 Animal b = new Dog(); //Dog对象 a.move(); //执行Animal类的方法 b.move(); //执行Dog类的方法 &#125;&#125; 方法的重写规则： 参数列表必须完全和被重写的方法相同 返回类型必须完全与被重写的方法的返回值类型相同 访问权限不能比父类中被重写的方法的访问权限更低。一般都是一样的权限，这一点倒是很少会注意到，既然有这么一条就写着吧 父类的成员方法只能被它的子类重写 声明为final的方法不能被重写，因为final是保护方法和类的 声明为static的方法不能被重写，因为static的是属于类的 子类和父类在同一个包中，则子类可以重写父类的所有方法，除了声明为private和final的方法。private的话子类也不能访问，final本身提供了保护 子类和父类不在同一个包中，则相比上一条，子类不能重写父类的friendly方法了，因为friendly表示同包访问权限 构造方法不能重写 如果不能继承，就不重写 重载(Overload)： 重载是在同一个类中，方法名字相同而参数不同，返回值类型可以相同可以不同 每个重载的方法（或构造函数）都必须有一个独一无二的参数型列表 最常见的重载是构造函数的重载 重载规则: 被重载的方法必须改变参数列表（参数个数或类型不同） 被重载的方法可以改变返回值类型 被重载的方法可以改变访问修饰符 方法可以在同一个类中或者在一个子类中被重载 无法以返回值作为重载函数的区分标准 方法的重写和重载是Java多态性的不同表现 Java多态多态是同一个行为具有多个不同表现形式或形态的能力 多态是一个接口，使用不同的实例而执行不同操作 多态的优点： 消除类型之间的耦合关系 可替换性 可扩充性 接口性 灵活性 简化性 多态存在的三个必要条件： 继承 重写 父类引用指向子类对象 虚方法子类可以重写父类的方法，当子类调用重写的方法时，调用的是子类的方法，而不是父类中被重写的方法，被重写的方法是可以动态绑定的，如果像调用父类中被重写的方法，则必须使用关键字super 多态的实现方式： 重写overwtire 接口interface 抽象类和抽象方法 Java抽象类在面向对象中，所有的对象都是通过类来描绘的，但不是所有类都是用来描绘对象的，如果一个类没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类 抽象类除了不能实例化对象之外，类的其它功能依然存在，成员变量，成员方法和构造方法的访问方式和普通类一样 抽象类不能实例化对象，所以抽象类必须被继承，才能使用 通过abstract来定义抽象类： 123456789101112131415161718192021222324252627282930313233public abstract class Employee&#123; private String name; private String address; private int number; public Employee(String name, String address, int number)&#123; System.out.println("Constructing an Employee"); this.name = name; this.address = address; this.number = number; &#125; public double computePay()&#123; System.out.println("Inside Employee computePay"); return 0.0; &#125; public void mailCheck()&#123; System.out.println("Mailing a check to " + this.name + " " + this.address); &#125; public String toString()&#123; return name + " " + address + " " + number; &#125; public String getName()&#123; return name; &#125; public String getAddress()&#123; return address; &#125; public void setAddress(String newAddress)&#123; address = newAddress; &#125; public int getNumber()&#123; return number; &#125;&#125; 抽象方法： 如果该方法的具体实现可以由它的子类确定，那么可以在父类中声明该方法为抽象方法 Abstract关键字可以用来声明抽象方法，抽象方法只包含一个方法名，没有方法体 1234567public abstract class Employee&#123; private String name; private String address; private int number; public abstract double computePay();&#125; 声明抽象方法会造成以下两个结果： 如果一个类包含抽象方法，那么该类必须是抽象类 任何子类必须重写父类的抽象方法，或者声明自身为抽象类 继承抽象方法的子类必须重写该方法。否则，该子类也必须声明为抽象类。实现后才能实例化对象 Java封装Encapsulation是一种将抽象是函式接口的实现细节部分包装、隐藏起来的方法。 封装被认为是一个保护屏障，防止该类的代码和数据被外部类定义的代码随机访问。 封装的优点 良好的封装能减少耦合 类内部的结构可以自由修改 可以对成员变量进行更精确的控制 隐藏信息，实现细节 实现封装的步骤： 修改属性的可见性： 1234public class Person&#123; private String name; private int age;&#125; 将name和age属性设置为私有，只能本类才能访问，其他类访问不了，这样就实现了对信息的隐藏 Java接口Interface，在Java语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个雷通过继承接口的方式，从而来继承接口的抽象方法。接口不是类，编写接口的方式和类很相似，但它们属于不同概念。类描述对象的属性和方法。接口则包含类要实现的方法。 除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。 接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内描述的所有方法，否则就必须声明为抽象类。另外，Java中接口类型可用来声明一个变量，他们可以成为一个空指针，或者绑定一个以此接口实现的对象。 接口与类的相似点： 一个接口可以有多个方法 接口文件保存在.java结尾的文件中，文件名使用接口名 接口的字节码文件保存在.class结尾的文件中 接口相应的字节码文件必须在于包名称相匹配的目录结构中 接口与类的区别： 接口不能用于实例化对象 接口没有构造方法 接口中所有方法必须是抽象方法 接口中所有方法必须是抽象方法 接口不能包含成员变量，除了static和final变量 接口不是被类继承了，而是要被类实现 接口支持多继承 接口特性： 接口中每一个方法也是隐式抽象的，接口中的方法会被隐式指定为public abstract 接口中可以含有变量，但是接口中的变量会被隐式指定为public static final变量 接口中的方法是不能在接口中实现的，只能由实现接口的类来实现接口中的方法 抽象类和接口的区别： 抽象类中的方法可以有方法体，但是接口中的方法不行 抽象类中的成员变量可以是多种类型的，而接口类中的变量只能是public static final类型的 接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法 一个类只能继承一个抽象类，而一个类却可以实现多个接口 接口声明： 1234interface 接口名称 [extends 其他的接口名]&#123; //声明变量 //声明抽象方法&#125; 接口隐式抽象，当声明一个接口的时候，不必使用abstract关键字 接口中每个方法也是隐式抽象的，声明不需要abstract关键字 接口中的方法都是公有的 1234interface Animal&#123; public void eat(); public void travel();&#125; 接口的实现： 当类实现接口的时候，需要实现接口中的所有方法，否则，类必须声明为抽象的类。 类使用implements关键字实现接口。类声明中，implements关键字放在class声明后面 实现一个接口的语法： 1...implements 接口名称 实现接口方法的时候记住要保持一致的方法名，和相同或兼容的返回值类型 如果实现接口的类是抽象类，那么就没有必要实现接口的方法 一个接口可以继承另一个接口，和类之间的继承方式比较相似。接口的继承用extends关键字，子接口继承父接口的方法 Java包Package 为了更好地组织类，Java提供了包机制，用于区别类名的命名空间 包的作用： 把功能相似或相关的接口组织在同一个包中，方便类的查找和使用 如同文件夹一样，包也采用了树形目录的存储方式。同一个包中的类名字是不同的，不同的包中的类的名字可以相同，当调用不同包中相同类名的类时，应该加上包名加以区分 包限定了访问权限，拥有包访问权限的类才能访问某个包中的类 Java使用包这种机制是为了防止命名冲突，访问控制，提供搜索和定位类、接口、枚举和注释等 包语法： 1package pkg; 包声明应该放在第一行 import关键字：导入包 1import pkg; Java高级主题Java数据结构 枚举（Enumeration） 位集合（BitSet） 向量（Vector） 栈（Stack） 字典（Dictionary） 哈希表（Hashtable） 属性（Properties） 上面的数据结构是传统遗留的，在Java2中引入了一种新的框架-集合框架（Collection） 枚举（Enumeration）枚举接口虽然本身不属于任何数据结构，但它在其他数据勾结的范畴里应用很广。枚举接口定义了一种从数据结构取回连续元素的方式。 枚举定义了一个叫nextElement的方法，该方法用来得到一个包含多个元素的数据结构的下一个元素。 123456789101112131415161718192021import java.util.Vector;import java.util.Enumeration; public class EnumerationTester &#123; public static void main(String args[]) &#123; Enumeration&lt;String&gt; days; Vector&lt;String&gt; dayNames = new Vector&lt;String&gt;(); dayNames.add("Sunday"); dayNames.add("Monday"); dayNames.add("Tuesday"); dayNames.add("Wednesday"); dayNames.add("Thursday"); dayNames.add("Friday"); dayNames.add("Saturday"); days = dayNames.elements(); while (days.hasMoreElements())&#123; System.out.println(days.nextElement()); &#125; &#125;&#125; 位集合（BitSet）位集合实现了一组可以单独设置和清除的位或标志 该类在处理一组布尔值的时候非常有用 向量（Vector）向量（Vector）类和传统数组非常相似，但是Vector的大小能根据需要动态变化。 和数组一样，Vector对象的元素也能通过索引访问。 使用Vector类最主要的好处就是在创建对象的时候不必给对象指定大小，它的大小会根据需要动态变化。 Vector类实现了一个动态数组，和ArrayList类似，但是两者是不同的： Vector是同步访问的 Vector包含了许多传统方法，这些方法不属于集合框架 Vector主要用在事先不知道数组的大小，或者只需要一个可以改变大小的数组的情况 Vector类支持四种构造方法： 1234Vector();Vector(int size);Vector(int size, int incr);Vector(Collection c); 除了从父类继承的方法外Vector还定义了以下方法： add：在向量的指定位置插入指定的元素，add(int index, Object element) add：提供了末尾添加的重载方法，add(Object element) capacity：返回此向量当前的容量 clear：从向量中移除所有元素 clone：返回向量的一个副本 contains：如果此向量包含指定的元素，则返回true equals：比较指定对象与此对象的相等性 get：返回向量中指定位置的元素，参数为索引值 indexOf：返回此向量中第一次出现的指定元素的索引，从index处正向搜索，如果未找到该元素，则返回-1 lastIndexOf：返回向量中最后一次出现指定元素的索引，如果未找到则返回-1 isEmpty：判断是否为空 firstElement：返回向量的第一个组件 lastElement：返回向量的最后一个组件 remove：移除指定位置的元素 size：和capacity不同，返回的是现在向量中的组件数 toString：返回此向量的字符串表示形式，其中包含每个元素的String表示形式 elements：返回此向量组件的枚举，可以直接赋值给枚举变量 remove:两类重载，接受index参数或者Object参数，移除指定位置的元素或者移除指定元素的第一个匹配项 removeAll：移除所有指定元素，接受Collection参数 toArray：返回一个数组 toString：返回一个字符串 栈（Stack）栈（Stack）实现了一个后进先出（LIFO）的数据结构 可以把栈理解为垂直分布的栈，当添加一个元素时，就将新元素放在其他元素的顶部 当从栈中取出元素的时候，就从栈顶取一个元素。换句话说，最后进栈的元素最先被取出。 是Vector一个子类，Stack定义了默认构造用来创建空栈 empty:测试堆栈是否为空 peek:查看栈顶对象并不移除 pop:移除栈顶对象并返回 push:把项压入堆栈顶部 search:返回对象在栈中的位置，以1位基数 字典（Dictionary）字典（Dictionary）类是一个抽象类，它定义了键值映射到值的数据结构 当想要通过特定的键而不是整数索引来访问数据的时候，应该使用Dictionary 由于Dictionary类是抽象类，所以它只提供了键映射到值的数据结构，而没有提供特定的实现 和Map类相似。 element:返回值的枚举 get:返回指定键对应的值 isEmpty:测试字典是否为空 keys:返回键的枚举 remove:接受key参数，从字典中移除指定key put:put(Object key, Object value),将指定key映射到该字典中指定的value size:返回条目的数量 Dictionary类已经过时了，在实际的开发中，常常使用Map 哈希表（Hashtable）Hashtable类提供了一种在用户键结构的基础上来组织数据的手段 Hashtable现已经集成到集合框架中。和HashMap类似，但是支持同步 构造方法： Hashable() Hashtable(int size) //创建指定大小的哈希表 Hashtable(int size, float fillRatio) //创建指定大小的哈希表，并根据fillRate填充 Hashtable(Map m) //以m中元素为初始化元素的哈希表 Hashtable除了实现Map接口中定义的方法之外，还自定义了其他的方法 clear: 清空哈希表，使其不包含任何键值 contains: 给的参数是值，测试是否存在对应的键 isEmpty: 判断哈希表是否为空 size: 返回键的数量 toString: 返回Hashtable的字符串形式 属性（Properties）Properties继承于Hashtable.Properties类表示一个持久的属性集，水星列表中每个键及其对应值都是一个字符串 Properties类被许多Java类使用。 集合框架Java的集合框架主要包括两种类型的容器，一种是集合(Collection)，存储一个元素集合，另一种是图(Map),存储键值映射。Collection接口有三种子类型：List, Set和Queue，再下面是抽象类，再下面是具体实现类，常用的有ArrayList, LinkedList, HashSet, LinkedHashset。集合框架提供了一套性能优良，使用方便的接口和类。Java集合框架位于java.util包里，所以使用集合框架的时候需要导包。 集合接口 Collection接口：是最基本的集合接口，一个Collection代表一组Object，存储一组不唯一，无序的对象 List接口：是一个有序的Collection，支持0索引。存储不唯一，有序的对象 Set接口：与Collection一样，只是不允许重复 SortedSet接口：继承于Set保存有序集合 Map接口：存储键值对，提供key到value的映射 SortedMap：继承于Map，使Map保证升序排列 Set和List相比，Set无序不重复，List有序可以重复 Set访问效率低，删除和插入效率高 List和数组类似，可以动态增长。其实现类有ArrayList，LinkedList，Vector 使用迭代器进行遍历： 1234Iterator&lt;String&gt; ite = list.iterator();while(ite.hasNext())&#123; System.out.println(ite.next());&#125; 把链表变成相关容器再遍历： 12345String strArray = new String[list.size()];list.toArray(strArray);for(int i=0;i&lt;strArray.length;i++)&#123; System.out.println(strArray[i]);&#125; Java泛型generics。和C++泛型差不多，具体要用可以再查，平时练习是用不到的。 泛型方法：方法在调用时可以接收不同类型的参数。根据传递给泛型方法的参数类型。编译器适当地处理每个方法的调用 泛型类：在类名后面加上类型参数声明部分 类型通配符：1public static void getData(List&lt;?&gt; data)&#123;&#125; 差不多就完结了，后面一些比如序列化，网络编程之类的，平常也用不到，只有特定的开发场景中才可能会用到。另外Java Mooc笔记没有上传，因为没有全部看完。]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2F2018%2F11%2F24%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[正则表达式是一种文本模式，包括普通字符和特殊字符(也称为元字符)。正则表达式使用单个字符来描述、匹配一系列匹配某个句法规则的字符串。 在练Codewars的时候，意识到了正则表达式的重要性，尤其是在字符串处理方面。另外正则表达式在Linux文件操作上也比较重要。 之前多多少少接触过一点，但是也意识到了他的复杂性。如果说shell编程那一套是鬼画符，那么这个应该也是差不多的。 但是正则表达式在某些情况下真的特别好用(听说学会正则表达式还能提升成就感)，于是就下定决心入这个坑了。 简介?通配符匹配文件名中的0个或1个字符，而*通配符匹配0个或多个字符。相比于通配符，正则表达式功能更强大，而且更加灵活。实例： 1^[0-9]+abc$ 说明： ^匹配输入字符串的开始位置 [0-9]+匹配多个数字，[0-9]匹配单个，+匹配一个或多个 abc$匹配字母abc并以abc结尾，$表示输入字符串的结束位置 为什么要用正则表达式？ 测试字符串内的模式。称为数据验证 替换文本。使用正则表达式来识别文档中的特定文本，完全删除该文本或者用其他文本来替换他 基于模式匹配从字符串中提取子字符串 发展历史： 可以追溯到对人类神经系统如何工作的早期研究，科学家提出数学的方式描述神经网络。后来有科学家发表神经网络方面的文章正式提出了正则表达式的概念。 应用领域： 目前，正则表达式在众多软件中得到广泛应用，包括*nix(Linux, Unix等)、HP操作系统、PHP、C#、Java开发环境 语法正则表达式描述了一种字符串匹配的模式(pattern)，可以用来检查一个串中是否含有某种子串、将匹配的子串替换或者从某个串中提取出符合某个条件的子串等。 正则表达式的组件可以是单个字符、字符集合、字符范围、字符间的选择或者所有这些组件的任意组合 普通字符： 没有显式指定为元字符的所有可打印和不可打印字符。包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。 非打印字符： \cx: 匹配由x指明的控制字符 \f: 匹配一个换页符，等价于\x0c和\cL \n: 匹配一个换行符，等价于\x0a和\cJ \r: 匹配匹配一个回车符，等价于\x0d和\cM \s: 匹配任何空白字符，包括空格、制表符、换页符等等 \S: 匹配任何非空白字符 \t: 匹配一个制表符，等价于\x09和\cl \v: 匹配一个垂直制表符，等价于\x0b和\cK 特殊字符： 如果要匹配特殊字符，要进行转义 $: 匹配输入字符串的结尾位置 (): 标记一个子表达式的开始和结束位置 *: 匹配前面的子表达式零次或多次 +: 匹配前面的子表达式一次或多次 .: 匹配除换行符之外的任何单字符 [: 标记一个中括号表达式的开始 ?: 匹配前面的子表达式零次或一次 \: 将下一个字符标记为特殊字符 ^: 匹配输入表达式的开始位置 {: 标记限定表达式的开始 |: 指明两项之间的一个选择 限定符： 指定正则表达式的一个给定组件必须出现多少次才能满足匹配 *: 匹配前面的子表达式零次或多次 +: 匹配前面的子表达式一次或多次 ?: 匹配前面的子表达式零次或一次 {n}: n是一个非负整数，匹配确定的n次。例如’o{2}’用来匹配两个o {n,}: n是一个非负整数，至少匹配n次，例如’o{2,}’用来匹配两个或多个o {n,m}: m和n均为非负整数，最少匹配n次且最多匹配m次，例如’o{1,3}’匹配1-3个o 实例： 以章节号为例： 12345678//任何位数的章节标题/chapter [1-9][0-9]*///匹配0-99章/chapter [0-9]&#123;1,2&#125;///匹配1-99章/chapter [1-9][0-9]?/ 定位符： 定位符能够将正则表达式固定到行首或行尾，定位符用来描述字符串或单词的边界 ^: 匹配输入字符串开始的位置 $: 匹配输入字符串结尾的位置 \b: 匹配一个单词边界，即字与空格间的位置 B: 非单词边界匹配 限定符和定位符不能一起用 选择： 用圆括号将所有选择项括起来 反向引用： 不太明白 元字符 \: 将下一个字符标记为特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符 ^: 匹配输入字符串的开始位置 $: 匹配输入字符串的结束位置 *: 匹配前面的子表达式零次或多次 +: 匹配前面的子表达式一次或多次 ?: 匹配前面的子表达式零次或一次 {n}: n是一个非负整数，匹配确定的n次 {n,}: n是一个非负整数，至少匹配n次 {n,m}: 至少匹配n次，最多m次 .: 匹配换行符\n \r之外的任何单个字符 (pattern): 匹配pattern并获取这一匹配 (?:pattern): 非获取匹配 (?=pattern): 正向匹配预查 (?!pattern): 正向否定预查 (?&lt;=pattern): 反向肯定预查 (?&lt;!pattern): 反向否定预查 x|y: 匹配x或y [xyz]: 字符集合，匹配所包含的任意一个字符 [^xyz]: 负值字符集合，匹配未包含的任意单个字符 [a-z]: 字符范围，匹配指定范围内的任意字符 [^a-z]: 负值字符范围，匹配任何不在指定范围内的任意字符 \b: 匹配一个单词边界，也就是单词和空格间的位置 \B: 匹配非单词边界 \cx: 匹配由x指明的控制字符 \d: 匹配一个数字字符，等价于[0-9] \D: 匹配一个非数字字符，等价于[^0-9] \f: 匹配一个换页符 \n: 匹配一个换行符 \r: 匹配一个回车符 \s: 匹配任何空白字符，包括空白、制表符、换页符等 \S: 匹配任何非空白字符 \t: 匹配一个制表符 \v: 匹配一个垂直制表符 \w: 匹配字母、数字、下划线。等价于[A-Za-z0-9_] \W: 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_] \xn: 匹配n，其中n为十六进制转义值 \num: 匹配num，其中num是一个正整数 \nm: 标志一个八进制转义值或向后引用 \un: 匹配n，n是一个用四个十六进制数字表示的Unicode字符 运算符优先级从左到右计算，并遵循运算符优先级 优先级由高到低： \: 转义符 (),(?:),(?=),[]: 圆括号和方括号 *,+,?,{n},{n,},{n,m}: 限定符 ^,$,\,任何元字符，任何字符: 定位点和序列 |: 替换 匹配规则基本模式匹配 模式是正则表达式最基本的元素，是一组描述字符串特征的字符。 1^once 这个模式包含^，表示字符串开头，用来匹配那些以once为开头的字符串 1bucket$ 这个模式包含$，表示字符串结尾，用来匹配以bucket为结尾的字符串 1^bucket$ 表示只匹配bucket 字符簇： 1[AaEeIiOoUu] 确定重复出现： {x}的意思是前面的字符或字符簇只出现x次，{x,}的意思是前面的内容出现x或更多的次数，{x,y}表示前面的内容至少出现x次，至多出现y次。特殊字符*和{0,}是等价的，+和{1,}是等价的。 示例简单表达式： 1/a7M/ 匹配a7M 字符匹配： 12/a.7//filename\.txt/ 中括号表达式： 创建匹配字符组的一个列表 12/Chapter [12345]//Chapter [1-5]/ 中括号表达式的典型应用是指定任何大写或小写字母或数字匹配： 1/[A-Za-z0-9]/ 实验楼正则表达式基础grep, expr, sed, awk或vi中会经常用到正则表达式 正则表达式的特殊符号： [:alnum:]: 代表英文大小写字母和数字 [:alpha:]: 代表英文大小写字母 [:blank:]: 代表空格和tab键 [:cntrl:]: 代表键盘上的控制按键，如CR,LF,TAB,DEL [:digit:]: 代表数字 [:graph:]: 代表空白字符以外的其他 [:lower:]: 代表小写字母 [:print:]: 代表可以被打印出来的任何字符 [:punct:]: 代表标点符号 [:upper:]: 代表大写字母 [:space:]: 代表会产生空白的字符如空格，tab，CR等 [:xdigt:]: 代表十六进制数字类型 在使用正则表达式时需要留意语系，不同语系同一模式匹配结果可能有差异 通过grep命令使用正则表达式grep参数 -a: 将binary档案以text档案的形式搜索 -c: 计算找到“搜索字符串”的次数 -i: 忽略大小写，所以大小写视为相同 -n: 顺便输出行号 -v: 反向选择，即输出不包含搜索字符串的内容 []中包含的字符，只能是一个，-用来表示字符范围，[^…]排除型字符组，跟反向选择是一样的。例如： [abc]: 表示a或b或c [0-9]: 表示0-9中任意一个数字，等价于0123456789 [^a1&lt;]: 表示除a，1，&lt;外的任意一个字符 [^a-z]: 表示除小写字母外的任意一个字符 行首行尾控制，例如： ^[A-Z]: 表示以大写字母开头 $[A-Z]: 表示以大写字母结尾 重复次数控制： {}可以用来限定字符重复出现的次数 {n}: 表示只匹配n次 {n,}: 表示至少匹配n次 {n,m}: 表示至少匹配n次，至多匹配m次 通过sed命令使用正则表达式sed是非交互式编辑器。它不会修改文件。sed编辑器逐行处理文件，并将结果发送到屏幕。处理过程为：把当前正在处理的行保存到一个临时缓冲区中（也称为模式空间），然后处理临时缓冲区中的行，完成后发送到屏幕上，sed每处理好一行就把它从临时缓冲区中删除，然后读入下一行，进行处理和显示。处理完最后一行后，sed就结束运行。 1nl regular_express.txt | sed '2,5d' 2,5表示2到5行，d表示删除 1nl regular_express.txt | sed '2,$d' 删除2到最后一行 1sed -i '1d' regular_express 在源文件中删除第一行 扩展正则表达式知识点:egrep命令 可以使用grep -E 来使用扩展正则表达式，效果和egrep相同 挑战 找到登录shell为bash的用户: 1grep -n 'bash' user 找到UID或GID是5位数或以上的用户行记录 1grep -n '[0-9]\&#123;5,\&#125;' user 有主目录在/var/spo??l下的用户，但想不起来spo后面到底有几个o，找出满足条件的用户行记录 1grep -n '/var/spo\+l' user 已知有个用户其用户名形如 ‘mi..M’，中间有未知多个mi，找出该用户的用户行记录 1grep -n '[mi]\+M' user 至于输出到文件，简单重定向就完事了]]></content>
      <tags>
        <tag>Programming</tag>
      </tags>
  </entry>
</search>
