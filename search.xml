<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Cryptology]]></title>
    <url>%2F2020%2F02%2F21%2FCryptology%2F</url>
    <content type="text"><![CDATA[Interesting things in Cryptology CryptologyReferenceCryptology and Number Theory by Paul Garrett Course materials by Andrew Odlyzko]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Math</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Task List]]></title>
    <url>%2F2020%2F02%2F12%2FTask%20List%2F</url>
    <content type="text"><![CDATA[列一下近期要做的事情。。。 算是第一次在博客上自我反省（吐槽） 最近有些忙的爆炸的感觉，很多事情想做却都还没有做。 2月 强行被拉去再参加一次数学建模美赛，说是国际比赛但其实水分很大，不管怎么说还是好好准备认真对待吧。 Github上以前很多的project文档写的是真的烂，找个时间集中整理一遍，顺便把前几个学期的课程project也整理一下写个文档po上去。工作量巨大。(最后简单整理了一波了事) 知乎专栏不知道多久没更了，总结来说是自己太懒了，啥事都拖着没去做。 月底due的ECCV的project找点事情做，目前就照着模板写了个难度不大的证明，总感觉有点太混了。(等paper交了再勾掉。) 继续考虑一下怎么在CURE-OR数据集上做测试，和学长讨论。尽量把这部分做了。也算锻炼一下实验能力。更新：自我感觉做了不少事情，前一个test弄work了但是数据集问题就不要了。后面这个实验是学长挺久都没做出来的，我弄了一天给弄出来了，而且目前看来效果算是稳定，但是最近忙的有点炸，没太多时间去跑数据。 自学数学，要看一些数学书，计划先看抽代和实分析，后面泛函和傅里叶分析。 练练英语口语和听力，准备托福GRE再考。 N久没写算法题了，GitHub OJ repo已经拖更N久，ACM算法笔记也拖更N久。 当所有课程小组作业自己都要担任主力的时候，时间总是感觉不太够用。把小组作业都给做了。 养成修仙习惯，晚睡（已经做到）早起（比原来起得早了）。 把博客上以前开的坑（那么多）尽量填掉一些。 2月13号，不睡觉的一天。3081zybook assignment扎堆布置下来+scattering transform example，5521机器学习第一次作业还没开始写。加之明天的数模比赛要做很多data analysis，很久没动手了比较生疏。今天也自闭了一天，越来越觉得自己太菜，和我认为优秀的人差了老远。 2月17号，今天用一天的时间把CSCI5521布置下来两周完成的作业完成了，看来潜力还是有待发掘。虽然上个学期日常用2-3天完成两周的作业（CSCI5561），但感觉应该还是尽量早做，ddl不能赶的这么紧张。 找个时间去做一下scattering transfrom，感觉挺有潜力的，而且有机会做独立的工作。顺便把VAE的idea继续完善一下。 把孙老师发下来的关于俩project的paper都仔细看一下。感觉project都挺有意思，但是不太好上手，尤其是inverse problem的那个。 把博客几篇文章的坑填完，包括但不限于：Pytorch tutorial，Kaggle-Scikit learn，feature engineering，Cryptology。 密码学的书看上瘾了，虽然都是些高中数论知识。。。 申请UROP(funding) 申请奖学金 MUDAC想去，但是需要找靠谱的队友，但是如果时间紧张的就不去了呗 春假前这一周已经要忙爆炸了，这次是真爆炸 春假里边把密码学里边几个有意思的数论题证明写一下po一下 不鸽不鸽，坚决不能鸽了。好多事情都鸽了太久 3月 把二月没做完的事情继续做。 今年暑研在本校继续做或者去外校想想清楚，尽早申请。 被强行拉去参加数据分析比赛（全美？） 去申请一下SSN 普林斯顿算法课的第二部分的坑填完（超级大坑） 近似算法那个project的文档好好写的一遍，demo重新做一个（大坑） 机器学习书继续看，专栏笔记（大坑） 所有ddl赶完之后，强迫自己考GT 觉得自己不够聪明，做事不够有毅力，不够上进，这样下去不会抑郁吧 努力成为自己想成为的人，不能继续在舒适区划水，要能静下心来，强者的世界不需要休息 Be positive and be away from snobbish people. 想到再更]]></content>
      <categories>
        <category>Random</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Reading List]]></title>
    <url>%2F2019%2F11%2F09%2FReadling%20List%2F</url>
    <content type="text"><![CDATA[Readling List BooksMathematics先学分析 Fourier Analysis: An Introduction Complex Analysis Real Analysis: Measure Theory, Integration, and Hilbert Spaces Functional Analysis: Introduction to Further Topics in Analysis Real Mathematical Analysis 补两本优化 Convex Optimization: Algorithms and Complexity Convex Optimization 抽象代数 Abstract Algebra An Inquiry-based Approach First Course in Abstract Algebra (抽代入门书？) Algebra Statistics An Introduction to Statistical Learning The Elements of Statistical Learning Computer Science 机器学习，周志华 Deep Learning 算法导论，刘汝佳 (找比赛靠谱的队友) Elements of the Theory of Computation Neural Networks and Deep Learning 想到再更]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Mathematics</tag>
        <tag>Computer Science</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ACM Algorithm Note]]></title>
    <url>%2F2019%2F09%2F25%2FACM%20Algorithm%20Note%2F</url>
    <content type="text"><![CDATA[ACM算法笔记 欧拉回路欧拉回路存在的充要条件： 无向图：连通并且最多存在两个奇点（奇点：度数为奇数的点） 有向图：底图连通并且一个点入度比出度大1，一个点出度比入度大1，其他点入度等于出度 编程的时候DFS，最后判断一遍是否访问到所有节点就行了，用邻接矩阵表示图（因为要随时看边是否被访问过，邻接矩阵效率更高） 枚举排列升序枚举： 递归调用，一个参数为当前序列，一个参数为可选元素集合，在不可重集时没问题，在可重集的时候要保证下标不重复 关于升序排列，也可以利用C++ STL里面的next_permutation函数来执行： 1234567#include &lt;algorithm&gt;...;do &#123; for(int i=0; i&lt;n; i++) printf("%d ", p[i]); printf("\n");&#125; while(next_permutation(p,p+n));...; 而且next_permutaiton适用于可重集（那还自己写干啥-.-） 子集生成位向量法用一个位向量表示是否选取某个元素 123456789void print_subset(int n, int* B, int cur) &#123; if(cur == n) &#123; // print &#125; B[cur] = 1; print_subset(n, B, cur+1); // 选第cur个元素 B[cur] = 0; print_subset(n, B, cur+1); // 不选cur个元素&#125; 有点回溯剪枝的感觉 二进制法部分没看懂。。。 回溯深度优先 八皇后但是时间复杂度比较难算 素数环问题描述：把整数1，2，3，…，n组成一个环，使相邻整数和为素数 12345678910111213void dfs(int cur) &#123; if(cur==n &amp;&amp; isp(A[0]+A[n-1])) &#123; //print &#125; else for(int i=2; i&lt;=n; i++) &#123; // 1固定为环起点，位置无所谓，所以从2开始试 if(!vis[i] &amp;&amp; isp[i+A[cur-1]]) &#123; A[cur] = i; vis[i] = 1; // 记录访问，递归到下一层 dfs(cur+1); vis[i] = 0; //清除访问，试下一个(回溯剪枝) &#125; &#125;&#125; 状态空间搜索没看懂。。。 迭代加深搜索按深度由小到大进行搜索，基本假设是，如果解的深度有限，总能找到解。相比于普通DFS或者回溯的优点是，不会再一条路上走到stack over flow还找不到。 迭代加深每次只考虑深度不超过maxd的结点。 对于回溯求解但解答树室深度没有上限的题目，可以考虑使用迭代加深搜索。 没看懂。。。 分治多练题 动态规划关键字：状态、状态转移、最优子结构（全局最优解包含局部最优解） 状态和状态转移方程一起描述算法，也是动态规划的核心 记忆化搜索，逆序枚举可以优化时间复杂度 DP没啥好说的，多练题，练出来感觉就行了 辗转相除法辗转相除法（欧几里德算法，Euclid algorithm）的关键在于恒等式 $$gcd(a,b) = gcd(b,a mod b)$$ 边界条件$$gcd(a,0) = a$$ 123int gcd(int a, int b) &#123; return b == 0 ? a : gcd(b, a%b);&#125; 利用辗转相除法求最小公倍数：$$gcd(a,b) lcm(a,b) = ab$$ $$lcm(a,b) = a / gcd(a,b) * b$$ 注意一个细节：求最小公倍数的时候先除再乘，目的是为了避免大整数溢出 Eratosthenes筛法筛法基本思想：对于不超过$n$的每个非负整数$p$，删除$2p$，$3p$，$4p$，…，处理完所有数后，剩下没被删除的数就是素数。程序很简单： 1234memset(vis, 0, sizeof(vis));for(int i=2; i&lt;=n; i++) for(int j=i*2; j&lt;=n; j+=i) vis[j] = 1; 内层循环次数是$$\sum_{i=2}^{n} \frac{n}{i} = O(nlogn)$$来源于欧拉常数的公式 注意到两个细节：外层循环筛其实只要基于素数基就行，可以加一个判断条件以实现；内层循环可以从$i*i$开始，直观理解是，$i$乘以任何一个小于$i$的数都在之前的外循环被筛掉了。 综上两条，修改后的筛法如下(欧拉线性筛？核心是那条判断以及内循环的下界)： 1234int m = sqrt(n+0.5);memset(vis, 0, sizeof(vis));for(int i=2; i&lt;=m; i++) if(!vis[i]) for(int j=i*i; j&lt;=n; j++) vis[j] = 1; 不超过$x$的素数约有(素数定理)：$$\frac{x}{lnx}$$ 扩展欧几里德算法问题：求直线$ax+by+c=0$上有多少个整点$(x,y)$满足$x\in[x_1,x_2], y\in[y_1,y_2]$。 原理比较复杂，涉及素数的线性分解 同余与模算术基本公式：$$(a+b) \ mod \ n = ((a \ mod\ n)+(b\ mod\ n))\ mod n \(a-b) \ mod \ n = ((a \ mod\ n)-(b\ mod\ n)+n)\ mod n \ab \ mod \ n = (a\ mod \ n)(b \ mod \ n) \ mod n$$幂取模的分治实现： 1234567int pow_mod(int a, int n, int m) &#123; if(n == 0) return 1; int x = pow_mod(a, n/2, m); long long ans = (long long)x * x % m; if(n%2 == 1) ans = ans * a % m; return (int) ans;&#125; 数论中的计数问题由数的唯一分解定理$$n = p_1^{a_1}p_2^{a_2}p_1^{a_2} \cdot \cdot \cdot p_k^{a_k}$$$n$的正约数个数为$$(a_1+1)(a_2+1)\cdot \cdot \cdot(a_k+1)$$欧拉函数(计数小于$n$且与$n$互素的数的个数)：$$\phi(n) = n(1-\frac{1}{p_1})(1-\frac{1}{p_2})\cdot \cdot \cdot (1-\frac{1}{p_k})$$计算欧拉函数(其中有个找素因子的trick，自己体会) 1234567891011int euler_phi(int n) &#123; int m = (int)sqrt(n+0.5); int ans = n; for(int i=2; i&lt;=m; i++) if(n % i == 0) &#123; ans = ans /i * (i-1); while(n % i == 0) n /= i; // 这就是那个trick，自己体会 &#125; if(n &gt; 1) ans = ans / n * (n-1); // 这种情况，处理的应该是n本身未素数的情况 return ans;&#125; 求1-n中所有数的欧拉函数值，复杂度为$O(nlognlogn)$，算法如下(是一种自底向上枚举素数的做法，有点难解释) 123456789void phi_table(int n, int* phi) &#123; for(int i=2; i&lt;=n; i++) phi[i] = 0; // 初始化 phi[1] = 1; // 初始化 for(int i=2; i&lt;=n; i++) if(!phi[i]) // 外层循环枚举素数 for(int j=i; j&lt;=n; j+=i) &#123; if(!phi[j]) phi[j] = j; // 赋初值n phi[j] = phi[j] / i * (i-1); // 参见欧拉函数 &#125;&#125; (Working in progress)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>C++</tag>
        <tag>Algorithm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OCaml Learning Notes]]></title>
    <url>%2F2019%2F09%2F12%2FOCaml%20Learning%20Notes%2F</url>
    <content type="text"><![CDATA[OCaml Notes, CSCI 2041, DNA of programming languages. Part 1: BasicsPart 1 is a basic introduction of OCaml syntax and characteristics as a functional language. Also we introduce some mechanism such as pattern matching and polymorphism to make it distinguished. First of all, the best REPL choice is utop program running under the terminal. Under this interactive environment, the OCaml phrases terminated with ;; will be evaluated. User inputs (system command) are specified with # at the beginning. Type assertion: exp : typ. The type assertion is said to be valid iff the expression exp has type typ. BindingBinding is permanent and can not be changed within specific scope of the program (normally the global scope). Syntax of type binding: 1type tycon = typ Semantics: tycon is a type constructor, bound to type typ Syntax of value binding: 1let var : typ = exp Semantics: var is a variable, introduced the type typ and value exp. Notice that we must specify both the type and value of this type. There will be type-checking when binding, if succeed, expression exp will be evaluated first, and then its value is bound to variable var. If exp does not have a value, then binding never happens. (Notice that None is a value.) Variable name must start with a lowercase letter or an underscore and excludes other punctuations. Purpose of binding: Make a variable or type constructor available for use within its scope. Substitution principle: A bound variable or type constructor is implicitly replaced by its binding prior to type checking and evaluation. Compound Declarations (Bindings): This is defined by sequential bindings of the form dec1, dec2, …decn, with nested scope. Binding is not assignment: The binding of a variable never changes, once bound to a value, it is always bound to that value (within the scope of the binding). But we can shadow a binding by introducing a second binding for a variable within the scope of the first binding. One might say that old bindings never die, they just fade away. Type environment records the types of variables. Value environment records their values. local binding: 1let x = u in v The binding of x to the result of u is only visible within the expression v. The semantics is to evaluate u first and bind to variable x, finally evaluate v with this bounded variable x. Notes: local binding shadowing only happens during that binding period, for example: 1234let x = 1let y = let x = 2 in xlet z = x + 2(* z will be binded to 3, not 4 because the global binding of x becomes visible again *) Primitive Data Types int (31-bit sign int on 32-bit processors or 63-bit sign int on 64-bit processors) float (IEEE double-precision floating point) booleans 12345# (1 &lt; 2) = false;;- : bool = false# let one = if true then 1 else 2;;val one : int = 1 characters (8-bit) 12345# 'a';;- : char = 'a'# int_of_char '\n'- : int = 10 unit () Unit type is useful in signaling the completion of some program. Ex: 12match print_endline "first string" with| () -&gt; print_endline "second string" immutable character strings 12# "Hello" ^ " " ^ "world";;- : string = "Hello world" Compound Data Types: Tuples 1# let a_tuple : int * string = (3, "three");; A tuple is an ordered collection of values that can each be of a different type. Lists Actually List is a build-in variants: 1type 'a list = [] | (::) of 'a * 'a list 12345# let l = ["is"; "a"; "tale"; "told"; "etc."];;val l : string list = ["is"; "a"; "tale"; "told"; "etc."]# "Life" :: l;;- : string list = ["Life"; "is"; "a"; "tale"; "told"; "etc."] 123# [1; 2; 3];;# 1 :: (2 :: (3 :: []));;# 1 :: 2 :: 3 :: [];; The bracket notation is a syntax sugar for ::. :: is right-associative. @ can be used to concatenate two lists. (not a constant-time operation) 1# [1; 2; 3] @ [4; 5; 6];; Options This is also a built-in variants: 1type 'a option = None | Some of 'a An option is used to express that a value might or might not be present. 12# let divide x y = if y = 0 then None else Some (x/y) ;; Keywords Some and None are construtors that let us build optional values. To examine the contents of an option, we use pattern matching. The None type is useful in many situations, for example, when allocating memory, if the allocation fails, return None value is usually a good choice. Records We can also define our own data type. 1# type point2d = &#123; x : float; y : float&#125;;; Dot notation for accessing record fields: 123let magnitude &#123; x; y&#125; = sqrt (x ** 2. +. y ** 2.);;# let distance v1 v2 = magnitude &#123; x = v1.x -. v2.x; y = v1.y -. v2.y&#125;;; FunctionOCaml use typer inference to work out the types. OCaml doesn’t do any implicit casting nor do any automatic conversion. A function which takes input of type a and can often give an output of type b may declare itself as type a -&gt; b option, indicating that it may give a None value for some reason. Function ExpressionFunction is an expression which can be evaluated. 12345(* syntax for a function expression*)fun n -&gt; n + 1;;(* applying a function to a value *)(fun n -&gt; n + 1) 2;; Function typeEach function has a type, which can be writen as: 1a -&gt; b Where a is its domain, and b is its codoman. The arrow operation is right-associative, so the following two type specifications are the same: 12int -&gt; (int -&gt; (bool -&gt; int))int -&gt; int -&gt; bool -&gt; int AnnotationsThere may be some ambiguity for function annotation, for example: 1fun x : int -&gt; exp actually means 1fun x -&gt; (exp : int) To annotate the parameter, we have to include a parathesis: 1fun (x : int) -&gt; exp Function with Multiple Parameters12345(* syntax, the parameter type and expression type is auto-checked by type checking mechanism*)fun x y -&gt; x +. y;;(* apply to 2 arguments *)(fun x y -&gt; x +. y) 3. 4. ;; Bind Function to Variable12let f = fun n -&gt; n + 1;;f 2;; Define Named Function (another syntax) let f = fun p1 p2 ... -&gt; expr let f p1 p2 ... = expr 1234let f x = x + 1;;f 3;;let f x y = x + y;;f 3 4;; Polymorphism12let id : 'a . 'a -&gt; 'a = fun x -&gt; x By type annotating the function in this way, we are saying that id function is of type a -&gt; a for any type a. For example, id can be of the types int -&gt; int, bool -&gt; bool or string -&gt; string. The type checking will all pass by annotating in this way. Syntax1'a1 'a2 'a3 ... 'an . type The type variables before the dot . Are like universal quantifiers, forcing OCaml to check the generality of the value. Part 2: InductionNon-effect assumption: we can change the evaluation order and assume every expression will terminate. Mathematical induction has two important components: Case analysis. The ability to assume that the theorem we want to prove holds for “smaller” objects. General form of induction works on any mathematical objects with well-founded relation (no infinite descending chains). The order chosen for induction is called induction order. The proof following the general form of induction involves: We want to prove some property P(x) about some collection of mathematical objects x. We choose a good order R as the induction order. (For the mathematical induction, R(x,y) if and only if x + 1 = y.) We prove that, for any x, if P(x&#39;) holds for any x&#39; such that R(x&#39;, x), then P(x) holds. We conclude that the property P(x) holds for every such mathematical object x. Examples of well-founded relation: “subtree” relation for binary trees, “sublist” relation for finite lists. For example, for a list, we define the relation as R(l1, l2) if and only if l1 is a proper suffix of l2. The partition for lists can be either empty list [] with no suffix, or hd :: tl. Then, we perform the following steps: We want to prove some property P(l) about values l of type a list. We show that P([]) holds. (There is no proper suffix). We show that for non-empty list l of form hd :: tl, if P(l&#39;) holds for all proper suffixes, then P(l) is true. We conclude that the property P(l) holds for any list l. Suggestions for deciding ordering and the partition: follow the pattern matching and recursive calls. Some induction proof (Reference from Favonia) Part 3: EffectsEvery OCaml expression either evaluates to a value raises an exception or fails to terminate (“infinite loop”) ExceptionsOCaml’s exception mechanism is similar to many other programming languages. Syntax of defining a new type of OCaml exception: 1exception E of t E is a constructor name and t is a type. The of t part is optional, similar to type variants. Create an exception value: 1Failure "something went wrong" Raise and exception value e: 1raise e Catch an exception, use: 1234try e with| p1 -&gt; e1| ...| pn -&gt; en The expression e may raise an exception. If it does not, the entire expression evaluate to what e does. If e does raise an exception value v, v is matched against the provided patterns, like pattern matching. All exception values have type exn. Common Usage of Exceptions Indicators of an error. Placeholders for unfinished code. Out-of-band communication. Sequencing of EffectsWe can use semicolon operator to sequence effects. Syntax: e1; e2 Dynamic semantics:(动态语义涉及程序运行顺序以及结果) To evaluate e1; e2, First evaluate e1 to a value v1. Then evaluate e2 to a value v2. Return v2. (Discard v1) Static semantics: (静态语义涉及表达式类型) e1; e2 : t if e1 : unit and e2 : t. Note that all expressions except for the last one should have type unit, otherwise OCaml will raise a warning. Part 4: ModulesModular ProgrammingOne key solution to managing complexity of large software is modular programming. The key idea of modular programming is “local reasoning”, for which the reasoning is only about just the module. The solution to local reasoning is abstraction (module specification), for which we only need to design the functionality of each components without considering how it is implemented. Module Systems Namespaces: a set of names are grouped together. In OCaml, we can use structures to group names. Abstraction: hides information, enables encapsulation, information hiding. In OCaml, we use signature to abstract structures by hiding some of the structure’s names. Code reuse: enables code from one module to be used as part of another module without having to copy. In OCaml, we can use functirs and includes to reuse code. OCaml ModulesThe OCaml module system is based on structures and signatures. In which structures are the core and signatures are the types of structures. Structuressyntax: 123module ModuleName = Struct (* definition *)end structure: 1struct (* definitions *) end A structure is a sequence of definitions, the structure itself is anonymous (has no name). Modules partition the namespace, any symbol x in side the module must be accessed with the module name ModuleName.x outside the module. (or use open to make the namespace public) The implementation of a module can contain type, exception, let, open and some others. ScopeAfter a module M has been defined, we can access the names by using the . operator. For example: M.x. We can also make the namepace public by using key word open: open M. Semantics meaning of open String: 1234let length = String.lengthlet get = String.getlet lowercase_ascii = String.lowercase_ascii... The module Stdlib is automatically opened in every OCaml program. The shadowing mechanism also fits for module opening: 12345module M = struct let x = 42 endmodule N = struct let x = "bigred" endopen Moepn N(* The name defined later shadows the name defined before. *) If we have multiple modules, it’s generally good practice not to open all the modules at the top of the program. One fatanstic solution to avoid collision is “local opening”: 12345678910(* without [open] *)let f x = let y = List.filter ((&gt;) 0) x in ...(* with [open] *)let f x = let open List in let y =filter ((&gt;) 0) x in ... SignaturesWe can use module type to describe the modules. One solution to defining module types is signatures. Syntax: 123module type ModuleTypeName = sig (* declarations *)end Stack signature: 12345678module type Stack = sig type &apos;a stack val empty : &apos;a stack val is_empty : &apos;a stack -&gt; bool val push : &apos;a -&gt; &apos;a stack -&gt; &apos;a stack val peek : &apos;a stack -&gt; &apos;a val pop : &apos;a stack -&gt; &apos;a stackend By convention, the module type name is also capitalized. val id : t means there is a value named id whose type is t. A structure matches a signature if the structure provides definitions for all the names specified in the signature and the types are also matched. (Allowing polymorphism) 1234567891011module type Sig = sig val f : int -&gt; intendmodule M1 : Sig = struct let f x = x+1endmodule M2 : Sig = struct let f x = xend Module M1 provides a function f of type int -&gt; int. Module M2 provides a function of type &#39;a -&gt; &#39;a. Both M1 and M2 match Sig. 1234module ListStack : Stack = struct type 'a stack = 'a list (* rest *)end Abstract TypesThe type &#39;a stack above is abstract. The Stack module type says that there is a type name &#39;a stack in any module that implements the module type. A module that implements a module type must specify concrete types for the abstract types in the signature and define all the names declared in the signature. Only declarations in the signature are accessible outside of the module. (encapsulation) An OCaml convention to short name the declaration: 12345678module type Stack = sig type 'a t val empty : 'a t val is_empty : 'a t -&gt; bool val push : 'a -&gt; 'a t -&gt; 'a t val peek : 'a t -&gt; 'a val pop : 'a t -&gt; 'a tend Custom Printers: https://www.cs.cornell.edu/courses/cs3110/2019fa/textbook/modules/abstract_types.html SemanticsSemantics of the OCaml module system Dynamic semantics: To evaluate a structure structure D1; ...; Dn end where each of the Di is a definition, evaluate each definition in order. Static semantics: For module M : T = struct ... end. There are two checks the compiler must perform: Signature matching: every name declared in T must be defined in M. Encapsulation: any name defined in M that does not appear in T is not visible to code outside of M. Functional Data StructuresFunctional data structures have the property of being persistent: updating the data structure with one of its operations does not change the existing version of the data structure but instead produces a new version. Both exist and both can be accessed. The opposite of a persistent data structure is an ephemeral data structure: changes are destructive so that only one version exists at any time. Both persistent and ephemeral data structures can be built in both functional and imperative languages. 1234567# open ListStack;;# let s = push 1 (push 2 empty);;val s : int list = [1; 2]# let s&apos; = pop s;;val s&apos; : int list = [2]# s;;- : int list = [1; 2] The value s is unchanged by the pop operation; both version of the stack coexist. Examples: StackExamples: QueuesExamples: DictionariesExamples: SetsExamples: ArithmeticSharing ConstraintsSyntax 123module Ints : (Arith with type t = int) = struct (* all of Ints as before *)end We can write sharing constraints that refine a signature by specifying equations that must hold on the abstract types in that signature. E.g. If T is a module type containing an abstract type t, then T with type t = int is a new module type that is the same T, except that t is known to be int. Compilation UnitsA compilation unit is a pair of OCaml source files in the same directory. They share the same prefix but their extension differ: one file is x.ml, the other is x.mli. The file x.ml is called the implementation, and x.mli is called the interface. Similar to x.c and x.h. E.g: foo.mli 12val x : intval f : int -&gt; int -&gt; int foo.ml 12345678module Foo : sig val x : int val f : int -&gt; int -&gt; intend = struct let x = 0 let y = 12 let f x y = x + yend In general, when the compiler encounters a compilation unit, it treats them as defining a module and a signature like this: 123module Foo : sig (* insert contents of foo.mli here *) end (* insert contents of foo.ml here *)end The unit name Foo is derived from the base name foo by just capitalizing the first letter. No named module type is defined, the signature of Foo is anonymous. CommentsThe comments that go in an interface file vs. an implementation file are different. Interface files will be read by clients of an abstraction. These will generally be specification comments describing how to use the abstraction, the preconditions and what exceptions they might raise, even time complexity and space complexity. Implementation files will be read by programmers and maintainers of an abstraction, so the comments that go there are for them. These will generally be specification about how the representation type is used, how the code works. Code ReuseIncludesOCaml provides a language features called included that enables code reuse, similar to the object-oriented language. It enables a structure to include all the values defined by another structure, or a signature to include all the names declared by another signature. E.g: 1234module ListSetDupsExtented = struct include ListSetDups let of_list lst = List.fold_right add lst emptyend We can also provide a new implementation of one of includedd functions: 1234567module ListSetDupsExtended = struct include ListSetDups let of_list lst = List.fold_right add lst empty let rec elts = function | [] -&gt; [] | h::t -&gt; if mem h t then elts' t else h::(elts' t)end The new implementation doesn’t replace the old one. Since the module evaluation is from top to bottom. Include vs. Open: 12345678910111213module M = struct let x = 0endmodule N = struct include M let y = x + 1endmodule O = struct open M let y = x + 1end Dynamic semantics: 123module M : sig val x : int endmodule N : sig val x : int val y : int endmodule O : sig val y : int end Include causes all the definitions to also be included. But open only makes those definitions available in the scope, it doesn’t make them part of the structure. FunctorsA functor is simply a function from structures to structures. E.g: 123module type X = sig val x : intend 123module IncX (M : X) = struct let x = M.x + 1end Apply functors: 123module A = struct let x = 0 endmodule B = IncX(A)module C = IncX(B) Syntax: 12345678910111213141516171819202122232425262728293031module F (M : S) = struct ...end(* anonymous functor *)module F = functor (M : S) -&gt; structmodule F (M1 : S1) ... (Mn : Sn) = struct ...end(* anonymous functor *)module F = functor (M1 : S1) -&gt; ... -&gt; functor (Mn : Sn) -&gt; struct ...end(* output type as a functor *)module F (M : Si) : So = struct ...end(* alternate form *)module F (M : Si) = (struct ...end : So)(* functor type annotation *)functor (M : Si) -&gt; Somodule F : functor (M : Si) -&gt; So = functor (M : Si) -&gt; struct ... end One thing to note: The output of the functor can depend on the input module. This can not happend on the expression level! Eg: 1functor (M : ORDERED_TYPE) -&gt; EXTENDED_ORDERED_TYPE with type t = M.t (* signature annotation explicitly *) The OCaml compiler won’t complain about the signature annotation without constraints, but this is fatal since we have to make sure type t is the same type as module M (we have to make the invoking function call work in this case, otherwise there might be runtime error). ReferenceLast time we talked about that OCaml binding is permanent which means “immutability”. But OCaml also supports “mutability” with the “reference” language feature. Refs A ref is like a pointer or reference in an imperative language. It is a location in memory whose contents may change. Refs are also called ref cells. Creates a reference: 1let x = ref 0 By using the keyword ref. OCaml allocates and initializes a memory location for us and gives us the handle. x has type int ref. This is a new type constructor. Access the content: 1!x !x dereferences x and returns the contents of the memory location. ! is the dereference operator. Assignment 1x := 1 := is the assign operator in OCaml, by using this operator, we are not changing the value x but are changing the content which it refers to. (Variable are immutable, memory is mutable but variable bindings are not) Dynamic Semantics: ref e Evaluate e to a value v Allocate a new location loc in memory to hold v Store v in loc Return loc e1 := e2 Evaluate e2 to a value v, and e1 to a location loc Store v in loc Return (), i.e., unit !e Evaluate e to a location loc Return the contents of loc Static Semantics ref e : t ref iff e : t e1 := e2 : unit iff e1 : t ref and e2 : t !e : t iff e : t ref Done!]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Ocaml</tag>
        <tag>Functional Programming</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch Tutorial]]></title>
    <url>%2F2019%2F05%2F11%2FPyTorch%20Tutorial%2F</url>
    <content type="text"><![CDATA[PyTorch Tutorial Defining networkPyTorch has a standard way to create your own models. The entire definition should stay inside an object that is a child of the class nn.Module. Inside this class, there are only two methods that must be implemented. These methods are init and forward. 123456789101112131415161718import torchimport torch.nn as nnimport torch.nn.functional as Fclass Net(nn.Module): def __init__(self): super(Net, self).__init__() # Defining 3 linear layers but not the way they should be connected self.fc1 = nn.Linear(240,120) self.fc2 = nn.Linear(120,60) self.fc3 = nn.Linear(60,10) def forward(self,x): # Defining the way that the layers of the model should be connected x = F.relu(self.fc1(x)) x = F.relu(self.fc2(x)) x = self.fc3(x) return x You can put inside the forward method all the layers that do not have any weights to be updated. On the other hand, you should put all the layers that have weights to be updated inside the init. Loading data: Dataset and Data Loaders123456789101112131415161718192021222324252627282930import torchimport pandas as pdfrom torch.utils.data import Dataset, DataLoaderclass ExampleDataset(Dataset): """Example Dataset""" def __init__(self, csv_file): """ csv_file (string): Path to the csv file containing data. """ self.data_frame = pd.read_csv(csv_file) def __len__(self): return len(self.data_frame) def __getitem__(self, idx): return self.data_frame[idx]# instantiates the dataset example_dataset = ExampleDataset('my_data_file.csv')# batch size: number of samples returned per iteration# shuffle: Flag to shuffle the data before reading so you don't read always in the same order# num_workers: used to load the data in parallelexample_data_loader = DataLoader(example_dataset, batch_size=4, shuffle=True, num_workers=4)# Loops over the data 4 samples at a timefor batch_index, batch in enumerate(example_data_loader): print(batch_index, batch) init: In the initialization, you should put your directories information and other things that would allow to access it. len: You should implement a way to get the entire size of your dataset. getitem: This is where you implement how to get a single item from your dataset. In order to more efficiently access your dataset, we use the DataLoader class. This class simply reads a batch of data at a time in parallel while optionally shuffling your data. Training: Updating the Network WeightsAn optimizer goes over all the weights and update them for you. The optimizer must have a criterion to use for optimization. This is where you need to define your loss function. 1234567891011121314151617181920import torch.optim as optimimport torch.nn as nn# instantiate your network that should be defined by younet = Net()# create your optimizeroptimizer = optim.SGD(net.parameters(), lr=0.01)# define your criterion for optimizationcriterion = nn.MSELoss()# dat_set comes from somewherefor data in data_set: # zero the gradient buffers optimizer.zero_grad() # Passes the data through your network output = net.forward(data) # calculates the loss loss = criterion(output, target) # Propagates the loss back loss.backward() # Updates all the weights of the network optimizer.step() Summarizing Steps Define your Network class by placing the layers with weights that can be updated inside the init method. Then define how the data flows through the layers inside the forward method. Define how your data should be loaded using the Dataset class. Then use DataLoader class to loop over your data. Choose an optimizer and a loss function. Loop over your training data and let the optimizer update the weights of your network. Cleaned up code of model with nn.Sequential123456789101112131415161718192021222324252627282930313233import torch.nn as nnclass NetSeq(nn.Module): def __init__(self): super(NetSeq, self).__init__() # conv layers: feature extractor self.conv_layers = nn.Sequential( nn.Conv2d(1, 10, kernel_size=5), nn.MaxPool2d(2), nn.ReLU(), nn.Conv2d(10, 20, kernel_size=5), nn.Dropout2d(), nn.MaxPool2d(2), nn.ReLU() ) # fc layers: classifier self.fc_layers = nn.Sequential( nn.Linear(320, 50), nn.ReLU(), nn.Dropout(), nn.Linear(50, 10), ) def forward(self, x): x = self.conv_layers(x) x = x.view(-1, 320) x = self.fc_layers(x) return F.log_softmax(x, dim=1) model = NetSeq().cuda()optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) Creditshttps://medium.com/deeplearningbrasilia/deep-learning-introduction-to-pytorch-5bd39421c84 https://www.kaggle.com/azure0102/pytorch-tutorial-for-deep-learning-lovers (Working in progess)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>PyTorch</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CS231n]]></title>
    <url>%2F2019%2F05%2F10%2FCS231n%2F</url>
    <content type="text"><![CDATA[Stanford University CS231n: Convolutional Neural Networks for Visual Recognition Course Notes Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition Camera Obscure Object Detection Benchmark PASCAL Visual Object Challenge Image Classification Benchmark ImageNet Image classification Object detection Action classification Image captioning Convolutional Neural Networks (CNN) have become an important tool for object recognition Computer Vision Technology Can Better Our Lives Lecture 2 | Image ClassificationImage Classification A core task in Computer Vision The Problem: Semantic Gap Challenges: Viewpoint variation, Illumination, Deformation, Occlusion, Background Clutter, Intraclass variation Data-Driven Approach Collect a dataset of images and labels Use Machine Learning to train a classifier Evaluate the classifier on new images First classifier: Nearest Neighbor Example Dataset: CIFAR10 Distance Metric to compare images L1 distance:$$d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p|$$ Train O(1), predict O(N). This is bad: we want classifiers that are fast at prediction; slow for training is ok K-Nearest Neighbors k and distance matrix are hyperparameters: choice about the algorithm that we set rather than learn Setting Hyperparameters Cross Validation is commonly used in small dataset, not commonly used in deep learning k-Nearest Neighbor on images never used. Very slow at test time Distance metrics on pixels are not informative Curse of dimensionality K-Nearest Neighbors: Summary In Image classification we start with a training set of images and labels, and must predict labels on the test set The K-Nearest Neighbors classifier predicts labels based on nearest training examples Distance metric and K are hyperparameters Choose hyperparameters using the validation set; only run on the test set once at the very end! Linear Classification (Parametric Approach) Sometimes we add a biased term $b$ Interpreting a Linear Classifier Hard cases for a linear classifier Lecture 3 | Loss Functions and Optimization Define a loss function that quantifies our unhappiness with the score across the training data. Come up with a way of efficiently finding the parameters that minimize the loss function (optimization) Loss over the dataset is a sum of loss over examples:$$L = \frac1N\sum_iL_i(f(x_i,W),y_i)$$ Multiclass SVM loss: Numpy implementatin 123456def L_i_vectorized(x, y, W): scores = W.dot(x) margins = np.maximum(0, scores-scores[y]+1) margins[y] = 0 loss_i = np.sum(margins) return loss_i Data loss: Model predictions should match training data regularization loss: Model should be “simple”, so it works on test data Regularization Softmax Classifier (Multinomial Logistic Regression) Recap Optimization Follow the slope Numerical gradient: approximate, slow, easy to write Analytic gradient: exact, fast, error-prone In practice: Always use analytic gradient, but check implementation with numerical gradient. This is called a gradient check. Gradient Descent 123while True: weights_grad = evaluate_gradient(loss_fun, data, weights) weights += - step_size * weights_grad Stochastic Gradient Descent (SGD) Histogram of Oriented Gradients (HoG) Bag of Words Assignment 1 understand the basic Image Classification pipeline and the data-driven approach (train/predict stages) Understand the train/val/test splits and the use of validation data for hyperparameter tuning Develop proficiency in writing efficient vectorized code with numpy Implement and apply k-Nearest Neighbor (kNN) classifier Implement and apply a Multiclass Support Vector Machine (SVM) classifier Implement and apply Softmax classifier Implement and apply a Two layer neural network classifier Understand the differences and tradeoffs between these classifiers get a basic understanding of performance improvements from using higher-level representations than raw pixels (e.g. color histograms, Histogram of Gradient (HOG) features) Lecture 4 | Introduction to Neural Networkscomputational graphs Backpropagation sigmoid function$$\sigma(x) = \frac{1}{1+e^{-x}}$$ $$\frac{d\sigma(x)}{dx}=(1-\sigma(x))\sigma(x)$$ We can group any node we want as long we can write down their local gradient add gate: gradient distributor max gate: gradient router mul gate: gradient switcher Gradients for vectorized code: Jacobian matrix Always check: The gradient with respect to a variable should have the same shape as the variable Modularized implementation Neural networks Activation functions Neural networks Architectures Lecture 5 | Convolutional Neural NetworksMark I Perceptron: Convolution Layer Lecture 6 | Training Neural Networks IMini-batch SGD Sample a batch of data Forward prop it through the graph (network), get loss Backprop to calculate the gradients Update the parameters using the gradient People like to initialzie ReLU neurons with slightly positive biases (e.g. 0.01) In practice: Use ReLU. Be careful with your learning rates Try out Leaky ReLU / Maxout / ELU Try out tanh but don’t expect much Don’t use sigmoid Reasonable initialization Batch Normalization Lecture 7 | Training Neural Networks II Fancier optimization Regularization Transfer Learning Learning rate decay is common with SGD momentum but less common with Adam Data Augmentation translation rotation stretching shearing lens distorions Transfer Learning Lecture 8 | Deep Learning SoftwareCPU vs GPU The point of deep learning frameworks Easily build big computational graphs Easily compute gradients in computational graphs Run it all efficiently on GPU (wrap cuDNN, cuBLAS, etc) Lecture 9 | CNN ArchitecturesLecture 10 | Recurrent Neural NetworksLecture 11 | Detection and SegmentationLecture 12 | Visualizing and UnderstandingLecture 13 | Generative ModelsLecture 14 | Deep Reinforcement LearningLecture 15 | Efficient Methods and Hardware for Deep LearningLecture 16 | Adversarial Examples and Adversarial Training(Working in progress)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
        <tag>Computer Vision</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Practical Deep Learning for Coders]]></title>
    <url>%2F2019%2F05%2F06%2FPractical%20Deep%20Learning%20for%20Coders%2F</url>
    <content type="text"><![CDATA[Fast.ai Course Notes Lesson 1Jupyter Notebook: Interactive environment for Python Import necessary libraries: 123from fastai import *from fastai.vision import *import matplotlib.pyplob as plt Tips: Don’t try to stop and understand the first time Making Deep Learning Accessible Software: To make these available to use quickly, reliably, and with minimal code Education: So that as many people as possible can use these Research: Ways to make state of the art deep learning techniques more accessible Community: So that we can all help each other We can do a lot more quickly with PyTorch than with TensorFlow Resources: fast.ai docs PyTorch Fastai provides four application areas: Computer Vision Natural Language Text Tabular Data Collaborative Filtering Fine-grained classification: distinguish between similar categories Some key functions Download and untar data: path = untar_data(URLs.PETS); path List the directory: path.ls() Path objects (of Python3): path_anno = path/&#39;annotations&#39;, path_img = path/&#39;images&#39; Grab an array of all image files: fname = get_image_files(path_img) Create a data bunch and normalize it: 123pat = r'/([^/]+\d+.jpg$)'data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=64) # bs represents the batch sizedata.normalize(imagenet_stats) 224x224 for a image generally works A data bunch contains typically 2 or 3 datasets Show the data bunch: data.show_batch(row=3, figsize=(7,6)) Labels: data.classes, data.c attributes Training: resnet34 learn = ConvLearner(data, models.resnet34, metrics=error_rate) ResNet34 and ResNet50 are always good for choosing Fit: learn.fit_one_cycle(4) the best way at the present for training Save the trained model: learn.save(&#39;stage-1&#39;) What comes out: interp = ClassificationInterpretation.from_learner(learn) Plot top losses: interp.plot_top_losses(9, figsize=(15,11)) (for error analysis) See the documentation: doc(interp.plot_top_losses) Plot the confusion matrix: interp.plot_confusion_matrix(figsize=(12,12), dpi=60) The most confused examples: interp.most_confused(min_val=2) Unfreezing: learn.unfreeze() (train the whole model to get high accuracy) Learning_rate find: learn.lr_find() Plot the learning_rate finder: learn.recorder.plot() Learning_rate slice: learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4)), distribute the learning_rate equally accross layers ImageDataBunch from folder: data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=26) ImageDataBunch from csv: df = pd.read_csv(path/&#39;labels.csv&#39;) data = ImageDataBunch.from_csv(path, ds_tfms=tfms, size=28) Dataset: Oxford-IIIT Pet Dataset Lesson 2Create an image dataset through Google Images Starting point: Find some example pictures Save the urls folder = &#39;black&#39; , file = urls_black.txt, path = Path(&#39;data/bears&#39;) Download images download_iamges(path/file, dest, max_pics=200) Verify the images verify_images(path/c, delete=True, max_workers=8) Set random state: np.random.seed(42) (Make sure the solution is stable) Create a databunch: data = ImageDataBunch.from_folder(path, train=&#39;.&#39;, valid_pct=0.2, ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats) See the size of training set: len(data.train_ds) See the size of validation set: len(data.valid(ds)) Picking the learning rate: picking the most steep part of the learning rate find curve Cleaning Up the data 123from fastai.widgets import *losses, idxs = interp.top_losses()top_loss_paths = data.valid_ds.x[idxs] 1fd = FileDeleter(file_paths=top_loss_paths) ipywidgets Putting your model in production Use a CPU rather than GPU to do inference Set CPU as defalut: fastai.defaults.device = torch.device(&#39;cpu&#39;) Create a single image data bunch: data = ImageDataBunch.single_from_classes(path, classes, tfms=get_transforms(), size=224).normalize(imagenet) Load the model: learn = create_cnn(data, models.resnet34) learn.load(&#39;stage-2&#39;) Make prediction: pred_class, pred_idx, outputs = learn.predict(img) Deployment: Starlette (Web app) Problems Most likely are: Learning rate Number of epochs Learning rate too high: Learning rate too low: If this kind of things happen, we have to redo again from the scratch Another problem is that the training loss is higher than the validation loss, that always means that you haven’t fit enough (learning rate is too low or number of epochs is too low) Any model that is trained correctly will have a lower training loss than the validation loss x@a: Matrix product Tensor: Array with regular shape Rank: How many dimensions are in the tensor In PyTorch, any function with an underscore: don’t return to me but replace in place type check: a.type() Gradient descent: 123456789a = nn.Parameters(a)def update(): y_hat = x@a loss = mse(y, y_hat) if t % 10 == 0: print(loss) loss.backward() with torch.no_grad(): a.sub_(lr * a.grad) a.grad.zero_() 12lr = 1e-1for t in range(100): update() Lesson 3Planet Dataset Multiple labels classification Download Data from Kaggle 123pip install kaggle --upgrademkdir -p ~/.kaggle/mv kaggle.json ~/.kaggle Instructions in detail Multiclassification data block API Dataset class for PyTorch (methods to manipulate data from the source): DataLoader class for PyTorch (load data from dataset): DataBunch class for fastai (split train and validation data): Transforms 1tfms = get_transforms() Image Segmentation with CamVid 12path = untar_data(URLs.CAMVID)fname = get_image_files(path_img) Lesson 4Lesson 5Lesson 6Lesson 7(Working in progess)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>PyTorch</tag>
        <tag>Fast.ai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithms, Part 2]]></title>
    <url>%2F2019%2F05%2F05%2FAlgorithms-Part-2%2F</url>
    <content type="text"><![CDATA[Princeton Algorithm course on coursera. Part 2 Intermediate-level survey course Programming and problem solving, with applications Learning Purpose: Being specialized in Java. Having fun with algorithms. Reference Books: Algorithms, 4th Edition Computer Science: An Interdisciplinary Approach Week 1Undirected GraphsDirected GraphsProgramming Assignment: WordNetWordNet Week 2Minimum Spanning TreesShortest PathsProgramming Assignment: Seam CarvingSeam Carving Week 3Maximum Flow and Minimum CutProgramming Assignment: Baseball EliminationBaseball Elimination Radix SortsWeek 4TriesSubstring SearchProgramming Assignment: BoggleBoggle Week 5Regular ExpressionsData CompressionProgramming Assignment: Burrows-WheelerBurrows-Wheeler Week 6ReductionsLinear ProgrammingIntractability(Working in progress)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models]]></title>
    <url>%2F2019%2F05%2F04%2FSequence%20Models%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai Specialization Course Notes Week 1Recurrent Neural NetworksSpeech recognition Music generation Sentiment classification DNA sequence analysis Machine translation Video activity recognition Name entity recognition Representing words Problem of a standard network: Inputs, outputs can be different lengths in different examples. Doesn’t share features learned across different positions of text. Recurrent Neural Networks Bidirectional RNN (BRNN) RNN architectures Language model Given a sentence, tell you the probability of that setence. Training set: large corpus of English text Tolenize: form a vocabulary and map each individual word into this vocabulary. The unknown is replaced with a unique token \&lt;UNK> Sampling sequence from a trained RNN Programming Assignment: Building a recurrent neural network - step by stepBuilding a recurrent neural network - step by step Programming Assignment: Dinosaur Island - Character-Level Language ModelingDinosaur Island - Character-Level Language Modeling Programming Assignment: Jazz improvisation with LSTMJazz improvisation with LSTM Week 2Natural Language Processing &amp; Word EmbeddingsProgramming Assignment: Oprations on word vectors - DebiasingOperations on word vectors - Debiasing Programming Assignment: EmojifyEmojify Week 3Sequence models &amp; Attention mechanismProgramming Assignment: Neural Machine Translation with AttentionNeural Machine Translation with Attention Programming Assignment: Trigger word detectionTrigger word detection (Working in progess)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks]]></title>
    <url>%2F2019%2F04%2F25%2FConvolutional%20Neural%20Networks%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai Specialization Course Notes Week 1Foundations of Convolutional Neural Networks Image Classification Object detection Neural Style Transfer With so many parameters, it’s difficult to get enough data for a model to get rid of overfitting. Edge Detection Convolution Padding Two problems: The image may shrink after some convolution The blocks in the middle of image have a higher chance to be utilized than the ones on the border For a deep neural network, we really don’t want the image to shrink because we have many convolution operations. Without padding, the image may shrink after every layer and after maybe 100 layers, we end up with a very small matrix like 1 by 1. The other problem is that we throw away information from the edges of the image. Traditionally without padding, if the original matrix is $n$ by $n$ and the filter is $f$ by $f$. Then the matrix after convolution will have a shape of $n-f+1$ by $n-f+1$ p: padding size After padding, the final output matrix will have shape $n+2p-f+1$ by $n+2p-f+1$ Valid and Same convolutions “Valid”: no padding, p = 0, nxn * fxf -&gt; n-f+1 x n-f+1 “Same”: Pad so that output size is the same as the input size. $p=\frac{f-1}{2}$ By convention, f is usually odd. The reasons: padding convience Odd dimensional filter has a central position Strided convolution shape formula: nxn * fxf with padding p and stride s output shape (square):$$\frac{n+2p-f}{s} + 1$$ Cross-correlation vs. convolution In computer vision, we don’t bother to use the non-flipped one because the flip operation is redundant in real computer vision applications. Convolution over volumes For example, convolutions on RGB images Notation: The number of the channels of a image must match the number of channels of the filter. Each time, do the 27 multiplications and add up the 27 numbers and get one entry. Multiple filters Summary: $n\times n\times n_c$ $f\times f \times n_c$ - &gt; $n-f+1$ $n-f+1$ $\times n_c’$ $n_c’$ is the number of filters we use. It seems that the more filters we use, the more features we can extract from an image. (like detecting two features simultaneously, vertical lines and horizontal lines…) One layer of convolutional network The number of parameters has nothing to do with the input images. If layer l is a convolution layer: $f^{[l]}$ = filter size $p^{[l]}$ = padding $s^{[l]}$ = stride $n_c^{[l]}$ = number of filters Each filter is: $f^{[l]}\times f^{[l]}\times n_c^{[l-1]}$ Activations: $a^{[l]}-&gt;n_H^{[l]} \times n_W^{[l]} \times n_C^{[l]}$ Weights: $f^{[l]}\times f^{[l]}\times n_c^{[l-1]}\times n_C^{[l]}$ Bias: $n_c^{[l]}$ - (1,1,1,$n_c^{[l]}$) Input: $n_H^{[l-1]}\times n_W^{[l-1]}\times n_c{[l-1]}$ Output: $n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$$$n^{[l]} = \lfloor \frac{n^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor$$$A^{[l]}$ -&gt; $m\times n_H^{[l]}\times n_W^{[l]} \times n_C^{[l]}$ Example ConvNet Types of layer in a convolutional network: Convolution (CONV) Pooling (POOL) Fully connnected (FC) Pooling layers Max pooling has no parameters to learn. Max pooling is used much more in the neural network than average pooling. Summary of pooling: Hyperparameters: f: filter size s: stride Max or average pooling Common choice: f=2, s=2. Roughly shrink the height and width by a factor of 2. f=3, s=3 is also used sometimes. padding is very very rare used when we do max pooling Pooling layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. No parameters to learn! Neural network example Common patterns when we go deeper and deeper: The height and width will decrease The number of channels will increase One or more conv layers follow by a pooling layer. At the end follow by FC A lot of the parameters tend to be in FC. The activation tends to go down gradually when going deeper and deeper. If it drops too fast, that’s usually not great performance. Why convolution? Parameter sharing and sparsity of connections. Reducing the number of parameters significantly Parameter sharing: A feature detector (such as a vertical edge detector) that’s useful in one part of the image is probably useful in another part of the image such as the vertical edge detector. Sparsity of connections: In each layer, each output value depends only on a small number of inputs. Translation invariance Programming Assignment: Convolutional Model: step by stepConvolutional Model: step by step Programming Assignment: Convolutional model: applicationConvolutional model: application Week 2Deep convolutional models: case studiesRead some research papers from the field of computer vision. Classic networks: LeNet-5 AlexNet VGG ResNet (152 layers) Inception LeNet-5 Goal: recognize hand written digits Trained on grey scale images Go from left to right, $n_H$ and $n_W$ tend to go down and $n_C$ tend to go up. AlexNet VGG-16 CONV = 3x3 filters, s = 1, same MAX-POOL = 2x2, s = 2 Residual network (ResNet) skip connections (“short cut”) Residual block: Using residual block, we can train a much deeper neural networks. In ResNet, there are a lot of “SAME” convolution to preserve dimension so at to carry out skip connection. Network in Network and 1x1 convolutions Imagine this like a “fully connected” layer [Lin et al., 2013. Network in network] This idea influence many other network architectures. One useful example: Shrinking the number of channels This is very useful for building Inception neural network. Inception network Do all the possible computation and concat them together. The problem: computational cost “Bottleneck layer” Shrink the representation before increasing the size So long as you implement this bottleneck layer with reason, you can shrink down the representation significant and don’t hurt the performance of the model. Inception module To deal with the problem of vanishing gradients: very deep network often have a gradient signal that goes to zero quickly, thus making gradient descent unbearably slow. Two types of block: Identity block Convolutional block Inception network Transfer learning (a better strategy) ImageNet, MS COCO When the training set is rather small, transfer learning is a good strategy. Small training set (freeze more layers): Large training set (freeze less layers): A lot of data (freeze 0 layer): Transfer is very worth consideration Data Augmentation Common augmentation method: Mirroring (frequently used) Random Cropping (isn’t a perfect method while frequently used) Rotation Shearing Local warping Color shifting PCA color augmentation Implementation details Data augmentation also has many hyperparameters. Two sources of knowledge in deep learning: Labeled data Hand engineered features/network architecture/other components Tips for doing well on benchmarks/winning competitions Ensembling: Train several networks independently and average their outputs (3-15 networks typically, so slow, almost never used in a product) Multi-crop at test time: Run classifier on multiple versions of test images and average results Use architectures of networks published in the literature Use open sourcfe implementations if possible Use pretrained models and fine-tune on your dataset Programming Assignment: Keras TutorialKeras Tutorial Programming Assignment: Residual NetworksResidual Networks Very deep “plain” networks don’t work in practice because they are hard to train due to vanishing gradients. The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function. There are two main types of blocks: The identity block and the convolutional block. Very deep Residual Networks are built by stacking these blocks together. Week 3Object detectionObject localization Defining the target label y Landmark detection Key position detection Basis of emotion detection, computer graphics and pose detection If you can hire labelers or label yourself a big enough data set to do the detection task, then a neural network can perform very well Sliding windows object detection algorithm Choosing a window size Slide the window accross the image with a fixed stride Make detection on each position (feed into the ConvNet and make prediction) Repeat with larger window Huge disadvantage: Computation cost Convolutional implementation of sliding window Turning FC layer into convolutional layers Share computation: Bounding box predictions YOLO algorithm: You only look once One single convolutional implementation Efficient, works well for real-time object detection Specify the bounding boxes: relative to the grid cell YOLO: One of the hardest papers to read Intersection over Union (IoU) Evaluating object localization Non-max Suppression The problem is that some objects might be detected multiple times Non-max Suppression make sure each object is detected only once Anchor boxes One grid detect multiple objects, overlapping objects YOLO algorithm None-max suppression in YOLO: Region proposalsR-CNN, Region with CNN, picking some regions to run CNN The ways to choose regions: semantic segmentation Still quite slow Programming Assignment: Car detection with YOLOv2Car detection with YOLOv2 YOLO model is very computationally expensive to train Find intersection: You’ll also need to find the coordinates (xi1, yi1, xi2, yi2) of the intersection of two boxes. Remember that: xi1 = maximum of the x1 coordinates of the two boxes yi1 = maximum of the y1 coordinates of the two boxes xi2 = minimum of the x2 coordinates of the two boxes yi2 = minimum of the y2 coordinates of the two boxes In order to compute the intersection area, you need to make sure the height and width of the intersection are positive, otherwise the intersection area should be zero. Use max(height, 0) and max(width, 0). What you should remember: YOLO is a state-of-the-art object detection model that is fast and accurate It runs an input image through a CNN which outputs a 19x19x5x85 dimensional volume. The encoding can be seen as a grid where each of the 19x19 cells contains information about 5 boxes. You filter through all the boxes using non-max suppression. Specifically: Score thresholding on the probability of detecting a class to keep only accurate (high probability) boxes Intersection over Union (IoU) thresholding to eliminate overlapping boxes Because training a YOLO model from randomly initialized weights is non-trivial and requires a large dataset as well as lot of computation, we used previously trained model parameters in this exercise. If you wish, you can also try fine-tuning the YOLO model with your own dataset, though this would be a fairly non-trivial exercise. Week 4Special applications: Face recognition &amp; Neural style transferFace verification vs. face recognition Verification: Input image, name/ID Output whether the input image is that of the claimed person 1:1 Recognition Has a database of K persons Get an input image Output ID if the image is any of the K persons (or “not recognized”) One-shot learning Learning from one example to recognize the person again Strategy: Learning a “similarity” function d(img1, img2) = degree of difference between images, and predict by difference Siamese network Triplet loss Always look at three images at a time: Anchor, Positive and Negative Choosing the triplets A,P,N During training, if A,P,N are chosen randomly, $d(A,P)+\alpha \le d(A,N)$ is easily satisfied. Idea: Choose triplets that’re “hard” to train on. (refer to the paper FaceNet) Popular way to name system: ____ Net Deep ____ Neural style transfer Visualizing what a deep network is learning Cost function$$J(G) = \alpha J_{content}(C,G)+\beta J_{style}(S,G)$$ Content cost function Style cost function Define style as correlation between activations across channels Convolutions in 2D and 1D 3D convolution Programming Assignment: Art generation with Neural Style TransferArt generation with Neural Style Transfer Neural Style Transfer (NST) uses a previously trained convolutional network, and builds on top of that. Programming Assignment: Face Recognition for the Happy HouseFace Recognition for the Happy House Face verification solves an easier 1:1 matching problem; face recognition addresses a harder 1:K matching problem. The triplet loss is an effective loss function for training a neural network to learn an encoding of a face image. The same encoding can be used for verification and recognition. Measuring distances between two images’ encodings allows you to determine whether they are pictures of the same person.]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Structuring Machine Learning Projects]]></title>
    <url>%2F2019%2F04%2F24%2FStructuring%20Machine%20Learning%20Projects%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai Specialization Course Notes Week 1ML StrategyIdeas: Collect more data Collect more diverse training set Train algorithm longer with gradient descent Try Adam instead of gradient descent Try bigger network Try smaller network Try dropout Add $L_2$ regularization Network architecture Activation functions Hidden units Orthogonalization Chain of assumptions in ML Fit training set well on cost function Fit dev set well on cost function Fit test set well on cost function Performs well in real world Early stopping is not a good strategy Single number evaluation metric $F_1$ Score can evaluate the model performance$$F_1 = \frac{2}{\frac1P+\frac1R}$$ Optimizing and satisficing E.g. Splitting data Set the test set to be big enough to give high confidence in the overall performance of your system Model performance So long as ML is worse than humans, you can: Get labeled data from humans Gain insight from manual error analysis: Why did a person get this right? Better analysis of bias/variance Human-level error as a proxy for Bayes error Surpassing human-level performance Online advertising Product recommendations Logistics (predicting transit time) Loan approvals Speech recognition Computer vision Two fundamental assumptions of supervised learning You can fit the training set pretty well. The training set performance generalizes pretty well to the dev/test set. Avoidable bias: Train bigger model. Train longer/better optimization algorithms. NN architecture/hyperparameters search. Variance: More data. Regularization. NN architecture/hyperparameters search. Week 2ML StrategyIncorrectly labeld examples DL algorithms are quite robust to random errors in the training set. (so long as the total dataset is large enough and the error percentage is not too high) DL are less robust to systematic errors Error analysis: Effor evaluation Correcting incorrect dev/test set examples Apply same process to your dev and test sets to make sure they continue come from the same distribution Consider examining examples your algorithm got right as well as ones it got wrong Train and dev/test data may now come slightly different distributions Tips for building a machine learning system Set up dev/test set and metric Build initial system quickly Use Bias/Variance analysis &amp; Error analysis to prioritize next steps Build your first system quickly, then iterate! Training and testing on different distributions To determine which aspect brings the effect of bias/variance, whether it’s the general reason or the reason caused by changing data distribution. It’s better to introduce a new set: Introducing this set helps us determine whether the problem is data mismatch or variance. Bias/variance on mismatched training and dev/test sets Human level Training set error Training_dev set error Dev error Test error Addressing data mismatch Carry out manual error analysis to try to understand difference between training and dev/test sets Making training data more similar; or collect more data similar to dev/test sets Artificial data synthesis Transfer learning Pre-training and fune-tuning When transfer learning makes sense Task A and B have the same input x. You have a lot more data for Task A than Task B. Low level features from A could be helpful for learning B. Multi-task learning Multiple labels When multi-task learning makes sense Training on a set of tasks could benefit from having shared lower-level features. Usually: Amount of data you have for each task is quite similar. Can train a big enough neural network to do well on all the tasks. Transfer learning is used much more often than multi-task learning End-to-end learning Multiple stages —&gt; A single neural network End-to-end network requires a lot of data to gain high performance Pros and cons of end-to-end deep learning Pros: Let the data speak Less hand-designing of components needed Cons: May need large amount of data Excludes potentially useful hand-designed components]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scikit-learn Summary]]></title>
    <url>%2F2019%2F04%2F24%2FSklearn%20Summary%2F</url>
    <content type="text"><![CDATA[Scikit-learn Summary ML Methods Decision tree 12from sklearn.tree import DecisionTreeRegressormodel = DecisionTreeRegressor(random_state=0) Random forest 12from sklearn.ensemble import RandomForestRegressormodel = RandomForestRegressor(n_estimators=100, random_state=0) Model selection 12from sklearn.model_selection import train_test_splittrain_X, val_X, train_y, val_y = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0) Evaluation metrics 12from sklearn.metrics import mean_absolute_errorval_mae = mean_absolute_error(val_prediction, val_y) Save to csv 12output = pd.DataFrame(&#123;'Id': test_data.Id, 'SalePrice': test_preds&#125;) Imputation 1234567891011121314from sklearn.impute import SimpleImputer# Imputationmy_imputer = SimpleImputer()imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))# Imputation removed column names; put them backimputed_X_train.columns = X_train.columnsimputer_X_valid.columns = X_valid.columns# Extension to Imputationfor col in cols_with_missing: X_train_plus[col + '_was_missing'] = X_train_plus[col].isnull() X_valid_plus[col + '_was_missing'] = X_valid_plus[val].isnull() Numerical selection 1X = X_full.select_dtypes(exclude=['object']) Drop NA 12cols_with_missing = [col in X_train.columns if X_train[col].isnull().any()]X_train = X_train.drop(cols_with_missing, axis=1) Drop Categorical Variables (typically perform worst) 12drop_X_train = X_train.select_dtypes(exclude=['object'])drop_X_valid = X_valid.select_dtypes(exclude=['object']) Label Encoding (randomly) 1234567from sklearn.preprocessing import LabelEncoderlabel_X_train = X_train.copy()label_X_valid = X_valid.copy()label_encoder = LabelEncoder()for col in object_cols: label_X_train[col] = label_encoder.fit_transform(X_train[col]) label_X_valid[col] = label_encoder.transform(X_valid[col]) One-Hot Encoding (typically perform best) 1234567891011121314151617181920from sklearn.preprocessing import OneHotEncoderOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))# One-hot encoding removed index; put it backOH_cols_train.index = X_train.indexOH_cols_valid.index = X_valid.index# Remove categorical columnsnum_X_train = X_train.drop(object_cols, axis=1)num_X_valid = X_valid.drop(object_cols, axis=1)# Add one-hot encoded columns to numerical featuresOH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)OH_X_valid = pd.concat([num_X_train, OH_cols_valid], axis=1)# pandas implementationX_train = pd.get_dummies(X_train)X_valid = pd.get_dummies(X_valid)X_test = pd.get_dummies(X_test)X_train, X_valid = X_train.align(X_valid, join='left', axis=1)X_train, X_test = X_train.align(X_test, join='left', axis=1) Remove rows with missing target 1X.dropna(axis=0, subset=['SalePrice', inplace=True]) Object columns selection 12345object_cols = [col for col in X_train.columns if X_train[col].dtype == "object"]# Columns that can be safely label encodedgood_label_cols = [col for col in object_cols if set(X_train[col]) == set(X_valid[col])]# Problematic columns that will be dropped from the datasetbad_label_cols = list(set(object_cols)-set(good_label_cols) Ont-Hot columns selection 12low_cardinality_cols = [col for col in object_cols if X_train[col].nunique() &lt; 10]high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols)) Pipelines 123456789101112131415161718192021222324252627282930from sklearn.compose import ColumnTransformerfrom sklearn.pipeline import Pipeline# from sklearn.pipeline import make_pipeline # used when there is no data preprocessingfrom sklearn.impute import SimpleImputerfrom sklearn.preprocessing import OneHotEncoderfrom sklearn.metrics import mean_absolute_error# Preprocessing for numerical datanumerical_transformer = SimpleImputer(strategy='constant')# Preprocessing for categorical datacategorical_transformer = Pipeline(steps=[ ('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handdle_unknown='ignore'))])# Bundle preprocessing for numerical and categorical datapreprocessor = ColumnTransformer( transformers=[ ('num', numerical_transformer, numerical_cols), ('cat', categorical_transformer, categorical_cols) ])# Bundle preprocessing and modeling code in a pipelinemy_pipeline = Pipeline(steps=[('preprossor', preprocessor), ('model', model) ])# Preprocessing of training data, fit modelmy_pipeline.fit(X_train, y_train)# Preprocessing of validation data, get predictionspreds = my_pipeline.predict(X_valid)# Evaluate the modelscore = mean_absolute_error(y_valid, preds) Proper columns selection 1234567# Select categorical columns with relatively low cardinalitycategorical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() &lt; 10 and X_train_full[cname].dtype == 'object']# Select numerical columnsnumerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']] Read in data 1X_full = pd.read_csv('../input/train.csv', index_col='Id') Output data 123output = pd.DataFrame(&#123;'Id': X_test.index, 'SalePrice': preds_test&#125;)output.to_csv('submission.csv', index=False) Cross validation 1234from sklearn.model_selection import cross_val_scorescore = -1 * cross_val_score(my_pipeline, X, y cv=5, # 5 folds cross validation scoring='neg_mean_absolute_error') # scoring='accuracy' for classification problem XGBoost 1234567891011from xgboost import XGBRegressormy_model = XGBRegressor()# my_model = XGBRegressor(n_estimators=500)# my_model.fit(X_train, y_train,# early_stopping_rounds=5,# eval_set=[(X_valid, y_valid)],# verbose=False)# my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)# my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)my_model.fit(X_train, y_train) parameters: n_estimators: specifies how many times to go through the modeling cycle. low: underfuttubg, high: overfitting. Typically value is 100-1000. early_stopping_rounds: this parameter causes the model to stop iterating when the validation scores stops improving. It’s smart to set a high value for n_estimators and then use early_stopping_rounds to find the optimal time to stop iterating. Since random chance sometimes causes a single round where validation scores don’t improve, you nedd to specify a number for how many rounds of straight deterioration to allow before stopping. Setting early_stopping_rounds=5 is a reasonable choice. In this case, we stop after 5 straight rounds of deteriorating validation scores. learning_rate: Instead of getting predictions by simply adding up the predictions from each component model, we can multiply the predictions from each model by a small number (known as the learning rate) before adding them in. In general, a small learning rate and large number of estimators will yield more accurate XGBoost models, through it will also take the model longer to train since it does more iterations through the cycle. As default, XGBoost sets learning_rate=0.1. n_jobs: On large datasets where runtime is a consideration, you can use parallelism to build your model faster. It’s common to set the parameter n_jobs equal to the number of cores on your machine. On smaller datasets, this won’t help. Data leakage: target leakage and train-test contamination. Target leakage: Any variable updated (or created) after the target value is realized should be excluded. Data exploration can really help identify target leakage. Train-test contamination: Happens when validation data affects the preprocessing behavior. If the validation is based on a simple train-test split, exclude the validation from any type of fitting, including the fitting of preprocessing steps. Careful separation of training and validation data can prevent train-test contamination and pipelines can help. Machine Learning Pipeline Define Preprocessing Steps Define the Model Create and Evaluate the Pipeline Pandas Creating data: DataFrame and Series 12# DataFramepd.DataFrame(&#123;'Yes': [50, 21], 'No': [131, 2]&#125;) 1234# DataFrame with customized index (row labels)pd.DataFrame(&#123;'Bob': ['I liked it.', 'It was awful.'], 'Sue': ['Pretty good.', 'Bland.']&#125;, index=['Product A', 'Product B']) 1234# Seriespd.Series([1, 2, 3, 4, 5])# Series with a namepd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A') Read file 1wine_reviews = pd.read_csv("../input/wine-reviews/winemag-data-130k-v2.csv", index_col=0) # set the index column (otherwise pandas will create a default column) Summary functions (type-aware) 1reviews.describe() List unique values 12reviews.taster_name.unique()reviews.taster_name.value_counts() # unique value counts Maps 123456789101112# Series.mapreview_point_mean = reviews.points.mean()reviews_points.map(lambda p: p - review_point_mean)# Apply to a whole DataFramedef remean_points(row): row.points = row.points - review_points_mean return rowreviews.apply(remean_points, axis='columns')# Alternative way (faster)review_points_mean = reviews.points.mean()review.points - review_points_mean Group and sorting 1234reviews.groupby('points').points.count()reviews.groupby('points').price.min()# Value countsreviews_per_region = reviews.region_1.fillna('Unknown').value_counts().sort_values(ascending=False) 123456countries_reviewd = countries_reviewd.reset_index()countries_reviewd.sort_values(by='len', ascending=True)# Sort by indexcountries_reviewd.sort_index()# Sort with multiple keyscountries_reviewd.sort_values(by=['country', 'len']) Data types 123reviews.price.dtype # Get type for a single columnreviews.dtypes # Get types for all columnsreviews.points.astype('float64') # Change data type Missing data 12reviews[reviews.country.isnull()]reviews.region_2.fillna("Unknown") # Fill in NA data entries Rename (specifying a index or column keyword parameter) 123reviews.rename(columns=&#123;'points': 'score'&#125;)reviews.rename(index=&#123;0: 'firstEntry', 1: 'secondEntry'&#125;) # Rarelyreviews.rename_axis("wines", axis='rows').rename_axis("fields", axis='columns') # Set names for row index and column index Combining (concat, join, merge) 1pd.concat([canadian_youtube, british_youtube]) Indexing 123456789101112131415161718192021222324252627282930# Single rowdf.iloc[2] # Make sure to specify a number, zero indexdf.loc['BADL'] # Make sure to pass a value from dataframes's index# Multiple rowsdf.loc[['BADL', 'ARCH', 'ACAD']]df.iloc[[2, 1, 0]]df[:3]# Indexing columnsdf['State'].head(3)df.State.head(3)# Clean the column namesdf.columns = [col.replace(' ', '_').lower() for col in df.columns]# Indexing columns and rowsdf[['state', 'acres']][:3]# Indexing scalar valuedf.state.iloc[2] # return a scalar rather than a Series or DataFrame# Boolean indexingdf[df.state == 'UT']# Some helpful logical operations: ~: not; |: or; &amp;: and# E.g.df[(df.latitude &gt; 60) | (df.acres &gt; 10**6)].head(3)# isin and isnulldf[df.state.isin(['WA', 'OR', 'CA'])].head() Bar charts and categorical data (nominal categories and ordinal categories) 1reviews['province'].value_counts().head(10).plot.bar() Line charts 1reviews['points'].value_counts().sort_index().plot.line() Area charts (line charts with the bottom shaded in) 1reviews['point'].value_count().sort_index().plot.area() Histograms (work best for interval variables without skew or for ordinal categorical variables) 1reviews[reviews['price'] &lt; 200]['price'].plot.hist() Scatter plot (remember to downsample to avoid duplicate), works best with relatively small datasets and large number of unique values 1review[reviews['price'] &lt; 100].sample(100).plot.scatter(x='price', y='points') Hexplot 1reviews[reviews['price'] &lt; 100].plot.hexbin(x='price', y='points', gridsize=15) Stacked plots (work best for nominal categorical or small ordinal categorical variables) One categorical variable in the columns, one categorical variable in the rows, and counts of their intersection in the entries. 1wine_counts.plot.bar(stacked=True) Area plot Bivariate line chart 1wine_counts.plot.line() Seaborn Line charts 123456import seaborn as snsimport matplotlib.pyplot as pltplt.figure(figsize=(14,6))plt.title("Daily Global Streams of Popular Songs in 2017-2018")sns.lineplot(daat=fifa_data) # plot a line for every column in the dataset# sns.lineplot(data=spotyfy_data['Shape of You'], label="Shape of You") # plot one column, label represents adding legend Bar charts 12345import seaborn as snsimport matplotlib.pyplot as pltplt.figure(figsize=(10,6))plt.title("...")sns.barplot(x=flight_data.index, y=flight_data=['NK']) Heatmap 123plt.figure(figsize=(14,7))plt.title("...")sns.heatmap(data=flight_data, annot=True) Scatter plot 1234567891011import seaborn as snssns.scatterplot(x=insurance_data['bmi'], y=[insurance_data['charges']])# Add a regression linesns.regplot(x=insurance_data['bmi'], y=insurance_data['charges'])# Color code with a boolean/categorical columnsns.scatterplot(x=insurance_data['bmi'], y=insurance_data['charges'], hue=insurance_data['smoker'])# Two regression linesns.lmplot(x="bmi", y="charges", hue="smoker", data=insurance_data)# Categorical scatter plotsns.swarmplot(x=insurance_data['smoker'], y=insurance_data['charges']) One regression line ​ Two regression lines (hue specified, color coded) ​ Categorical scatter plot Histograms 12345678910import seaborn as snssns.distplot(a=iris_data['Petal Length (cm)'], kde=False, bins=5)# a: choose the column we'd like to plot# kde=False (always included in a histogram)# Histograms for multiple columnssns.distplot(a=iris_set_data['Petal Length (cm)'], label='Iris-setosa', kde=False)sns.distplot(a=iris_ver_data['Petal Length (cm)'], label='Iris-versicolor', kde=False)sns.distplot(a=iris_vir_data['Petal Length (cm)'], label='Iris-virginica', kde=False)plt.legend() # Force legend to appear ​ General higtogram Histogram of multiple columns Density plots 12345678import seaborn as snssns.kdeplot(data=iris_data['Petal Length (cm)'], shade=True)# 2D kde plotssns.jointplot(x=iris_data['Petal Length (cm)'], y=iris_data['Sepal Width (cm)'], kind="kde")# KDE plot for multiple columnssns.kdeplot(data=iris_set_data['Petal Length (cm)'], label='Iris-setosa', shade=True) # shade is used to fill in the color below the KDE plot# and so on ​ General KDE plot ​ 2D KDE plot **KDE plot for multiple columns** Choosing the best type of chart Trends: A trend is defined as a pattern of change. sns.lineplot - Line charts are the best to show trends over a period of time, and multiple lines can be used to show trends in more than one group. Relationship: There are many different chart for show this. sns.barplot- Bar charts are useful for comparing quantities corresponding to different groups. sns.heatmap- Heatmaps can be used to find color-coded patterns in table of numbers. sns.scatterplot- Scatter plots show the relation between two continuous variables; if color-coded, we can also show the relationship with categorical variables. sns.regplot- Including a regression line in the scatter plot makes it easier to see linear relationship between two variables. sns.lmplot- This command is useful for drawing multiple regression lines, if the scatter plot contains multiple, color-coded groups. sns.swarmplot- Categorical scatter plots show the relationship between a continuous variable and a categorical variable. Distribution: We visualize distribution to show the possible values that we can expect to see in a variable. sns.distplot- Histograms show the distribution of a single numerical variable. sns.kdeplot- KDE plots (or 2D KDE plots) to show anestimated, smooth distribution of a single numerical variable (or two numerical variables). sns.jointplot- This command is useful for simultaneously displaying a 2D KDE plot with the correspoinding KDE plots for each individual variable. Set styles for the figure 12sns.set_style("dark") # set dark style for the figure, five themes: "darkgrid", "whitegrid", "dark", "white", "ticks". The default theme is "darkgrid"plt.figure(figure=(12,6)) # change the figure size Countplot (doesn’t require us to shape the data) 1sns.countplot(reviews['points']) KDE plot (kernel density estimate), worse choice for ordinal categorical data, KDE plot will fit to something that doesn’t exist. 1sns.kdeplot(reviews.query('price &lt; 200').price) Bivariate hex plot 1sns.jointplot(x='price', y='points', data=reviews[reviews['price'] &lt; 100], kind='hex', gridsize=20) Boxplot 1234567df = reviews[reviews.variety.isin(reviews.variety.value_counts().head(5).index)]sns.boxplot( x='variety', y='points', data=df) The center of the distributions shown above is the “box” in boxplot. The top of the box is the 75th percentile, while the bottom is the 25th percentile. In other words, half of the data is distributed within the box. The green line in the middle is the median. (50% of the data in the distribution is located within the box) The other part of the plot, the “whiskers”, shows the extent of the points beyond the center of the distribution. Individual circles beyond that are outliers. Boxplots are great for summarizing the shape of many datasets. They also don’t have a limit in terms of numeracy: you can place as many boxes in the plot as you feel comfortable squeezing onto the page. However, they only work for interval variables and nomial variables and nominal variables with a large number of possible values and they don’t carry any information about individual values, only treating the distribution as a whole. Violinplot 12345sns.violinplot( x='variety', y='points', data=reviews[reviews.variety.isin(reviews.variety.value_counts()[:5].index)]) Harder to misinterpret and much prettier than the utilitarian boxplot Facet Deep Learning Transfer Learning 12345678910111213141516171819202122232425262728293031323334353637383940from tensorflow.python.keras.applications import ResNet50from tensorflow.python.keras.models import Sequentialfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2Dnum_classes = 2resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'my_new_model = Sequential()my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))my_new_model.add(Dense(num_classes, activation='softmax'))# Say not to train first layer (ResNet) model. It is already trainedmy_new_model.layers[0].trainable = False# Compipe modelmy_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])from tensorflow.python.keras.applications.resnet50 import preprocess_inputfrom tensorflow.python.keras.preprocessing.image import ImageDataGeneratorimage_size = 224data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)# Fit modeltrain_generator = data_generator.flow_from_directory( '../input/urban-and-rural-photos/rural_and_urban_photos/train', target_size=(image_size, image_size), batch_size=24, class_mode='categorical')validation_generator = data_generator.flow_from_directory( '../input/urban-and-rural-photos/rural_and_urban_photos/val', target_size=(image_size, image_size), class_mode='categorical')my_new_model.fit_generator( train_generator, steps_per_epoch=3, validation_data=validation_generator, validation_steps=1) Relate CoLab and Google Drive123456789101112!apt-get install -y -qq software-properties-common python-software-properties module-init-tools!add-apt-repository -y ppa:alessandro-strada/ppa 2&gt;&amp;1 &gt; /dev/null!apt-get update -qq 2&gt;&amp;1 &gt; /dev/null!apt-get -y install -qq google-drive-ocamlfuse fusefrom google.colab import authauth.authenticate_user()from oauth2client.client import GoogleCredentialscreds = GoogleCredentials.get_application_default()import getpass!google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; &lt; /dev/null 2&gt;&amp;1 | grep URLvcode = getpass.getpass()!echo &#123;vcode&#125; | google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; 123# specify Google Drive root directory，名为drive!mkdir -p drive!google-drive-ocamlfuse drive 12import osos.chdir(&quot;drive/Colab Notebooks&quot;) Success!]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
        <tag>Keras</tag>
        <tag>Machine Learning</tag>
        <tag>Scikit-learn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks in TensorFlow]]></title>
    <url>%2F2019%2F04%2F21%2FConvolutional%20Neural%20Networks%20in%20TensorFlow%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai, Convolutional Neural Networks in TensorFlow Course Notes Week 1Exploring a Larger Datasetdata generation: 12345678910111213141516171819202122from tensorflow.keras.preprocessing.imageimport ImageDataGeneratortrain_datagen = ImageDataGenerator(rescale=1./255)train_generator = train_datagen.flow_from_directory( train_dir, target_size=(150,150), batch_size=20, class_mode='binary')...history = model.fit_generator( train_generator, steps_per_epoch=100, epochs=15, validation_data=validation_generator, validation_steps=50, verbose=2) RMSProp optimization algorithm is preferable to stochastic gradient descent (SGD). Week 2Augmentation: A technique to avoid overfitting1234567891011# Updated to do image augmentationtrain_datagen = ImageDataGenerator( rescale = 1./255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest') We should do image augmentation both on training set and testing set. Using keras API, all augmentation is done in memory, not in disk. Week 3Transfer LearningTake existing model rather than train from scratch. Inception 1234567891011121314151617import osfrom tensorflow.keras import layersfrom tensorflow.keras import Modelfrom tensorflow.keras.applications.inception_v3 import InceptionV3local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'pre_trained_model = InceptionV3(input_shape = (150,150,3), include_top = False, weights = None)pre_trained_model.load_weights(local_weights_file)for layer in pre_trained_model.layers: layer.trainable = False # lock layers 1234567891011121314from tensorflow.keras.optimizers import RMSproplast_layer = pre_trained_model.get_layer('mixed7')last_output = last_layer.outputx = layers.Flatten()(last_output)x = layers.Dense(1024, activation='relu')(x)x = layers.Dropout(0.2)(x)x = layers.Dense(1, activation='sigmoid')(x)model = Model(pre_trained_model.input, x)model.compile(optimizer = RMSprop(lr=0.0001), loss = 'binary_crossentropy', metrics = ['acc']) Week 4Multiclass Classifications12345678train_datagen = ImageDataGenerator(rescale=1./255)train_generator = tran_datagen.flow_from_directory( train_dir, target_size=(300,300), batch_size=128, class_mode='categorical') 12345from tensorflow.keras.optimizers import RMSpropmodel.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['acc']) Useful function: 1234567# summarymodel.summary()# visualizationplot_model(model, to_file='model.png')SVG(model_to_dot(happyModel).create(prog='dot', format='svg'))# evaluatemodel.evaluate(X_test, y_test)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks]]></title>
    <url>%2F2019%2F04%2F20%2FImproving%20Deep%20Neural%20Networks%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai Specialization Course Notes Week 1Practical aspects of Deep LearningTrain/dev/test sets Applied ML is a highly iterative process layers Hidden units Learning rates Activation functions Idea - Code - Experiment Make sure the dev and test come from the same distribution. Because we want to evaluate effects from the dev set. Not having a test set might be okay. (Only dev set.) Bias and Variance Basic recipe for machine learning Hign bias -&gt; Bigger network High variance -&gt; More data / Regularization / NN architecture Training a bigger network almost never hurts if regularized well Regularization L2 regularization is used much more often Frobenius norm is used in Neural network -&gt; weight decay Another technical regularization method is dropout Inverted dropout 1234keep_prob = 0.8 # chosen by userd = np.random.rand(a.shape[0],a.shape[1]) &lt; keep_proba = np.multiply(a,d)a /= keep_prob # because the output will be reduced by ... At test time, we should not include drop out because we don’t want our prediction to be random. Otherwise, there will be noise. We should apply dropout both during forward and backward propagation and shutdown the same neurons in each iteration and we should scale the output by divide keep_prob Intuition: Cant’t rely on any one feature, so have to spread out weights. Drop out is very frequently used by computer vision. But doesn’t generalize in other application areas. We will lose gradient checking tool when including drop out. So in conclusion, we should plot the loss figure when including drop out. Because the cost function J is no longer well-defined (thinking about the dead neurons) Other regularization methods: Data augmentation Early stopping L2 regularization is more useful but the search space for $\lambda$ is large Normalization$$\mu=\frac1m\sum_{i=1}^mx^{(i)} \\sigma=\frac1m\sum_{i=1}^mx^{(i)}**2$$ Normalize the training set and test set the same way Zero mean and variance one Vanishing / Exploding gradients Random initialization 1Wl = np.random.randn(shape) * np.sqrt(2/n) Different initialization lead to different results Random initialization is used to break symmetry and make sure different hidden units can learn different things We should not initialize to values that are too large In the weight initialization procedure, we can also tuning the hyper parameter for the variance. Poor initialization can lead to vanishing/exploding gradients, which also slow down the optimization algorithm. He initialization （designed for ReLU activation), of significant importance Multiply random initialization by$$\sqrt{\frac{2}{dimension\space of\space the\space previous \space layer}}$$ Gradient checking$$\frac{f(\theta+\epsilon)-f(\theta-\epsilon)}{2\epsilon} \approx g(\theta)$$Two-side difference is prefered$$\epsilon = 10^{-7}$$ Tips for Grad check Don’t use in training - only to debug If algorithm fails grad check, look at components to try to identify bug Remeber regularization Doesn’t work with dropout (set keep_prob = 1.0 to do grad check) Run at random initialization Programming Assignment: InitializationInitialization Programming Assignment: RegularizationRegularization Programming Assignment: Gradient CheckingGradient Checking Week 2Optimization algorithmsMini-batch gradient descent Choosing mini-batch size: If mini-batch size = m : Batch gradient descend If mini-batch size size = 1: Stochastic gradient descent: Every example is a mini-batch Tipds: If small training set: Use batch gradient descent —— 2000 Otherwise typical mini-batch size: 64, 128, 256, 512 Make sure mini batch fit in CPU/GPU memory Shuffling and Partitioning are the two steps required to build mini-batches Exponentially weighted averages$$v_t=\beta v_{t-1}+(1-\beta)\theta_t$$Bias correction$$\frac{v_t}{1-\beta^t}$$ Graduebt descent with momentum Hyperparameters: $\alpha,\beta$$$\beta = 0.9$$In practice, people don’t usually do bias correction in deep learning because after just ten iterations, moving average will warm up. RMSprop Adam Take momentum and RMSprop and put them together Hyperparameters choice:$$\beta_1=0.9 \\\theta_2=0.999 \\\epsilon=10^{-8}$$And try different range of $\alpha $ Adam: Adaptive moment estimation For complex problems there will be bigger gains Learning rate decay$$\alpha=\frac{1}{1+decay-rate*epoch-num}\alpha_0 \\\alpha = 0.95^{epoch-num}\alpha_0 \\\alpha =\frac{k}{\sqrt{epoch-num}}\alpha_0$$ Saddle point is different from local optimum. In high dimensional space, we are more likely to encounter saddle point. Unlikely to get stuck in a bad local optima Plateaus can make learning slow Programming Assignment: OptimizationOptimization Week 3Hyperparameter tuning, Batch Normalization and Programming FrameworksIn deep learning, choose the hyperparameter combination at random Batch Normalization Given some intermediate value in NN. $z^{(1)},…,z^{(m)}$$$\mu=\frac1m\sum z^{(i)} \\\sigma^2=\frac1m\sum(z_i-\mu)^2 \\z_{norm}^{(i)} = \frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}} \\\hat{z^{(i)}} = \gamma z_{norm}^{(i)} + \beta$$$\gamma $ and $\beta$ are learnable parameters BN deals with the situation of Covariate shift BN weakens the coupling between earlier layer’s paramers abd later layer’s parameters BN has a slight regularization effect, similar to dropout BN speeds up training process Softmax regression Softmax regressuib generalizes logistic regression to C classes Loss function$$L(\hat{y},y) = -\sum_{j=1}^cy_jlog\hat{y_j}$$ Choosing deep learning frameworks Ease of programming (development and deployment) Running speed Truly open (open source with good governance) TensorFlow 12tf.Variable(0, dtype.float32)tf.placeholder(tf.float32, [3,1]) Typical steps: Create a graph containing Tensors (Variables, Placeholders …) and Operations (tf.matmul, tf.add) Create a session Initialize the session Run the session to execute the graph Programming Assignment: TensorFlowTensorFlow]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Networks and Deep Learning]]></title>
    <url>%2F2019%2F04%2F20%2FNeural%20Networks%20and%20Deep%20Learning%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai Specialization Course Notes Week 1Introduction to deep learning AI is the new Electricity Electricitty had once transformed countless industries: transportation, manufacturing, healthcare, communications, and more AI will now bring about an equally big transformation ReLU: Rectified Linear Unit Supervised Learning Structured Data vs. Unstructured Data Keys in deep learning: Week 2Neural Networks BasicsBinary Classification Input group: output group: Logistic Regression (again…)$$\hat{y} = \sigma(w^Tx+b) \\\sigma(z) = \frac{1}{1+e^{-z}}$$ Logistic Regression cost function When deciding which loss function to use, we should really consider if it is convex or not. $$L(\hat{y},y) = -(ylog\hat{y}+(1-y)log(1-\hat{y}))$$ $$J(w,b)=\frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})$$ Gradient Descent$$w:=w-\alpha\frac{\partial J(w,b)}{\partial w} \\w:=w-\alpha dw \\b:=b-\alpha\frac{\partial J(w,b)}{\partial b} \\b:=b-\alpha db$$ Computation Graph Logistic regression derivatives Vectorization 1234567891011121314import numpy as npa = np.array([1,2,3,4])print(a)import timea = np.random.rand(100000)b = np.random.rand(100000)tic = time.time()c = np.dot(a,b)toc = time.time()print(&quot;Vectorized version:&quot; + str(1000*(toc-tic) + &quot;ms&quot;)) Whenever possible, avoid explicit for-loops. Programming Assignment: Logistic Regression with a Neural Network mindsetPython Basics with numpy Logistic Regression with a Neural Network mindset Week 3Shallow neural networks Neural Network Representation Vectorization Convention: stacking by column Activation functions$$sigmoid(z)=\frac{1}{1+e^{-z}} \\tanh(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}} \\ReLU(z) = max(0,z)$$Tanh function is superior than sigmoid function. (generally) sigmoid: binary classification (used in the output layer) suggestions: use relu in all other units except for the output unit. If we are doing a binary classification, we use sigmoid in the output unit in most cases. Fornulas for propagation Random initilization: Symmetry breaking Small initialization: make update faster Programming Assignment: Planar data classification with a hidden layerPlanar data classification with a hidden layer Week 4Deep Neural NetworksDimension:$$W^{[l]}:(n^{[l]},n^{[l-1]})$$ $$b^{[l]}:(n^{[l]},1)$$ $$z^{[l]},a^{[l]}:(n^{[l]},1)$$ $$Z^{[l]},A^{[l]}:(n^{[l]},m)$$ Circuit theory and deep learning Informally: There are functions you can compute with a “small”L-layer deep neural network that shallower networks require exponentially more hidden units to compute. Forward and backward functions Forward propagation for layer l Input $a^{[l-1]}$ Output $a^{[l]}$, cache ($z^{[l]}$) Backward propagation for layer l Input $da^{[l]}$ Output $da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$$$dz^{[l]}=da^{[l]}*g^{[l]’}(z^{[l]}) \\dw^{[l]}=dz^{[l]} \cdot a^T \\db^{[l]} = dz^{[l]} \\da^{[l-1]} = w^{[l]^T} \cdot dz^{[l]}$$ Programming Assignment: Building your deep neural network: Step by StepBuilding your deep neural network: Step by Step Programming Assignment: Deep Neural Network ApplicationDeep Neural Network Application Done!]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction to TensorFlow]]></title>
    <url>%2F2019%2F04%2F12%2FIntroduction%20to%20TensorFlow%2F</url>
    <content type="text"><![CDATA[Deeplearning.ai, Introduction to TensorFlow Course Notes Week 1A New Programming Paradigm 123456789import tensorflow as tfimport numpy as npfrom tensorflow import kerasmodel = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])model.compile(optimizer='sgd', loss='mean_squared_error')xs = np.array([0,1,2,3,4,5],dtype=float)ys = np.array([50,100,150,200,250,300],dtype=float)model.fit(xs,ys,epochs=1000)print(model.predict([7.0]))# Week2## Introduction to Computer VisionFashion MNIST12fashion_mnist = keras.datasets.fashion_mnist(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()12345model = keras.Sequential([ keras.layers.Flatten(input_shape=(28,28)), keras.layers.Dense(128, actication=tf.nn.relu), keras.layers.Dense(10, activation=tf.nn.softmax)])Using callbacks to control training123456789101112131415161718class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=&#123;&#125;): if(logs.get(&apos;loss&apos;)&lt;0.4): # logs.get(&apos;acc&apos;) control by accuracy print(&apos;\nLoss is low so cancelling training!&apos;) self.model.stop_training = Truecallbacks = myCallback()mnist = tf.keras.datasets.fashion_mnist(training_images, training_labels), (test_images, test_labels) = mnist.load_data()training_images = training_images/255.0test_images = test_images/255.0model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation = tf.nn.relu), tf.keras.layers.Dense(10, activation = tf.nn.softmax)])model.compile(optimizer=&apos;adam&apos;, loss=&apos;sparse_categorical_crossentropy&apos;)model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])# Week3## Enhancing Vision with Convolutional Neural NetworksEffects of convolution Pooling 12345678910model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(64, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(10, activation='softmax')]) model.summary() Week 4Using Real-world ImagesImage generator in TensorFlow (directories structure): 12345678910from tensorflow.keras.preprocessing.imageimport ImageDataGeneratortrain_datagen = ImageDataGenerator(rescale=1./255)train_generator = train_datagon.flow_from_directory( train_dir, target_size = (300, 300), batch_size = 128, class_mode = 'binary') sigmoid is great for binary classification 123456789# learn from generatorhistory = model.fit_generator( train_generator, steps_per_epoch=8, epochs=15, validation_data=validation_generator, validation_steps=8, verbose=2)]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>TensorFlow</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning]]></title>
    <url>%2F2019%2F03%2F29%2FMachine%20Learning%2F</url>
    <content type="text"><![CDATA[Stanford University, Machine Learning Course Notes Week 1Facebook, Apple’s photo application. Google’s page rank algorithm. Email spam filter. IntroductionAlgorithms, math and how to get them work. Machine Learning: Grew out of work in AI New capability for computers Examples: Database mining, E.g., Web click data, medical records, biology, engineering. Applications can’t program by hand. Helicopter, handwriting recognition, most of NLP, CV. Self-customizing programs: E.g., Amazon, Netflix product recommendations. Understanding human learning (brain, real AI). Arthur Samuel (1959). Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed. Tom Mitchell (1998). Well-posed Learnining Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. Machine learning algorithms: Supervised learning Unsupervised learning Others: Reinforcement learning, recommender systems. Supervised learning E.g., housing price prediction (regression) E.g., Breast cancer (malignant, benign) (classification) Unsupervised learning Clustering Applications: Organize computing clusters Social network analysis Market segmentation Astronomical data analysis E.g. Cocktail party algorithm Linear Regression with One VariableLinear Regression with One VariableHousing Prices. Traing set: housing prices Notation: m = Number of training examples x’s = “input” variable / features y’s = “output” variable / “target” variable (x, y) – one training example $(x^{(i)}, y^{(i)})$ – $i^{th}$ trainining example $$h_\theta(x)=\theta_0+\theta_1x$$Linear regression with one variable. Univariate linear regerssion. Cost function Idea: Choose $\theta_0, \theta_1$ so that $h_\theta(x)$ is close to $y$ for our training examples $(x, y)$ square error cost function:$$J(\theta_0,\theta_1)=\frac1{2m}\sum_1^m(h_\theta(x^{(1)})-y^{(1)})^2$$Target: choose $\theta_0, \theta_1 $ to minimize $J(\theta_0,\theta_1)$ Contour plots to show 3D surface: Gradient descent Have some function $J(\theta_0,\theta_1)$ Want $min_{\theta_0,\theta_1}J(\theta_0,\theta_1)$ Outline: Start with some $\theta_0, \theta_1 $ Keep changing $\theta_0, \theta_1$ to reduce $J(\theta_0,\theta_1) $ until we hopefully end up at a minimum Gradient descent algorithm: repeat until convergence:$$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)$$Note: Correct implementation is simultaneous update as following:$$temp0 :=\theta_0-\alpha\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)\\temp1 :=\theta_1-\alpha\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)\\\theta_0:=temp0\\\theta_1:=temp1$$ := assignment = assertion $\alpha$ step length If $\alpha$ is too small, gradient descent can be slow. If $\alpha$ is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge. Gradient descent can converge to a local minimum, even with the learning rate $\alpha$ fixed. As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease $\alpha$ over time. Gradient for linear regression:$$j = 0 : \frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1) = \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\\j = 1 : \frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1) = \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\cdot x^{(i)}$$Note again: update $\theta_0$ and $\theta_1$ simultaneously. Gradient descent always works with convex function (without local optimum). Batch Gradient Descent: Batch: Each step of gradient descent uses all the training examples. (Refer to the fact that the cost function is over the entire training set.) Linear Algebra ReviewMatrix: Rectangular array of numbers:$$\begin {pmatrix}1402 &amp; 191 \\1371 &amp; 821\end {pmatrix}$$Dimension of matrix: number of rows x number of columns $A_{ij}$ = “$i,j$ entry” in the $i^{th}$ row, $j^{th}$ column. Vector: An nx1 matrix.$$\begin {pmatrix}1402 \\901\end {pmatrix}$$$y_i$ = $i^{th}$ element 1-indexed or 0-indexed$$\begin {pmatrix}y_1 \\y_2 \\y_3 \\y_4\end {pmatrix}\space \space\begin {pmatrix}y_0 \\y_1 \\y_2 \\y_3\end {pmatrix}$$ Convention: upper case to refer to matrics and lower case to refer to numbers or vectors. Matrix Addition Element-wise addition. Legal matrix addtion requires matrixes with same dimension. Scalar Multiplication $$3 *\begin {bmatrix}1 &amp; 0 \\2 &amp; 5 \\3 &amp; 1\end {bmatrix}=\begin {bmatrix}3 &amp; 0 \\6 &amp; 15 \\9 &amp; 3\end {bmatrix}$$ Matrix Multiplication: Matrix multiply vector: To get $y_i$, multiply A’s $i^{th} $ row with elements of vector$x$, and add them up. Prediction = DataMatrix * parameters Matrix-matrix multiplication: $$\begin {bmatrix}1 &amp; 3 &amp; 2 \\4 &amp; 0 &amp; 1\end {bmatrix} \begin {bmatrix}1 &amp; 3 \\0 &amp; 1 \\5 &amp; 2\end {bmatrix}=\begin {bmatrix}11 &amp; 10 \\9 &amp; 14\end {bmatrix}$$ Details: A m$\times $n matrix B n$\times $o matrix m$\times $o matrix The $i^{th}$ column of the matrix $C$ is obtained by multiplying $A$ with the $i^{th}$ column of $B$. (for $i$ = 1,2,…,o). Then convert to matrix-vector multiplication. Multiple compeing hypotheses: let each hypotheses corespond to a column in the second matrix. Let $A$ and $B$ be matrices. Then in general,$$A \times B \ne B \times A$$ $$A \times (B \times C) = (A \times B) \times C$$ Identity Matrix: Denoted $I$ (or $I_{n\times n}$) Examples of identity matrices:$$\begin {bmatrix}1 &amp; 0 \\0 &amp; 1\end {bmatrix}\\begin {bmatrix}1 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 1\end {bmatrix}\\begin {bmatrix}1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end {bmatrix}$$For any matrix $A$$$A \cdot I = I \cdot A = A$$ Matrix inverse: Not all numbers have an inverse. If $A$ is an m$\times $m matrix (square matrix), and if it has an inverse,$$AA^{-1}=A^{-1}A=I$$Matrices that don’t have an inverse are “singular” or “degenerate”. Matrix Transpose: Example: $$A =\begin {bmatrix}1 &amp; 2 &amp; 0 \\3 &amp; 5 &amp; 9\end {bmatrix} \ A^T =\begin {bmatrix}1 &amp; 3 \\2 &amp; 5 \\0 &amp; 9\end {bmatrix}$$ Let $A$ be an m$\times $n matrix, and let $B=A^T$. Then $B$ is an n$\times $m matrix, and$$B_{ij}=A_{ji}$$ Week 2Linear Regression with Multiple VariablesMultiple features (variables). Notation: $n$ = number of features $x^{(i)}$ = input (features) of $i^{th}$ training example. $x_j^{(i)}$ = value of feature $j$ in $i^{th}$ training example. Hypothesis:$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n$$For convenience of notation, define $x_0=1$. ($x_0^{(i)}=1$)$$x =\begin {bmatrix}x_0 \\x_1 \\… \\x_n\end {bmatrix} \space\space \theta =\begin {bmatrix}\theta_0 \\\theta_1 \\… \\\theta_n\end {bmatrix}\inR^{n+1}$$ $$h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n=\theta^Tx$$ Multivariate linear regression. Gradient descent for multivariate linear regression $$\theta_j:=\theta_j-\alpha \frac{\partial}{\partial\theta_j}J(\theta)$$ $$\theta_j:=\theta_j-\alpha \frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$ Feature Scaling Idea: Make sure features are on a similar scale. Get every feature into approximately a $-1\leq x_i \leq 1$ range. Mean normalization Replace $x_i$ with $x_i-\mu_i$ to make features have approximately zero mean (Do not apply to $x_0=1$) and then divide it by its standard deviatioin (divide by max-min is also fine). Convergence test: Declare convergence if $J(\theta)$ decreases by less than $10^{-3}$ in one iteration. For sufficiently small $\alpha$, $J(\theta )$ should decrease on every iteration. But if $\alpha$ is too small, gradient descent can be slow to converge. Summary If $\alpha$ is too small: slow convergence. If $\alpha$ is too large: $J(\theta) $ may not decrease on every iteration; may not converge. To choose $\alpha$ , try: …, 0.001, 0.01, 0.1, 1, … (0.003, 0.03, 0.3), 3x each time. Polynomial regression Sometimes by defining new features we can get better data and model. We can transform a polynomial regression into a mutlivariant linear regression model: Normal Equation Method to solve for $\theta$ analytically. Design matrix: each row represents a sample. With normal equation, feature scaling is not necessary. Comparasion Gradient Descent: Need to choose $\alpha$. Needs many iterations. Works well even when $n$ is large. Normal Equation: No need to choose $\alpha$. Don’t need to iterate. Need to compute $(X^TX)^{-1}$ Slow if $n$ is very large. (depending on the number of features, typically n ~ 1000) Noninvertibility when using normal equation For normal equation method:$$\theta = (X^TX)^{-1}X^Ty$$What if $X^TX$ is non-invertible? (Singular/degenerate) pinv inv What causes $X^TX$ non-invertible? Redundant features (linearly dependent). Too many features (e.g. $m\leq n$). (delete some features, or use regularization). Octave/Matlab TutorialChoices: Octave, MATLAB, Python Numpy and R. who: list all the variables. whos: list all the variables in details. max(A(:)): take the maximum element of matrix A. disp(“…”): print a string. Function: 12function y = squareThisNumber(x)y = x^2; addpath(): add search path. Vectorization $$h_\theta(x)=\sum_{j=0}^n\theta_jx_j=\theta^Tx$$ $$\theta =\begin {bmatrix}\theta_0 \\\theta_1 \\\theta_2\end {bmatrix}\x =\begin {bmatrix}x_0 \\x_1 \\x_2\end {bmatrix}$$ Unvectorized implementation: 1234prediction = 0.0;for j = 1:n+1 prediction = prediction + theta(j) * x(j)end; Vectorized implementation: 1prediction = theta&apos; * x; Programming Assignment: Linear RegressionLinear Regression Week 3Logistic RegressionClassification Email: Spam / Not Spam? Online Transactions: Fraudulent (Yes/ No)? Tumor: Malignant / Benign? $$y \in {0,1}$$ 0: “Negative Class” 1: “Positive Class” Binary Classification by Linear Regression is easily affected by extreme value. Logistic Regression:$$0 \leq h_\theta(x) \leq 1$$Hypothesis:$$h_\theta(x) = g(\theta^Tx)\\g(z) = \frac{1}{1+e^{-z}}$$g is called sigmoid function or logistic function.$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$$Interpretation of Hypothesis Output $h_\theta(x)$ = estimated probability that y = 1 on input x$$h_\theta(x)=P(y=1|x;\theta)$$“Probability that y = 1, given x, parameteruzed by $\theta $”$$P(y=0|x;\theta)+P(y=1|x;\theta)=1$$Decision Boundary Cost Function If we use the same cost function as before, it would be non-convex. Thus it’s not a wise choice. So we tend to choose a convex function. Logistic regression cost function:$$Cost(h_\theta(x),y)=\begin{equation}\left{ \begin{array}{lr} -log(h_\theta(x)), &amp; if \space y =1 \\ -log(1-h_\theta(x)), &amp; if \space y = 0 \end{array}\right.\end{equation}$$ $$Cost(h_\theta(x),y)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))$$ $$J(\theta)=-\frac1m[\sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]$$ Gradient descent$$\theta_j:=\theta_j - \alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$It looks identical to linear regression! (only hypothesis changes) Advanced optimization Conjugate gradient BFGS L-BFGS Advantages: No need to manually pick $\alpha $ Often faster than gradient descent Disadvantages: More complex Multiclass classification Email foldering/tagging: Work, Friends, Family, Hobby Medical diagrams: Nol ill, Cold, Flu Weather: Sunny, Cloudy, Rain, Snow One-vs-all (one-vs-rest): Treat one multiple class problem as several binary classification problems. Train a logistic regression classifier $h_\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y=i$. On a new input $x$, to make a prediction, pick the class $i$ that maximizes$$max\space h_\theta^{(i)}(x)$$Which means the prediction takes the maximum probability the sample belongs to. Regularization Underfit: High bias Overfit: High variance Overfitting: If we have too many features, the learned hypothesis may fit the training set very well, but fail to generalize to new examples (predict prices on new examples). Addressing overfitting: Reduce number of features Manually select which features to keep. Model selection algorithm. Regularization Keep all the features, but reduce magnitude/values of parameters $\theta_j$. Works well when we have a lot of features, each of which contributes a bit to predicting $y$. Regularization Small values for parameters $\theta_0,\theta_1,…,\theta_n$ Simpler hypothesis Less prone to overfitting $$J(\theta)=\frac1{2m}[\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum_{i=1}^m\theta_j^2]$$ $\lambda$: regularization parameter, control the trade off between fitting the training set well and keeping parameters small (keeping hypothesis simple) If $\lambda $ is extremely large, then $h_\theta(x)=\theta_0$. (end up with the simplest hypothesis and high bias) Gradient descent with regularization$$\theta_0:=\theta_0-\alpha \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_0^{(i)}$$ $$\theta_j:=\theta_j-\alpha [\frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}+\frac\lambda m\theta_j], \space for \space j = 1, 2, …, n$$ Equivalent:$$\theta_j:=\theta_j(1-\alpha\frac\lambda m)-\alpha \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$ Normal equation with normalization Regularized logistic regression Cost function:$$J(\theta) = -[\frac1m \sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2$$ Regularized advanced optimization Programming Assignment: Logistic RegressionLogistic Regression One way to fit the data better is to create more features from each data point. Logistic classifier prones to be overfitting on higher-dimension features. (consider the decision boundary) Week 4Neural Networks: RepresentationLinear regression and logistic regression are not designed for Non-linear Classification problems and multiple features. Neural Networks Origins: Algorithms that try to mimic the brain. Was very widely used in 80s and early 90s; popularity diminished in late 90s. Recent resurgence: State-of-the-art technique for many applications Neuron model: Logistic unit Sigmoid (logistic) activation function.$$g(z) = \frac{1}{1+e^{-z}}$$$\theta $: “weights” Neural Network $a_i^{(j)}$ = “activation” of unit $i$ in layer $j$ $\theta^{(j)}$ = matrix of weights controlling function mapping from layer $j$ to layer $j+1$ If network has $s_j$ units in layer $j$, $s_{j+1}$ units in layer $j+1$, then $\theta^{(j)}$ will be of dimension $s_{j+1}*(s_j+1)$. The extra dimension represents the bias. Forward propagation: Vectorized implementation Neural Network learning its own features “Architectures” refers to how the different neurons are connected to each other. Handwritten digit classification Multi-class Classification Multiple output units: One-vs-all. Programming Assignment: Multi-class Classification and Neural NetworksMultile-class Classification and Neural Networks Week 5Neural Networks: Learning$L$ = total no. of layers in network $s_l$ = no. of units (not counting bias unit) in layer $l$ Binary classification: $y$ = 0 or 1, 1 output unit Multi-class classification (K classes): $y \in R^K$ Cost function Gradient computation Given one training example $(x,y)$: Forward propagation:$$a^{(1)} = x \\z^{(2)}=\theta^{(1)}a^{(1)} \\a^{(2)}=g(z^{(2)}) \space (add \space a_0^{(2)}) \\z^{(3)}=\theta^{(2)}a^{(2)} \\a^{(3)}=g(z^{(3)}) \space (add \space a_0^{(3)}) \\z^{(4)}=\theta^{(3)}a^{(3)} \\a^{(4)}=h_\theta(x)=g(z^{(4)})$$Backpropagation algorithm Intuition: $\delta_j^{(l)}$ = “error” of node $j$ in layer $l$.$$\delta^{(4)} = a^{(4)}-y$$ $$\delta^{(3)}=(\theta^{(3)})^T\delta^{(4)}.*g’(z^{(3)})$$ $$\delta^{(2)}=(\theta^{(2)})^T\delta^{(3)}.*g’(z^{(2)})$$ $$\frac{\partial}{\partial\theta_{ij}^{(l)}}J(\theta) = a_j^{(l)}\delta_i^{(l+1)}$$Training set ${ (x^{(1)},y^{(1)}),…, (x^{(m)},y^{(m)})}$ Set $\Delta_{ij}^{(l)}=0 $ for all $l,i,j$. For $i$ = 1 to $m$ ​ Set $a^{(1)}=x^{(i)}$ ​ Perform forward propagation to compute $a^{(l)}$ for $l$ = 2,3,…,L ​ Using $y^{(i)}$, compute $\delta^{(L)}=a^{(L)}-y^{(i)}$ ​ Compute $\delta^{(L-1)},\delta^{(L-2)},…,\delta^{(2)}$ // backpropagation step ​ $\Delta_{ij}^{(l)}:=\Delta_{ij}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$$$D_{ij}^{(l)}:=\frac1m\Delta_{ij}^{(l)}+\lambda\theta_{ij}^{(l)} \space if \space j \neq0 \\D_{ij}^{(l)}:=\frac1m\Delta_{ij}^{(l)} \space if \space j \ =0$$ Random initialization: Symmetry breaking Training a neural network Pick a network architecture (connectivity pattern between neurons) No. of input units: Dimension of features $x^{(i)}$ No. output units: Number of classes Reasonable default: 1 hidden layer, or if &gt;1 hidden layer, have same no. of hidden units in every layer (usually the more the better) Randomly initialize weights Implement forward propagation to get $h_\theta(x^{(i)})$ for any $x^{(i)}$ Implement code to compute cost function $J(\theta)$ Implement backprop to compute partial derivatives $\frac{\partial}{\partial\theta_{jk}^{(l)}}J(\theta)$ Use gradient checking to compare $\frac{\partial}{\partial\theta_{jk}^{(l)}}J(\theta)$ using backpropagation vs. using numerical estimate of gradient of $J(\theta)$, Then disable gradient checking code. Use gradient descent or advanced optimization method with backpropagation to try to minimize $J(\theta)$ as a function of parameters $\theta$ Programming Assignment: Neural Network LearningNeural Network Learning Week 6Advice for Applying Machine LearningDebuggin a learning algorithm: Get more training examples Try smaller sets of features Try getting additional features Try adding polynomial features $(x_1^2,x_2^2,x_1x_2,etc)$ Try decreasing $\lambda$ Try increasing $\lambda$ Evaluating your hypothesis Training set/ Test set split, typically 70% vs. 30% (remember to randomly shuffle) Learn parameter $\theta$ from training data (minimizing training error $J(\theta)$) Compute test set error Misclassification error (0/1 misclassification error) Model selection Training set, cross validation set and test set split. Typically 60%, 20% and 20% Select by validation set, and finally test on test set. Note that we should not select by test set. (Means that we fit an extra parameter to the validation set) Bias and variance Choosing the regularization parameter $\lambda$ Try $\lambda=0$ Try $\lambda=0.01$ Try $\lambda=0.02$ Try $\lambda=0.04$ … Try $\lambda=10.24$ Steps of choosing $\lambda $: Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24}); Create a set of models with different degrees or any other variants. Iterate through the \lambdaλs and for each \lambdaλ go through all the models to learn some Θ. Compute the cross validation error using the learned Θ (computed with λ) on the JCV(Θ) without regularization or λ = 0. Select the best combo that produces the lowest error on the cross validation set. Using the best combo Θ and λ, apply it on Jtest(Θ) to see if it has a good generalization of the problem. Learning curves High bias If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much. High variance If a learning algorithm is suffering from high variance, getting more training data is likely to help. “Small” neural network (fewer parameters; more prone to underfitting): Computationally cheaper “Large” neural network (more parameters; more prone to overfitting): Computationally more expensive Programming Assignment: Regularized Linear Regression and Bias/VarianceRegularized Linear Regression and Bias/Variance Machine Learning System DesignBuilding a spam classifier Supervised learning. $x$ = features of emails. $y$ = spam (1) or not spam (0). Feature $x$: Choose 100 words indicative of spam/not spam. Note: In practice, take most frequently occurring $n$ words (10,000 to 50,000) in training set, rather than manually pick 100 words. How to improve model performance? Collect lots of data Develop sophisticated features based on email routing information (from email header). Develop sophisticated features for message body, e.g. should “discount” and “discounts” be treated as the same word? How about “deal” and “Dealer”? Features about punctuation? Develop sophisticated algorithm to detect misspellings (e.g. m0rtgage, med1cine, w4tches.) Error Analysis Start with a simple algorithm that you can implement quickly. Implement it and test it on your cross-validation data. Plot learning curves to decide if more data, more features, etc. are likely to help. Error analysis: Manually examine the examples (in cross validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on. Precision/Recall We prefer high Precision and high Recall. Trade off precision and recall $F_1$ Score (F score)$$2\frac{PR}{P+R}$$ Week 7Support Vector MachinesCost:$$minC\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{i=0}^n\theta_j^2$$Trade-off$$CA+B$$Hypothesis$$h_\theta(x)=\begin{equation}\left{ \begin{array}{lr} 1, &amp; if \space \theta^Tx \geq0 \\ 0, &amp; otherwise \end{array}\right.\end{equation}$$ SVM Decision Boundary: Linearly separable case Non-linear Decision Boundary Each landmarks define a new feature thought all samples. Some intuition of the kernel function Choosing the landmarks Exactly the location as the training examples. Given $(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})$. choose $l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…,l^{(m)}=x^{(m)}$. Given example $x$:$$f_1 = similarity(x,l^{(1)}) \\f_2 = similarity(x,l^{(2)}) \\…$$ $$f =\begin {bmatrix}f_0 \\f_1 \\f_2 \\… \\f_m\end {bmatrix}$$ Hypothesis: Given $x$, compute features $f \in R^{m+1}$ Predict “y=1” if $\theta^Tf \geq 0$ Training:$$minC\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)})]+\frac{1}{2}\sum_{i=0}^n\theta_j^2$$C (=$\frac{1}{\lambda}$) Large C: Lower bias, high variance. (small $\lambda $) Small C: Higher bias, lower variance. (Large $\lambda $) $\sigma^2$ Large $\sigma^2$: Features $f_i$ vary more smoothly. High bias, lower variance. Small $\sigma^2$: Features $f_i$ vary less smoothly. Lower bias, higher variance. Use SVM software package (e.g. liblinear, libsvm, …) to solve for parameters $\theta$. Need to specify: Choice of parameter C. Choice of kernel (similarity function): No kernel (“linear kernel”, apply for n large, m small), Gaussian kernel (Non-linear classifier, apply for n small, m large). Note: Not all similarity functions $similarity(x,l)$ make valid kernels. (Need to satisfy technical condition called “Mercer’s Theorem” to make sure SVM packages’ optimizations run correctly, and do not diverge). Many off-the-shelf kernels available: Polynomial kernel: $k(x,l) = (x^Tl)^2, (x^Tl)^3,(x^Tl+1)^3, (x^Tl+constant)^{degree}$ More esoteric: String kernel, chi-square kernel, histogram intersection kernel, … Multi-class classification Many SVM packages already have built-in multi-class classification functionality. Otherwise, use one-vs.-all method. (Train $K$ SVMs, one to distinguish $y=i$ from the rest, for $i$ = 1,2,…,$K$), get $\theta^{(1)},\theta^{(2)},…,\theta^{(K)}$ Pick class $i$ with largest $(\theta^{(i)})^Tx$ Logistic regression vs. SVMs If $n$ is large (relative to $m$): Use logistic regression, or SVM without a kernel (“linear kernel”) If $n$ is small, $m$ is intermediate: Use SVM with Gaussian kernel If $n$ is small, $m$ is large: Create/add more features, then use logistic regression or SVM without a kernel Neural network likely to work well for most of these settings, but may be slower to train. Programming Assignment: Support Vector MachinesSupport Vector Machines Week 8Unsupervised LearningTraining set: ${ x^{(1)},x^{(2)},x^{(3)},…,x^{(m)} }$ Applications of clustering Market segmentation Social network analysis Organize computing clusters Astronomical data analysis K-means algorithm cluster centroids Input: $K$ (number of clusters) Training set ${x^{(1)},x^{(2)},…,x^{(m)}}$ $x^{(i)}\in R^n$ (drop $=x_0=1$ convention ) Randomly initialize $K$ cluster centroids $\mu_1,\mu_2,…,\mu_K \in R^n$ Repeat{ ​ for i = 1 to m ​ $c^{(i)}$ := index (from 1 to $K$) of cluster centroid closest to $x^{(i)}$ ​ for k = 1 to $K$ ​ $\mu_k$ := average (mean) of points assigned to cluster $k$ } K-means optimization objective $c^{(i)}$ = index of cluster (1,2,…,$K$) to which example $x^{(i)}$ is currently assigned $\mu_k$ = cluster centroid $k$ ($\mu_k \in R^n$) $\mu_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned Optimization objective:$$J = \frac1m\sum_{i=1}^{m}||x^{(i)}-\mu_{c^{(i)}}||^2$$Distortion cost function Random initialization Should have $K &lt; m$ Randomly pick $K$ training examples. Set $\mu_1 ,…, \mu_K$ equal to these $K$ examples. Choosing the value of K Elbow method. Dimensionality ReductionData Compression Data Visulization Prefer 2-d or 3d data. Principal Component Analysis (PCA) problem formulation Reduce from 2-dimension to 1-dimension: Find a direction (a vector $u^{(1)}\in R^n$) onto which to project the data so as to minimize the projection error. Reduce from n-dimension to k-dimension: Find $k$ vectors $u^{(1)},u^{(2)},…,u^{(k)}$ onto which to project the data, so as to minimize the projection error. PCA is not linear regression Left: linear regression Right: PCA Principal Component Analysis algorithm Data preprocessing: Training set: $x^{(1)},x^{(2)},…,x^{(m)}$ Preprocessing (feature scaling/mean normalization)$$\mu_j=\frac1m\sum_{i=1}^mx_j^{(i)}$$Replace each $x_j^{(i)}$ with $x_j-\mu_j$. If different features on different scales, scale features to have comparable range of values.$$x_j^{(i)}=\frac{x_j^{(i)}-\mu_j}{s_j}$$Algorithm steps: Mean normalization and feature scaling. Compute “covariance matrix”: $$\Sigma = \frac{1}{m}\sum_{i=1}^n(x^{(i)})(x^{(i)})^T$$ Compute “eigenvectors” of matrix $\Sigma$: 1[U,S,V] = svd(Sigma); Sigma is a $n\times n$ matrix. U is also a $n \times n$ matrix, with each column represents a eigenvector. Ureduce = U(:, 1:k) z = Ureduce’ * x; Reconstruction from compressed representation$$z = U^T_{reduce}x$$ $$x_{approx} = U_{reduce}*z$$ Choosing $k$ (number of principal components) Average squared projection error: $\frac1m\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2$ Total variation in the data: $\frac1m\sum_{i=1}^m||x^{(i)}||^2$ Typically, choose $k$ to be smallest value so that$$\frac{Average \space error}{Variation} \leq0.01$$“99%” of variance is retained Application of PCA Compression Reduce memory/disk needed to store data Speed up learning algorithm Visualization Before implementing PCA, first try running whaever you want to do with the original/raw data. Only if that doesn’t do what you want, then implement PCA. Programming Assignment: K-Means Clustering and PCAK-Means Clustering and PCA Week 9Anomaly DetectionAnomaly detection example Dataset: ${ x^{(1)},x^{(2)},…,x^{(m)} }$ Is $x_{test}$ anomalous? $p(x_{test}) &lt; \epsilon$ -&gt; flag anomaly $p(x_{test}) \geq \epsilon$ -&gt; OK Fraud detection (Online website): $x^{(i)}$ = features of user $i$’s activities Model $p(x)$ from data. Identify unusual users by checking which have $p(x) &lt; \epsilon$ Manufacturing Monitoring computers in a data center. $x^{(i)}$ = features of machine $i$ $x_1$ = memory use, $x_2$ = number of disk accesses/sec, $x_3$ = CPU load, $x_4$ = CPU load/network traffic. … Gaussian (Normal) distribution N ~ N($\mu$, $\sigma ^2$) $$p(x;\mu,\sigma ^2) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})$$ Parameter estimation$$\mu = \frac1m\sum_{i=1}^mx^{(i)} \\\sigma^2 = \frac1m\sum_{i=1}^m(x^{(i)}-\mu)^2$$ Density estimation Data set split: Possible evaluation metrics: True positive, false positive, false negative, true negative Precision/Recall $F_1$-score Can also use cross validation set to choose parameter $\epsilon$ Anomaly detection vs. Supervised learning Anomaly detection: Very small number of positive examples (y = 1). (0-20 is common). Large number of negative (y = 0) examples. Many different “tyles” of anomalies. Hard for any algorithm to learn from positive examples what the anomalies may look like; future anomalies may look nothing like any of the anomalous examples we’ve seen so far. Fraud detection Manufacturing (e.g. aircraft engines) Monitoring machines in a data center Supervised learning: Large number of positive and negative examples. Enough positive examples for algorithm to get sense of what positive examples are like, future positive examples likely to be similar to ones in training set. Email spam classification Weather prediction (sunny/rainy/etc). Cancer classification Feature selection and transformation Error analysis for anomaly detection Want $p(x)$ large for normal examples $x$. ​ $p(x)$ small for anomalous examples $x$. Most common problem: ​ $p(x)$ is comparable (say, both large) for normal and anomalous examples Choosing features that might take on unusually large or small values in the event of an anomaly. Multivariate Gaussian (Normal) distribution $x\in R^n$. Don’t model $p(x_1),p(x_2),…,$ etc. separately. Model $p(x)$ all in one go. Parameters: $\mu \in R^n$, $\Sigma \in R^{n\times n}$ (convariance matrix)$$p(x;\mu,\Sigma) = \frac{1}{(2\pi)^\frac n2 |\Sigma|^{\frac12}}exp(-\frac12(x-\mu)^T\Sigma^{-1}(x-\mu))$$ Original model vs. Multivariate Gaussian Original: Manually create features to capture anomalies where $x_1,x_2$ take unusual combinations of values. Multivariate: Automatically captures correlations between features. Have many constrains. Recommender SystemsContent-based recommendations For each user $j$, learn a parameter $\theta^{(j)}\in R^3$. Predict user $j$ as rating movie $i$ with $(\theta^{(j)})^Tx^{(i)} $ stars. Problem formulation: $r(i,j)=1$ if user $j$ has rated movie $i$ (0 otherwise) $y^{(i,j)}$ = rating by user $j$ on movie $i$ (if defined) $\theta^{(j)}$ = parameter vector for user $j$ $x^{(i)}$ = feature vector for movie $i$ For user $j$, movie $i$, predicted rating: $(\theta^{(j)})^Tx^{(i)} $ Collaborative filtering Algorithm Low Rank Vectorization Finding related movies$$small \space ||x^{(i)}-x^{(j)}|| -&gt; movie \space j \space and \space i \space are \space “similar”$$ Mean Normalization Programming Assignment: Anomaly Detection and Recommender SystemsAnomaly Detection and Recommender Systems Week 10Large Scale Machine Learning It’s not who has the best algorithm that wins. It’s who has the most data. Stochatic gradient descent Out loop typically 1-10 times. Mini-batch gradient descent Batch gradient descent: Use all $m$ examples in each iteration Stochastic gradient descent: Use 1 example in each iteration Mini-batch gradient descent: Use $b$ examples in each iteration b = mini-batch size b = 2~100 With vectorization, Mini-batch outperforms Stochastic as regard to computation efficiency. Learning rate decay:$$\alpha = \frac{const1}{iterationNumber+const2}$$ Online learning Map-reduce and data parallelism Many learning algorithms can be expressed as computing sums of functions over the training set. Week 11Application Example: Photo OCRPhoto Optical Character Recognition Photo OCR pipeline Text detection Character segmentation Character classification Sliding window detection step-size / stride These cencepts are related to computer vision which is introduced in the deeplearninng specialization. I should take notes for these in another course/specialization. Artificial data systhesizing Make sure you have a low bias classifier before expanding the effor. (Plot learning curves). E.g. keep increasing the number of features/number of hidden units in neural network until you have a low bias classifier. “How much work would it be to get 10x as much data as we currently have?” Artificial data synthesis Collect/label it yourself “Crowd source” (E.g. Amazon Mechanical Turk) Ceiling analysis Estimating the errors due to each component. What part of the pipeline should you spend the most time trying to improve? E.g. It is really important to do ceiling analysis. Summary]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Machine Learning</tag>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Robotics: Perception]]></title>
    <url>%2F2019%2F03%2F26%2FRobotics-Perception%2F</url>
    <content type="text"><![CDATA[University of Pennsylvania, Robotics: Perception Course Notes Cover: Geometry of Image Formation Projective Transformations Pose Estimation Multi-View Geometry Learning Purpose: To be a candidate. Self promotion. Be familiar with Matlab again. Matlab help Videos are all from Youtube Week 1, Geometry of Image FormationIntroduction Projection center Augmented reality Where am I? Camera ModelingGannet: Estimate distance from water. Camera: imaging chip and a lens $\frac 1f = \frac 1a + \frac 1b$ blured picture (when we change the image plane by sticking on the mannual mode of the camera) A point object of the same size coming closer results on a larger image. A point moving on the same ray does not change its image. (regarding to fixed image plane) Single View GeometryWorld Coordinates: x, y, z locations. Camera Coordinates: Two dimensional plane. Given the picture, how tall is the person in the picture? “Single View Metrology”, ICCV 1999, CVPR 1998 Ideas 1: Measurements on planes. Moving “not vertical” to “vertical” and then measure. Ideas 2: Vanishing points. Phical lines in the real world which are parallel will meet at the vanishing point when approaching infinity. More on Perspective ProjectionPerspectography. Strategy for projecting $P^*$ to $P$ on the same plane rather than on the image plane. Quiz: Introduction Glimpse on Vanishing PointsVanishing points Properties: Any two parallel lines have the same vanishing point. The ray from C throught v point is parallel to the lines. An image may have more than one vanishing point. A single point can form a line between the optical center and that point, the ray can represent all the physical lines out there which are parallel. Multiple Vanishing Points: For every direction we have on the ground plane, there is a unique point in the image space. All the vanishing points will form a horizon. Any set of parallel lines on the plane define a vanishing point. The union of all of these vanishing points is the horizon line (also called vanishing line) Different planes define different vanishing lines. Computing vanishing lines: I is intersection of horizontal plane through C with image plane. Compute I from two sets of parallel lines on ground plane. All points at same height as C project to I. Provided way of comaring height of objects in the scene. Measuring height: Trace a line from the bottom of the ruler throught feet of the person to infinity (intersect with the horizon). Quiz: Vanishing Points Perspective Projection IOne-Point Perspective Partial review. Not all pictures should have the same vanishing points. The projective plane: Represent points at infinity, homographies, perspective projection, multi-view relationships. A point in the image is a ray in projective space. $$\begin{bmatrix}x \\y \\\end{bmatrix}-homogeneous coords-&gt;\begin{bmatrix}x \\y \\1 \\\end{bmatrix}$$Projective lines Eg: a, b and c are parameters in the 3D space but also related to the equation of the line. 3D plane equation:$$ax + by + cz = 0$$ Perspective Projection IIDefine a line: we use two points on the line to define it: We have:$$x\cdot l = 0 ,\space x’\cdot l = 0$$So $l$ is the surface normal vector of the orange plane, which is coresponding to the line on the plane $P_1P_2$ . (Please think that points on the line can be represented as $(x,y,1)$, then it’s easy to understand) Reference materials of projective view: surface normal: a unit vector at a given point of a surface which is perpendicular to the tangent plane. Intersection of lines: Mistake in this video at arround 8:30. Point-Line DualityWhen P has the form $(x,y,0)$: We convert a 3D point into a 2D point by dividing the last element out. (Homogeous coords) Some intuitions: $x/0 -&gt; infinity$. So very likely it’s a vanishing point. Point at infinity: Eg: More general of intersection of parallel lines: All parallel lines intersects at the point at infinity:$$line \space l = (a,b,c)^T \space intersects \space at \space (b,-a,0)^T$$ Line at infinity (a line passing all points at infinity) :$$l_\infty=(0,0,1)^T$$Because:$$\begin {bmatrix}0\0\1\end {bmatrix}\begin {bmatrix}x_1 \\x_2 \\0\end {bmatrix}= 0$$ Ideal points and lines (noting that there are two coords system, one for real space which is 3D, one for image space which is 2D): Ideal point (“point at infinity”) $p = (x,y,0)$ — parallel to image plane It has ifinite image coordinates (2D coordinates for point) Ideal line $l = (a,b,0)$ — parallel to image plane Corresponds to a line in the image (finite coordinates) Quiz: Perspective Projection Rotations and TranslationsTransformation between camera and world coordinates systems Convention: Red for X, Green for Y and Blue for Z.$$^cP = ^cR_w \space^wP+^cT_w$$Point P can be expressed with respect to “w” or “c” coordinate frames. If we set $^wP$ to zero, then, $^cP=^cR_w+^cT_w$ is the vector from camera origin to world origin.$$^cR_w=(r_1 \ r_2 \ r_3)$$Set $^wP=(1,0,0)$ and imagine $^cT_w=0$. Then $^cP = r_1 $ whch means that the rotation columns are the world axis expressed in the camera coordinate system. Eg: The translation is easy from the picture:$$\begin {pmatrix}0 \\5 \\10\end {pmatrix}$$We have to make sure that the 3x3 matrix is a rotation matrix, which means $R^TR=I$ and det(R) = 1. Transform between coordinate systems of three: Inverse: Quiz: Rotations and Translations Pinhole Camera Model Pinhole Camera: $1^{st}$ Person Camera world 3D to 2D image:$$x’=f\frac X Z \ y’=f\frac Y Z$$ Focal Length and Dolly Zoom EffectFocal length Process of changing focal length: zooming Focal length longer: field of view narrow Intrinsic Camera a Parameter3D to 2D image:$$x’=f\frac X Z \ y’=f\frac Y Z$$ $$x=P_0X$$ $P_0$ is the camera projection matrix Conversion from mm to pixels Optical center on the image plane: Principal point What we do is shifting and scaling by the measurement of pixels: Map camera coordinate to pixel coordinate (matrix form): $Px,P_y$ is the principle point (where optical axis hits image plane) (not exactly the center of the image) s is the slant factor, when the image plane is not normal to the optical axis Three factors: A scale factor that converts physical focal length to pixel unit. Position of image center (principal point). A skew factor between x and y axis of the image. 3D World to First Person TransformationMultiple View Geometry $3^{rd}$ person view measurement Why: When we are moving around to see different objects from different point of view, which means that the origin is always changing. Convert the 3D representation into first person coordinate. Every camera has its own first person coordinate system. Translate the world coordinate into the camera coordiante Translate the camera coordinate into the pixel coordinate Combining them together, we get:$$x=K[R,t]X$$Comlete form: $$3D \space from \space 3^{rd} \space person –&gt;3D \space from \space 1^{rd} \space person –&gt;2D \space pixel \space domain$$ Special cases Plnar objects: all x,y,z sits in a plane We have freedom to choose how we measure 3D points from $3^{rd}$ person view. Rotating camera: known optical center panorama Quiz: Dolly Zoom Quiz: Feeling of Camera Motion How to Compute Intrinsics from Vanishing PointsCompute focal length and image center from pure geometry without using projection equations. Eg: Three orthogonal sets of parallel lines create three orthogonal vanishing points. What does the horizon between A and B tells us about the camera? It gives us information about how the horizon is oriented with respect to the camera. Because the camera is tilted, point C is not on the horizon. Just knowledge of A and B doesn’t determine C. We need also the focal length and the image center in order to fix C. Later for how to compute: H is the orthocenter of ABC Focal length computation, easy as following: So f can be determined from $d_1$, $d_2$ and $d_3$, which are all known. Quiz: How to Compute Intrinsics from Vanishing Points Camera Calibration Cameras with large field of view have radial distortions. A procedure called calibration (Estimates the intrinsic parameters) f focal length ($u_0$,$v_0$) image center $k_1,k_2,…$ radial distortion parameters Matlab has calibration toolbox. Quiz: Camera Calibration Programming Assignment: Dolly ZoomDolly Zoom Week 2, Projective TransformationsVanishing Points; How to Compute Camera Orientation$3^{rd}$ person perspective: World coordinate system First person coordinate system: The person himself How we orientate in the real world: $R$ and $t$ For $z_\infty=[0\space 0 \space 1 \space 0]^T$, $v_z=Kr_3$, K is the calibration matrix. To fixed all rotation angles, we need 2 vanishing point in perpendicular direction. If we can recognize two perpendicular directions in the physical space, then we can recover the camera orientation relative to the world. How to figure out both translation and rotation? If we do translation on the camera, the vanishing point remain itself. But when we rotate, the vanishing point will move.We can recover rotation column $r_3$ from vanishing point z and $r_1$ from vanishiong point x. And using these two, we can figure out the camera orientation.Rotation column $r_3$ tells us about the pan and tilt angles. (left and right, up and down)Using K inverse transformation, we can transform from pixel-domain points into optical world.## Quiz: Homogeneous Coordinates Compute Projective TransformationsA perspective projection of a plane (like a camera image) is always a projective transformation. Definition A projective transformation is any invertible matrix transformation $P^2-&gt;P^2$ A projective transformation $A$ maps $p$ to $p’—Ap$ A projective transformation is also known as collineation or homography A projective transformation preserves incidence: Three collinear points are mapped to three collinear points. And three concurrent lines are mapped to three concurrent lines. Projective transformation of lines If $A$ maps a point to $Ap$, then where does a line $l$ map to? Line equation in original plane$$l^Tp=0$$Line equation in image plane $p’—Ap$$$l^TA^{-1}p’=0$$implies that $l’=A^Tl$. Computation of projective transformation: Assume that a mapping $A$ maps the three points$$\begin {pmatrix}a \b \c\end {pmatrix}=\begin {pmatrix}a\alpha \b\beta \c\gamma\end {pmatrix}\begin {pmatrix}1 &amp; 0 &amp; 0 \0 &amp; 1 &amp; 0 \0 &amp; 0 &amp; 1\end {pmatrix}$$is a valid projective transformation, but 3 degrees of freedom so not sufficient.This transformation map (1,0,0), (0,1,0) and (0,0,1) to a,b and c correspondingly. We neeed to compute $\alpha,\beta$ and $ \gamma$. Four points not three of them collinear suffice to recover unambiguously projective transformation. With the forth point mapped point $d$, we can calculate as following:$$\begin {pmatrix}a \b \c\end {pmatrix}\begin {pmatrix}\alpha \\\beta \\\gamma\end {pmatrix}=d$$ Quiz: Projective Transformations Projective Transformations and Vanishing PointsGeometric interpretation of the projective transformations. Projective transformation Aka Homography or Collineation Represents the perspective projection from a ground plane to an image plane! It is an invertible 3x3 matrix but has 8 independent parameters For example if (X,Y) measured in meters on the ground and (u,v) in pixels $$\begin {pmatrix}u \\v \\1 \end {pmatrix}H\begin {pmatrix}X \\Y \\1\end {pmatrix}$$ &lt;img src = “https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-10.png&quot; style = “zoom:60%” Quiz: Vanishing PointsNote for question 2 and 3: When zooming, the calibration matrix K varies, so the K inverse transformation will change the location of vanishing points. While for translation, the vanishing points remain in their original position because translation disappear. Question 4 requires one more step “inverse”. Cross Ratios and Single View MetrologyThe middle point of a segment preserved under parallel projection. For a camera, the middle point of a segment doesn’t preserve. But the Cross-Ratio is preserved. The cross-ratio remain the same under any projective transformation. We can use this to measure distances in the real world. E.g. What happens when one of the points is at infinity? And we can also compute the position of the vanishing point in the image. Distance transfer: Single View Metrology via Cross Ratios: If we know a vanishing point we can compute any ratio along this direction! We can transfer distances among parallel lines in the world if we know two vanishing points. In none of these steps we used focal length or any other intrinsics. We can do some image forensics on paintings or old photos! Quiz: Cross Ratios and Single View Metrology Two View Soccer MetrologyThe forth week of the course will focus on this problem. Programming Assignment: Image Projection using HomographiesImage Projection using Homographies Week 3, Pose EstimationVisual FeaturesWhat we want from features? Detection repeatability: When they are detected in one image to be detected in another one from the same scene even if image differs in scale and orientation. We should be able to match features using a descriptor of the neighborhood. This descriptor should not change significantly under viewpoint changes like scale and rotation. We call this property descriptor invariance. The notion of scale space We can build a same scale by subsampling.Scale selection Laplacian of Gaussian (LoG) Scale Space SIFT: Scale Invariant Feature Transform Laplacian Each key point corresponds to a 4x4 grid of histograms. Quiz: Visual Features Singular Value Decomposition1890， Carl Friedrich Gauss U/V: Column orthogonal matrix D: Diagnal matrix: SVD as basis + transformed Address Eigenface generation: Rank: Nullspace: Matrix Inversion with SVD Two types of Least Square Problem: Line fitting: Quiz: Singular Value Decomposition RANSAC: Random Sample Consensus IOutlier effects (sensitivity): Strategy: To find a model that accords with the maximum number of samples. Assumptions: Majority of good samples agree with the underlying model (good apples are same and simple). Bad samples does dot consistently agree with a single model (all bad apples are different and complicated). Each time choose two points, pick the ‘best’ two points pair. Quiz: RANSAC Answer for the 3rd question is “264”, a little strange.## Where am I? Part 1Homography Linear Estimation Where am I? Part 2Perspective-n-Point 6 points can give 12 constrains Pose from 3D Point Correspondences: The Procrustes ProblemProcrustes Problem Given two shapes find the scaling, rotation, and translation that fits one into the other. Quiz: 3D-3D Pose Pose from Projective Transformations Pose from Point Correspondences P3PThe perspective 3-Point problem of P3P or in photogrammetry the Resection problem: The Snellius-Pothenot problem. Quiz: Pose Estimation Programming Assignment: Image ProjectionImage Projection Pose Estimation Week 4, Multi-View GeometryEpipolar Geometry IGiven two pictures of the scene, calculate the relative transformation and rotation between the two. Epipole &amp; Epipolar line Point correspondence Epipole calculation -&gt; Least Square problem $$E = [t]_xR$$$E$ is called the essential matrix. It hides inside both transformation and rotation relations between the two cameras. So we can compute $E$ by a few point correspondence.## Epipolar Geometry IIFundamental matrix: $$x_1=KX_1 \space x_2=KX_2$$ Fundamental matrix 8 correspondences are needed to solve $F$ (one for scaling). 8 Point Algorithm Epipolar Geometry IIIRecovery of R,T from Fundamental Matrix Essential matrix and fundamental matrix transformation:$$E = K^TFK$$ $$E = [t]_xR$$ First recover t: SVD of E if $det(R) =-1,t=-t,R=-R$ Point Triangulation $$C=-R^Tt$$ Quiz: Epipolar Geometry10.5/12 。。。。 RANSAC: Random Sample Consensus IIError function: distance to the Epipolar line$$\theta=\frac{|ax+by+c|}{\sqrt{a^2+b^2}}$$ Nonlinear Least Squares IThe properti4es of linear least squares: Has the global/unique solution. Has the closed form solution (non-iterative solve). Is solved efficiently (SVD). Requires no extra parameters such as initialization. Nonlinear Least Squares IIReprojection Error (Geometric Error) Nonlinear Least Squares IIIJacobian matrix Quiz: Nonlinear Least Squares Optical Flow: 2D Point Correspondences 3D Velocities from Optical Flow Quiz: 3D Velocities from Optical Flow 3D Motion and Structure from Multiple ViewsVisual Odometry Bundle Adjustment IBundle Adjustment IIBundle Adjustment IIIQuiz: Bundle Adjustment Programming Assignment: Structure from MotionStructure from Motion]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Matlab</tag>
        <tag>Robotics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MathJax Formula]]></title>
    <url>%2F2019%2F03%2F23%2FMathJax%20Formula%2F</url>
    <content type="text"><![CDATA[MathJax Formula memo. MathJax is an open-source JavaScript display engine for Latex, MathML, and AsciiMath notation that works in all modern browsers. Two modes: Inline: embedded into text. Displayed: displayed individually. Greek alphabet Name Upper Tex Lower Tex alpha $A$ A $\alpha$ \alpha beta $B$ B $\beta$ \beta gamma $\Gamma$ \Gamma $\gamma$ \gamma delta $\Delta$ \Delta $\delta$ \delta epsilon $E$ E $\epsilon$ \epsilon zeta $Z$ Z $\zeta$ \zeta eta $H$ H $\eta$ \eta theta $\Theta$ \Theta $\theta$ \theta iota $I$ I $\iota$ \iota kappa $K$ K $\kappa$ \kappa lambda $\Lambda$ \Lambda $\lambda$ \lambda mu $M$ M $\mu$ \mu nu $N$ N $\nu$ \nu xi $\Xi$ \Xi $\xi$ \xi omicron $O$ O $\omicron$ \omicron pi $\Pi$ \Pi $\pi$ \pi rho $P$ P $\rho$ \rho sigma $\Sigma$ \Sigma $\sigma$ \sigma tau $T$ T $\tau$ \tau upsilon $\Upsilon$ \Upsilon $\upsilon$ \upsilon phi $\Phi$ \Phi $\phi$ \phi chi $X$ X $\chi$ \chi psi $\Psi$ \Psi $\psi$ \psi omega $\Omega$ \Omega $\omega$ \omega Superscript and SubscriptGroup the notation by curly bracket “{}”, other wise, the script only count for the one consecutive letter. Text Tex $x^{2}$ x^{2} $x_0$ x_0 $\hat x$ \hat x $\widehat {xy} $ \widehat {xy} $\hat {xy} $ \hat {xy} $\overline {xyz}$ \overline {xyz} $\vec x$ \vec x $\dot x$ \dot x $\ddot x$ \ddot x Brackets Left Tex Right Tex$$ $\lbrace$ \lbrace $\rbrace$ \rbrace $\langle$ \langle $\rangle$ \rangle $\lceil$ \lceil $\rceil$ \rceil $\lfloor$ \lfloor $\rfloor$ \rfloor Fraction and Radical expressionSimilarly, we group numerator and denominator with “{}”, otherwise we only count the first digit or letter. Simple form Tex General form Tex $\frac ab$ \frac ab $\frac{abc}{def}$ \frac{abc}{def} Radical: Text Tex $\sqrt[2]{2}$ \sqrt[2]{2} Summation and Integral Text Tex $\sum_1^n$ \sum_1^n $\int_1^\infty$ \int_1^\infty $\prod_1^n$ \prod_1^n Comparison Text Tex $\lt$ \lt $\gt$ \gt $\le$ \leq $\geq$ \geq $\neq$ \neq Arithmetic Text Tex $\times$ \times $\div$ \div $\pm$ \pm $\mp$ \mp $\cdot$ \cdot $\approx$ \approx Set Text Tex $\cup$ \cup $\cap$ \cap $\setminus$ \setminus $\subset$ \subset $\subseteq $ \subseteq $\subsetneq$ \subsetneq $\supset$ \supset $\in$ \in $\notin$ \notin Empty set: $\emptyset ​$ , Text: \emptyset Combination Text Tex Optional ${n+1 \choose 2k}$ {n+1 \choose 2k} \binom{n+1}{2k} Row Text Tex $\to$ \rightarrow $\leftarrow$ \leftarrow $\Rightarrow$ \Rightarrow $\Leftarrow$ \Leftarrow Logical operation Text Tex $\land$ \land $\lor$ \lor $\lnot$ \lnot $\forall$ \forall $\exists $ \exists Modular arithmetic Text Tex $a\equiv b\pmod n$ a\equiv b\pmod b TableEg1, Tex: \begin {array}{c+|lcr} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\ 2 &amp; -1 &amp; 189 &amp; -8 \\ 3 &amp; -20 &amp; 2000 &amp; 1+10i \end {array} $$\begin {array} \text{n} &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i\end {array}$$ Eg2: Tex: \begin {array}{c+|lcr} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\ 2 &amp; -1 &amp; 189 &amp; -8 \\ 3 &amp; -20 &amp; 2000 &amp; 1+10i \end {array} $$\begin {array}{c+|lcr}n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\\hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i\end {array}$$ Matrixmatrix \begin {matrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{matrix} $$\begin {matrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{matrix}$$ pmatrix\begin {pmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{pmatrix} $$\begin {pmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{pmatrix}$$ bmatrix\begin {bmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{bmatrix} $$\begin {bmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{bmatrix}$$ Bmatrix\begin {Bmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{Bmatrix} $$\begin {Bmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{Bmatrix}$$ vmatrix \begin {vmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{vmatrix} $$\begin {vmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{vmatrix}$$ Vmatrix \begin {Vmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{Vmatrix} $$\begin {Vmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{Vmatrix}$$ Reference: Hoocoln]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithms, Part 1]]></title>
    <url>%2F2019%2F03%2F10%2FAlgorithms-Part-1%2F</url>
    <content type="text"><![CDATA[Princeton Algorithm course on coursera. Part 1 Cover: Disjoint set Analysis of Algorithms Stack and Queue Elementary Sorts Mergesort Quicksort Priority Queue Elementary Symbol Tables BST Hash Table Learning Purpose: Being familiar with Java. Having fun with algorithms. Reference Books: Algorithms, 4th Edition Computer Science: An Interdisciplinary Approach Week 1Why study algorithms“Great algorithms are the poetry of computation.” — Francis Sullivan “Algorithms + Data Structures = Programs.” — Niklaus Wirth Union-FindSteps to developing a usable algorithm Model the problem. Find an algorithm to solve it. Fast enough? Fits in memory? If not, figure out why. Find a way to address the problem. Iterate until satisfied. dynamic connectivityGiven a set of N objects. Union command: connect two objects Find/conneted query: is there a path connecting the two objects? Connectivity example Q. Is there a path connecting p and q? Some common understandings: Reflexive: p is connected to p itself. Symmetric: if p is connected to q, then q is connected to p. Transitive: if p is connected to q and q is connected to r, then p is connected to r. Connected components. Maximal set of objects that are mutually connected. e.g. ​ Goal. Design efficient data structure for union-find. Number of objects N can be huge. Number of operations M can be huge. Find queries and union commands may be intermixed. 12345678// APIpublic class UF &#123; UF(int N) // initialize union-find data structure with N objects (0 to N-1) void union(int p, int q) // add connection between p and q boolean connected(int p, int q) // are p and q the same component? int find(int p) //component identifier for p (0 to N-1) int count() // number of components&#125; quick findData structure Integer array id[] of size N. Interpretation: p and q are connected iff they have the same id. Find: Check if p and q have the same id Union: To merge components containing p and q, change all entries whose id equals id[p] to id[q]. Costly. 12345678910111213141516171819202122public class QuickFindUF&#123; private int[] id; public QuickFindUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; public boolean connected(int p, int q) &#123; return id[p] == id[q]; &#125; public void union(int p, int q) &#123; int pid = id[p]; int qid = idp[q]; for (int i = 0; i &lt; id.length; i++) if (id[i] == pid) id[i] = qid; &#125;&#125; algorithm initialize union find quick-find N N 1 N union commands on N object: quadratic time. Much too slow. Quadratic algorithms don’t scale with technology. quick unionData structure Integer array id[] of size N. Interpretation: id[i] is parent of i. Root of i is id[id[id[…id[i]…]]]. Each root represents the connected components. Find: Check if p and q have the same root. Union: To merge components containing p and q, set the id of p’s root to the id of q’s root. (path compression) 12345678910111213141516171819202122232425262728public class QuickUnionUF&#123; private int[] id; public QuickUnionUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; private int root(int i) &#123; while (i != id[i]) i = id[i]; return i; &#125; public boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int i = root(p); int j = root(q); id[i] = j; &#125;&#125; Worst case: algorithm initialize union find Quick-union N N N Quick-union defect Trees can get tall Find too expensive (could be N array accesses). improvementsImprovement 1: weighting Weighted quick-union Modify quick-union to avoid tall trees. Keep track of size of each tree (number of objects). Balance by linking root of smaller tree to root of larger tree. Data structure： Same as quick-union, but maintain extra array sz[i] to count number of objects in the tree rooted at i. Find: Identical to quick-union. return root(p) == root(q) Union: Modify quick-union to: Link root of samller tree to root of larger tree. Update the sz[] array. 12345int i = root(p);itn j = root(q);if (i == j) return;if (sz[i] &lt; sz[j]) &#123; id[i] = j; sz[j] += sz[i]; &#125;else &#123; id[j] = i; sz[i] += sz[j]; &#125; Proposition: Depth of any node x is at most $lg N$ algorithm initialize union find Weighted QU N lg N Lg N Improvement 2: path compressionQuick union with path compression: Just after computing the root of p, set the id of each examined node to point to that root. Two-pass implementation: add second loop to root() to set the id[] of each examined node to the root. Simpler one-pass variant: Make every other node in path point to its grandparent (thereby halving path length). 12345678910// variantprivate int root(int i)&#123; while (i != id[i]) &#123; id[i] = id[id[i]] i = id[i] &#125; return i;&#125; Weighted QU + path compression: worst-case time is N + M lg* N (lg * is an iterate function, plz refer to slide for more information) applications Percolation Games (Go, Hex) Dynamic connectivity Least common ancestor Equivalence of finite state automata Hoshen-Kopelman algorithm in physics Hinley-Milner polymorphic type inference Kruskal’s minimum spanning tree algorithm Compiling equivalence statements in Fortran Morphological attribute openings and closings Matlab’s bwlabel() function in image processing Subroutine of many other algorithms Programming Assignment 1Problem: Programming Assignment 1 Code is on my Github page: Percolation Missing the optional task of running time analysis, but I don’t want to do it again because this task is somewhat discouraging for some beginners I think. Analysis of AlgorithmsobservationsAnalytic Engine Reasons to analyze algorithms Predict performance Compare algorithms Provide guarantees Understand theoretical basis Primary practical reason: avoid performance bugs. Discrete Fourier transform N-body simulation Scientific method Observe Hypothesize Predict Verify Validate Principles Experiments must be reproducible Hypotheses must be falsifiable 3-sum problem Standard plot on running time Log-log scale strategy Doubling hypothesis: run program, doubling the size of the input. System independent effects Algorithm Input data System dependent effects Hardware: CPU, memory, cache Software: compiler, interpreter, garbage collector System: operating system, network, other apps mathematical modelsTotal running time: sum of cost * frequency for all operations General concepts 1-sum problem 2-sum problem tilde notation Estimating a discrete sum order-of-growth classification$1, log N, N, N lgN, N^2, N^3, 2^N$ Recurence Easy concepts theory of algorithmsBest case: Lower bound on cost Determined by “easiest” input Provides a goal for all inputs Worst case: Upper bound on cost Determined by “most difficult” input Provides a way to predict performance Average case: Expected cost for random input Need a model for “random” input Provides a way to predict performance Actual data Need to understand input to effectively process it Approach 1: design for the worst case Approach 2: randomize, depend on probailistic guarantee Goals Establish “difficulty” of a problem Develop “optimal” algorithms Approach Suppress details in analyze “to within a constant factor” Eliminate variability in input model by focusing on the worst case Algorithm design approach Start Develop an algorithm Prove a lower bound Gap? Lower the upper bound (discover a new algorithm) Raise the lower bound (more difficult) memoryBit Byte Megabyte (MB) Gigabyte (GB) Old machine: We used to assume a 32-bit machine with 4 byte pointers Modern machine: We now assume a 64-bit machine with 8 byte pointers Typical memory usage for objects in Java Object overhead: 16 bytes Reference: 8 bytes Padding: Each object uses a multiple of 8 bytes Week 2Stacks and QueuesFundamental data types. Value: collection of objects Operations: insert, remove, iterate, test if empty Intent is clear when we insert Which item do we remove Modular programming: Seperate interface and implementation Benefits. Client can’t know details of implementation Implementation can’t know details of client needs Design: creates modular, reusable libraries Performance: useoptimized implementation where it matters stacksLIFO, examine the item most recently added. push, pop API. 1234567public class StackOfStrings&#123; StackOfStrings() // create an empty stack void push(String item) //insert a new string onto stack String pop() // remove and return the string most recently added boolean isEmpty() // is the stack empty? int size() // number of strings on the stack&#125; Linked-list representation 12345// inner classprivate class Node &#123; String item; Node next;&#125; Pop: Push: Array implementation Use array s[] to store N items on stack. push(): add new item at s[N]. pop(): remove item from s[N-1]. Defect: Stack overflows when N exceeds capacity. Full implementation: 12345678910111213141516public class FixedCapacityStackOfStrings &#123; private String[] s; private int N = 0; public FixedCapacityStackOfStrings(int capacity) &#123; s = new String[capacity]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void push(String item) &#123; s[N++] = item; &#125; public String pop() &#123; return s[--N]; &#125;&#125; Stack considerations: Overflow and underflow Underflow: throw exception if pop from an empty stack. Overflow: use resizing array for array implementation. Null items: We allow null items to be inserted. Loitering: Holding a reference to an object when it is no longer needed. To avoid the problem caused by loitering, we need to remove the pointer and free the memory: 1234567// the version avoids "loitering" garbage collector can reclaim memory only// if no outstanding referencespublic String pop() &#123; String item = s[--N]; s[N] = null; return item;&#125; resizing arraysProblem. Requiring client to provide capacity does not implement API First try: push(): increase size of array s[] by 1. pop(): decrease size of array s[] by 1. Too expensive Need to copy all item to a new array. Inserting first N items takes time proportional to 1+2+…+N Repeated doubling: If the array is full, create a new array of twice the size, and copy items 1234567891011121314public ResizingArrayStackOfStrings()&#123; s = new String[1]; &#125;public void push(String item) &#123; if (N == s.length) resize(2 * s.length); s[N++] = item;&#125;private void resize(int capacity) &#123; String[] copy = new String[capacity]; for (int i = 0; i &lt; N; i++) copy[i] = s[i]; s = copy;&#125; Efficient solution for shrinking an array: halve size of array s[] when array is one-quarter full. Invariant: Array is between 25% and 100% full. Amortized analysis: Average running time per operation over a worst-case sequence of operations. Proposition: Starting from an empty stack, any sequence of M push and pop operations takes time proportional to M. Tradeoffs: Linked-list implementation Every operation takes constant time in the worst case. Uses extra time and space to deal with the links. Resizing-array implementation. Every operation takes constant amortized time. Less wasted space. queuesFIFO, examine the item least recently added. enqueue, dequeue API: 1234567public class QueueOfStrings &#123; QueueOfStrings(); // create an empty queue void enqueue(String item); // insert a new string onto queue String dequeue(); // remove and return the string least recently added boolean isEmpty(); // is the queue empty? int size(); // number of strings on the queue&#125; Linked-list representation Maintain pointer to first and last nodes in a linked list; Insert/remove from opposite ends Enqueue: Array implementation of a queue Use array q[] to store items in queue. enqueue(): add new item at q[tail]. dequeue(): remove item from q[head]. Update head and tail modulo the capacity Add resizing array. genericsJava generics Avoid casting in client. Discover type mismatch errors at compile-time instead of run-time. 123456Stack&lt;Apple&gt; s = new Stack&lt;Apple&gt;();Apple a = new Apple();Orange b = new Orange();s.push(a);s.push(b); // compile-time errora = s.pop(); Guilding principles: Welcome compile-time errors; avoid run-time errors. Full implementation (Linked-list version): 12345678910111213141516171819202122232425262728public class Stack&lt;Item&gt;&#123; private Node first = null; private class Node &#123; Item item; Node next; &#125; public boolean isEmpty() &#123; return first == null; &#125; public void push(Item item) &#123; Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; &#125; public Item pop() &#123; Item item = first.item; first = first.next; return item; &#125;&#125; Wrapper type. Each primitive type has a wrapper object type. Ex: Integer is wrapper type for int. Autoboxing: Automatic case between a primitive type and its wrapper. Syntactic sugar: Behind-the-scenes casting. Bottom line: Client code can use generic stack for any type of data. iteratorsDesign challenge: Support iteration over stack items by client, without revealing the internal representation of the stack. Java solution: Make stack implement the Iterable interface. An Iterable has a method that returns an Iterator. Iterable interface: 1234public interface Iterable&lt;Item&gt;&#123; Iterator&lt;Item&gt; iterator();&#125; An Iterator has methods hasNext() and next(). Iterator interface: 123456public interface Iterator&lt;Item&gt;&#123; boolean hasNext(); Item next(); void remove(); // optional&#125; “foreach” statement: 12for (String s : stack) StdOut.println(s); Equivalent code: 123456Iterator&lt;String&gt; i = stack.iterator();while(i.hasNext())&#123; String s = i.next(); StdOut.println(s);&#125; Example: Stack iterator: linked-list implementation 12345678910111213141516171819202122import java.util.Iterator;public class Stack&lt;Item&gt; implements Iterable&lt;Item&gt;&#123; ... public Iterator&lt;Item&gt; iterator() &#123; return new ListIterator(); &#125; private class ListIterator implements Iterator&lt;Item&gt; &#123; private Node current = first; public boolean hasNext() &#123; return current != null; &#125; public void remove() &#123; /* not supported */ &#125; public Item next() &#123; Item item = current.item; current = current.next; return item; &#125; &#125;&#125; Bag API Main application: Adding items to a collection and iterating (when order doesn’t matter). 1234567public class Bag&lt;Item&gt; implements Iterable&lt;Item&gt;&#123; Bag(); // create an empty bag void add(Item x); // insert a new item onto bag int size(); // number of items in bag Iterator&lt;Item&gt; iterator(); // iterator for all items in bag&#125; applicationsWhy not simply use Java collections library? “Performance” Lesson: Don’t use a library until you understand its API or you can tolerate the defect of the efficiency. Stack applications: Parsing in a compiler. Java virtual machine. Undo in a word processor. Back button in a Web browser. PostScript language for printers Implementing function calls in a compiler. Dijkstra’s two-stack algorithm: Value: push onto the value stack. Operator: push onto the operator stack. Left parenthesis: ignore. Right parenthesis: pop operator and two values; push the result of applying that operator to those values onto the operand stack. Programming Assignment 2Problem: Programming Assignment 2 Code is on my Github page: Deques and Randomized Queues Missing bonus memory challenge task. (I think it’s easy) Elementary Sortsrules of the gameGoal: Sort any type of data. Q. How can sort() know how to compare data of type Double, String, and java.io.File without any information about the type of an item’s key? Callback = reference to executable code. Client passes array of objects to sort() function. The sort() function calls back object’s compareTo() method as needed. Comparable interface (built in to Java) 1234public interface Comparable&lt;Item&gt;&#123; public int compareTo(Item that);&#125; Object implementation: 12345678910111213public class File implements Compareble&lt;File&gt;&#123; ... public int compareTo(File b) &#123; ... return -1; ... return +1; ... return 0; &#125;&#125; Sort implementation 123456789public static void sort(Comparable[] a)&#123; int N = a.length; for (int i = 0; i &lt; N; i++) for (int j = i; j &gt; 0; j--) if (a[j].compareTo(a[j-1]) &lt; 0) exch(a, j, j-1); else break;&#125; Total order A total order is a binary relation ≤ that satisfies Antisymmetry: if v ≤ w and w ≤ v, then v = w. Transitivity: if v ≤ w and w ≤ x, then v ≤ x. Totality: either v ≤ w or w ≤ v or both. Comparable API implement compareTo() so that v.compareTo(w) Is a total order. Returns a negative integer, zero, or positive integer if v is less than, equal to, or greater than w, repectively. Throws an exception if incompatible types (or either is null). 12345678910111213141516171819202122public class Date implements Comparable&lt;Date&gt;&#123; private final int month, day, year; public Date(int m, int d, int y) &#123; month = m; day = dl year = yl &#125; public int compareTo(Date that) &#123; if (this.year &lt; that.year) return -1; if (this.year &gt; that.year) return +1; if (this.month &lt; that.month) return -1; if (this.month &gt; that.month) return +1; if (this.day &lt; that.day) return -1; if (this.day &gt; that.day) return +1; return 0; &#125;&#125; Two useful sorting abstractions Less: Is item v less than w? 12private static boolean less(Comparable v, Comparable w)&#123; return v.compareTo(w) &lt; 0; &#125; Exchange: Swap item in array a[] at index i with the one at index j. 123456private static void exch(Comparable[] a, int i, int j)&#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; selection sortIn iteration i, find index min of smallest remaining entry. Swap a[i] and a[min]. 123456789101112131415161718192021public class Selection&#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; i &lt; N; j++) if (less(a[j], a[min])) min = j; exch(a, i, min) &#125; &#125; private static boolean less(Comparable v, Comparable w) &#123; /* as before */ &#125; private static void exch(Comparable[] a, int i, int j) &#123; /* as before */ &#125;&#125; insertion sortIn iteration i, swap a[i] with each larger entry to its left. 12345678910111213141516171819public class Insertion&#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) for (int j = i; j &gt; 0; j--) if (less(a[j], a[j-1])) exch(a, j, j-1); else break; &#125; private static boolean less(Comparable v, Comparable w) &#123; /* as before */ &#125; private static void exch(Comparable[] a, int i, int j) &#123; /* as before */ &#125;&#125; Def: An inversion is a pair of keys that are out of order. Def: An array is partially sorted if the number of inversions is ≤ cN. Proposition: For partially-sorted arrays, insertion sort runs in linear time. Pf: Number of exchanges equals the number of inversions. shellsortIdea: Move entries more than one position at a time by h-sorting the array. How to h-sort an array? Insertion sort, with stride length h. Useful in practice: Fast unless array size is huge. Tiny, fixed footprint for code (used in embedded systems). Hardware sort prototype. shufflingShuffle sort Generate a random real number for each array entry. Sort the array. Proposition: Shuffle sort produces a uniformly random permutation of the input array, provided no duplicate values. Goal: Rearrange array so that result is a uniformly random permutation in linear time. Knuth shuffle In iteration i, pick integer r between 0 and i uniformly at random. Swap a[i] and a[r]. Proposition: Knuth shuffling algorithm produces a uniformly random permutation of the input array in linear time. 12345678910111213public class StdRandom&#123; ... public static void shuffle(Object[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int r = StdRandom.uniform(i + 1); // between 0 and i exch(a, i, r); &#125; &#125;&#125; online poker: easily cracked Bottom line: Shuffling a deck of cards is hard! convex hullThe convex hull of a set of N points is the smallest perimeter fence enclosing the points. Equivalent definitions: Smallest convex set containing all the points. Smallest area convex polygon enclosing the points. Convex polygon enclosing the points, whose vertices are points in set. Convex hull output: Sequence of vertices in counterclockwise order. Convex hull application: motion planning Robot motion planning: Find shortest path in the plane from s to t that avoids a polygonal obstacle. Fact: Shortest path is either straight line from s to t or it is one of two polygonal chains of convex hull. Farthest pair problem: Given N points in the plane, find a pair of points with the largest Euclidean distance between them. Graham scan: Choose point p with smallest y-coordinate. Sort points by polar angle with p. Consider points in order; discard unless it create a ccw turn. Implementation: Define a total order, comparing by y-coordinate. Define a total order for each point p. (polar angle) Computational geometry to determine counterclockwise for triple. Mergesort to sort efficiently. Implementing ccw: CCW: Given three points a, b, and c, is a-&gt;b-&gt;c a counterclockwise turn? (is c to the left of the ray a-&gt;b) A good strategy involves computing areas (high school compitation knowledge) To show respectations: Week 3MergesortmergesortBasic plan: Divide array into two halves. Recursively sort each half. Merge two halves. 12345678910111213141516171819private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi)&#123; assert isSorted(a, lo, mid); // precondition: a[lo...mid] sorted assert isSorted(a, mid+1, hi); // precondition: a[mid+1...hi] sorted for (int k = lo; k &lt;= hi; k++) aux[k] = a[k]; int i = lo, j = mid+1; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; assert isSorted(a, lo, hi); // poscondition: a[lo...hi] sorted&#125; Assertion: Statement to test assumptions about your program. Helps detect logic bugs. Documents code. Java assert statement: Throws exception unless boolean condition is true. 1assert isSorted(a, lo, hi); Can enable or disable at runtime: 12java -ea MyProgram // enable assertionsjava -da MyProgram // disable assertions (default) Best practices: Use assertions to check internal invariants; assume assertions will be disabled in production code. Recurrence relation Proposition: Mergesort uses extra space proportional to N. Pf: The array aux[] needs to be of size N for the last merge. Some detailed improvements can be done. bottom-up mergesortBasic plan: Pass through array, merging subarrays of size 1. Repeat for subarrays of size 2, 4, 8, 16, …… Bottom line: No recursion needed! Several passes. 12345678910111213141516public class MergeBU&#123; private static Comparable[] aux; private static void merge(Comparable[] a, int lo, int mid, int hi) &#123; /* as before */ &#125; public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) for (int lo = 0; lo &lt; M - sz; lo += sz+sz) merge(a, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1)); &#125;&#125; log N passes sorting complexityModel of computation: Allowable operations. Cost model: Operation count(s). Upper bound: Cost guarantee provided by some algorithm for X. Lower bound: Proven limit on cost guarantee of all algorithms for X. Optimal algorithm: Algorithm with best possible cost guarantee for X. Decision tree: please refer to CLRS Mergesort is optimal with respect to compares. Mergesort is not optimal with respect to space usage. Lower bound N log N may not hold if the algorithm has information about: The initial order of the input. The distribution of key values. The representation of the keys. Eg: Partially-ordered arrays. Duplicate keys. Digital properties of keys. comparatorsComparable interface: sort using a type’s natural order. Comparator interface: sort using an alternate order. 12public interface Comparator&lt;Key&gt; int compare(Key v, Key w) // compare keys v and w Required property: Must be a total order. 1234567891011121314151617181920public class Student&#123; public static final Comparator&lt;Student&gt; BY_NAME = new ByName(); public static final Comparator&lt;Student&gt; BY_SECTION = new BySection(); private final String name; private final int section; ... private static class ByName implements Comparator&lt;Student&gt; &#123; public int compare(Student v, Student w) &#123; return v.name.compareTo(w.name); &#125; &#125; private static class BySection implements Comparator&lt;Student&gt; &#123; public int compare(Student v, Student w) &#123; return v.section - w.section; &#125; &#125;&#125; stabilitySelection/Shell sort are not stable. Insertion/Merge sort are stable. Long-distance exchange may lead to problems. Mergesort is stable because merge is stable. Programming Assignment 3Problem: Programming Assignment 3 Code is on my Github page: Collinear Failed some timing tests because HashMap is not allowed. Got 92 out of 100. QuicksortquicksortBasic plan: Shuffle the array. Partition. Sort each piece recursively. Phase 1: Repeat until i and j pointers cross. Scan i from left to right so long as (a[i] &lt; a[lo]) Scan j from right to left so long as (a[j] &gt; a[lo]) Exchange a[i] with a[j] Phase 2: When pointers cross. Exchange a[lo] with a[j] 123456789101112131415161718public static int partition(Comparable[] a, int lo, int hi)&#123; int i = lo, j = hi+1; while (true) &#123; while (less(a[++i], a[lo])) if (i == hi) break; while (less(a[lo], a[--j])) if (j == lo) break; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j;&#125; 12345678910111213141516171819public class Quick&#123; private static int partition(Comparable[] a, int lo, int hi) &#123; /* as before */ &#125; public static void sort(Comparable[] a) &#123; StdRandom.shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi); &#125;&#125; Details: Partitioning in-place: Can be done with extra memoy. Terminating the loop: Testing whether the pointers cross is a bit trickier than it might seem. Staying in bounds: The (j == lo) test is redundant because of the key, but (i == hi) test is not. Preserving randomness: Shuffling is needed for performance guarantee. Equal keys: When duplicates are present, it is bettuer to stop on keys equal to the partitioning item’s key. Best case: N log N Worst case: $N^2$ Approximate sum by an integral. Proposition: Quicksort is an in-place sorting algorithm, not stable. Pf: Partitioning: constant extra space. Depth of recursion: logarithmic extra space (with high probability). Insertion sort small subarrays: Even quicksort has too much overhead for tiny subarrays. Cutoff to insertion sort for around 10 items. Note: could delay insertion sort until one pass at end. Practical improvements: Insertion sort small subarrays: 1234567891011private static void sort(Comparable[] a, int lo, int hi)&#123; if (hi &lt;= lo + CUTOFF - 1) &#123; Insertion.sort(a, lo, hi); return; &#125; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi);&#125; Median of sample: 1234567891011private static void sort(Comparable[] a, int lo, int hi)&#123; if (hi &lt;= lo) return; int m = medianOf3(a, lo, lo + (hi -lo)/2, hi); swap(a, lo, m); int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi);&#125; selectionGoal: Given an array of N items, find the kth largest. Applications: Order statistics. Find the “top k.” Quick-select: Partition array so that: Entry a[j] is in place. No larger entry to the left of j. No smaller entry to the right of j. Repeat in one subarray, depending on j; finished when j equals k. 12345678910111213public static Comparable select(Comparable[] a, int k)&#123; StdRandom.shuffle(a); int lo = 0; hi = a.length - 1; while (hi &gt; lo) &#123; int j = partition(a, lo, hi); if (j &lt; k) lo = j + 1; else if (j &gt; k) hi = j - 1; else return a[k]; &#125; return a[k];&#125; Proposition: Quick-select takes linear time on average. Remard: Quadratic time in the worst case while random shuffle provides a probabilistic guarantee. duplicate keysQuicksort with duplicate keys: Algorithm goes quadratic unless partitioning stops on equal keys! 3-way partitioning: Goal: Partition array into 3 parts so that: Entries between lt and gt equal to partition item v. No larger entries to left of lt. No smaller entries to right of gt. Bottom line: Randomized quicksort with 3-way partitioning reduces running time from linearithmic to linear in broad class of applications. system sortsJava system sorts: Arrays.sort() Has different method for each primitive type. Has a method for data types that implement Comparable. Has a method that uses a Comparator. Uses tuned quicksort for primitive types; tuned mergesort for objects. 123456789101112import java.util.Arrays;public class StringSort&#123; public static void main(String[] args) &#123; String[] a = StdIn.readStrings(); Arrays.sort(a); for (int i = 0; i &lt; N; i++) StdOut.println(a[i]); &#125;&#125; Choices: Week 4Priority QueuesAPI and elementary implementationsCollections: Insert and delete items. Stack: Remove the item most recently added. Queue: Remove the item least recently added. Randomized queue: Remove a random item. Priority queue: Remove the largest (or smallest) item. Priority queue API 12345678910public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; MaxPQ(); // create an empty priority queue MaxPQ(Key[] a); // create a priority with given keys void insert(Key v); // insert a key into the priority queue Key delMax(); // return and remove the largest key boolean isEmpty(); // is the priority queue empty? Key max(); // return the largest key int size(); // number of entries in the priority queue&#125; Applications: Event-driven simulation Numerical computation Data compression Graph searching Number theory Artificial intelligence Statistics Operating systems Discrete optimization Spam filtering Generalizes: stack, queue, randomized queue. Unordered array implementation: 1234567891011121314151617181920212223public class UnorderedMaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; private Key[] pq; private int N; public UnorderedMaxPQ(int capacity) &#123; pq = (Key[]) new Comparable[capacity]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void insert(Key x) &#123; pq[N++] = x; &#125; public Key delMax() &#123; int max = 0; for (int i = 1; i &lt; N; i++) if (less(max, i)) max = i; exch(max, N-1); return pq[--N]; &#125;&#125; implementation insert delmax max unordered array 1 N N ordered array N 1 1 Goal log N log N log N binary heapsBased on complete binary tree (Perfectly balanced, except for bottom level). Binary heap: Array representation of a heap-ordered complete binary tree. Heap-ordered binary tree: Keys in nodes. Parent’s key no smaller than children’s key. Array representation: Indices start at 1. (Start at 0 causes a little trouble) Take nodes in level order. No explicit liniks needed! Proposition: Largest key is a[1], which is root of binary tree. Proposition: Can use array indices to move through tree. Parent of node at k is at k/2. Children of node at k are at 2k and 2k+1. Swim: 12345678private void swim(int k)&#123; while (k &gt; 1 &amp;&amp; less(k/2, k)) &#123; exch(k, k/2); k = k/2; &#125;&#125; Insertion: 12345public void insert(Key x)&#123; pq[++N] = x; swim(N); // swim means swim up&#125; Sink: 1234567891011private void sink(int k)&#123; while (2*k &lt;= N) &#123; int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; if (!less(k, j)) break; exch(k, j); k = j; &#125;&#125; Delete max: 12345678public Key delMax()&#123; Key max = pq[1]; exch(1, N--); sink(1); pq[N+1] = null; // prevent loitering return max;&#125; Complete Java implementation: 1234567891011121314151617181920212223242526272829public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; private Key[] pq; private int N; public MaxPQ(int capacity) &#123; pq = (Key[]) new Comparable[capacity+1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void insert(Key key) &#123; /* as before */ &#125; public void delMax(); &#123; /* as before */ &#125; private void swim(int k); &#123; /* as before */ &#125; private sink(int k) &#123; /* as before */ &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125;&#125; Improvements: Fibonacci heap Some considerations Immutability of keys: Assumption: client does not change keys while they’re on the PQ. Best practice: use immutable keys. Underflow and overflow: Underflow: throw exception if deleting from empty PQ. Overflow: add no-arg constructor and use resizing array. Minimum-oriented priority queue: Replace less() with greater(). Implement greater(). Other operations: Remove an arbitrary item. Change the priority of an item. Immutability: 1234567891011public final class Vector &#123; private final int N; private final double[] data; public Vector(double[] data) &#123; this.N = data.length; this.data = new double[N]; for (int i = 0; i &lt; N; i++) this.data[i] = data[i]; &#125;&#125; Immutable: String, Integer, Double, Color, Vector, Transaction, Point2D. Mutable: StringBuilder, Stack, Counter, Java array. Advantages of immutability: Simplifies debugging. Safer in presence of hostile code. Simplifiers concurrent programming. Safe to use as key in priority queue or symbol table. Disadvantage: Must create new object for each data type value. heapsortBasic plan for in-place sort: Create max-heap with all N keys. Repeatedly remove the maximum key. Heap construction: Sink, bottom-up. Build: 12for (int k = N/2; k &gt;= 1; k--) sink(a, k, N); Sort: 12345while (N &gt; 1)&#123; exch(a, 1, N--); sink(a, 1, N);&#125; Bottom line: Inner loop longer than quicksort’s Makes poor use of cache memory Not stable event-driven simulationMolecular dynamics simulation of hard discs Goal. Simulate the motion of N moving particles that behave according to the laws of elastic collision. Time-driven simulation: Judge collision with dt Event-driven simulation: Maintain PQ of collision events, prioritized by time. Collision prediction: Given position, velocity, and radius of a particle, when will it collide next with a wall or another particle? Collision resolution: If collision occurs, update colliding particle(s) according to laws of elastic collisions. Difficult simulation, involving a lot of physics and math, or at least not easy. Programming Assignment 4Problem: Programming Assignment 4 Code is on my Github page: 8 Puzzle Failed some timing tests. Got 96 out of 100. Symbol TablesAPIKey-value pair abstraction: Insert a value with specified key. Given a key, search for the corresponding value. Associative array abstraction: Associate one value with each key. 12345678910public class ST&lt;Key, Value&gt; &#123; ST(); // create a symbol table void put(Key key, Value val); // put key-value pair into the table (remove key from table if value is null) Value get(Key key); // value paired with key (null if key is absent) void delete(Key key); // remove key (and its value) from table boolean contains(Key key); // is there a value paired with key? boolean isEmpty(); // is the table empty? int size(); // number of key-value pairs in the table Iterable&lt;Key&gt; keys(); // all the keys in the table&#125; Convetions: Value are not null. Method get() returns null if key not present. Method put() overwrites old value with new value. Contains: 12public boolean contains(Key key)&#123; return get(key) != null; &#125; Lazy delete: 12public void delete(Key key)&#123; put(key, null); &#125; Keys and values Value type: Any generic type. Key type: several natural assumptions: Assume keys are Comparable, use compareTo(). Assume keys are any generic type, use equals() to test equality. Assume keys are any generic type, use equals() to test equality; use hashCode() to scramble key. Best practices: Use immutable types for symbol table keys. Equality test: 123456789101112131415161718192021222324public final class Data implements Comparable&lt;Date&gt;&#123; private final int month; private final int day; private final int year; ... public boolean equals(Object y) &#123; if (y == this) return true; if (y == null) return false; if (y.getClass() != this.getClass()) return false; Date that = (Date) y; if (this.day != that.day) return false; if (this.month != that.month) return false; if (this.year != that.year) return false; return true; &#125;&#125; elementary implementationsSequential search in a linked list: Data structure: Maintain an (unordered) linked list of key-value pairs. Search: Scan through all keys until find a match. Insert: Scan through all keys until find a match; if no match add to front. Binary search in an ordered array: Data structure: Maintain an ordered array of key-value pairs. Rank helper function: How many keys &lt; k? 12345678910111213141516171819202122public Value get(Key key)&#123; if (isEmpty()) return null; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) return vals[i]; else return null;&#125;private int rank(Key key)&#123; int lo = 0; hi = N-1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) hi = mid - 1; else if (cmp &gt; 0) lo = mid + 1; else return mid; &#125; return lo;&#125; ordered operationsAPI: 123456789101112131415161718192021public class ST&lt;Key extends Comparable&lt;Key&gt;, Value&gt;&#123; ST(); // create an ordered symbol table void put(Key key, Value val); // put key-value pair into the table (remove key from table if value is null) Value get(Key key); // value paired with key (null if key is absent) void delete(Key key); // remove key (and its value) from table boolean contains(Key key); // is there a value paired with key? boolean isEmpty(); // is the table empty? int size(); // number of key-value pairs Key min(); // smallest key Key max(); // largest key Key floor(Key key); // smallest key less than or equal to key Key ceiling(Key key); // smallest key greater than or equal to key int rank(Key key); // number of keys less than key Key select(int k); // key of rank k void deleteMin(); // delete smallest key void deleteMax(); // delete largest key int size(Key lo, Key hi); // number of keys in [lo..hi] Iterable&lt;Key&gt; keys(Key lo, Key hi); // keys in [lo..hi], in sorted order Iterable&lt;Key&gt; keys(); // all keys in the table, in sorted order&#125; Binary Search TreesBSTsDefinition: A BST is binary tree in symmetric order. A binary tree is either: Empty Two disjoint binary trees (left and right). Symmetric order: Each node has a key, and every node’s key is: Larger than all keys in its left subtree. Smaller than all keys in its right subtree. Java definition: A BST is a reference to a root Node. A Node is comprised of four fields: A Key and a Value. A reference to the left and right subtree. 1234567891011private class Node&#123; private Key key; private Value val; private Node left, right; public Node(Key key, Value val) &#123; this.key = key; this.val = val; &#125;&#125; 12345678910111213141516171819public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt;&#123; private Node root; private class Node &#123; /* see previous slide */ &#125; public void put(Key key, Value val) &#123; /* see later */ &#125; public Value get(Key key) &#123; /* see later */ &#125; public void delete(Key key) &#123; /* see later */ &#125; public Iterable&lt;Key&gt; iterator() &#123; /* see later */ &#125;&#125; Search: If less, go left; if greater, go right; if equal, search hit. 12345678910111213public Value get(Key key)&#123; Node x = root; while (x != null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x.val; &#125; return null;&#125; Insertion (concise but tricky recursive code): 12345678910111213public void put(Key key, Value val)&#123; root = put(root, key, val); &#125;private Node put(Node x, Key key, Value val)&#123; if (x == null) return new Node(key, val); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left, key, val); else if (cmp &gt; 0) x.right = put(x.right, key, val); else x.val = val; return x;&#125; ordered operationsMinimum: Smallest key in table. Maximum: Largest key in table. Rank: How many keys &lt; k? 1234567891011public int rank(Key key)&#123; return rank(key, root); &#125;private int rank(Key key, Node x)&#123; if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return rank(key,x.left); else if (cmp &gt; 0) return 1 + size(x.left) + rank(key, x.right); else return size(x.left);&#125; Inorder traversal: Traverse left subtree. Enqueue key. Traverse right subtree. 1234567891011121314public Iterable&lt;Key&gt; keys();&#123; Queue&lt;Key&gt; q = new Queue&lt;Key&gt;(); inorder(root, q); return q;&#125;private void inorder(Node x, Queue&lt;Key&gt; q)&#123; if (x == null) return; inorder(x.left, q); q.enqueue(x.key); inorder(x.right, q);&#125; deletionLazy deletion: Set its value to null. Leave key in tree to guide searches (but don’t consider it equal in search). Delete the minimum key: Go left until finding a node with a null left link. Replace that node by its right link. Update subtree counts. Else, Hibbard deletion, please refer to CLRS BST chapter for more details Week 5Balanced Search Trees2-3 search treesAllow 1 or 2 keys per node 2-node: one key, two children 3-node: two keys, three children Perfect balance: Every path from root to null link has same length Symmetric order: Inorder traversal yields keys in ascending order Search Compare search key against keys in node Find interval containing search key Follow associated link (recursively) Insert into a 2-node at bottom Search for key, as usual Replace 2-node with 3-node Splitting a 4-node is a local transformation: constant number of operations Invariants: Maintain symmetric order and perfect balance Pf: Each transformation maintains symmetric order and perfect balance Tree height: Always $lg N$ red-black BSTsLeft-leaning RB tree Idea: Represent 2-3 tree as a BST Use “internal” left-leaning links as “glue” for 3-nodes A BST such that: No node has two red links connected to it Every path from root to null link has the same number of black links Red links lean left 2-3 tree and RB BST are coresponding as following: Search for red-black BST is the same as the general BST Representation: 12345678910111213141516private static final boolean RED = true;private static final boolean BLACK = false;private class Node&#123; Key key; Value val; Node left, right; boolean color; // color of parent link&#125;private boolean isRed(Node x)&#123; if (x == null) return false; return x.color == RED;&#125; Left rotation: Orient a (temporarily) right-leaning red link to lean left 12345678910private Node rotateLedt(Node h)&#123; assert isRed(h.right); Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; return x;&#125; Invariants: Maintains symmetric order and perfect black balance Right rotation is similar. Color flip: Recolor to split a (temporary) 4-node 123456789private void flipColors(Node h)&#123; assert !isRed(h); assert isRed(h.left); assert isRed(h.right); h.color = RED; h.left.color = Black; h.right.color = Black;&#125; Insertion in a LLRB tree Basic strategy: Maintain 1-1 correspondence with 2-3 trees by applying elementary red-black BST operations Warmup 1: Insert into a tree with exactly 1 node Warmup 2: Insert into a tree with exactly 2 nodes (3 cases) Case 2: Insert into a 3-node at the bottom Do standard BST insert; color new link red Rotate to balance the 4-node (if needed) Flip colors to pass red link up one level Rotate to make lean left (if needed) Repeat case 1 or case 2 up the tree (if needed) Java implementation Reduce one case to another 1234567891011121314private Node put(Node h, Key key, Value val)&#123; if (h == null) return new Node(key, val, RED); int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else if (cmp == 0) h.val = val; if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h; if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); return h; &#125; B-trees (Bayer-McCreight, 1972)File system model: Page: Contiguous block of data Probe: First access to a page Property: Time required for a probe is much larger than time to access data within a page Cost model: Number of probes Goal: Access data using minimum number of probes B-tree: Generalize 2-3 trees by allowing up to M-1 key-link pairs per node At least 2 key-link pairs at root At least M/2 key-link pairs in other nodes External nodes contain client keys Internal nodes contain copies of keys to guide search Searching in a B-tree: Start at root Find interval for search key and take corresponding link Search terminates in external node Insertion in a B-tree: Search for new key Insert at bottom Split nodes with M key-link pairs on the way up the tree Red-black trees are widely used as system symbol tables Java: java.util.TreeMap, java.util.TreeSet C++ STL: map, multimap, multiset Linux kernel: completely fair scheduler, linux/rbtree.h Emacs: conservative stack scanning B-tree variants: B+ tree, B* tree, B# tree, … B-trees (and variants) are videly used for file systems and databases Windows: NTFS Mac: HFS, HFS+ Linux: ReiserFS, XFS, Ext3FS, JFS Databases: Oracle, DB2, Ingres, SQL, PostgreSQL Geometric Applications of BSTsApplications: CAD, games, movies, virtual reality, databases, … 1d range search Insert key-value pair Search for key k Delete key k Range search: find all keys between $k_1$ and $k_2$ Range count: number of keys between $k_1$ and $k_2$ Implementations: data structure insert range count range search unordered array 1 N N ordered array N log N R + log N goal log N log N R + log N N = number of keys R = number of keys that match BST implementation: Proposition: Running time proportional to log N. Pf: Nodes examined = search path to lo + search path to hi. line segment intersectionOrthogonal line segment intersection search Quadratic algorithm: Check all pairs of line segments for intersection. Nondegeneracy assumption: All x- and y- coordinates are distinct. Sweep-line algorithm: Sweep vertical line from left to right X-coordinates define events. H-segment (left endpoint): insert y-coordinate into BST. H-segment (right endpoint): remove y-coordinate from BST. When hit a vertical line segment, do a 1-d search Proposition: The sweep-line algorithm takes time proportional to N log N + R to find all R intersections among N orthogonal line segments. Pf. Put x-coordinates on a PQ (or sort). N log N Insert y-coordinates into BST N log N Delete y-coordinates from BST N log N Range searches in BST N log N + R Bottom line: Sweep line reduces 2d orthogonal line segment intersection search to 1d range search kd treesExtension of ordered symbol-table to 2d keys Insert a 2d key Delete a 2d key Search for a 2d key Range search: find all keys that lie in a 2d range Range count: number of keys that lie in a 2d range Geometric interpretation: Keys are point in the plane Find/count points in a given h-v rectangle Grid implementation: Divide space into M-by-M grid of squares Create list of points contained in each square Use 2d array to directly index relevant square Insert: add(x, y) to list for corresponding square Range search: examine only squares that intersect 2d range query Space-time tradeoff Space: $M^2+N$ Time: 1 + $N/M^2$ per square examined, on average Choose grid square size to tune performance Too small: waste space Too large: too many points per square It’s fast, simple solution for evenly-distributed points Problem: Clustering a well-knwon phenomenon in geometric data Lists are too long, even though average length is short Need data structure that adapts gracefully to data 2d tree construction Recursively partition plane into two halfplanes. Data structure: BST, but alternate using x- and y- coordinates as key. Search gives rectangle containing point Insert further subdivides the plane Range search in a 2d tree Goal: Find all points in a query axis-aligned rectangle. Check if point in node lies in given rectangle Recursively search left/bottom (if any could fall in rectangle) Recursively search right/top (if any could fall in rectangle) Nearest neighbor search in a 2d tree Goal: Find closest point to query point Check distance from point in node to query point Recursively search left/bottom (if it could contain a closer point) Recursively search right/top (if it could contain a closer point) Organize method so that it begins by searching for query point Kd tree Recursively partition k-dimensional space into 2 halfspaces Efficient, simple data structure for processing k-dimensional data Widely used Apapts well to high-dimensional and clustered data Discovered by an undergrad in an algorithms class! N-body simulation Build 3d-tree with N particles sa nodes Store center-of-mass of subtree in each node. To compute total force acting on a particle, traverse tree, but stop as soon as distance from particle to subdivision is sufficiently large. interval search trees1d interval search: Data structure to hold set of (overlapping) intervals Insert an interval (lo, hi). Search for an interval (lo, hi). Delete an interval (lo, hi). Interval intersection query: given an interval (lo, hi), find all intervals (or one interval) in data structure that intersects (lo, hi). API 123456public class IntervalST IntervalST() void put(Key lo, Key hi, Value val) Value get(Key lo, Key hi) void delete(Key lo, Key hi) Iterable&lt;Value&gt; intersects(Key lo, Key hi) Interval search trees Create BST, where each node stores an interval (lo, hi). Use left endpoint as BST key. Store max endpoint in subtree rooted at node. To insert an interval (lo, hi): Insert into BST, using lo as the key. Update max in each node on search path. To search for any one interval that intersects query interval (lo, hi): If interval in node intersects query interval, return it. Else if left subtree is null, go right. Else if max endpoint in left subtree is less than lo, go right. Else go left. Case 1. If search goes right, then no intersection in left. Case 2. If search goes left, then there is either an intersection in left subtree or no intersections in either Pf. Suppose no intersection in left. Since went left, we have lo ≤ max. Then for any interval (a,b) in right subtree of x, hi &lt; c ≤ a, no intersection in right. rectangle intersectionOrthogonal rectangle intersection search Goal: Find all intersections among a set of N orthogonal rectangles Quadratic algorithm: Check all pairs of rectangles for intersection Non-degeneracy assumption: All x- and y- coordinates are distinct. Design-rule checking: Certain wires cannot intersect Certain spacing needed between different types of wires Debugging = orthogonal rectangle intersection search Sweep-line algorithm (similar to previous one) X-coordinates of left and right endpoints define events. Maintain set of rectangles that intersect the sweep line in an interval search tree (using y-intervals of rectangle). Left endpoint: interval search for y-interval of rectangle; insert y-interval. Right endpoint: remove y-interval. Bottom line: Sweep line reduces 2d orthogonal rectangle intersection search to 1d interval search. Summary Of Geometric Applications of BSTs Programming Assignment 5Problem: Programming Assignment 5 Code is on my Github page: Kdtree Missing the optional task of running time analysis because it’s optional. Week 6Hash Tableshash functionsBasic plan: save items in a key-indexed table (index is a function of the key). Hash function: Method for computing array index from key. hash(&quot;it&quot;) = 3 Issues: Computing the hash function. Equality test. Collision resolution. Classic space-time tradeoff. No space limitation: trivial hash function with key as index. No time limitation: trivial collision resolution with sequential search. Space and time limitations: hashing (the real world). Hash function Idealistic goal: Scramble the keys uniformly to produce a table index. Efficiently computable. Each table index equally likely for each key. All Java classes inherit a method hashCode(), which returns a 32-bit int. Default implementation: Memory address of x. Some typicals in Java libraries: Hash for strings: Horner’s method 12345678910111213141516public final class String&#123; private int hash = 0; private final char[] s; ... public int hashCode() &#123; int h = hash; if (h != 0) return h; for (int i = 0; i &lt; length(); i++) h = s[i] + (31 * h); hash = h; return h; &#125;&#125; Modular hashing Hash code: A int between $-2^{32}$ and $2^{31}-1$ Hash function: An int between 0 and M-1 (for use as array index). 123// to be between 0 and M-1private int hash(Key key)&#123; return (key.hashCode() &amp; 0x7fffffff) % M; &#125; Assumption Uniform hashing assumption: Each key is equally likely to hash to an integer between 0 and M-1. seperate chaining Typical choice of M: near N / 5 linear probingOpen addressing (IBM 1953): When a new key collides, find next empty slot, and put it there. Hash: Map key to integer i between 0 and M-1. Insert: Put at table index i if free; if not try i+1, i+2, etc. Search: Search table index i; if occupied but no match, try i+1, i+2, etc. Note: Array size M must be greater than number of key-value pairs N. contextAlgorithmic complexity attack. One-way hash function: “Hard” to find a key that will hash to a desired value. Separate chaining vs. linear probing Separate chaining: Easier to implement delete. Performance degrades gracefully. Clustering less sensitive to poorly-designed hash function. Linear probing: Less wasted space. Better cache performance. Variations: Two-probe hashing Double hashing Cuckoo hashing And so on… Symbol Table ApplicationssetsMathematical set: A collection of distinct keys. 123456789public class SET&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; SET(); // create an empty set void add(Key key); // add the key to the set boolean contains(Key key); // is the key in the set? void remove(Key key); // remove the key from the set int size(); // return the number of keys in the set Iterator&lt;Key&gt; iterator(); // iterator through keys in the set&#125; Exception filter: Read in a list of words from one file. Print out all words from standard input that are { in, not in } the list. dictionary clientsDictionary lookup. indexing clientsFile indexing Goal: Given a list of files specified, create an index so that you can efficiently find all files containing a given query string. Key: String. Value: Set of files. Concordance Goal: Preprocess a text corpus to support concordance queries: given a word, find all occurrences with their immediate contexts. sparse vectors Problem: Sparse matrix-vector multiplication. Vector representations 1 D array representation: Constant time access to elements. Space proportional to N. Symbol table representation: Key = index, value = entry. Efficient iterator. Space proportional to number of nonzeros. Sparse matrix representation: Each row of matrix is a sparse vector. Efficient access to elements. Space proportional to number of nonzeros (plus N). 123456789...SparseVector[] a = new SparseVector[N];double[] x = new double[N];double[] b = new double[N];...// Initialize a[] and x[]...for (int i = 0; i &lt; N; i++) b[i] = a[i].dot(x);]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
