<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Comments]]></title>
    <url>%2F2019%2F03%2F31%2FComments%2F</url>
    <content type="text"><![CDATA[正式远离社交，有事找我此处留言]]></content>
  </entry>
  <entry>
    <title><![CDATA[Machine Learning]]></title>
    <url>%2F2019%2F03%2F29%2FMachine%20Learning%2F</url>
    <content type="text"><![CDATA[Stanford University, Machine Learning Course notes Week 1Facebook, Apple’s photo application. Google’s page rank algorithm. Email spam filter. IntroductionAlgorithms, math and how to get them work. Machine Learning: Grew out of work in AI New capability for computers Examples: Database mining, E.g., Web click data, medical records, biology, engineering. Applications can’t program by hand. Helicopter, handwriting recognition, most of NLP, CV. Self-customizing programs: E.g., Amazon, Netflix product recommendations. Understanding human learning (brain, real AI). Arthur Samuel (1959). Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed. Tom Mitchell (1998). Well-posed Learnining Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E. Machine learning algorithms: Supervised learning Unsupervised learning Others: Reinforcement learning, recommender systems. Supervised learning E.g., housing price prediction (regression) E.g., Breast cancer (malignant, benign) (classification) Unsupervised learning Clustering Applications: Organize computing clusters Social network analysis Market segmentation Astronomical data analysis E.g. Cocktail party algorithm Linear Regression with One VariableLinear Regression with One VariableHousing Prices. Traing set: housing prices Notation: m = Number of training examples x’s = “input” variable / features y’s = “output” variable / “target” variable (x, y) – one training example $(x^{(i)}, y^{(i)})$ – $i^{th}$ trainining example $$h_\theta(x)=\theta_0+\theta_1x$$Linear regression with one variable. Univariate linear regerssion. Cost function Idea: Choose $\theta_0, \theta_1$ so that $h_\theta(x)$ is close to $y$ for our training examples $(x, y)$ square error cost function:$$J(\theta_0,\theta_1)=\frac1{2m}\sum_1^m(h_\theta(x^{(1)})-y^{(1)})^2$$Target: choose $\theta_0, \theta_1 $ to minimize $J(\theta_0,\theta_1)$ Contour plots to show 3D surface: Gradient descent Have some function $J(\theta_0,\theta_1)$ Want $min_{\theta_0,\theta_1}J(\theta_0,\theta_1)$ Outline: Start with some $\theta_0, \theta_1 ​$ Keep changing $\theta_0, \theta_1$ to reduce $J(\theta_0,\theta_1) $ until we hopefully end up at a minimum Gradient descent algorithm: repeat until convergence:$$\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)$$Note: Correct implementation is simultaneous update as following:$$temp0 :=\theta_0-\alpha\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)\\temp1 :=\theta_1-\alpha\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)\\\theta_0:=temp0\\\theta_1:=temp1$$ := assignment = assertion $\alpha$ step length If $\alpha$ is too small, gradient descent can be slow. If $\alpha$ is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge. Gradient descent can converge to a local minimum, even with the learning rate $\alpha$ fixed. As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease $\alpha$ over time. Gradient for linear regression:$$j = 0 : \frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1) = \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\\j = 1 : \frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1) = \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\cdot x^{(i)}$$Note again: update $\theta_0$ and $\theta_1$ simultaneously. Gradient descent always works with convex function (without local optimum). Batch Gradient Descent: Batch: Each step of gradient descent uses all the training examples. (Refer to the fact that the cost function is over the entire training set.) Linear Algebra ReviewMatrix: Rectangular array of numbers:$$\begin {pmatrix}1402 &amp; 191 \\1371 &amp; 821\end {pmatrix}$$Dimension of matrix: number of rows x number of columns $A_{ij}$ = “$i,j$ entry” in the $i^{th}$ row, $j^{th}$ column. Vector: An nx1 matrix.$$\begin {pmatrix}1402 \\901\end {pmatrix}$$$y_i$ = $i^{th}$ element 1-indexed or 0-indexed$$\begin {pmatrix}y_1 \\y_2 \\y_3 \\y_4\end {pmatrix}\space \space\begin {pmatrix}y_0 \\y_1 \\y_2 \\y_3\end {pmatrix}$$ Convention: upper case to refer to matrics and lower case to refer to numbers or vectors. Matrix Addition Element-wise addition. Legal matrix addtion requires matrixes with same dimension. Scalar Multiplication$$3 *\begin {bmatrix}1 &amp; 0 \\2 &amp; 5 \\3 &amp; 1\end {bmatrix}=\begin {bmatrix}3 &amp; 0 \\6 &amp; 15 \\9 &amp; 3\end {bmatrix}$$ Matrix Multiplication: Matrix multiply vector: To get $y_i$, multiply A’s $i^{th} $ row with elements of vector$x$, and add them up. Prediction = DataMatrix * parameters Matrix-matrix multiplication:$$\begin {bmatrix}1 &amp; 3 &amp; 2 \\4 &amp; 0 &amp; 1\end {bmatrix} \begin {bmatrix}1 &amp; 3 \\0 &amp; 1 \\5 &amp; 2\end {bmatrix}=\begin {bmatrix}11 &amp; 10 \\9 &amp; 14\end {bmatrix}$$Details: A m$\times $n matrix B n$\times $o matrix m$\times $o matrix The $i^{th}$ column of the matrix $C$ is obtained by multiplying $A$ with the $i^{th}$ column of $B$. (for $i$ = 1,2,…,o). Then convert to matrix-vector multiplication. Multiple compeing hypotheses: let each hypotheses corespond to a column in the second matrix. Let $A$ and $B​$ be matrices. Then in general,$$A \times B \ne B \times A$$ $$A \times (B \times C) = (A \times B) \times C$$ Identity Matrix: Denoted $I$ (or $I_{n\times n}$) Examples of identity matrices:$$\begin {bmatrix}1 &amp; 0 \\0 &amp; 1\end {bmatrix}\\begin {bmatrix}1 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 1\end {bmatrix}\\begin {bmatrix}1 &amp; 0 &amp; 0 &amp; 0 \\0 &amp; 1 &amp; 0 &amp; 0 \\0 &amp; 0 &amp; 1 &amp; 0 \\0 &amp; 0 &amp; 0 &amp; 1\end {bmatrix}$$For any matrix $A$$$A \cdot I = I \cdot A = A$$ Matrix inverse: Not all numbers have an inverse. If $A$ is an m$\times $m matrix (square matrix), and if it has an inverse,$$AA^{-1}=A^{-1}A=I$$Matrices that don’t have an inverse are “singular” or “degenerate”. Matrix Transpose: Example:$$A =\begin {bmatrix}1 &amp; 2 &amp; 0 \\3 &amp; 5 &amp; 9\end {bmatrix} \ A^T =\begin {bmatrix}1 &amp; 3 \\2 &amp; 5 \\0 &amp; 9\end {bmatrix}$$Let $A$ be an m$\times $n matrix, and let $B=A^T$. Then $B$ is an n$\times $m matrix, and$$B_{ij}=A_{ji}$$ Week 2Linear Regression with Multiple VariablesMultiple features (variables). Notation: $n$ = number of features $x^{(i)}$ = input (features) of $i^{th}$ training example. $x_j^{(i)}$ = value of feature $j$ in $i^{th}$ training example. Hypothesis:$$h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n$$For convenience of notation, define $x_0=1$. ($x_0^{(i)}=1$)$$x =\begin {bmatrix}x_0 \\x_1 \\… \\x_n\end {bmatrix} \space\space \theta =\begin {bmatrix}\theta_0 \\\theta_1 \\… \\\theta_n\end {bmatrix}\inR^{n+1}$$ $$h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n=\theta^Tx$$ Multivariate linear regression. Gradient descent for multivariate linear regression $$\theta_j:=\theta_j-\alpha \frac{\partial}{\partial\theta_j}J(\theta)$$ $$\theta_j:=\theta_j-\alpha \frac{1}{m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$ Feature Scaling Idea: Make sure features are on a similar scale. Get every feature into approximately a $-1\leq x_i \leq 1$ range. Mean normalization Replace $x_i$ with $x_i-\mu_i$ to make features have approximately zero mean (Do not apply to $x_0=1$) and then divide it by its standard deviatioin (divide by max-min is also fine). Convergence test: Declare convergence if $J(\theta)$ decreases by less than $10^{-3}$ in one iteration. For sufficiently small $\alpha$, $J(\theta )$ should decrease on every iteration. But if $\alpha$ is too small, gradient descent can be slow to converge. Summary If $\alpha$ is too small: slow convergence. If $\alpha$ is too large: $J(\theta) $ may not decrease on every iteration; may not converge. To choose $\alpha$ , try: …, 0.001, 0.01, 0.1, 1, … (0.003, 0.03, 0.3), 3x each time. Polynomial regression Sometimes by defining new features we can get better data and model. We can transform a polynomial regression into a mutlivariant linear regression model: Normal Equation Method to solve for $\theta$ analytically. Design matrix: each row represents a sample. With normal equation, feature scaling is not necessary. Comparasion Gradient Descent: Need to choose $\alpha$. Needs many iterations. Works well even when $n$ is large. Normal Equation: No need to choose $\alpha$. Don’t need to iterate. Need to compute $(X^TX)^{-1}$ Slow if $n$ is very large. (depending on the number of features, typically n ~ 1000) Noninvertibility when using normal equation For normal equation method:$$\theta = (X^TX)^{-1}X^Ty$$What if $X^TX$ is non-invertible? (Singular/degenerate) pinv inv What causes $X^TX$ non-invertible? Redundant features (linearly dependent). Too many features (e.g. $m\leq n$). (delete some features, or use regularization). Octave/Matlab TutorialChoices: Octave, MATLAB, Python Numpy and R. who: list all the variables. whos: list all the variables in details. max(A(:)): take the maximum element of matrix A. disp(“…”): print a string. Function: 12function y = squareThisNumber(x)y = x^2; addpath(): add search path. Vectorization $$h_\theta(x)=\sum_{j=0}^n\theta_jx_j=\theta^Tx$$ $$\theta =\begin {bmatrix}\theta_0 \\\theta_1 \\\theta_2\end {bmatrix}\x =\begin {bmatrix}x_0 \\x_1 \\x_2\end {bmatrix}$$ Unvectorized implementation: 1234prediction = 0.0;for j = 1:n+1 prediction = prediction + theta(j) * x(j)end; Vectorized implementation: 1prediction = theta&apos; * x; Programming Assignment: Linear RegressionLinear Regression Week 3Logistic RegressionClassification Email: Spam / Not Spam? Online Transactions: Fraudulent (Yes/ No)? Tumor: Malignant / Benign? $$y \in {0,1}$$ 0: “Negative Class” 1: “Positive Class” Binary Classification by Linear Regression is easily affected by extreme value. Logistic Regression:$$0 \leq h_\theta(x) \leq 1$$Hypothesis:$$h_\theta(x) = g(\theta^Tx)\\g(z) = \frac{1}{1+e^{-z}}$$g is called sigmoid function or logistic function.$$h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}$$Interpretation of Hypothesis Output $h_\theta(x)$ = estimated probability that y = 1 on input x$$h_\theta(x)=P(y=1|x;\theta)$$“Probability that y = 1, given x, parameteruzed by $\theta $”$$P(y=0|x;\theta)+P(y=1|x;\theta)=1$$Decision Boundary Cost Function If we use the same cost function as before, it would be non-convex. Thus it’s not a wise choice. So we tend to choose a convex function. Logistic regression cost function:$$Cost(h_\theta(x),y)=\begin{equation}\left{ \begin{array}{lr} -log(h_\theta(x)), &amp; if \space y =1 \\ -log(1-h_\theta(x)), &amp; if \space y = 0 \end{array}\right.\end{equation}$$ $$Cost(h_\theta(x),y)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))$$ $$J(\theta)=-\frac1m[\sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]$$ Gradient descent$$\theta_j:=\theta_j - \alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$It looks identical to linear regression! (only hypothesis changes) Advanced optimization Conjugate gradient BFGS L-BFGS Advantages: No need to manually pick $\alpha $ Often faster than gradient descent Disadvantages: More complex Multiclass classification Email foldering/tagging: Work, Friends, Family, Hobby Medical diagrams: Nol ill, Cold, Flu Weather: Sunny, Cloudy, Rain, Snow One-vs-all (one-vs-rest): Treat one multiple class problem as several binary classification problems. Train a logistic regression classifier $h_\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y=i$. On a new input $x$, to make a prediction, pick the class $i$ that maximizes$$max\space h_\theta^{(i)}(x)$$Which means the prediction takes the maximum probability the sample belongs to. Regularization Underfit: High bias Overfit: High variance Overfitting: If we have too many features, the learned hypothesis may fit the training set very well, but fail to generalize to new examples (predict prices on new examples). Addressing overfitting: Reduce number of features Manually select which features to keep. Model selection algorithm. Regularization Keep all the features, but reduce magnitude/values of parameters $\theta_j$. Works well when we have a lot of features, each of which contributes a bit to predicting $y​$. Regularization Small values for parameters $\theta_0,\theta_1,…,\theta_n$ Simpler hypothesis Less prone to overfitting $$J(\theta)=\frac1{2m}[\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum_{i=1}^m\theta_j^2]$$ $\lambda$: regularization parameter, control the trade off between fitting the training set well and keeping parameters small (keeping hypothesis simple) If $\lambda $ is extremely large, then $h_\theta(x)=\theta_0$. (end up with the simplest hypothesis and high bias) Gradient descent with regularization$$\theta_0:=\theta_0-\alpha \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_0^{(i)}$$ $$\theta_j:=\theta_j-\alpha [\frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}+\frac\lambda m\theta_j], \space for \space j = 1, 2, …, n$$ Equivalent:$$\theta_j:=\theta_j(1-\alpha\frac\lambda m)-\alpha \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}$$ Normal equation with normalization Regularized logistic regression Cost function:$$J(\theta) = -[\frac1m \sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]+\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2$$ Regularized advanced optimization Programming Assignment: Logistic RegressionLogistic Regression Week 4Neural Networks: RepresentationWeek 5Neural Networks: LearningWeek 6Advice for Applying Machine LearningMachine Learning System DesignWeek 7Support Vector MachinesWeek 8Unsupervised LearningDimensionality ReductionWeek 9Anomaly DetectionRecommender SystemsWeek 10Large Scale Machine LearningWeek 11Application Example: Photo OCRLinear Algebra Review]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Matlab</tag>
        <tag>Machine Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Robotics: Perception]]></title>
    <url>%2F2019%2F03%2F26%2FRobotics-Perception%2F</url>
    <content type="text"><![CDATA[University of Pennsylvania, Robotics: Perception Course notes Cover: Geometry of Image Formation Projective Transformations Pose Estimation Multi-View Geometry Learning Purpose: To be a candidate. Self promotion. Be familiar with Matlab again. Matlab help Videos are all from Youtube Week 1, Geometry of Image FormationIntroduction Projection center Augmented reality Where am I? Camera ModelingGannet: Estimate distance from water. Camera: imaging chip and a lens $\frac 1f = \frac 1a + \frac 1b$ blured picture (when we change the image plane by sticking on the mannual mode of the camera) A point object of the same size coming closer results on a larger image. A point moving on the same ray does not change its image. (regarding to fixed image plane) Single View GeometryWorld Coordinates: x, y, z locations. Camera Coordinates: Two dimensional plane. Given the picture, how tall is the person in the picture? “Single View Metrology”, ICCV 1999, CVPR 1998 Ideas 1: Measurements on planes. Moving “not vertical” to “vertical” and then measure. Ideas 2: Vanishing points. Phical lines in the real world which are parallel will meet at the vanishing point when approaching infinity. More on Perspective ProjectionPerspectography. Strategy for projecting $P^*$ to $P$ on the same plane rather than on the image plane. Quiz: Introduction Glimpse on Vanishing PointsVanishing points Properties: Any two parallel lines have the same vanishing point. The ray from C throught v point is parallel to the lines. An image may have more than one vanishing point. A single point can form a line between the optical center and that point, the ray can represent all the physical lines out there which are parallel. Multiple Vanishing Points: For every direction we have on the ground plane, there is a unique point in the image space. All the vanishing points will form a horizon. Any set of parallel lines on the plane define a vanishing point. The union of all of these vanishing points is the horizon line (also called vanishing line) Different planes define different vanishing lines. Computing vanishing lines: I is intersection of horizontal plane through C with image plane. Compute I from two sets of parallel lines on ground plane. All points at same height as C project to I. Provided way of comaring height of objects in the scene. Measuring height: Trace a line from the bottom of the ruler throught feet of the person to infinity (intersect with the horizon). Quiz: Vanishing Points Perspective Projection IOne-Point Perspective Partial review. Not all pictures should have the same vanishing points. The projective plane: Represent points at infinity, homographies, perspective projection, multi-view relationships. A point in the image is a ray in projective space. $$\begin{bmatrix}x \\y \\\end{bmatrix}-homogeneous coords-&gt;\begin{bmatrix}x \\y \\1 \\\end{bmatrix}$$Projective lines Eg: a, b and c are parameters in the 3D space but also related to the equation of the line. 3D plane equation:$$ax + by + cz = 0$$ Perspective Projection IIDefine a line: we use two points on the line to define it: We have:$$x\cdot l = 0 ,\space x’\cdot l = 0$$So $l$ is the surface normal vector of the orange plane, which is coresponding to the line on the plane $P_1P_2$ . (Please think that points on the line can be represented as $(x,y,1)$, then it’s easy to understand) Reference materials of projective view: surface normal: a unit vector at a given point of a surface which is perpendicular to the tangent plane. Intersection of lines: Mistake in this video at arround 8:30. Point-Line DualityWhen P has the form $(x,y,0)$: We convert a 3D point into a 2D point by dividing the last element out. (Homogeous coords) Some intuitions: $x/0 -&gt; infinity$. So very likely it’s a vanishing point. Point at infinity: Eg: More general of intersection of parallel lines: All parallel lines intersects at the point at infinity:$$line \space l = (a,b,c)^T \space intersects \space at \space (b,-a,0)^T$$ Line at infinity (a line passing all points at infinity) :$$l_\infty=(0,0,1)^T$$Because:$$\begin {bmatrix}0\0\1\end {bmatrix}\begin {bmatrix}x_1 \\x_2 \\0\end {bmatrix}= 0$$ Ideal points and lines (noting that there are two coords system, one for real space which is 3D, one for image space which is 2D): Ideal point (“point at infinity”) $p = (x,y,0)​$ — parallel to image plane It has ifinite image coordinates (2D coordinates for point) Ideal line $l = (a,b,0)$ — parallel to image plane Corresponds to a line in the image (finite coordinates) Quiz: Perspective Projection Rotations and TranslationsTransformation between camera and world coordinates systems Convention: Red for X, Green for Y and Blue for Z.$$^cP = ^cR_w \space^wP+^cT_w$$Point P can be expressed with respect to “w” or “c” coordinate frames. If we set $^wP$ to zero, then, $^cP=^cR_w+^cT_w$ is the vector from camera origin to world origin.$$^cR_w=(r_1 \ r_2 \ r_3)$$Set $^wP=(1,0,0)$ and imagine $^cT_w=0$. Then $^cP = r_1 $ whch means that the rotation columns are the world axis expressed in the camera coordinate system. Eg: The translation is easy from the picture:$$\begin {pmatrix}0 \\5 \\10\end {pmatrix}$$We have to make sure that the 3x3 matrix is a rotation matrix, which means $R^TR=I$ and det(R) = 1. Transform between coordinate systems of three: Inverse: Quiz: Rotations and Translations Pinhole Camera Model Pinhole Camera: $1^{st}$ Person Camera world 3D to 2D image:$$x’=f\frac X Z \ y’=f\frac Y Z$$ Focal Length and Dolly Zoom EffectFocal length Process of changing focal length: zooming Focal length longer: field of view narrow Intrinsic Camera a Parameter3D to 2D image:$$x’=f\frac X Z \ y’=f\frac Y Z$$ $$x=P_0X$$ $P_0$ is the camera projection matrix Conversion from mm to pixels Optical center on the image plane: Principal point What we do is shifting and scaling by the measurement of pixels: Map camera coordinate to pixel coordinate (matrix form): $Px,P_y$ is the principle point (where optical axis hits image plane) (not exactly the center of the image) s is the slant factor, when the image plane is not normal to the optical axis Three factors: A scale factor that converts physical focal length to pixel unit. Position of image center (principal point). A skew factor between x and y axis of the image. 3D World to First Person TransformationMultiple View Geometry $3^{rd}$ person view measurement Why: When we are moving around to see different objects from different point of view, which means that the origin is always changing. Convert the 3D representation into first person coordinate. Every camera has its own first person coordinate system. Translate the world coordinate into the camera coordiante Translate the camera coordinate into the pixel coordinate Combining them together, we get:$$x=K[R,t]X$$Comlete form: $$3D \space from \space 3^{rd} \space person –&gt;3D \space from \space 1^{rd} \space person –&gt;2D \space pixel \space domain$$ Special cases Plnar objects: all x,y,z sits in a plane We have freedom to choose how we measure 3D points from $3^{rd}$ person view. Rotating camera: known optical center panorama Quiz: Dolly Zoom Quiz: Feeling of Camera Motion How to Compute Intrinsics from Vanishing PointsCompute focal length and image center from pure geometry without using projection equations. Eg: Three orthogonal sets of parallel lines create three orthogonal vanishing points. What does the horizon between A and B tells us about the camera? It gives us information about how the horizon is oriented with respect to the camera. Because the camera is tilted, point C is not on the horizon. Just knowledge of A and B doesn’t determine C. We need also the focal length and the image center in order to fix C. Later for how to compute: H is the orthocenter of ABC Focal length computation, easy as following: So f can be determined from $d_1$, $d_2$ and $d_3$, which are all known. Quiz: How to Compute Intrinsics from Vanishing Points Camera Calibration Cameras with large field of view have radial distortions. A procedure called calibration (Estimates the intrinsic parameters) f focal length ($u_0$,$v_0$) image center $k_1,k_2,…$ radial distortion parameters Matlab has calibration toolbox. Quiz: Camera Calibration Programming Assignment: Dolly ZoomDolly Zoom Week 2, Projective TransformationsVanishing Points; How to Compute Camera Orientation$3^{rd}$ person perspective: World coordinate system First person coordinate system: The person himself How we orientate in the real world: $R$ and $t$ For $z_\infty=[0\space 0 \space 1 \space 0]^T$, $v_z=Kr_3$, K is the calibration matrix. To fixed all rotation angles, we need 2 vanishing point in perpendicular direction. If we can recognize two perpendicular directions in the physical space, then we can recover the camera orientation relative to the world. How to figure out both translation and rotation? If we do translation on the camera, the vanishing point remain itself. But when we rotate, the vanishing point will move.We can recover rotation column $r_3$ from vanishing point z and $r_1$ from vanishiong point x. And using these two, we can figure out the camera orientation.Rotation column $r_3$ tells us about the pan and tilt angles. (left and right, up and down)Using K inverse transformation, we can transform from pixel-domain points into optical world.## Quiz: Homogeneous Coordinates Compute Projective TransformationsA perspective projection of a plane (like a camera image) is always a projective transformation. Definition A projective transformation is any invertible matrix transformation $P^2-&gt;P^2$ A projective transformation $A$ maps $p$ to $p’—Ap$ A projective transformation is also known as collineation or homography A projective transformation preserves incidence: Three collinear points are mapped to three collinear points. And three concurrent lines are mapped to three concurrent lines. Projective transformation of lines If $A$ maps a point to $Ap$, then where does a line $l$ map to? Line equation in original plane$$l^Tp=0$$Line equation in image plane $p’—Ap$$$l^TA^{-1}p’=0$$implies that $l’=A^Tl$. Computation of projective transformation: Assume that a mapping $A$ maps the three points$$\begin {pmatrix}a \b \c\end {pmatrix}=\begin {pmatrix}a\alpha \b\beta \c\gamma\end {pmatrix}\begin {pmatrix}1 &amp; 0 &amp; 0 \0 &amp; 1 &amp; 0 \0 &amp; 0 &amp; 1\end {pmatrix}$$is a valid projective transformation, but 3 degrees of freedom so not sufficient.This transformation map (1,0,0), (0,1,0) and (0,0,1) to a,b and c correspondingly. We neeed to compute $\alpha,\beta$ and $ \gamma$. Four points not three of them collinear suffice to recover unambiguously projective transformation. With the forth point mapped point $d$, we can calculate as following:$$\begin {pmatrix}a \b \c\end {pmatrix}\begin {pmatrix}\alpha \\\beta \\\gamma\end {pmatrix}=d$$ Quiz: Projective Transformations Projective Transformations and Vanishing PointsGeometric interpretation of the projective transformations. Projective transformation Aka Homography or Collineation Represents the perspective projection from a ground plane to an image plane! It is an invertible 3x3 matrix but has 8 independent parameters For example if (X,Y) measured in meters on the ground and (u,v) in pixels $$\begin {pmatrix}u \\v \\1 \end {pmatrix}H\begin {pmatrix}X \\Y \\1\end {pmatrix}$$ &lt;img src = “https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-10.png&quot; style = “zoom:60%” Quiz: Vanishing PointsNote for question 2 and 3: When zooming, the calibration matrix K varies, so the K inverse transformation will change the location of vanishing points. While for translation, the vanishing points remain in their original position because translation disappear. Question 4 requires one more step “inverse”. Cross Ratios and Single View MetrologyThe middle point of a segment preserved under parallel projection. For a camera, the middle point of a segment doesn’t preserve. But the Cross-Ratio is preserved. The cross-ratio remain the same under any projective transformation. We can use this to measure distances in the real world. E.g. What happens when one of the points is at infinity? And we can also compute the position of the vanishing point in the image. Distance transfer: Single View Metrology via Cross Ratios: If we know a vanishing point we can compute any ratio along this direction! We can transfer distances among parallel lines in the world if we know two vanishing points. In none of these steps we used focal length or any other intrinsics. We can do some image forensics on paintings or old photos! Quiz: Cross Ratios and Single View Metrology Two View Soccer MetrologyThe forth week of the course will focus on this problem. Programming Assignment: Image Projection using HomographiesWeek 3, Pose EstimationVisual FeaturesQuiz: Visual FeaturesSingular Value DecompositionQuiz: Singular Value DecompositionRANSAC: Random Sample Consensus IQuiz: RANSACWhere am I? Part 1Where am I? Part 2Pose from 3D Point Correspondences: The Procrustes ProblemQuiz: 3D-3D PosePose from Projective TransformationsPose from Point Correspondences P3PQuiz: Pose EstimationProgramming Assignment: Image ProjectionWeek 4, Multi-View GeometryEpipolar Geometry IEpipolar Geometry IIEpipolar Geometry IIIQuiz: Epipolar GeometryRANSAC: Random Sample Consensus IINonlinear Least Squares INonlinear Least Squares IINonlinear Least Squares IIIQuiz: Nonlinear Least SquaresOptical Flow: 2D Point Correspondences3D Velocities from Optical FlowQuiz: 3D Velocities from Optical Flow3D Motion and Structure from Multiple ViewsVisual OdometryBundle Adjustment IBundle Adjustment IIBundle Adjustment IIIQuiz: Bundle AdjustmentProgramming Assignment: Structure from Motion]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Matlab</tag>
        <tag>Robotics</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MathJax Formula]]></title>
    <url>%2F2019%2F03%2F23%2FMathJax%20Formula%2F</url>
    <content type="text"><![CDATA[MathJax Formula memo. MathJax is an open-source JavaScript display engine for Latex, MathML, and AsciiMath notation that works in all modern browsers. Two modes: Inline: embedded into text. Displayed: displayed individually. Greek alphabet Name Upper Tex Lower Tex alpha $A$ A $\alpha$ \alpha beta $B$ B $\beta$ \beta gamma $\Gamma$ \Gamma $\gamma$ \gamma delta $\Delta$ \Delta $\delta$ \delta epsilon $E$ E $\epsilon$ \epsilon zeta $Z$ Z $\zeta$ \zeta eta $H$ H $\eta$ \eta theta $\Theta$ \Theta $\theta$ \theta iota $I$ I $\iota$ \iota kappa $K$ K $\kappa$ \kappa lambda $\Lambda$ \Lambda $\lambda$ \lambda mu $M$ M $\mu$ \mu nu $N$ N $\nu$ \nu xi $\Xi$ \Xi $\xi$ \xi omicron $O$ O $\omicron$ \omicron pi $\Pi$ \Pi $\pi$ \pi rho $P$ P $\rho$ \rho sigma $\Sigma$ \Sigma $\sigma$ \sigma tau $T$ T $\tau$ \tau upsilon $\Upsilon$ \Upsilon $\upsilon$ \upsilon phi $\Phi$ \Phi $\phi$ \phi chi $X$ X $\chi$ \chi psi $\Psi$ \Psi $\psi$ \psi omega $\Omega$ \Omega $\omega$ \omega Superscript and SubscriptGroup the notation by curly bracket “{}”, other wise, the script only count for the one consecutive letter. Text Tex $x^{2}$ x^{2} $x_0$ x_0 $\hat x$ \hat x $\widehat {xy} $ \widehat {xy} $\hat {xy} $ \hat {xy} $\overline {xyz}$ \overline {xyz} $\vec x$ \vec x $\dot x$ \dot x $\ddot x$ \ddot x Brackets Left Tex Right Tex$$ $\lbrace$ \lbrace $\rbrace$ \rbrace $\langle$ \langle $\rangle$ \rangle $\lceil$ \lceil $\rceil$ \rceil $\lfloor$ \lfloor $\rfloor$ \rfloor Fraction and Radical expressionSimilarly, we group numerator and denominator with “{}”, otherwise we only count the first digit or letter. Simple form Tex General form Tex $\frac ab$ \frac ab $\frac{abc}{def}$ \frac{abc}{def} Radical: Text Tex $\sqrt[2]{2}$ \sqrt[2]{2} Summation and Integral Text Tex $\sum_1^n$ \sum_1^n $\int_1^\infty$ \int_1^\infty $\prod_1^n$ \prod_1^n Comparison Text Tex $\lt$ \lt $\gt$ \gt $\le$ \leq $\geq$ \geq $\neq$ \neq Arithmetic Text Tex $\times$ \times $\div$ \div $\pm$ \pm $\mp$ \mp $\cdot$ \cdot $\approx$ \approx Set Text Tex $\cup$ \cup $\cap$ \cap $\setminus$ \setminus $\subset$ \subset $\subseteq $ \subseteq $\subsetneq$ \subsetneq $\supset$ \supset $\in$ \in $\notin$ \notin Empty set: $\emptyset ​$ , Text: \emptyset Combination Text Tex Optional ${n+1 \choose 2k}$ {n+1 \choose 2k} \binom{n+1}{2k} Row Text Tex $\to$ \rightarrow $\leftarrow$ \leftarrow $\Rightarrow$ \Rightarrow $\Leftarrow$ \Leftarrow Logical operation Text Tex $\land$ \land $\lor$ \lor $\lnot$ \lnot $\forall$ \forall $\exists $ \exists Modular arithmetic Text Tex $a\equiv b\pmod n$ a\equiv b\pmod b TableEg1, Tex: \begin {array}{c+|lcr} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\ 2 &amp; -1 &amp; 189 &amp; -8 \\ 3 &amp; -20 &amp; 2000 &amp; 1+10i \end {array} $$\begin {array} \text{n} &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i\end {array}$$ Eg2: Tex: \begin {array}{c+|lcr} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\ 2 &amp; -1 &amp; 189 &amp; -8 \\ 3 &amp; -20 &amp; 2000 &amp; 1+10i \end {array} $$\begin {array}{c+|lcr}n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\\hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\2 &amp; -1 &amp; 189 &amp; -8 \\3 &amp; -20 &amp; 2000 &amp; 1+10i\end {array}$$ Matrixmatrix \begin {matrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{matrix} $$\begin {matrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{matrix}$$ pmatrix\begin {pmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{pmatrix} $$\begin {pmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{pmatrix}$$ bmatrix\begin {bmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{bmatrix} $$\begin {bmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{bmatrix}$$ Bmatrix\begin {Bmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{Bmatrix} $$\begin {Bmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{Bmatrix}$$ vmatrix \begin {vmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{vmatrix} $$\begin {vmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{vmatrix}$$ Vmatrix \begin {Vmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{Vmatrix} $$\begin {Vmatrix}1 &amp; x &amp; x^2 \\1 &amp; y &amp; y^2 \\1 &amp; z &amp; z^2\end{Vmatrix}$$ Reference: Hoocoln]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Math</tag>
        <tag>MathJax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Algorithms, Part 1]]></title>
    <url>%2F2019%2F03%2F10%2FAlgorithms-Part-1%2F</url>
    <content type="text"><![CDATA[Princeton Algorithm course on coursera. Part 1 Cover: Disjoint set Analysis of Algorithms Stack and Queue Elementary Sorts Mergesort Quicksort Priority Queue Elementary Symbol Tables BST Hash Table Learning Purpose: Being familiar with Java. Having fun with algorithms. Reference Books: Algorithms, 4th Edition Computer Science: An Interdisciplinary Approach Week 1Why study algorithms“Great algorithms are the poetry of computation.” — Francis Sullivan “Algorithms + Data Structures = Programs.” — Niklaus Wirth Union-FindSteps to developing a usable algorithm Model the problem. Find an algorithm to solve it. Fast enough? Fits in memory? If not, figure out why. Find a way to address the problem. Iterate until satisfied. dynamic connectivityGiven a set of N objects. Union command: connect two objects Find/conneted query: is there a path connecting the two objects? Connectivity example Q. Is there a path connecting p and q? Some common understandings: Reflexive: p is connected to p itself. Symmetric: if p is connected to q, then q is connected to p. Transitive: if p is connected to q and q is connected to r, then p is connected to r. Connected components. Maximal set of objects that are mutually connected. e.g. ​ Goal. Design efficient data structure for union-find. Number of objects N can be huge. Number of operations M can be huge. Find queries and union commands may be intermixed. 12345678// APIpublic class UF &#123; UF(int N) // initialize union-find data structure with N objects (0 to N-1) void union(int p, int q) // add connection between p and q boolean connected(int p, int q) // are p and q the same component? int find(int p) //component identifier for p (0 to N-1) int count() // number of components&#125; quick findData structure Integer array id[] of size N. Interpretation: p and q are connected iff they have the same id. Find: Check if p and q have the same id Union: To merge components containing p and q, change all entries whose id equals id[p] to id[q]. Costly. 12345678910111213141516171819202122public class QuickFindUF&#123; private int[] id; public QuickFindUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; public boolean connected(int p, int q) &#123; return id[p] == id[q]; &#125; public void union(int p, int q) &#123; int pid = id[p]; int qid = idp[q]; for (int i = 0; i &lt; id.length; i++) if (id[i] == pid) id[i] = qid; &#125;&#125; algorithm initialize union find quick-find N N 1 N union commands on N object: quadratic time. Much too slow. Quadratic algorithms don’t scale with technology. quick unionData structure Integer array id[] of size N. Interpretation: id[i] is parent of i. Root of i is id[id[id[…id[i]…]]]. Each root represents the connected components. Find: Check if p and q have the same root. Union: To merge components containing p and q, set the id of p’s root to the id of q’s root. (path compression) 12345678910111213141516171819202122232425262728public class QuickUnionUF&#123; private int[] id; public QuickUnionUF(int N) &#123; id = new int[N]; for (int i = 0; i &lt; N; i++) id[i] = i; &#125; private int root(int i) &#123; while (i != id[i]) i = id[i]; return i; &#125; public boolean connected(int p, int q) &#123; return root(p) == root(q); &#125; public void union(int p, int q) &#123; int i = root(p); int j = root(q); id[i] = j; &#125;&#125; Worst case: algorithm initialize union find Quick-union N N N Quick-union defect Trees can get tall Find too expensive (could be N array accesses). improvementsImprovement 1: weighting Weighted quick-union Modify quick-union to avoid tall trees. Keep track of size of each tree (number of objects). Balance by linking root of smaller tree to root of larger tree. Data structure： Same as quick-union, but maintain extra array sz[i] to count number of objects in the tree rooted at i. Find: Identical to quick-union. return root(p) == root(q) Union: Modify quick-union to: Link root of samller tree to root of larger tree. Update the sz[] array. 12345int i = root(p);itn j = root(q);if (i == j) return;if (sz[i] &lt; sz[j]) &#123; id[i] = j; sz[j] += sz[i]; &#125;else &#123; id[j] = i; sz[i] += sz[j]; &#125; Proposition: Depth of any node x is at most $lg N$ algorithm initialize union find Weighted QU N lg N Lg N Improvement 2: path compressionQuick union with path compression: Just after computing the root of p, set the id of each examined node to point to that root. Two-pass implementation: add second loop to root() to set the id[] of each examined node to the root. Simpler one-pass variant: Make every other node in path point to its grandparent (thereby halving path length). 12345678910// variantprivate int root(int i)&#123; while (i != id[i]) &#123; id[i] = id[id[i]] i = id[i] &#125; return i;&#125; Weighted QU + path compression: worst-case time is N + M lg* N (lg * is an iterate function, plz refer to slide for more information) applications Percolation Games (Go, Hex) Dynamic connectivity Least common ancestor Equivalence of finite state automata Hoshen-Kopelman algorithm in physics Hinley-Milner polymorphic type inference Kruskal’s minimum spanning tree algorithm Compiling equivalence statements in Fortran Morphological attribute openings and closings Matlab’s bwlabel() function in image processing Subroutine of many other algorithms Programming Assignment 1Problem: Programming Assignment 1 Code is on my Github page: Percolation Missing the optional task of running time analysis, but I don’t want to do it again because this task is somewhat discouraging for some beginners I think. Analysis of AlgorithmsobservationsAnalytic Engine Reasons to analyze algorithms Predict performance Compare algorithms Provide guarantees Understand theoretical basis Primary practical reason: avoid performance bugs. Discrete Fourier transform N-body simulation Scientific method Observe Hypothesize Predict Verify Validate Principles Experiments must be reproducible Hypotheses must be falsifiable 3-sum problem Standard plot on running time Log-log scale strategy Doubling hypothesis: run program, doubling the size of the input. System independent effects Algorithm Input data System dependent effects Hardware: CPU, memory, cache Software: compiler, interpreter, garbage collector System: operating system, network, other apps mathematical modelsTotal running time: sum of cost * frequency for all operations General concepts 1-sum problem 2-sum problem tilde notation Estimating a discrete sum order-of-growth classification$1, log N, N, N lgN, N^2, N^3, 2^N$ Recurence Easy concepts theory of algorithmsBest case: Lower bound on cost Determined by “easiest” input Provides a goal for all inputs Worst case: Upper bound on cost Determined by “most difficult” input Provides a way to predict performance Average case: Expected cost for random input Need a model for “random” input Provides a way to predict performance Actual data Need to understand input to effectively process it Approach 1: design for the worst case Approach 2: randomize, depend on probailistic guarantee Goals Establish “difficulty” of a problem Develop “optimal” algorithms Approach Suppress details in analyze “to within a constant factor” Eliminate variability in input model by focusing on the worst case Algorithm design approach Start Develop an algorithm Prove a lower bound Gap? Lower the upper bound (discover a new algorithm) Raise the lower bound (more difficult) memoryBit Byte Megabyte (MB) Gigabyte (GB) Old machine: We used to assume a 32-bit machine with 4 byte pointers Modern machine: We now assume a 64-bit machine with 8 byte pointers Typical memory usage for objects in Java Object overhead: 16 bytes Reference: 8 bytes Padding: Each object uses a multiple of 8 bytes Week 2Stacks and QueuesFundamental data types. Value: collection of objects Operations: insert, remove, iterate, test if empty Intent is clear when we insert Which item do we remove Modular programming: Seperate interface and implementation Benefits. Client can’t know details of implementation Implementation can’t know details of client needs Design: creates modular, reusable libraries Performance: useoptimized implementation where it matters stacksLIFO, examine the item most recently added. push, pop API. 1234567public class StackOfStrings&#123; StackOfStrings() // create an empty stack void push(String item) //insert a new string onto stack String pop() // remove and return the string most recently added boolean isEmpty() // is the stack empty? int size() // number of strings on the stack&#125; Linked-list representation 12345// inner classprivate class Node &#123; String item; Node next;&#125; Pop: Push: Array implementation Use array s[] to store N items on stack. push(): add new item at s[N]. pop(): remove item from s[N-1]. Defect: Stack overflows when N exceeds capacity. Full implementation: 12345678910111213141516public class FixedCapacityStackOfStrings &#123; private String[] s; private int N = 0; public FixedCapacityStackOfStrings(int capacity) &#123; s = new String[capacity]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void push(String item) &#123; s[N++] = item; &#125; public String pop() &#123; return s[--N]; &#125;&#125; Stack considerations: Overflow and underflow Underflow: throw exception if pop from an empty stack. Overflow: use resizing array for array implementation. Null items: We allow null items to be inserted. Loitering: Holding a reference to an object when it is no longer needed. To avoid the problem caused by loitering, we need to remove the pointer and free the memory: 1234567// the version avoids "loitering" garbage collector can reclaim memory only// if no outstanding referencespublic String pop() &#123; String item = s[--N]; s[N] = null; return item;&#125; resizing arraysProblem. Requiring client to provide capacity does not implement API First try: push(): increase size of array s[] by 1. pop(): decrease size of array s[] by 1. Too expensive Need to copy all item to a new array. Inserting first N items takes time proportional to 1+2+…+N Repeated doubling: If the array is full, create a new array of twice the size, and copy items 1234567891011121314public ResizingArrayStackOfStrings()&#123; s = new String[1]; &#125;public void push(String item) &#123; if (N == s.length) resize(2 * s.length); s[N++] = item;&#125;private void resize(int capacity) &#123; String[] copy = new String[capacity]; for (int i = 0; i &lt; N; i++) copy[i] = s[i]; s = copy;&#125; Efficient solution for shrinking an array: halve size of array s[] when array is one-quarter full. Invariant: Array is between 25% and 100% full. Amortized analysis: Average running time per operation over a worst-case sequence of operations. Proposition: Starting from an empty stack, any sequence of M push and pop operations takes time proportional to M. Tradeoffs: Linked-list implementation Every operation takes constant time in the worst case. Uses extra time and space to deal with the links. Resizing-array implementation. Every operation takes constant amortized time. Less wasted space. queuesFIFO, examine the item least recently added. enqueue, dequeue API: 1234567public class QueueOfStrings &#123; QueueOfStrings(); // create an empty queue void enqueue(String item); // insert a new string onto queue String dequeue(); // remove and return the string least recently added boolean isEmpty(); // is the queue empty? int size(); // number of strings on the queue&#125; Linked-list representation Maintain pointer to first and last nodes in a linked list; Insert/remove from opposite ends Enqueue: Array implementation of a queue Use array q[] to store items in queue. enqueue(): add new item at q[tail]. dequeue(): remove item from q[head]. Update head and tail modulo the capacity Add resizing array. genericsJava generics Avoid casting in client. Discover type mismatch errors at compile-time instead of run-time. 123456Stack&lt;Apple&gt; s = new Stack&lt;Apple&gt;();Apple a = new Apple();Orange b = new Orange();s.push(a);s.push(b); // compile-time errora = s.pop(); Guilding principles: Welcome compile-time errors; avoid run-time errors. Full implementation (Linked-list version): 12345678910111213141516171819202122232425262728public class Stack&lt;Item&gt;&#123; private Node first = null; private class Node &#123; Item item; Node next; &#125; public boolean isEmpty() &#123; return first == null; &#125; public void push(Item item) &#123; Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; &#125; public Item pop() &#123; Item item = first.item; first = first.next; return item; &#125;&#125; Wrapper type. Each primitive type has a wrapper object type. Ex: Integer is wrapper type for int. Autoboxing: Automatic case between a primitive type and its wrapper. Syntactic sugar: Behind-the-scenes casting. Bottom line: Client code can use generic stack for any type of data. iteratorsDesign challenge: Support iteration over stack items by client, without revealing the internal representation of the stack. Java solution: Make stack implement the Iterable interface. An Iterable has a method that returns an Iterator. Iterable interface: 1234public interface Iterable&lt;Item&gt;&#123; Iterator&lt;Item&gt; iterator();&#125; An Iterator has methods hasNext() and next(). Iterator interface: 123456public interface Iterator&lt;Item&gt;&#123; boolean hasNext(); Item next(); void remove(); // optional&#125; “foreach” statement: 12for (String s : stack) StdOut.println(s); Equivalent code: 123456Iterator&lt;String&gt; i = stack.iterator();while(i.hasNext())&#123; String s = i.next(); StdOut.println(s);&#125; Example: Stack iterator: linked-list implementation 12345678910111213141516171819202122import java.util.Iterator;public class Stack&lt;Item&gt; implements Iterable&lt;Item&gt;&#123; ... public Iterator&lt;Item&gt; iterator() &#123; return new ListIterator(); &#125; private class ListIterator implements Iterator&lt;Item&gt; &#123; private Node current = first; public boolean hasNext() &#123; return current != null; &#125; public void remove() &#123; /* not supported */ &#125; public Item next() &#123; Item item = current.item; current = current.next; return item; &#125; &#125;&#125; Bag API Main application: Adding items to a collection and iterating (when order doesn’t matter). 1234567public class Bag&lt;Item&gt; implements Iterable&lt;Item&gt;&#123; Bag(); // create an empty bag void add(Item x); // insert a new item onto bag int size(); // number of items in bag Iterator&lt;Item&gt; iterator(); // iterator for all items in bag&#125; applicationsWhy not simply use Java collections library? “Performance” Lesson: Don’t use a library until you understand its API or you can tolerate the defect of the efficiency. Stack applications: Parsing in a compiler. Java virtual machine. Undo in a word processor. Back button in a Web browser. PostScript language for printers Implementing function calls in a compiler. Dijkstra’s two-stack algorithm: Value: push onto the value stack. Operator: push onto the operator stack. Left parenthesis: ignore. Right parenthesis: pop operator and two values; push the result of applying that operator to those values onto the operand stack. Programming Assignment 2Problem: Programming Assignment 2 Code is on my Github page: Kdtree Missing bonus memory challenge task. (I think it’s easy) Elementary Sortsrules of the gameGoal: Sort any type of data. Q. How can sort() know how to compare data of type Double, String, and java.io.File without any information about the type of an item’s key? Callback = reference to executable code. Client passes array of objects to sort() function. The sort() function calls back object’s compareTo() method as needed. Comparable interface (built in to Java) 1234public interface Comparable&lt;Item&gt;&#123; public int compareTo(Item that);&#125; Object implementation: 12345678910111213public class File implements Compareble&lt;File&gt;&#123; ... public int compareTo(File b) &#123; ... return -1; ... return +1; ... return 0; &#125;&#125; Sort implementation 123456789public static void sort(Comparable[] a)&#123; int N = a.length; for (int i = 0; i &lt; N; i++) for (int j = i; j &gt; 0; j--) if (a[j].compareTo(a[j-1]) &lt; 0) exch(a, j, j-1); else break;&#125; Total order A total order is a binary relation ≤ that satisfies Antisymmetry: if v ≤ w and w ≤ v, then v = w. Transitivity: if v ≤ w and w ≤ x, then v ≤ x. Totality: either v ≤ w or w ≤ v or both. Comparable API implement compareTo() so that v.compareTo(w) Is a total order. Returns a negative integer, zero, or positive integer if v is less than, equal to, or greater than w, repectively. Throws an exception if incompatible types (or either is null). 12345678910111213141516171819202122public class Date implements Comparable&lt;Date&gt;&#123; private final int month, day, year; public Date(int m, int d, int y) &#123; month = m; day = dl year = yl &#125; public int compareTo(Date that) &#123; if (this.year &lt; that.year) return -1; if (this.year &gt; that.year) return +1; if (this.month &lt; that.month) return -1; if (this.month &gt; that.month) return +1; if (this.day &lt; that.day) return -1; if (this.day &gt; that.day) return +1; return 0; &#125;&#125; Two useful sorting abstractions Less: Is item v less than w? 12private static boolean less(Comparable v, Comparable w)&#123; return v.compareTo(w) &lt; 0; &#125; Exchange: Swap item in array a[] at index i with the one at index j. 123456private static void exch(Comparable[] a, int i, int j)&#123; Comparable swap = a[i]; a[i] = a[j]; a[j] = swap;&#125; selection sortIn iteration i, find index min of smallest remaining entry. Swap a[i] and a[min]. 123456789101112131415161718192021public class Selection&#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int min = i; for (int j = i+1; i &lt; N; j++) if (less(a[j], a[min])) min = j; exch(a, i, min) &#125; &#125; private static boolean less(Comparable v, Comparable w) &#123; /* as before */ &#125; private static void exch(Comparable[] a, int i, int j) &#123; /* as before */ &#125;&#125; insertion sortIn iteration i, swap a[i] with each larger entry to its left. 12345678910111213141516171819public class Insertion&#123; public static void sort(Comparable[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) for (int j = i; j &gt; 0; j--) if (less(a[j], a[j-1])) exch(a, j, j-1); else break; &#125; private static boolean less(Comparable v, Comparable w) &#123; /* as before */ &#125; private static void exch(Comparable[] a, int i, int j) &#123; /* as before */ &#125;&#125; Def: An inversion is a pair of keys that are out of order. Def: An array is partially sorted if the number of inversions is ≤ cN. Proposition: For partially-sorted arrays, insertion sort runs in linear time. Pf: Number of exchanges equals the number of inversions. shellsortIdea: Move entries more than one position at a time by h-sorting the array. How to h-sort an array? Insertion sort, with stride length h. Useful in practice: Fast unless array size is huge. Tiny, fixed footprint for code (used in embedded systems). Hardware sort prototype. shufflingShuffle sort Generate a random real number for each array entry. Sort the array. Proposition: Shuffle sort produces a uniformly random permutation of the input array, provided no duplicate values. Goal: Rearrange array so that result is a uniformly random permutation in linear time. Knuth shuffle In iteration i, pick integer r between 0 and i uniformly at random. Swap a[i] and a[r]. Proposition: Knuth shuffling algorithm produces a uniformly random permutation of the input array in linear time. 12345678910111213public class StdRandom&#123; ... public static void shuffle(Object[] a) &#123; int N = a.length; for (int i = 0; i &lt; N; i++) &#123; int r = StdRandom.uniform(i + 1); // between 0 and i exch(a, i, r); &#125; &#125;&#125; online poker: easily cracked Bottom line: Shuffling a deck of cards is hard! convex hullThe convex hull of a set of N points is the smallest perimeter fence enclosing the points. Equivalent definitions: Smallest convex set containing all the points. Smallest area convex polygon enclosing the points. Convex polygon enclosing the points, whose vertices are points in set. Convex hull output: Sequence of vertices in counterclockwise order. Convex hull application: motion planning Robot motion planning: Find shortest path in the plane from s to t that avoids a polygonal obstacle. Fact: Shortest path is either straight line from s to t or it is one of two polygonal chains of convex hull. Farthest pair problem: Given N points in the plane, find a pair of points with the largest Euclidean distance between them. Graham scan: Choose point p with smallest y-coordinate. Sort points by polar angle with p. Consider points in order; discard unless it create a ccw turn. Implementation: Define a total order, comparing by y-coordinate. Define a total order for each point p. (polar angle) Computational geometry to determine counterclockwise for triple. Mergesort to sort efficiently. Implementing ccw: CCW: Given three points a, b, and c, is a-&gt;b-&gt;c a counterclockwise turn? (is c to the left of the ray a-&gt;b) A good strategy involves computing areas (high school compitation knowledge) To show respectations: Week 3MergesortmergesortBasic plan: Divide array into two halves. Recursively sort each half. Merge two halves. 12345678910111213141516171819private static void merge(Comparable[] a, Comparable[] aux, int lo, int mid, int hi)&#123; assert isSorted(a, lo, mid); // precondition: a[lo...mid] sorted assert isSorted(a, mid+1, hi); // precondition: a[mid+1...hi] sorted for (int k = lo; k &lt;= hi; k++) aux[k] = a[k]; int i = lo, j = mid+1; for (int k = lo; k &lt;= hi; k++) &#123; if (i &gt; mid) a[k] = aux[j++]; else if (j &gt; hi) a[k] = aux[i++]; else if (less(aux[j], aux[i])) a[k] = aux[j++]; else a[k] = aux[i++]; &#125; assert isSorted(a, lo, hi); // poscondition: a[lo...hi] sorted&#125; Assertion: Statement to test assumptions about your program. Helps detect logic bugs. Documents code. Java assert statement: Throws exception unless boolean condition is true. 1assert isSorted(a, lo, hi); Can enable or disable at runtime: 12java -ea MyProgram // enable assertionsjava -da MyProgram // disable assertions (default) Best practices: Use assertions to check internal invariants; assume assertions will be disabled in production code. Recurrence relation Proposition: Mergesort uses extra space proportional to N. Pf: The array aux[] needs to be of size N for the last merge. Some detailed improvements can be done. bottom-up mergesortBasic plan: Pass through array, merging subarrays of size 1. Repeat for subarrays of size 2, 4, 8, 16, …… Bottom line: No recursion needed! Several passes. 12345678910111213141516public class MergeBU&#123; private static Comparable[] aux; private static void merge(Comparable[] a, int lo, int mid, int hi) &#123; /* as before */ &#125; public static void sort(Comparable[] a) &#123; int N = a.length; aux = new Comparable[N]; for (int sz = 1; sz &lt; N; sz = sz+sz) for (int lo = 0; lo &lt; M - sz; lo += sz+sz) merge(a, lo, lo+sz-1, Math.min(lo+sz+sz-1, N-1)); &#125;&#125; log N passes sorting complexityModel of computation: Allowable operations. Cost model: Operation count(s). Upper bound: Cost guarantee provided by some algorithm for X. Lower bound: Proven limit on cost guarantee of all algorithms for X. Optimal algorithm: Algorithm with best possible cost guarantee for X. Decision tree: please refer to CLRS Mergesort is optimal with respect to compares. Mergesort is not optimal with respect to space usage. Lower bound N log N may not hold if the algorithm has information about: The initial order of the input. The distribution of key values. The representation of the keys. Eg: Partially-ordered arrays. Duplicate keys. Digital properties of keys. comparatorsComparable interface: sort using a type’s natural order. Comparator interface: sort using an alternate order. 12public interface Comparator&lt;Key&gt; int compare(Key v, Key w) // compare keys v and w Required property: Must be a total order. 1234567891011121314151617181920public class Student&#123; public static final Comparator&lt;Student&gt; BY_NAME = new ByName(); public static final Comparator&lt;Student&gt; BY_SECTION = new BySection(); private final String name; private final int section; ... private static class ByName implements Comparator&lt;Student&gt; &#123; public int compare(Student v, Student w) &#123; return v.name.compareTo(w.name); &#125; &#125; private static class BySection implements Comparator&lt;Student&gt; &#123; public int compare(Student v, Student w) &#123; return v.section - w.section; &#125; &#125;&#125; stabilitySelection/Shell sort are not stable. Insertion/Merge sort are stable. Long-distance exchange may lead to problems. Mergesort is stable because merge is stable. Programming Assignment 3Problem: Programming Assignment 3 Code is on my Github page: Pattern Recognition Failed some timing tests because HashMap is not allowed. Got 92 out of 100. QuicksortquicksortBasic plan: Shuffle the array. Partition. Sort each piece recursively. Phase 1: Repeat until i and j pointers cross. Scan i from left to right so long as (a[i] &lt; a[lo]) Scan j from right to left so long as (a[j] &gt; a[lo]) Exchange a[i] with a[j] Phase 2: When pointers cross. Exchange a[lo] with a[j] 123456789101112131415161718public static int partition(Comparable[] a, int lo, int hi)&#123; int i = lo, j = hi+1; while (true) &#123; while (less(a[++i], a[lo])) if (i == hi) break; while (less(a[lo], a[--j])) if (j == lo) break; if (i &gt;= j) break; exch(a, i, j); &#125; exch(a, lo, j); return j;&#125; 12345678910111213141516171819public class Quick&#123; private static int partition(Comparable[] a, int lo, int hi) &#123; /* as before */ &#125; public static void sort(Comparable[] a) &#123; StdRandom.shuffle(a); sort(a, 0, a.length - 1); &#125; private static void sort(Comparable[] a, int lo, int hi) &#123; if (hi &lt;= lo) return; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi); &#125;&#125; Details: Partitioning in-place: Can be done with extra memoy. Terminating the loop: Testing whether the pointers cross is a bit trickier than it might seem. Staying in bounds: The (j == lo) test is redundant because of the key, but (i == hi) test is not. Preserving randomness: Shuffling is needed for performance guarantee. Equal keys: When duplicates are present, it is bettuer to stop on keys equal to the partitioning item’s key. Best case: N log N Worst case: $N^2$ Approximate sum by an integral. Proposition: Quicksort is an in-place sorting algorithm, not stable. Pf: Partitioning: constant extra space. Depth of recursion: logarithmic extra space (with high probability). Insertion sort small subarrays: Even quicksort has too much overhead for tiny subarrays. Cutoff to insertion sort for around 10 items. Note: could delay insertion sort until one pass at end. Practical improvements: Insertion sort small subarrays: 1234567891011private static void sort(Comparable[] a, int lo, int hi)&#123; if (hi &lt;= lo + CUTOFF - 1) &#123; Insertion.sort(a, lo, hi); return; &#125; int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi);&#125; Median of sample: 1234567891011private static void sort(Comparable[] a, int lo, int hi)&#123; if (hi &lt;= lo) return; int m = medianOf3(a, lo, lo + (hi -lo)/2, hi); swap(a, lo, m); int j = partition(a, lo, hi); sort(a, lo, j-1); sort(a, j+1, hi);&#125; selectionGoal: Given an array of N items, find the kth largest. Applications: Order statistics. Find the “top k.” Quick-select: Partition array so that: Entry a[j] is in place. No larger entry to the left of j. No smaller entry to the right of j. Repeat in one subarray, depending on j; finished when j equals k. 12345678910111213public static Comparable select(Comparable[] a, int k)&#123; StdRandom.shuffle(a); int lo = 0; hi = a.length - 1; while (hi &gt; lo) &#123; int j = partition(a, lo, hi); if (j &lt; k) lo = j + 1; else if (j &gt; k) hi = j - 1; else return a[k]; &#125; return a[k];&#125; Proposition: Quick-select takes linear time on average. Remard: Quadratic time in the worst case while random shuffle provides a probabilistic guarantee. duplicate keysQuicksort with duplicate keys: Algorithm goes quadratic unless partitioning stops on equal keys! 3-way partitioning: Goal: Partition array into 3 parts so that: Entries between lt and gt equal to partition item v. No larger entries to left of lt. No smaller entries to right of gt. Bottom line: Randomized quicksort with 3-way partitioning reduces running time from linearithmic to linear in broad class of applications. system sortsJava system sorts: Arrays.sort() Has different method for each primitive type. Has a method for data types that implement Comparable. Has a method that uses a Comparator. Uses tuned quicksort for primitive types; tuned mergesort for objects. 123456789101112import java.util.Arrays;public class StringSort&#123; public static void main(String[] args) &#123; String[] a = StdIn.readStrings(); Arrays.sort(a); for (int i = 0; i &lt; N; i++) StdOut.println(a[i]); &#125;&#125; Choices: Week 4Priority QueuesAPI and elementary implementationsCollections: Insert and delete items. Stack: Remove the item most recently added. Queue: Remove the item least recently added. Randomized queue: Remove a random item. Priority queue: Remove the largest (or smallest) item. Priority queue API 12345678910public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; MaxPQ(); // create an empty priority queue MaxPQ(Key[] a); // create a priority with given keys void insert(Key v); // insert a key into the priority queue Key delMax(); // return and remove the largest key boolean isEmpty(); // is the priority queue empty? Key max(); // return the largest key int size(); // number of entries in the priority queue&#125; Applications: Event-driven simulation Numerical computation Data compression Graph searching Number theory Artificial intelligence Statistics Operating systems Discrete optimization Spam filtering Generalizes: stack, queue, randomized queue. Unordered array implementation: 1234567891011121314151617181920212223public class UnorderedMaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; private Key[] pq; private int N; public UnorderedMaxPQ(int capacity) &#123; pq = (Key[]) new Comparable[capacity]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void insert(Key x) &#123; pq[N++] = x; &#125; public Key delMax() &#123; int max = 0; for (int i = 1; i &lt; N; i++) if (less(max, i)) max = i; exch(max, N-1); return pq[--N]; &#125;&#125; implementation insert delmax max unordered array 1 N N ordered array N 1 1 Goal log N log N log N binary heapsBased on complete binary tree (Perfectly balanced, except for bottom level). Binary heap: Array representation of a heap-ordered complete binary tree. Heap-ordered binary tree: Keys in nodes. Parent’s key no smaller than children’s key. Array representation: Indices start at 1. (Start at 0 causes a little trouble) Take nodes in level order. No explicit liniks needed! Proposition: Largest key is a[1], which is root of binary tree. Proposition: Can use array indices to move through tree. Parent of node at k is at k/2. Children of node at k are at 2k and 2k+1. Swim: 12345678private void swim(int k)&#123; while (k &gt; 1 &amp;&amp; less(k/2, k)) &#123; exch(k, k/2); k = k/2; &#125;&#125; Insertion: 12345public void insert(Key x)&#123; pq[++N] = x; swim(N); // swim means swim up&#125; Sink: 1234567891011private void sink(int k)&#123; while (2*k &lt;= N) &#123; int j = 2*k; if (j &lt; N &amp;&amp; less(j, j+1)) j++; if (!less(k, j)) break; exch(k, j); k = j; &#125;&#125; Delete max: 12345678public Key delMax()&#123; Key max = pq[1]; exch(1, N--); sink(1); pq[N+1] = null; // prevent loitering return max;&#125; Complete Java implementation: 1234567891011121314151617181920212223242526272829public class MaxPQ&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; private Key[] pq; private int N; public MaxPQ(int capacity) &#123; pq = (Key[]) new Comparable[capacity+1]; &#125; public boolean isEmpty() &#123; return N == 0; &#125; public void insert(Key key) &#123; /* as before */ &#125; public void delMax(); &#123; /* as before */ &#125; private void swim(int k); &#123; /* as before */ &#125; private sink(int k) &#123; /* as before */ &#125; private boolean less(int i, int j) &#123; return pq[i].compareTo(pq[j]) &lt; 0; &#125; private void exch(int i, int j) &#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125;&#125; Improvements: Fibonacci heap Some considerations Immutability of keys: Assumption: client does not change keys while they’re on the PQ. Best practice: use immutable keys. Underflow and overflow: Underflow: throw exception if deleting from empty PQ. Overflow: add no-arg constructor and use resizing array. Minimum-oriented priority queue: Replace less() with greater(). Implement greater(). Other operations: Remove an arbitrary item. Change the priority of an item. Immutability: 1234567891011public final class Vector &#123; private final int N; private final double[] data; public Vector(double[] data) &#123; this.N = data.length; this.data = new double[N]; for (int i = 0; i &lt; N; i++) this.data[i] = data[i]; &#125;&#125; Immutable: String, Integer, Double, Color, Vector, Transaction, Point2D. Mutable: StringBuilder, Stack, Counter, Java array. Advantages of immutability: Simplifies debugging. Safer in presence of hostile code. Simplifiers concurrent programming. Safe to use as key in priority queue or symbol table. Disadvantage: Must create new object for each data type value. heapsortBasic plan for in-place sort: Create max-heap with all N keys. Repeatedly remove the maximum key. Heap construction: Sink, bottom-up. Build: 12for (int k = N/2; k &gt;= 1; k--) sink(a, k, N); Sort: 12345while (N &gt; 1)&#123; exch(a, 1, N--); sink(a, 1, N);&#125; Bottom line: Inner loop longer than quicksort’s Makes poor use of cache memory Not stable event-driven simulationMolecular dynamics simulation of hard discs Goal. Simulate the motion of N moving particles that behave according to the laws of elastic collision. Time-driven simulation: Judge collision with dt Event-driven simulation: Maintain PQ of collision events, prioritized by time. Collision prediction: Given position, velocity, and radius of a particle, when will it collide next with a wall or another particle? Collision resolution: If collision occurs, update colliding particle(s) according to laws of elastic collisions. Difficult simulation, involving a lot of physics and math, or at least not easy. Programming Assignment 4Problem: Programming Assignment 4 Code is on my Github page: 8 Puzzle Failed some timing tests. Got 96 out of 100. Symbol TablesAPIKey-value pair abstraction: Insert a value with specified key. Given a key, search for the corresponding value. Associative array abstraction: Associate one value with each key. 12345678910public class ST&lt;Key, Value&gt; &#123; ST(); // create a symbol table void put(Key key, Value val); // put key-value pair into the table (remove key from table if value is null) Value get(Key key); // value paired with key (null if key is absent) void delete(Key key); // remove key (and its value) from table boolean contains(Key key); // is there a value paired with key? boolean isEmpty(); // is the table empty? int size(); // number of key-value pairs in the table Iterable&lt;Key&gt; keys(); // all the keys in the table&#125; Convetions: Value are not null. Method get() returns null if key not present. Method put() overwrites old value with new value. Contains: 12public boolean contains(Key key)&#123; return get(key) != null; &#125; Lazy delete: 12public void delete(Key key)&#123; put(key, null); &#125; Keys and values Value type: Any generic type. Key type: several natural assumptions: Assume keys are Comparable, use compareTo(). Assume keys are any generic type, use equals() to test equality. Assume keys are any generic type, use equals() to test equality; use hashCode() to scramble key. Best practices: Use immutable types for symbol table keys. Equality test: 123456789101112131415161718192021222324public final class Data implements Comparable&lt;Date&gt;&#123; private final int month; private final int day; private final int year; ... public boolean equals(Object y) &#123; if (y == this) return true; if (y == null) return false; if (y.getClass() != this.getClass()) return false; Date that = (Date) y; if (this.day != that.day) return false; if (this.month != that.month) return false; if (this.year != that.year) return false; return true; &#125;&#125; elementary implementationsSequential search in a linked list: Data structure: Maintain an (unordered) linked list of key-value pairs. Search: Scan through all keys until find a match. Insert: Scan through all keys until find a match; if no match add to front. Binary search in an ordered array: Data structure: Maintain an ordered array of key-value pairs. Rank helper function: How many keys &lt; k? 12345678910111213141516171819202122public Value get(Key key)&#123; if (isEmpty()) return null; int i = rank(key); if (i &lt; N &amp;&amp; keys[i].compareTo(key) == 0) return vals[i]; else return null;&#125;private int rank(Key key)&#123; int lo = 0; hi = N-1; while (lo &lt;= hi) &#123; int mid = lo + (hi - lo) / 2; int cmp = key.compareTo(keys[mid]); if (cmp &lt; 0) hi = mid - 1; else if (cmp &gt; 0) lo = mid + 1; else return mid; &#125; return lo;&#125; ordered operationsAPI: 123456789101112131415161718192021public class ST&lt;Key extends Comparable&lt;Key&gt;, Value&gt;&#123; ST(); // create an ordered symbol table void put(Key key, Value val); // put key-value pair into the table (remove key from table if value is null) Value get(Key key); // value paired with key (null if key is absent) void delete(Key key); // remove key (and its value) from table boolean contains(Key key); // is there a value paired with key? boolean isEmpty(); // is the table empty? int size(); // number of key-value pairs Key min(); // smallest key Key max(); // largest key Key floor(Key key); // smallest key less than or equal to key Key ceiling(Key key); // smallest key greater than or equal to key int rank(Key key); // number of keys less than key Key select(int k); // key of rank k void deleteMin(); // delete smallest key void deleteMax(); // delete largest key int size(Key lo, Key hi); // number of keys in [lo..hi] Iterable&lt;Key&gt; keys(Key lo, Key hi); // keys in [lo..hi], in sorted order Iterable&lt;Key&gt; keys(); // all keys in the table, in sorted order&#125; Binary Search TreesBSTsDefinition: A BST is binary tree in symmetric order. A binary tree is either: Empty Two disjoint binary trees (left and right). Symmetric order: Each node has a key, and every node’s key is: Larger than all keys in its left subtree. Smaller than all keys in its right subtree. Java definition: A BST is a reference to a root Node. A Node is comprised of four fields: A Key and a Value. A reference to the left and right subtree. 1234567891011private class Node&#123; private Key key; private Value val; private Node left, right; public Node(Key key, Value val) &#123; this.key = key; this.val = val; &#125;&#125; 12345678910111213141516171819public class BST&lt;Key extends Comparable&lt;Key&gt;, Value&gt;&#123; private Node root; private class Node &#123; /* see previous slide */ &#125; public void put(Key key, Value val) &#123; /* see later */ &#125; public Value get(Key key) &#123; /* see later */ &#125; public void delete(Key key) &#123; /* see later */ &#125; public Iterable&lt;Key&gt; iterator() &#123; /* see later */ &#125;&#125; Search: If less, go left; if greater, go right; if equal, search hit. 12345678910111213public Value get(Key key)&#123; Node x = root; while (x != null) &#123; int cmp = key.compareTo(x.key); if (cmp &lt; 0) x = x.left; else if (cmp &gt; 0) x = x.right; else return x.val; &#125; return null;&#125; Insertion (concise but tricky recursive code): 12345678910111213public void put(Key key, Value val)&#123; root = put(root, key, val); &#125;private Node put(Node x, Key key, Value val)&#123; if (x == null) return new Node(key, val); int cmp = key.compareTo(x.key); if (cmp &lt; 0) x.left = put(x.left, key, val); else if (cmp &gt; 0) x.right = put(x.right, key, val); else x.val = val; return x;&#125; ordered operationsMinimum: Smallest key in table. Maximum: Largest key in table. Rank: How many keys &lt; k? 1234567891011public int rank(Key key)&#123; return rank(key, root); &#125;private int rank(Key key, Node x)&#123; if (x == null) return 0; int cmp = key.compareTo(x.key); if (cmp &lt; 0) return rank(key,x.left); else if (cmp &gt; 0) return 1 + size(x.left) + rank(key, x.right); else return size(x.left);&#125; Inorder traversal: Traverse left subtree. Enqueue key. Traverse right subtree. 1234567891011121314public Iterable&lt;Key&gt; keys();&#123; Queue&lt;Key&gt; q = new Queue&lt;Key&gt;(); inorder(root, q); return q;&#125;private void inorder(Node x, Queue&lt;Key&gt; q)&#123; if (x == null) return; inorder(x.left, q); q.enqueue(x.key); inorder(x.right, q);&#125; deletionLazy deletion: Set its value to null. Leave key in tree to guide searches (but don’t consider it equal in search). Delete the minimum key: Go left until finding a node with a null left link. Replace that node by its right link. Update subtree counts. Else, Hibbard deletion, please refer to CLRS BST chapter for more details Week 5Balanced Search Trees2-3 search treesAllow 1 or 2 keys per node 2-node: one key, two children 3-node: two keys, three children Perfect balance: Every path from root to null link has same length Symmetric order: Inorder traversal yields keys in ascending order Search Compare search key against keys in node Find interval containing search key Follow associated link (recursively) Insert into a 2-node at bottom Search for key, as usual Replace 2-node with 3-node Splitting a 4-node is a local transformation: constant number of operations Invariants: Maintain symmetric order and perfect balance Pf: Each transformation maintains symmetric order and perfect balance Tree height: Always $lg N$ red-black BSTsLeft-leaning RB tree Idea: Represent 2-3 tree as a BST Use “internal” left-leaning links as “glue” for 3-nodes A BST such that: No node has two red links connected to it Every path from root to null link has the same number of black links Red links lean left 2-3 tree and RB BST are coresponding as following: Search for red-black BST is the same as the general BST Representation: 12345678910111213141516private static final boolean RED = true;private static final boolean BLACK = false;private class Node&#123; Key key; Value val; Node left, right; boolean color; // color of parent link&#125;private boolean isRed(Node x)&#123; if (x == null) return false; return x.color == RED;&#125; Left rotation: Orient a (temporarily) right-leaning red link to lean left 12345678910private Node rotateLedt(Node h)&#123; assert isRed(h.right); Node x = h.right; h.right = x.left; x.left = h; x.color = h.color; h.color = RED; return x;&#125; Invariants: Maintains symmetric order and perfect black balance Right rotation is similar. Color flip: Recolor to split a (temporary) 4-node 123456789private void flipColors(Node h)&#123; assert !isRed(h); assert isRed(h.left); assert isRed(h.right); h.color = RED; h.left.color = Black; h.right.color = Black;&#125; Insertion in a LLRB tree Basic strategy: Maintain 1-1 correspondence with 2-3 trees by applying elementary red-black BST operations Warmup 1: Insert into a tree with exactly 1 node Warmup 2: Insert into a tree with exactly 2 nodes (3 cases) Case 2: Insert into a 3-node at the bottom Do standard BST insert; color new link red Rotate to balance the 4-node (if needed) Flip colors to pass red link up one level Rotate to make lean left (if needed) Repeat case 1 or case 2 up the tree (if needed) Java implementation Reduce one case to another 1234567891011121314private Node put(Node h, Key key, Value val)&#123; if (h == null) return new Node(key, val, RED); int cmp = key.compareTo(h.key); if (cmp &lt; 0) h.left = put(h.left, key, val); else if (cmp &gt; 0) h.right = put(h.right, key, val); else if (cmp == 0) h.val = val; if (isRed(h.right) &amp;&amp; !isRed(h.left)) h = rotateLeft(h; if (isRed(h.left) &amp;&amp; isRed(h.left.left)) h = rotateRight(h); if (isRed(h.left) &amp;&amp; isRed(h.right)) flipColors(h); return h; &#125; B-trees (Bayer-McCreight, 1972)File system model: Page: Contiguous block of data Probe: First access to a page Property: Time required for a probe is much larger than time to access data within a page Cost model: Number of probes Goal: Access data using minimum number of probes B-tree: Generalize 2-3 trees by allowing up to M-1 key-link pairs per node At least 2 key-link pairs at root At least M/2 key-link pairs in other nodes External nodes contain client keys Internal nodes contain copies of keys to guide search Searching in a B-tree: Start at root Find interval for search key and take corresponding link Search terminates in external node Insertion in a B-tree: Search for new key Insert at bottom Split nodes with M key-link pairs on the way up the tree Red-black trees are widely used as system symbol tables Java: java.util.TreeMap, java.util.TreeSet C++ STL: map, multimap, multiset Linux kernel: completely fair scheduler, linux/rbtree.h Emacs: conservative stack scanning B-tree variants: B+ tree, B* tree, B# tree, … B-trees (and variants) are videly used for file systems and databases Windows: NTFS Mac: HFS, HFS+ Linux: ReiserFS, XFS, Ext3FS, JFS Databases: Oracle, DB2, Ingres, SQL, PostgreSQL Geometric Applications of BSTsApplications: CAD, games, movies, virtual reality, databases, … 1d range search Insert key-value pair Search for key k Delete key k Range search: find all keys between $k_1$ and $k_2$ Range count: number of keys between $k_1$ and $k_2$ Implementations: data structure insert range count range search unordered array 1 N N ordered array N log N R + log N goal log N log N R + log N N = number of keys R = number of keys that match BST implementation: Proposition: Running time proportional to log N. Pf: Nodes examined = search path to lo + search path to hi. line segment intersectionOrthogonal line segment intersection search Quadratic algorithm: Check all pairs of line segments for intersection. Nondegeneracy assumption: All x- and y- coordinates are distinct. Sweep-line algorithm: Sweep vertical line from left to right X-coordinates define events. H-segment (left endpoint): insert y-coordinate into BST. H-segment (right endpoint): remove y-coordinate from BST. When hit a vertical line segment, do a 1-d search Proposition: The sweep-line algorithm takes time proportional to N log N + R to find all R intersections among N orthogonal line segments. Pf. Put x-coordinates on a PQ (or sort). N log N Insert y-coordinates into BST N log N Delete y-coordinates from BST N log N Range searches in BST N log N + R Bottom line: Sweep line reduces 2d orthogonal line segment intersection search to 1d range search kd treesExtension of ordered symbol-table to 2d keys Insert a 2d key Delete a 2d key Search for a 2d key Range search: find all keys that lie in a 2d range Range count: number of keys that lie in a 2d range Geometric interpretation: Keys are point in the plane Find/count points in a given h-v rectangle Grid implementation: Divide space into M-by-M grid of squares Create list of points contained in each square Use 2d array to directly index relevant square Insert: add(x, y) to list for corresponding square Range search: examine only squares that intersect 2d range query Space-time tradeoff Space: $M^2+N$ Time: 1 + $N/M^2$ per square examined, on average Choose grid square size to tune performance Too small: waste space Too large: too many points per square It’s fast, simple solution for evenly-distributed points Problem: Clustering a well-knwon phenomenon in geometric data Lists are too long, even though average length is short Need data structure that adapts gracefully to data 2d tree construction Recursively partition plane into two halfplanes. Data structure: BST, but alternate using x- and y- coordinates as key. Search gives rectangle containing point Insert further subdivides the plane Range search in a 2d tree Goal: Find all points in a query axis-aligned rectangle. Check if point in node lies in given rectangle Recursively search left/bottom (if any could fall in rectangle) Recursively search right/top (if any could fall in rectangle) Nearest neighbor search in a 2d tree Goal: Find closest point to query point Check distance from point in node to query point Recursively search left/bottom (if it could contain a closer point) Recursively search right/top (if it could contain a closer point) Organize method so that it begins by searching for query point Kd tree Recursively partition k-dimensional space into 2 halfspaces Efficient, simple data structure for processing k-dimensional data Widely used Apapts well to high-dimensional and clustered data Discovered by an undergrad in an algorithms class! N-body simulation Build 3d-tree with N particles sa nodes Store center-of-mass of subtree in each node. To compute total force acting on a particle, traverse tree, but stop as soon as distance from particle to subdivision is sufficiently large. interval search trees1d interval search: Data structure to hold set of (overlapping) intervals Insert an interval (lo, hi). Search for an interval (lo, hi). Delete an interval (lo, hi). Interval intersection query: given an interval (lo, hi), find all intervals (or one interval) in data structure that intersects (lo, hi). API 123456public class IntervalST IntervalST() void put(Key lo, Key hi, Value val) Value get(Key lo, Key hi) void delete(Key lo, Key hi) Iterable&lt;Value&gt; intersects(Key lo, Key hi) Interval search trees Create BST, where each node stores an interval (lo, hi). Use left endpoint as BST key. Store max endpoint in subtree rooted at node. To insert an interval (lo, hi): Insert into BST, using lo as the key. Update max in each node on search path. To search for any one interval that intersects query interval (lo, hi): If interval in node intersects query interval, return it. Else if left subtree is null, go right. Else if max endpoint in left subtree is less than lo, go right. Else go left. Case 1. If search goes right, then no intersection in left. Case 2. If search goes left, then there is either an intersection in left subtree or no intersections in either Pf. Suppose no intersection in left. Since went left, we have lo ≤ max. Then for any interval (a,b) in right subtree of x, hi &lt; c ≤ a, no intersection in right. rectangle intersectionOrthogonal rectangle intersection search Goal: Find all intersections among a set of N orthogonal rectangles Quadratic algorithm: Check all pairs of rectangles for intersection Non-degeneracy assumption: All x- and y- coordinates are distinct. Design-rule checking: Certain wires cannot intersect Certain spacing needed between different types of wires Debugging = orthogonal rectangle intersection search Sweep-line algorithm (similar to previous one) X-coordinates of left and right endpoints define events. Maintain set of rectangles that intersect the sweep line in an interval search tree (using y-intervals of rectangle). Left endpoint: interval search for y-interval of rectangle; insert y-interval. Right endpoint: remove y-interval. Bottom line: Sweep line reduces 2d orthogonal rectangle intersection search to 1d interval search. Summary Of Geometric Applications of BSTs Programming Assignment 5Problem: Programming Assignment 5 Code is on my Github page: Kdtree Missing the optional task of running time analysis because it’s optional. Week 6Hash Tableshash functionsBasic plan: save items in a key-indexed table (index is a function of the key). Hash function: Method for computing array index from key. hash(&quot;it&quot;) = 3 Issues: Computing the hash function. Equality test. Collision resolution. Classic space-time tradeoff. No space limitation: trivial hash function with key as index. No time limitation: trivial collision resolution with sequential search. Space and time limitations: hashing (the real world). Hash function Idealistic goal: Scramble the keys uniformly to produce a table index. Efficiently computable. Each table index equally likely for each key. All Java classes inherit a method hashCode(), which returns a 32-bit int. Default implementation: Memory address of x. Some typicals in Java libraries: Hash for strings: Horner’s method 12345678910111213141516public final class String&#123; private int hash = 0; private final char[] s; ... public int hashCode() &#123; int h = hash; if (h != 0) return h; for (int i = 0; i &lt; length(); i++) h = s[i] + (31 * h); hash = h; return h; &#125;&#125; Modular hashing Hash code: A int between $-2^{32}$ and $2^{31}-1$ Hash function: An int between 0 and M-1 (for use as array index). 123// to be between 0 and M-1private int hash(Key key)&#123; return (key.hashCode() &amp; 0x7fffffff) % M; &#125; Assumption Uniform hashing assumption: Each key is equally likely to hash to an integer between 0 and M-1. seperate chaining Typical choice of M: near N / 5 linear probingOpen addressing (IBM 1953): When a new key collides, find next empty slot, and put it there. Hash: Map key to integer i between 0 and M-1. Insert: Put at table index i if free; if not try i+1, i+2, etc. Search: Search table index i; if occupied but no match, try i+1, i+2, etc. Note: Array size M must be greater than number of key-value pairs N. contextAlgorithmic complexity attack. One-way hash function: “Hard” to find a key that will hash to a desired value. Separate chaining vs. linear probing Separate chaining: Easier to implement delete. Performance degrades gracefully. Clustering less sensitive to poorly-designed hash function. Linear probing: Less wasted space. Better cache performance. Variations: Two-probe hashing Double hashing Cuckoo hashing And so on… Symbol Table ApplicationssetsMathematical set: A collection of distinct keys. 123456789public class SET&lt;Key extends Comparable&lt;Key&gt;&gt;&#123; SET(); // create an empty set void add(Key key); // add the key to the set boolean contains(Key key); // is the key in the set? void remove(Key key); // remove the key from the set int size(); // return the number of keys in the set Iterator&lt;Key&gt; iterator(); // iterator through keys in the set&#125; Exception filter: Read in a list of words from one file. Print out all words from standard input that are { in, not in } the list. dictionary clientsDictionary lookup. indexing clientsFile indexing Goal: Given a list of files specified, create an index so that you can efficiently find all files containing a given query string. Key: String. Value: Set of files. Concordance Goal: Preprocess a text corpus to support concordance queries: given a word, find all occurrences with their immediate contexts. sparse vectors Problem: Sparse matrix-vector multiplication. Vector representations 1 D array representation: Constant time access to elements. Space proportional to N. Symbol table representation: Key = index, value = entry. Efficient iterator. Space proportional to number of nonzeros. Sparse matrix representation: Each row of matrix is a sparse vector. Efficient access to elements. Space proportional to number of nonzeros (plus N). 123456789...SparseVector[] a = new SparseVector[N];double[] x = new double[N];double[] b = new double[N];...// Initialize a[] and x[]...for (int i = 0; i &lt; N; i++) b[i] = a[i].dot(x);]]></content>
      <categories>
        <category>Note</category>
      </categories>
      <tags>
        <tag>Programming</tag>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
