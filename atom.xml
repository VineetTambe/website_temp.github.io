<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qingliu</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-03-10T22:11:30.037Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Qingliu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Algorithms, Part 1</title>
    <link href="http://yoursite.com/2019/03/08/Algorithms-Part-1/"/>
    <id>http://yoursite.com/2019/03/08/Algorithms-Part-1/</id>
    <published>2019-03-08T20:06:34.000Z</published>
    <updated>2019-03-10T22:11:30.037Z</updated>
    
    <content type="html"><![CDATA[<p>Princeton Algorithm course on coursera. Part 1</p><a id="more"></a><p>Cover:</p><ul><li>Disjoint set</li><li>Analysis of Algorithms</li><li>Stack and Queue</li><li>Elementary Sorts</li><li>Mergesort</li><li>Quicksort</li><li>Priority Queue</li><li>Elementary Symbol Tables</li><li>BST</li><li>Hash Table</li></ul><p>Learning Purpose: </p><ul><li>Being familiar with Java. </li><li>Having fun with algorithms.</li></ul><p>Reference Books:</p><ul><li><a href="https://algs4.cs.princeton.edu/home/" target="_blank" rel="noopener">Algorithms, 4th Edition</a></li><li><a href="https://introcs.cs.princeton.edu/java/home/" target="_blank" rel="noopener">Computer Science:   An Interdisciplinary Approach</a></li></ul><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Why-study-algorithms"><a href="#Why-study-algorithms" class="headerlink" title="Why study algorithms"></a>Why study algorithms</h2><p><em>“Great algorithms are the poetry of computation.” — Francis Sullivan</em></p><p><em>“Algorithms + Data Structures = Programs.” — Niklaus Wirth</em></p><h2 id="Union-Find"><a href="#Union-Find" class="headerlink" title="Union-Find"></a>Union-Find</h2><p>Steps to developing a usable algorithm</p><ul><li>Model the problem.</li><li><p>Find an algorithm to solve it.</p></li><li><p>Fast enough? Fits in memory?</p></li><li>If not, figure out why.</li><li>Find a way to address the problem.</li><li>Iterate until satisfied.</li></ul><h3 id="dynamic-connectivity"><a href="#dynamic-connectivity" class="headerlink" title="dynamic connectivity"></a>dynamic connectivity</h3><p>Given a set of N objects.</p><ul><li>Union command: connect two objects</li><li>Find/conneted query: is there a path connecting the two objects?</li></ul><center><br>    <img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0w2nx25iwj30jm06yjse.jpg" style="zoom:60%"><br></center><p><u><strong>Connectivity example</strong></u></p><font color="blue">Q. Is there a path connecting <em>p</em> and <em>q</em>?</font><center><br>    <img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0w31l36egj30nt0j2k6w.jpg" style="zoom:60%"><br></center><p>Some common understandings:</p><ul><li>Reflexive: <em>p</em> is connected to <em>p</em> itself.</li><li>Symmetric: if <em>p</em> is connected to <em>q</em>, then <em>q</em> is connected to <em>p</em>.</li><li>Transitive: if <em>p</em> is connected to <em>q</em> and <em>q</em> is connected to <em>r</em>, then <em>p</em> is connected to <em>r</em>.</li></ul><p><strong>Connected components.</strong> Maximal set of objects that are mutually connected.</p><p>e.g.</p><center><br>    <img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0w3d6dfv8j30co09zabx.jpg" style="zoom:60%"><br>    </center><p>​    </p><p><font color="blue"> Goal. </font> Design efficient data structure for union-find.</p><ul><li>Number of objects <em>N</em> can be huge.</li><li>Number of operations <em>M</em> can be huge.</li><li>Find queries and union commands may be intermixed.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// API</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UF</span></span></span><br><span class="line"><span class="class">    <span class="title">UF</span>(<span class="title">int</span> <span class="title">N</span>)// <span class="title">initialize</span> <span class="title">union</span>-<span class="title">find</span> <span class="title">data</span> <span class="title">structure</span> <span class="title">with</span> <span class="title">N</span> <span class="title">objects</span> (0 <span class="title">to</span> <span class="title">N</span>-1)</span></span><br><span class="line"><span class="class">    <span class="title">void</span> <span class="title">union</span>(<span class="title">int</span> <span class="title">p</span>, <span class="title">int</span> <span class="title">q</span>)// <span class="title">add</span> <span class="title">connection</span> <span class="title">between</span> <span class="title">p</span> <span class="title">and</span> <span class="title">q</span></span></span><br><span class="line"><span class="class">    <span class="title">boolean</span> <span class="title">connected</span>(<span class="title">int</span> <span class="title">p</span>, <span class="title">int</span> <span class="title">q</span>)// <span class="title">are</span> <span class="title">p</span> <span class="title">and</span> <span class="title">q</span> <span class="title">the</span> <span class="title">same</span> <span class="title">component</span>?</span></span><br><span class="line"><span class="class">    <span class="title">int</span> <span class="title">find</span>(<span class="title">int</span> <span class="title">p</span>)//<span class="title">component</span> <span class="title">identifier</span> <span class="title">for</span> <span class="title">p</span> (0 <span class="title">to</span> <span class="title">N</span>-1)</span></span><br><span class="line"><span class="class">    <span class="title">int</span> <span class="title">count</span>()// <span class="title">number</span> <span class="title">of</span> <span class="title">components</span></span></span><br></pre></td></tr></table></figure><h3 id="quick-find"><a href="#quick-find" class="headerlink" title="quick find"></a>quick find</h3><p>Data structure</p><ul><li>Integer array id[] of size N.</li><li>Interpretation: <em>p</em> and <em>q</em> are connected iff they have the same id.</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0xaw2d1qzj30ok03lwfw.jpg" style="zoom:60%"><br></center><p>Find: Check if <em>p</em> and <em>q</em> have the same id</p><p>Union: To merge components containing <em>p</em> and <em>q</em>, change all entries whose id equals id[p] to id[q]. Costly.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuickFindUF</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] id;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuickFindUF</span><span class="params">(<span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        id = <span class="keyword">new</span> <span class="keyword">int</span>[N];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">            id[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">connected</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;<span class="keyword">return</span> id[p] == id[q]; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> pid = id[p];</span><br><span class="line">        <span class="keyword">int</span> qid = idp[q];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; id.length; i++)</span><br><span class="line">            <span class="keyword">if</span> (id[i] == pid) id[i] = qid;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><table><thead><tr><th>algorithm</th><th>initialize</th><th>union</th><th>find</th></tr></thead><tbody><tr><td>quick-find</td><td>N</td><td>N</td><td>1</td></tr></tbody></table><p>N union commands on N object: quadratic time. Much too slow.</p><p>Quadratic algorithms don’t scale with technology.</p><h3 id="quick-union"><a href="#quick-union" class="headerlink" title="quick union"></a>quick union</h3><p>Data structure</p><ul><li>Integer array id[] of size N.</li><li>Interpretation: id[i] is parent of i.</li><li>Root of i is id[id[id[…id[i]…]]].</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0xbfl4c0kj30au06aaav.jpg" style="zoom:60%"><br></center><p>Each root represents the connected components.</p><p>Find: Check if <em>p</em> and <em>q</em> have the same root.</p><p>Union: To merge components containing <em>p</em> and <em>q</em>, set the id of p’s root to the id of q’s root.</p><p>(path compression)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuickUnionUF</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] id;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuickUnionUF</span><span class="params">(<span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        id = <span class="keyword">new</span> <span class="keyword">int</span>[N];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)id[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">root</span><span class="params">(<span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (i != id[i])i = id[i];</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">connected</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> root(p) == root(q);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = root(p);</span><br><span class="line">        <span class="keyword">int</span> j = root(q);</span><br><span class="line">        id[i] = j;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Worst case:</p><table><thead><tr><th>algorithm</th><th>initialize</th><th>union</th><th>find</th></tr></thead><tbody><tr><td>Quick-union</td><td>N</td><td>N</td><td>N</td></tr></tbody></table><p>Quick-union defect</p><ul><li>Trees can get tall</li><li>Find too expensive (could be N array accesses).</li></ul><h3 id="improvements"><a href="#improvements" class="headerlink" title="improvements"></a>improvements</h3><h4 id="Improvement-1-weighting"><a href="#Improvement-1-weighting" class="headerlink" title="Improvement 1: weighting"></a>Improvement 1: weighting</h4><hr><p>Weighted quick-union</p><ul><li>Modify quick-union to avoid tall trees.</li><li>Keep track of size of each tree (number of objects).</li><li>Balance by linking root of smaller tree to root of larger tree.</li></ul><p>Data structure： Same as quick-union, but maintain extra array sz[i] to count number of objects in the tree rooted at i.</p><p>Find: Identical to quick-union. <code>return root(p) == root(q)</code></p><p>Union: Modify quick-union to:</p><ul><li>Link root of samller tree to root of larger tree.</li><li>Update the sz[] array.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = root(p);</span><br><span class="line">itn j = root(q);</span><br><span class="line"><span class="keyword">if</span> (i == j) <span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">if</span> (sz[i] &lt; sz[j])&#123; id[i] = j; sz[j] += sz[i]; &#125;</span><br><span class="line"><span class="keyword">else</span>&#123; id[j] = i; sz[i] += sz[j]; &#125;</span><br></pre></td></tr></table></figure><hr><p>Proposition: Depth of any node x is at most  $lg N$</p><table><thead><tr><th>algorithm</th><th>initialize</th><th>union</th><th>find</th></tr></thead><tbody><tr><td>Weighted QU</td><td>N</td><td>lg N</td><td>Lg N</td></tr></tbody></table><h4 id="Improvement-2-path-compression"><a href="#Improvement-2-path-compression" class="headerlink" title="Improvement 2: path compression"></a>Improvement 2: path compression</h4><p>Quick union with path compression: Just after computing the root of p, set the id of each examined node to point to that root.</p><p>Two-pass implementation: add second loop to root() to set the id[] of each examined node to the root.</p><p>Simpler one-pass variant: Make every other node in path point to its grandparent (thereby halving path length).</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// variant</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">root</span><span class="params">(<span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (i != id[i])</span><br><span class="line">    &#123;</span><br><span class="line">        id[i] = id[id[i]]</span><br><span class="line">            i = id[i]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Weighted QU + path compression: worst-case time is N + M lg* N</p><p>(lg * is an iterate function, plz refer to slide for more information)</p><h3 id="applications"><a href="#applications" class="headerlink" title="applications"></a>applications</h3><ul><li>Percolation</li><li>Games (Go, Hex)</li><li>Dynamic connectivity</li><li>Least common ancestor</li><li>Equivalence of finite state automata</li><li>Hoshen-Kopelman algorithm in physics</li><li>Hinley-Milner polymorphic type inference</li><li>Kruskal’s minimum spanning tree algorithm</li><li>Compiling equivalence statements in Fortran</li><li>Morphological attribute openings and closings</li><li><p>Matlab’s <code>bwlabel()</code> function in image processing</p></li><li><p>Subroutine of many other algorithms</p></li></ul><h3 id="Programming-Assignment-1"><a href="#Programming-Assignment-1" class="headerlink" title="Programming Assignment 1"></a>Programming Assignment 1</h3><p>Problem:</p><p><a href="http://coursera.cs.princeton.edu/algs4/assignments/percolation.html" target="_blank" rel="noopener">Programming Assignment 1</a></p><p>Code is on my Github page:</p><p><a href="https://github.com/Aden-Q/Percolation" target="_blank" rel="noopener">Percolation</a></p><p>Missing the optional task of running time analysis, but I don’t want to do it again because this task is somewhat discouraging for some beginners I think.</p><h2 id="Analysis-of-Algorithms"><a href="#Analysis-of-Algorithms" class="headerlink" title="Analysis of Algorithms"></a>Analysis of Algorithms</h2><h3 id="observations"><a href="#observations" class="headerlink" title="observations"></a>observations</h3><p>Analytic Engine</p><p>Reasons to analyze algorithms</p><ul><li>Predict performance</li><li>Compare algorithms</li><li>Provide guarantees</li><li>Understand theoretical basis</li></ul><p>Primary practical reason: avoid performance bugs.</p><p>Discrete Fourier transform</p><p>N-body simulation</p><p>Scientific method</p><ul><li>Observe</li><li>Hypothesize</li><li>Predict</li><li>Verify</li><li>Validate</li></ul><p>Principles</p><ul><li>Experiments must be reproducible</li><li>Hypotheses must be falsifiable</li></ul><p>3-sum problem</p><p>Standard plot on running time</p><p>Log-log scale strategy</p><p>Doubling hypothesis: run program, doubling the size of the input.</p><p>System independent effects</p><ul><li>Algorithm</li><li>Input data</li></ul><p>System dependent effects</p><ul><li>Hardware: CPU, memory, cache</li><li>Software: compiler, interpreter, garbage collector</li><li>System: operating system, network, other apps</li></ul><h3 id="mathematical-models"><a href="#mathematical-models" class="headerlink" title="mathematical models"></a>mathematical models</h3><p>Total running time: sum of cost * frequency for all operations</p><p>General concepts</p><p>1-sum problem</p><p>2-sum problem</p><p>tilde notation</p><p>Estimating a discrete sum</p><h3 id="order-of-growth-classification"><a href="#order-of-growth-classification" class="headerlink" title="order-of-growth classification"></a>order-of-growth classification</h3><p>1, log N, N, N lgN, N^2, N^3, 2^N</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0xgesix2pj30xn0m511g.jpg" style="zoom:60%"><br></center><p>Recurence</p><p>Easy concepts</p><h3 id="theory-of-algorithms"><a href="#theory-of-algorithms" class="headerlink" title="theory of algorithms"></a>theory of algorithms</h3><p>Best case: Lower bound on cost</p><ul><li>Determined by “easiest” input</li><li>Provides a goal for all inputs</li></ul><p>Worst case: Upper bound on cost</p><ul><li>Determined by “most difficult” input</li><li>Provides a way to predict performance</li></ul><p>Average case: Expected cost for random input</p><ul><li>Need a model for “random” input</li><li>Provides a way to predict performance</li></ul><p>Actual data</p><ul><li>Need to understand input to effectively process it</li><li>Approach 1: design for the worst case</li><li>Approach 2: randomize, depend on probailistic guarantee</li></ul><p>Goals</p><ul><li>Establish “difficulty” of a problem</li><li>Develop “optimal” algorithms</li></ul><p>Approach</p><ul><li>Suppress details in analyze “to within a constant factor”</li><li>Eliminate variability in input model by focusing on the worst case</li></ul><p>Algorithm design approach</p><hr><p>Start</p><ul><li>Develop an algorithm</li><li>Prove a lower bound</li></ul><p>Gap?</p><ul><li>Lower the upper bound (discover a new algorithm)</li><li>Raise the lower bound (more difficult)</li></ul><h3 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h3><p>Bit</p><p>Byte</p><p>Megabyte (MB)</p><p>Gigabyte (GB)</p><p>Old machine: We used to assume a 32-bit machine with 4 byte pointers</p><p>Modern machine: We now assume a 64-bit machine with 8 byte pointers</p><p>Typical memory usage for objects in Java</p><ul><li>Object overhead: 16 bytes</li><li>Reference: 8 bytes</li><li>Padding: Each object uses a multiple of 8 bytes</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0xhbzceq9j310l0ekwl9.jpg" style="zoom:60%"><br></center><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Stacks-and-Queues"><a href="#Stacks-and-Queues" class="headerlink" title="Stacks and Queues"></a>Stacks and Queues</h2><h3 id="stacks"><a href="#stacks" class="headerlink" title="stacks"></a>stacks</h3><h3 id="resizing-arrays"><a href="#resizing-arrays" class="headerlink" title="resizing arrays"></a>resizing arrays</h3><h3 id="queues"><a href="#queues" class="headerlink" title="queues"></a>queues</h3><h3 id="generics"><a href="#generics" class="headerlink" title="generics"></a>generics</h3><h3 id="iterators"><a href="#iterators" class="headerlink" title="iterators"></a>iterators</h3><h3 id="applications-1"><a href="#applications-1" class="headerlink" title="applications"></a>applications</h3><h2 id="Elementary-Sorts"><a href="#Elementary-Sorts" class="headerlink" title="Elementary Sorts"></a>Elementary Sorts</h2><h3 id="rules-of-the-game"><a href="#rules-of-the-game" class="headerlink" title="rules of the game"></a>rules of the game</h3><h3 id="selection-sort"><a href="#selection-sort" class="headerlink" title="selection sort"></a>selection sort</h3><h3 id="insertion-sort"><a href="#insertion-sort" class="headerlink" title="insertion sort"></a>insertion sort</h3><h3 id="shellsort"><a href="#shellsort" class="headerlink" title="shellsort"></a>shellsort</h3><h3 id="shuffling"><a href="#shuffling" class="headerlink" title="shuffling"></a>shuffling</h3><h3 id="convex-hull"><a href="#convex-hull" class="headerlink" title="convex hull"></a>convex hull</h3><h1 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5"></a>Week 5</h1><h2 id="Balanced-Search-Trees"><a href="#Balanced-Search-Trees" class="headerlink" title="Balanced Search Trees"></a>Balanced Search Trees</h2><h3 id="2-3-search-trees"><a href="#2-3-search-trees" class="headerlink" title="2-3 search trees"></a>2-3 search trees</h3><p>Allow 1 or 2 keys per node</p><ul><li>2-node: one key, two children</li><li>3-node: two keys, three children</li></ul><p>Perfect balance: Every path from root to null link has same length</p><p>Symmetric order: Inorder traversal yields keys in ascending order</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0yd3afksej30ka0bsgov.jpg" style="zoom:60%"><br></center><p>Search</p><ul><li>Compare search key against keys in node</li><li>Find interval containing search key</li><li>Follow associated link (recursively)</li></ul><p>Insert into a 2-node at bottom</p><ul><li>Search for key, as usual</li><li>Replace 2-node with 3-node</li></ul><p>Splitting a 4-node is a local transformation: constant number of operations</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0yde48g5vj30nb0gdgs4.jpg" style="zoom:60%"><br></center><p>Invariants: Maintain symmetric order and perfect balance</p><p>Pf: Each transformation maintains symmetric order and perfect balance</p><p>Tree height: Always $lg N$</p><h3 id="red-black-BSTs"><a href="#red-black-BSTs" class="headerlink" title="red-black BSTs"></a>red-black BSTs</h3><p>Left-leaning RB tree</p><p>Idea:</p><ul><li>Represent 2-3 tree as a BST</li><li>Use “internal” left-leaning links as “glue” for 3-nodes</li></ul><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g0ydp9v9ckj30sj06wmzw.jpg" style="zoom:60%"><br></center><p>A BST such that:</p><ul><li>No node has two red links connected to it</li><li>Every path from root to null link has the same number of black links</li><li>Red links lean left</li></ul><p>2-3 tree and RB BST are coresponding as following:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0ydtk0xlaj30ge0h478m.jpg" style="zoom:60%"><br></center><p>Search for red-black BST is the same as the general BST</p><p>Representation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> RED = <span class="keyword">true</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> BLACK = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    Key key;</span><br><span class="line">    Value val;</span><br><span class="line">    Node left, right;</span><br><span class="line">    <span class="keyword">boolean</span> color;<span class="comment">// color of parent link</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isRed</span><span class="params">(Node x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">return</span> x.color == RED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Left rotation: Orient a (temporarily) right-leaning red link to lean left</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">rotateLedt</span><span class="params">(Node h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isRed</span><span class="params">(h.right)</span></span>;</span><br><span class="line">    Node x = h.right;</span><br><span class="line">    h.right = x.left;</span><br><span class="line">    x.left = h;</span><br><span class="line">    x.color = h.color;</span><br><span class="line">    h.color = RED;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Invariants: Maintains symmetric order and perfect black balance</p><p>Right rotation is similar.</p><hr><p>Color flip: Recolor to split a (temporary) 4-node</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">flipColors</span><span class="params">(Node h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">assert</span> !isRed(h);</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isRed</span><span class="params">(h.left)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isRed</span><span class="params">(h.right)</span></span>;</span><br><span class="line">    h.color = RED;</span><br><span class="line">    h.left.color = Black;</span><br><span class="line">    h.right.color = Black;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Insertion in a LLRB tree</p><p>Basic strategy: Maintain 1-1 correspondence with 2-3 trees by applying elementary red-black BST operations</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0yebsxcraj30dz0esact.jpg" style="zoom:60%"><br></center><p>Warmup 1: Insert into a tree with exactly 1 node</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0yeeyme4uj30ln0av795.jpg" style="zoom:60%"><br></center><p>Warmup 2: Insert into a tree with exactly 2 nodes (3 cases)</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0yej8db99j30ue0i1qc8.jpg" style="zoom:60%"><br></center><p>Case 2: Insert into a 3-node at the bottom</p><ul><li>Do standard BST insert; color new link red</li><li>Rotate to balance the 4-node (if needed)</li><li>Flip colors to pass red link up one level</li><li>Rotate to make lean left (if needed)</li><li>Repeat case 1 or case 2 up the tree (if needed)</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0yenl6vckj30vo0d8443.jpg" style="zoom:60%"><br></center><hr><p>Java implementation</p><p>Reduce one case to another</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">put</span><span class="params">(Node h, Key key, Value val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (h == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">new</span> Node(key, val, RED);</span><br><span class="line">    <span class="keyword">int</span> cmp = key.compareTo(h.key);</span><br><span class="line">    <span class="keyword">if</span>(cmp &lt; <span class="number">0</span>) h.left = put(h.left, key, val);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(cmp &gt; <span class="number">0</span>) h.right = put(h.right, key, val);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (cmp == <span class="number">0</span>) h.val = val;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (isRed(h.right) &amp;&amp; !isRed(h.left))h = rotateLeft(h;</span><br><span class="line">    <span class="keyword">if</span> (isRed(h.left) &amp;&amp; isRed(h.left.left))h = rotateRight(h);</span><br><span class="line">    <span class="keyword">if</span> (isRed(h.left) &amp;&amp; isRed(h.right))flipColors(h);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> h;                                                              </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="B-trees-Bayer-McCreight-1972"><a href="#B-trees-Bayer-McCreight-1972" class="headerlink" title="B-trees (Bayer-McCreight, 1972)"></a>B-trees (Bayer-McCreight, 1972)</h3><p>File system model:</p><ul><li>Page: Contiguous block of data</li><li>Probe: First access to a page</li><li>Property: Time required for a probe is much larger than time to access data within a page</li><li>Cost model: Number of probes</li><li>Goal: Access data using minimum number of probes</li></ul><p>B-tree: Generalize 2-3 trees by allowing up to M-1 key-link pairs per node</p><ul><li>At least 2 key-link pairs at root</li><li>At least M/2 key-link pairs in other nodes</li><li>External nodes contain client keys</li><li>Internal nodes contain copies of keys to guide search</li></ul><p>Searching in a B-tree:</p><ul><li>Start at root</li><li>Find interval for search key and take corresponding link</li><li>Search terminates in external node</li></ul><p>Insertion in a B-tree:</p><ul><li>Search for new key</li><li>Insert at bottom</li><li>Split nodes with M key-link pairs on the way up the tree</li></ul><p>Red-black trees are widely used as system symbol tables</p><ul><li>Java: java.util.TreeMap, java.util.TreeSet</li><li>C++ STL: map, multimap, multiset</li><li>Linux kernel: completely fair scheduler, linux/rbtree.h</li><li>Emacs: conservative stack scanning</li></ul><p>B-tree variants: B+ tree, B* tree, B# tree, …</p><p>B-trees (and variants) are videly used for file systems and databases</p><ul><li>Windows: NTFS</li><li>Mac: HFS, HFS+</li><li>Linux: ReiserFS, XFS, Ext3FS, JFS</li><li>Databases: Oracle, DB2, Ingres, SQL, PostgreSQL</li></ul><h2 id="Geometric-Applications-of-BSTs"><a href="#Geometric-Applications-of-BSTs" class="headerlink" title="Geometric Applications of BSTs"></a>Geometric Applications of BSTs</h2><h3 id="1d-range-search"><a href="#1d-range-search" class="headerlink" title="1d range search"></a>1d range search</h3><h3 id="line-segment-intersection"><a href="#line-segment-intersection" class="headerlink" title="line segment intersection"></a>line segment intersection</h3><h3 id="kd-trees"><a href="#kd-trees" class="headerlink" title="kd trees"></a>kd trees</h3><h3 id="interval-search-trees"><a href="#interval-search-trees" class="headerlink" title="interval search trees"></a>interval search trees</h3><h3 id="rectangle-intersection"><a href="#rectangle-intersection" class="headerlink" title="rectangle intersection"></a>rectangle intersection</h3>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Princeton Algorithm course on coursera. Part 1&lt;/p&gt;
    
    </summary>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2019/03/02/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/03/02/卷积神经网络课堂笔记/</id>
    <published>2019-03-02T07:18:05.000Z</published>
    <updated>2019-03-02T07:18:05.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络课堂笔记"><a href="#卷积神经网络课堂笔记" class="headerlink" title="卷积神经网络课堂笔记"></a>卷积神经网络课堂笔记</h1><h2 id="课时1-1"><a href="#课时1-1" class="headerlink" title="课时1.1"></a>课时1.1</h2><p>计算机视觉</p><p>分为两个任务：</p><p>Image Classification和Object Detection</p><p>另外还有一个Neural Style Transfer</p><p>标准全连接网络连接所有输入和神经元</p><p>难以用数据的方式来解决过拟合的问题</p><h2 id="课时1-2"><a href="#课时1-2" class="headerlink" title="课时1.2"></a>课时1.2</h2><p>边缘检测实例</p><p>edge detection</p><p>filter/kernel convolve，卷积核/过滤器</p><p>用*表示卷积运算，在原图上进行element wise product，结果求和</p><p>卷积后得到的图片可以理解为另一张图片</p><p>python conv_forward函数。tensorflow tf.nn.conv2d</p><p>Keras Conv2d</p><p>后面讲了为什么卷积可以进行边缘检测</p><h2 id="课时1-3"><a href="#课时1-3" class="headerlink" title="课时1.3"></a>课时1.3</h2><p>进一步讲了边缘检测</p><p>区分正边和负边，亮到暗和暗到亮</p><p>不同的filter可以过滤出不同的边缘</p><p>有一些公认的filter：Sobel， Scharr</p><p>filter里的数字也可以learn出来，当参数训练，甚至可以识别不同的角度的edges</p><h2 id="课时1-4"><a href="#课时1-4" class="headerlink" title="课时1.4"></a>课时1.4</h2><p>Padding 划重点</p><p>一个n*n的原图，用f*f的kernel做卷积，得到的结果是(n-f+1)*(n-f+1)</p><p>不做Padding原图会缩小，因为边缘上的像素点被触碰到的概率远小于中间像素点，可能会丢失边缘信息</p><p>解决方案是在做conv前做pad</p><p>padding amout: p</p><p>让2p-f+1为0，这样conv后图像就不会缩小了</p><p>如果选择padding amount：对于Valid conv，不做padding；对于Same conv，padding到无损</p><p>在conv kernel中有一个central pixel会方便-&gt;选择奇数filter</p><h2 id="课时1-5"><a href="#课时1-5" class="headerlink" title="课时1.5"></a>课时1.5</h2><p>卷积步长 strided conv</p><p>带卷积步长时的输入输出维度关系：</p><p>n*n输入，f*f filter，padding p，stride s。得到的输出维度将会是(n+2p-f)/s+1方阵，如果商不是整数，就向下取整，这么做是限制卷积核不会移到原图之外</p><p>cross -correction 和 conv：不同领域的不同叫法</p><h2 id="课时1-6"><a href="#课时1-6" class="headerlink" title="课时1.6"></a>课时1.6</h2><p>如何在3D图像上做卷积</p><p>在RGB图像上做卷积，假设输入是6*6*3，其中三个数字分别表示height, width和channel。卷积核也是height, width和channel，channel必须匹配</p><p>这节课讲的有点慢，一点点东西讲了一整节课</p><p>Multiple filters： 把最后得到的卷积图像叠加</p><p>维度总结：n*n*channels的输入图像，f*f*channels的kernel，得到的是(n-f+1)*(n-f+1)的图像，用多个kernel，这样输出结果的通道数可以表征需要检测的特征数</p><h2 id="课时1-7"><a href="#课时1-7" class="headerlink" title="课时1.7"></a>课时1.7</h2><p>单层卷积神经网络</p><p>在卷积层实际应用的时候，也是需要增加一个偏执项</p><p>Ng在这一节2:10左右又有一个地方讲错了</p><p>和之前神经网络相似，卷积层也是先做线性运算，然后做激活</p><p>卷积层的representation：</p><p>convolutional layer</p><p>$$f^{[l]}$$表示卷积核的大小filter size</p><p>$$p^{[l]}$$表示padding</p><p>$$s^{[l]}$$表示步幅stride</p><p>$$n^{[l-1]}<em>{H} * n^{[l-1]}</em>{W} * n^{[l-1]}_{C}$$表示l-1层的高度维度，宽度维度，以及通道数，输出的通道数由filter数量来决定</p><p>别的公式就不打算写了，感觉Ng一直是在炒冷饭，一个representation讲了真TM久</p><p>在做batch或mini batch的时候把第一个维度改成number of samples，后面再和上面一样就行了</p><h2 id="课时1-8"><a href="#课时1-8" class="headerlink" title="课时1.8"></a>课时1.8</h2><p>卷积神经网络实例</p><p>深层卷积神经网络</p><p>在卷积最后输出进行flatten，平滑处理成一个列向量，然后再经过最后一层输出激活进行预测</p><p>设计神经网络的时候，设置参数比较麻烦</p><p>一个典型的深层卷积神经网络至少有三层，一个conv层，一个pool层，一个FC层(全连接)</p><h2 id="课时1-9"><a href="#课时1-9" class="headerlink" title="课时1.9"></a>课时1.9</h2><p>pooling layers</p><p>max pooling，有超参数，但是没有要学习的参数</p><p>之前卷积计算维度的公式同样适用于最大池化</p><p>average pooling</p><p>目前来说，maxpooling比average pooling更加常用</p><p>很少把padding作为超参数</p><h2 id="课时1-10"><a href="#课时1-10" class="headerlink" title="课时1.10"></a>课时1.10</h2><p>卷积神经网络实例</p><p>在文献中有两类约定：一类是把一次conv和一次pool当做一个卷积层，另外=一类则是分别计算</p><p>就是讲了一下深层卷积神经网络的整体架构，卷积，池化，全连接这些</p><p>通常高度宽度维度会逐渐减小，而通道数会逐渐增加</p><p>还有种卷积神经网络的架构是若干的卷积层加上一个池化层</p><p>Ng说如何构建高效的网络需要看别人的文献，学习他们的做法</p><h2 id="课时1-11"><a href="#课时1-11" class="headerlink" title="课时1.11"></a>课时1.11</h2><p>为什么使用卷积</p><p>想象一下一张输入图片的size如果特别大，用传统方法的话需要训练的参数矩阵就会特别大，但是用卷积的话，参数只在卷积核里面，就很小了</p><p>卷积核参数少的原因是：参数共享，即在图片的不同区域可以使用相同的参数，如果图片的不同部分有相似特征，那么用相同的特征检测器(conv kernel)来提取特征效果就比较好。另一个原因是稀疏连接：输出矩阵中呃某一个元素与原始图片的一小部分稀疏连接，其他部分对这个输出没有影响。</p><p><strong>卷积神经网络善于捕捉平移不变</strong></p><p>最后又讲了如何在实际任务中构建卷积神经网络，这TM的不是已经在上一节课里讲过了么</p><p>通过本周课程学会了整个卷积神经网络的各个基本模块</p><p>下周会讲卷积神经网路的实例，用来学习人家是怎么设置超参数和构建网络的</p><h2 id="课时2-1"><a href="#课时2-1" class="headerlink" title="课时2.1"></a>课时2.1</h2><p>一些神经网络的实例探究</p><p>LeNet-5</p><p>AlexNet</p><p>VGG</p><p>ResNet：残差网络，Residual Network</p><p>Inception Network</p><h2 id="课时2-2"><a href="#课时2-2" class="headerlink" title="课时2.2"></a>课时2.2</h2><p>经典神经网络架构：LeNet-5, AlexNet, VGGNet</p><p>LeNet-5: 识别手写数字。在那个年代，还没有padding和softmax，所以算是比较古老的一个神经网络模型。用的sigmoid激活和tanh，还没有用ReLU。这个网络比较神奇的一点是在做pooling之后还做了非线性激活</p><p>AlexNet: 用RGB图片做输入，与LeNet网络结构相似，但是AlexNet大很多，另外就是AlexNet用了ReLU作为激活函数，还有个另外的层：Local Response Normalization Layer。现在应用不多。而且研究者也发现这个层没啥用。</p><p>VGG-16: 简化了网络结构，名字里的16指示这个网络包含16个卷积层和全连接层</p><h2 id="课时2-3"><a href="#课时2-3" class="headerlink" title="课时2.3"></a>课时2.3</h2><p>残差网络</p><p>ResNets</p><p>深度神经网络是比较难训练的，因为有梯度爆炸和梯度消失的问题</p><p>这节课讲Skip Connection，通过某一层获取激活，然后马上反馈给另外一层</p><p>用跳远链接Skip Connection来训练ResNet，有时深度超度100</p><p>ResNet由残差块组成，Residual Block</p><p>残差网络的short cut</p><p>插入的残差块应该是某一层的激活值，插入到另一层的线性输出之后，激活之前</p><p>Plain Network加上Skip Connection就可以变成Residual Network</p><p>每个Skip Connection会创建一个Residual Block</p><p>对于Plain Network而言，实际上网络层数越多，训练准确率先下降后上升，与理论有差距。但是对ResNet而言，网络越深，训练准确率就越低</p><h2 id="课时2-4"><a href="#课时2-4" class="headerlink" title="课时2.4"></a>课时2.4</h2><p>为什么ResNet表现这么好？</p><p>$$a^{[l+2]} = g(z^{[l+2]}+a^{[l]})$$</p><p>残差跳远连接的好处是如果中间的神经元失活了，通过残差仍然可以将前层的激活值传递下去</p><p>残差快学习恒等式是很容易的</p><p>有一个key point是残差跳远连接的输入维度应该保持一致，这也成为限制卷积层构造的原因之一。如果维度不一致，那么在构造残差块的时候还需要再引入一个矩阵</p><h2 id="课时2-5"><a href="#课时2-5" class="headerlink" title="课时2.5"></a>课时2.5</h2><p>1*1的卷积层</p><p>网络中的网络</p><p>1*1的卷积网络在深度channel输入上有用：比如1*1*32的filter对原输入上同一个位置但不同通道的数据进行element wise product，这样的一个卷积层可以理解为一次全连接</p><p>举个例子讲，如何把一个28*28*192的输入shrink成一个28*28*32的输出？</p><p>可以用32个filter，每个filter都是1*1*192的，相当于每个filter在原输入上做全连接，然后把所有的filter进行堆叠，就得到了32个通道的输出了。理解1*1卷积只是增加了非线性函数激活，允许网络学习更复杂的特征</p><h2 id="课时2-6"><a href="#课时2-6" class="headerlink" title="课时2.6"></a>课时2.6</h2><p>Inception Network</p><p>代替人工来决定是否要加某些层</p><p>用1*1卷积核可以减小计算成本</p><p>使用1*1卷积核的策略是把原来的输入先压缩，完成压缩操作的层叫做bottleneck layer</p><p>大幅缩小数据规模是否会影响网络的性能？如果bottlenect layer选择合适就不会出现这个问题</p><h2 id="课时2-7"><a href="#课时2-7" class="headerlink" title="课时2.7"></a>课时2.7</h2><p>完整的Inception Network的结构</p><p>把输入经过各个层处理，然后最后做Channel Concat进行堆叠</p><p>GoogLeNet</p><p>Inception名字来源于盗梦空间和小李子。。。</p><h2 id="课时2-8"><a href="#课时2-8" class="headerlink" title="课时2.8"></a>课时2.8</h2><p>使用开源代码</p><p>通过阅读他人论文来复现是非常非常难的</p><p>这节课就教了一下怎么用Google找到开源代码和下载</p><h2 id="课时2-9"><a href="#课时2-9" class="headerlink" title="课时2.9"></a>课时2.9</h2><p>迁移学习Transfer Learning</p><p>在别人训练好的网络权重的基础上再进行训练，这样效率会高很多</p><p>计算机视觉数据集：ImageNet，MS COCO，Pascal</p><p>Transfer选择把输出层的激活改成自己的激活函数，冻结网络层的前层参数</p><p>另一个加速训练的策略是把固定的前层封装成一个函数，将输入映射到固定层的最后一层，然后保存起来，这样就不用每次都计算固定的值了</p><p>计算机视觉是经常用到transfer learning的一个领域</p><h2 id="课时2-10"><a href="#课时2-10" class="headerlink" title="课时2.10"></a>课时2.10</h2><p>数据扩充，数据增强，data augmentation</p><p>对计算机视觉领域而言，最大的一个问题就是缺少训练数据</p><p>数据增强的常用方法有：垂直镜像对称，随机裁剪，旋转rotation，剪切shearing，色彩转换color shifting(在通道上加减值)，实际应用中颜色转换是根据某种概率分布来做的</p><p>对RGB有不同的采样方式，一种是PCA主成分分析，PCA颜色增强。在AlexNet论文里有实现PCA的方法</p><p>实现数据增强：用一个CPU线程或多个CPU线程加载数据和实现distortion，然后传递给其他线程</p><h2 id="课时2-11"><a href="#课时2-11" class="headerlink" title="课时2.11"></a>课时2.11</h2><p>计算机视觉研究现状</p><p>如果没有足够多的数据就要做hand-engineering</p><p>另一种解决数据量小的问题的技术是Transfer Learing，也就是上一节课里讲到的</p><p>后面讲了实际工业领域的几个tricks</p><h2 id="课时3-1"><a href="#课时3-1" class="headerlink" title="课时3.1"></a>课时3.1</h2><p>Object localization目标定位</p><p>先有图像分类，然后有classification with localization，再有detection</p><p>Classification：bounding box，红框中心点(bx, by), bh, bw，训练集还需要上面的数据</p><p>输出标签包含多种信息：是否属于要检测的目标，输出要检测目标的bx, by, bh, bw, c1, c2, c3，表示输出哪一类，这个的话输出层就不只是一个神经元了，不同的神经元可以用不同的激活函数，计算不同的损失</p><h2 id="课时3-2"><a href="#课时3-2" class="headerlink" title="课时3.2"></a>课时3.2</h2><p>landmark detection</p><p>特征点检测</p><p>比如要检测眼角，可以在输出层加两个entry，来表征眼角信息</p><p>检测关键点也是计算机图形模块的一个重要部分，比如脸部扭曲等</p><h2 id="课时3-3"><a href="#课时3-3" class="headerlink" title="课时3.3"></a>课时3.3</h2><p>Object detection</p><p>对象检测</p><p>示例是基于滑动窗口的目标检测算法，sliding windows detection</p><p>滑动窗口算法缺点是计算cost，与stride有关系，又是一个trade off</p><p>这个想法好天真啊，我也是醉了，难道这就是目标检测吗</p><h2 id="课时3-4"><a href="#课时3-4" class="headerlink" title="课时3.4"></a>课时3.4</h2><p>卷积的滑动窗口实现</p><p>把FC层转成Conv层，想法也比较简单，就是用很多个filters去conv就行了</p><p>讲义内容借鉴了OverFeat论文</p><p>可以发现滑动窗口中有很多计算是重复的</p><p>trick就是在跑conv的时候实际不是把裁剪下来的输入，而是把整个都输入，然后分部分标记。在整张输入图片上做卷积，然后对输出进行滑动裁剪就行了</p><p>这个卷积滑动窗口的缺点是可能bounding box不太准确</p><h2 id="课时3-5"><a href="#课时3-5" class="headerlink" title="课时3.5"></a>课时3.5</h2><p> Bounding  Box预测</p><p> YOLO算法的思想大概是把输入图像分割成一个个的grid，然后再每个grid跑图像识别的算法，判断一个物体是否属于这个格子，看的是这个物体的中心点是否在这个格子里面，实际用的时候会用19*19\这样的精细划分</p><p>如何编码边界坐标？</p><h2 id="课时3-6"><a href="#课时3-6" class="headerlink" title="课时3.6"></a>课时3.6</h2><p>抑制交并比intersection over union</p><p>IoU交并比函数是个评价函数，计算交集和并集之比，一般约定，如果IoU大于0.5，那么预测正确，当然阈值是可以人为设定的</p><h2 id="课时3-7"><a href="#课时3-7" class="headerlink" title="课时3.7"></a>课时3.7</h2><p>非最大值抑制 Non-max suppression</p><p>可以确保每个对象只识别一次</p><p>先丢弃所有低概率边框预测结果</p><p>然后跑一个while，每次选出最高概率的box预测，丢弃所有和这个box有高IoU值的预测结果</p><h2 id="课时3-8"><a href="#课时3-8" class="headerlink" title="课时3.8"></a>课时3.8</h2><p>Anchor box</p><p>让一个格子检测出多个对象</p><p>思想是预先定义几个不同shape的Anchor boxes</p><p>输出y的值由这几个Anchor boxes分别的预测结果堆叠</p><h2 id="课时3-9"><a href="#课时3-9" class="headerlink" title="课时3.9"></a>课时3.9</h2><p>YOLO network</p><p>把之前几节课讲的综合起来放到一个网络来实现</p><h2 id="课时3-10"><a href="#课时3-10" class="headerlink" title="课时3.10"></a>课时3.10</h2><p>RPN网络，区域生成网络</p><p>R-CNN：区域卷积网络，在少数窗口上跑CNN来做预测，找窗口的方法是用图像分割的技巧，segmentation，R-CNN的问题是太慢了，F-R-CNN是用卷积实现滑动窗口，也就是在之前的情况下做了一点点优化，还是不如YOLO，just for fun</p><h2 id="课时4-1"><a href="#课时4-1" class="headerlink" title="课时4.1"></a>课时4.1</h2><p>什么是人脸识别</p><p>face recognition</p><p>百度Andrew Ng，林元庆哈哈哈哈</p><p>人脸识别和活体检测配合使用</p><p>face verification是验证是否匹配，是一对一的问题，face recognition是一对多的问题，比验证问题难很多</p><h2 id="课时4-2"><a href="#课时4-2" class="headerlink" title="课时4.2"></a>课时4.2</h2><p>One-shot learning problem: 只有一个训练样例</p><p>学习一个似然函数Similarity function，一个差异函数d，拿到两张图片后用这个差异函数去比对输入</p><h2 id="课时4-3"><a href="#课时4-3" class="headerlink" title="课时4.3"></a>课时4.3</h2><p>Siamese network</p><p>是一个编码网络，当两张图片是同一个人的时候，编码相似度要很大，对应的范数小</p><h2 id="课时4-4"><a href="#课时4-4" class="headerlink" title="课时4.4"></a>课时4.4</h2><p>triplet loss function</p><p>引入一个margin防止恒等于0的输出，margin parameter：拉大了正样本和负样本之间的距离</p><p>引入损失函数为范数差的形式</p><p>将训练样本以三元组的形式进行分组，需要有同一个人的很多图片</p><p>选择训练样本的原则是使两个范数尽可能相似，这样的数据才有训练意义(学难学的东西才能有成长)</p><h2 id="课时4-5"><a href="#课时4-5" class="headerlink" title="课时4.5"></a>课时4.5</h2><p>面部验证和二分类</p><p>想法比较简单，感觉这节课就没啥东西</p><h2 id="课时4-6"><a href="#课时4-6" class="headerlink" title="课时4.6"></a>课时4.6</h2><p>神经风格迁移(编程作业里面)</p><p>neural style transfer</p><p>C表示图像内容，S表示图像风格，G表示生成的图像</p><h2 id="课时4-7"><a href="#课时4-7" class="headerlink" title="课时4.7"></a>课时4.7</h2><p>深度神经网络到底在学什么</p><p>找到最大化激活隐藏单元的图片块</p><h2 id="课时4-8"><a href="#课时4-8" class="headerlink" title="课时4.8"></a>课时4.8</h2><p>代价函数</p><p>评价函数用于评价生成的图像的好坏</p><p>代价函数可以分为内容代价和风格代价</p><p>内容代价用来度量生成图像的内容和原来图像的内容有多相似，风格同理</p><p>提出神经风格迁移的作者提出用两个超参数</p><p>在做梯度下降的时候更新的实际上是图像的像素值</p><p>随机初始化的图像时白噪声图像</p><h2 id="课时4-9"><a href="#课时4-9" class="headerlink" title="课时4.9"></a>课时4.9</h2><p>内容代价函数</p><p>content cost component</p><h2 id="课时4-10"><a href="#课时4-10" class="headerlink" title="课时4.10"></a>课时4.10</h2><p>风格损失函数style cost function</p><p>把图像的style定义为不同通道之间的互相关系</p><p>什么时候两个通道之间有高度互相关性呢？correlation，不同块之间的激活特征高度重合，那么是高度correlated，否则不然</p><p>style matrix风格矩阵</p><p>Frobenius范数</p><h2 id="课时4-11"><a href="#课时4-11" class="headerlink" title="课时4.11"></a>课时4.11</h2><p>一维和三维的卷积</p><p>心电图处理的是一维数据，时间序列</p><p>一维的卷积思想比较简单</p><p>CT：3D数据块</p><p>3D volume，3D filter</p><p>完结了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;卷积神经网络课堂笔记&quot;&gt;&lt;a href=&quot;#卷积神经网络课堂笔记&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络课堂笔记&quot;&gt;&lt;/a&gt;卷积神经网络课堂笔记&lt;/h1&gt;&lt;h2 id=&quot;课时1-1&quot;&gt;&lt;a href=&quot;#课时1-1&quot; class=&quot;he
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Mac删除launchpad中无法正常删除的图标</title>
    <link href="http://yoursite.com/2018/11/24/Mac%E5%88%A0%E9%99%A4launchpad%E4%B8%AD%E6%97%A0%E6%B3%95%E6%AD%A3%E5%B8%B8%E5%88%A0%E9%99%A4%E7%9A%84%E5%9B%BE%E6%A0%87/"/>
    <id>http://yoursite.com/2018/11/24/Mac删除launchpad中无法正常删除的图标/</id>
    <published>2018-11-25T00:51:38.000Z</published>
    <updated>2019-03-08T20:18:08.321Z</updated>
    
    <content type="html"><![CDATA[<p>如何删除launchpad里一些无法正常删除的程序图标</p><a id="more"></a><p>一般launchpad里面应用可以通过两种方式删除：</p><ol><li>用访达，在用户家目录的应用程序目录下找到对应的程序，直接删除即可。</li><li>直接进launchpad，按住option，点按应用，选择”x”删除即可。</li></ol><p>但有些<strong>第三方应用</strong>无法用这两种方式删除，具体来说，有些应用不会出现在应用程序目录下，但却留在launchpad里面，还删不掉，超级恶心，已经两次碰到过这个问题了，就介绍一下删除这些应用的方法，以防日后的不测。</p><p>launchpad这个东西设计比较辣鸡，有很多bug，但总的来说找应用还算方便，但有了Alfrad，就不怎么打开launchpad了。有时候在总可能因为一些奇怪的操作，把一些应用或者文档弄到了launchpad里面，删不掉。出于强迫症，还是想让他变得干干净净的。</p><h2 id="第一步，找到com-apple-dock-launchpad文件夹"><a href="#第一步，找到com-apple-dock-launchpad文件夹" class="headerlink" title="第一步，找到com.apple.dock.launchpad文件夹"></a>第一步，找到com.apple.dock.launchpad文件夹</h2><p>打开访达，按command+shift+G，在地址栏输入/private/var/folders，如下图所示：</p><p><img src="http://118.25.111.76:8360/static/upload/20180724/MmEhQZaFQjDbZ4apiakCz1XL.png" alt="![alt](http://118.25.111.76:8360/static/upload/20180724/0lSjihPw9yxi4Se9QoXxaLZD.png)"></p><p>然后再folders目录下找到一个名字为com.apple.dock.launchpad的文件夹，我的是在./6l/…/0/目录下。</p><h2 id="获取数据库路径"><a href="#获取数据库路径" class="headerlink" title="获取数据库路径"></a>获取数据库路径</h2><p>在这个文件夹下面继续走，找到名字为db的文件，它就是我们想要修改的数据库，右键这个文件，获取它的路径，如下图所示：</p><p><img src="http://118.25.111.76:8360/static/upload/20180724/lGL2p11bdtjT1ki5hRt3uUf_.png" alt="alt"></p><p>右键-&gt;显示简介</p><p>然后把路径复制下来</p><h2 id="操作数据库"><a href="#操作数据库" class="headerlink" title="操作数据库"></a>操作数据库</h2><p>获取数据库路径之后，打开终端，进入到上面的路径，如下图所示：</p><p><img src="http://118.25.111.76:8360/static/upload/20180724/Q6lD7sGQIsL4UTvgIZvnNBdf.png" alt="alt"></p><p>按照下面的格式输入命令删除第三方应用(或文档)即可<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sqlite3 db &quot;delete from apps where title=&apos;应用名称&apos;;&quot;&amp;&amp;killall Dock</span><br></pre></td></tr></table></figure></p><p>然后就可以把这些应用都删掉了</p><p>这里有几点要注意一下：</p><ol><li>每次删除应用会重启一次dock，屏幕会黑一下，但马上就会好，不用担心。</li><li>直接操作数据库比较危险，因此应用名称记得一定要输准确，名字输错(输了一个不存在的应用程序)，可能会把文件夹都展开。</li></ol><p>另外再说一点，launchpad还有个bug就是有时候会出现空的文件夹，这些空文件夹也不能用正常手段删除，一个简便可行的方法是把一个应用拖进这个文件夹，然后再拖出来，这个空文件夹就会自动消失。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;如何删除launchpad里一些无法正常删除的程序图标&lt;/p&gt;
    
    </summary>
    
    
      <category term="Mac" scheme="http://yoursite.com/tags/Mac/"/>
    
  </entry>
  
  <entry>
    <title>Java笔记</title>
    <link href="http://yoursite.com/2018/11/24/Java%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/11/24/Java笔记/</id>
    <published>2018-11-25T00:46:57.000Z</published>
    <updated>2019-03-08T20:14:20.954Z</updated>
    
    <content type="html"><![CDATA[<p>参考菜鸟教程、实验楼、ZJU翁凯MOOC然后做的一些比较入门级的笔记</p><a id="more"></a><p>javac命令后面跟的是java文件的文件名，例如HelloWorld.java。该命令用于将.java源文件编译为class字节码文件，如：javac HelloWorld.java</p><p>运行javac命令后，如果成功编译没有错误的话，会出现一个HelloWorld.class的文件</p><p>java后面跟的是java文件中的类名字，例如HelloWorld就是类名，如：java HelloWorld</p><p>java命令后面不要加.class</p><p>java分为三个体系：</p><p>JavaSE：平台标准版</p><p>JavaEE：平台企业版</p><p>JavaME：平台微型版</p><p>java程序员不需要管内存管理，支持类之间的单继承和接口之间的多继承。支持动态绑定</p><p>可移植性强，是解释型的，Java程序在Java平台上被编译为字节码格式，然后可以在实现这个Java平台的任何系统中运行，Java平台的解释器对这些字节码进行解释执行，执行中需要的类再联结阶段被载入到运行环境中。</p><p>高性能，接近于C++。是多线程的，提供多线程之间的同步机制，关键字synchronized</p><h2 id="基础语法"><a href="#基础语法" class="headerlink" title="基础语法"></a>基础语法</h2><p>对象：对象是类的一个实例，有状态和行为。</p><p>类：类是一个模板，它描述一类对象的行为和状态。</p><p>方法：方法就是行为，一个类可以有很多方法。逻辑运算、数据修改以及所有动作都是在方法中完成的。</p><p>实例变量：每个对象都有独特的实例变量，对象的状态由这些实例变量的值决定。即实例变量是属于对象的。</p><p>注意事项：</p><p>大小写敏感，Hello和hello是不同的。</p><p>类名：</p><p>对于所有的类来说，类名的首字母应该大写。如果类由若干单词组成，那么每个单词的首字母应该大写，例如MyFirstClass。</p><p>方法名：</p><p>所有方法名应该以小写字母开头。如果方法名含有若干单词，则后面的每个单词首字母大写。</p><p>源文件名：</p><p>源文件名必须和类名相同。当保存文件的时候，应该使用类名作为文件名保存，文件后缀名必须为.java（如果文件名和类名不同会导致编译错误）。</p><p>主方法入口：</p><p>所有的java程序由public static void main(String []args)方法开始执行</p><p>Java标识符：不能是关键字</p><p>修饰符：分两类：</p><p>访问控制修饰符：default，public，protected，private</p><p>非访问控制修饰符：final，abstract，strictfp</p><p>变量：局部变量、类变量（静态变量）、成员变量（非静态变量）</p><p>数组：数组是储存在堆上的对象，可以保存多个同类型变量。</p><p>枚举：enum FreshJuiceSize{SMALL, MEDIUM, LARGE}</p><p>用.访问运算符访问枚举成员</p><p>利用继承的方法可以重用已存在的类的属性和方法，而不用重写这些代码。被继承的类称为超类（super class），派生类称为子类（subclass）</p><p>接口：可以理解为对象间相互通信的协议。接口在继承中很重要</p><p>接口只定义派生要用到的方法，方法的具体实现还是取决于派生类</p><p>支持的面向对象特性：多态，继承，封装，抽象，类，对象，实例，方法，重载</p><p>一个类可以包含局部变量（在方法，构造方法或者语句块中定义的变量，方法结束后自动销毁），成员变量（定义在类中，方法体之外，在创建对象的时候实例化，成员变量可以被类中的方法、构造方法和特定类的语句块访问）类变量（声明在类中，方法体之外，必须声明为static类型）</p><p>构造方法：每个类都有构造方法，如果没有显式指定，Java编译器会为该类提供一个默认构造方法。在创建对象时，至少要调用一个构造方法，构造方法的名称必须与类同名，一个类可以有多个构造方法（可以在一个构造方法里滴啊用另一个构造方法）</p><p>创建对象：三步：</p><p>声明：声明一个对象，包括对象名称和对象类型</p><p>实例化：用关键字new创建一个对象</p><p>初始化：使用new创建对象时，会调用构造方法初始化对象</p><p>访问实例变量可以用.运算符或者调用类中的方法</p><h3 id="源文件声明规则"><a href="#源文件声明规则" class="headerlink" title="源文件声明规则"></a>源文件声明规则</h3><p>一个源文件只能有一个public类</p><p>一个源文件可以有多个非public类</p><p>源文件的名称应该和public类的类名保持一致。</p><p>如果一个类定义在某个包中，那么package应该在源文件首行</p><p>如果源文件有import语句，应该放在package语句和类定义之前。如果没有package语句，那么import语句应该在源文件中最前面。import语句和package语句对源文件中定义的所有类都有效。在同一源文件中，不能给不同的类不同的包声明。</p><p>包：包主要用来对类和接口分类</p><p>import语句提供一个合理路径，使得编译器可以找到某个类</p><h3 id="Java数据类型"><a href="#Java数据类型" class="headerlink" title="Java数据类型"></a>Java数据类型</h3><p>两大数据类型：内置数据类型和引用数据类型</p><p>八种基本类型</p><p>byte类型8位，主要用来替代int</p><p>char类型是一个单一的16位Unicode字符，最小\u0000(即0)，最大值是\uffff(即65535)</p><p>引用类型：</p><p>类似于指针，指向一个对象，指向对象的变量是引用变量，在声明时被指定为一个特定类型。默认值null</p><p>boolean类型不支持类型转换</p><p>强制类型转换，自动类型转换</p><h3 id="Java变量类型"><a href="#Java变量类型" class="headerlink" title="Java变量类型"></a>Java变量类型</h3><p>在Java语言中，所有变量在使用前必须声明。</p><p>Java支持的变量类型有：</p><p>类变量：独立于方法之外的变量，用static修饰</p><p>实例变量：独立于方法之外的变量，没有static修饰</p><p>局部变量：类的方法中的变量</p><h4 id="Java局部变量"><a href="#Java局部变量" class="headerlink" title="Java局部变量"></a>Java局部变量</h4><p>局部变量声明再方法、构造方法或者语句块中。</p><p>局部变量在方法、构造方法或者语句块被执行时候创建，当它们执行完后，变量会自动销毁。</p><p><strong>访问修饰符不能用于修饰局部变量。</strong></p><p>局部变量只在声明它的方法、构造方法或语句块中可见。</p><p>局部变量是在栈上分配的。</p><p>局部变量没有默认值，所以局部变量被声明后，它的作用域就限制在这个方法中。</p><h4 id="Java实例变量"><a href="#Java实例变量" class="headerlink" title="Java实例变量"></a>Java实例变量</h4><p>实例变量声明在一个类中，但在方法、构造方法和语句块之外。</p><p>当一个对象被实例化之后，每个实例变量的值就跟着被确定。</p><p>实例变量在对象被创建的时候创建，在对象被销毁的时候销毁。</p><p>实例变量的值至少被一个方法、构造方法或者语句块引用，使得外部能够通过这些方式获取实例变量信息。</p><p>实例变量可以声明在使用前或者使用后，这是因为在创建对象的时候总是会先去初始化那些实例变量。</p><p>访问修饰符可以修饰实例变量。</p><p>实例变量对于类中的方法、构造方法或者语句块是可见的。一般情况下应该把实例变量设为私有，是封装的基本理念。可以通过访问修饰符使实例变量对子类可见。</p><p>实例变量具有默认值。数值型变量的默认值是0，布尔型变量的默认值是false，引用型变量的默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定。</p><p>在静态方法或者其他类中要访问实例变量需要用完全限定名。</p><h4 id="Java类变量"><a href="#Java类变量" class="headerlink" title="Java类变量"></a>Java类变量</h4><p>类变量也称为静态变量，在类中用static关键字声明，但必须在构造方法和语句块之外。</p><p>无论一个类创建了多少个对象，类只拥有类变量一份拷贝。</p><p>静态变量除了被声明为常量外很少使用。常量是指声明为public/private，final和static类型的变量。常量初始化后不可改变。</p><p>静态变量储存在静态存储区。<strong>经常被声明为常量，很少单独使用static声明变量。</strong></p><p>静态变量在第一次被访问时创建，在程序结束时销毁。</p><p>与实例变量具有相似的可见性。但为了对类的使用者可见，<strong>大多数静态变量声明为public类型。</strong></p><p>默认值和实例变量相似。数值型变量默认值是0，布尔型默认值是false，引用类型默认值是null。变量的值可以在声明时指定，也可以在构造方法中指定。也可以在静态语句块中初始化。</p><p>静态变量通过ClassName.VariableName的方式访问。</p><p>类变量被声明为public static final类型时，类变量名称一般建议使用大写字母。</p><h3 id="Java修饰符"><a href="#Java修饰符" class="headerlink" title="Java修饰符"></a>Java修饰符</h3><p>Java语言的修饰符主要分为：</p><p>1、访问修饰符</p><p>2、非访问修饰符</p><p>Java支持4种不同的访问权限</p><p>default（缺省）：在同一包内可见，不使用任何修饰符。使用对象：类、接口、变量、方法。</p><p>private：在同一类内可见。使用对象：变量、方法。不能修饰类</p><p>public：对所有类可见。使用对象：类、接口、变量、方法</p><p>protected：对同一包内的类和所有子类可见。使用对象：变量、方法。不能修饰类</p><p>final方法：final方法可以被子类继承，但是不能被子类修改。</p><p>声明final方法的主要目的是防止该方法的内容被修改。</p><p>final类：不能被继承</p><p>abstract：抽象类，类似于接口类，声明抽象类的唯一目的是将来对该类进行扩充。抽象方法，是一种没有任何实现的方法，该方法的实现由子类提供。抽象方法不能被声明为final和static。任何继承抽象类的子类必须实现父类的所有抽象方法，除非该子类也是抽象类，这个就类似于C++中的纯虚函数了。也即抽象类中的抽象方法在抽象类中只需要提供声明，不需要提供实现，而需要在继承它的子类中实现对应的抽象方法。</p><p>synchronized修饰符：</p><p>这个关键字声明的方法同一时间只能被一个线程访问。</p><h3 id="Java运算符"><a href="#Java运算符" class="headerlink" title="Java运算符"></a>Java运算符</h3><p>大的可以分为：算术运算符，关系运算符，位运算符，逻辑运算符，赋值运算符，其他运算符。</p><p>?:条件运算符，三元运算符。其他没什么好说的</p><p>instanceof运算符：用于操作对象实例，检查对象是否是一个特定类型（类类型或接口类型）</p><h3 id="循环控制"><a href="#循环控制" class="headerlink" title="循环控制"></a>循环控制</h3><p>只说新出现的：</p><p>Java增强for循环：</p><p>Java5引入了一种主要用于数组的增强型for循环。</p><p>格式如下：</p><p>for(声明语句:表达式)</p><p>{</p><pre><code>//代码句子</code></pre><p>}</p><p>声明语句：声明新的局部变量，变量类型必须和数组元素的类型匹配。作用域限定在循环语句块。</p><p>表达式：要访问的数组名，或者返回值为数组的方法。</p><p>break关键字：</p><p>主要用在循环语句或者switch语句中，用来跳出整个语句块。</p><p>continue关键字：</p><p>不说了</p><h3 id="包裹类型：封包和解包"><a href="#包裹类型：封包和解包" class="headerlink" title="包裹类型：封包和解包"></a>包裹类型：封包和解包</h3><p>以Character为例</p><p>Character：是char的包裹类型，处理char型对象，方法有：</p><p>1、isLetter()：判断是否是一个字母</p><p>2、isDigit()：判断是否是一个数字字符</p><p>3、isWhitespace()：判断是否是一个空格</p><p>4、isUpperCase()：判断是否是大写字母</p><p>5、isLowerCase()：判断是否是小写字母</p><p>6、toUpperCase()：指定字母的大写形式</p><p>7、toLowerCase()：指定字母的小写形式</p><p>8、toString()：返回字符的字符串形式，字符串的长度仅为1</p><h3 id="Java-String类"><a href="#Java-String类" class="headerlink" title="Java String类"></a>Java String类</h3><p>在Java中字符串属于对象，Java提供了String类来创建和操作字符串</p><p>创建字符串：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String greeting = <span class="string">"cainiao"</span>;</span><br></pre></td></tr></table></figure><p>在代码中遇到字符串常量时，编译器会使用该值创建一个String对象，可以使用关键字和构造方法来创建String对象。</p><p>String类不可修改</p><p>用于获取有关对象的信息的方法称为<strong>访问器方法</strong>。</p><p>String类的一个访问器方法是length()方法，返回字符串对象包含的字符数</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String site = <span class="string">"www.runoob.com"</span>;</span><br><span class="line"><span class="keyword">int</span> len = site.length();</span><br></pre></td></tr></table></figure><p>连接字符串：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">string1.concat(string2);</span><br></pre></td></tr></table></figure><p>返回string2连接string1的新字符串。也可以对字符串常量使用concat()方法。如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"我的名字是"</span>.concat(<span class="string">"Runoob"</span>);</span><br></pre></td></tr></table></figure><p>更常用的是用’+’运算符来连接字符串：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"Hello,"</span> + <span class="string">" runoob"</span> + <span class="string">"!"</span>;</span><br></pre></td></tr></table></figure><p>创建格式化字符串：</p><p>使用静态方法format()可以生成格式化字符串</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String fs;</span><br><span class="line">fs = String.format(<span class="string">"sdfasdfasdf"</span>);<span class="comment">//因为是静态方法，直接用类名调用即可</span></span><br></pre></td></tr></table></figure><p>String方法：</p><p>1、chaAt():返回指定索引处的char值</p><p>2、compateTo():把这个字符串和另一个对象或者字符串比较，按字典序</p><p>3、concat():连接字符串</p><p>4、equals():将此字符串与指定的对象比较</p><p>5、length():返回此字符串的长度</p><p>6、toLowerCase():小写化</p><p>7、toUpperCase():大写化</p><p>8、trim():返回字符串的副本，忽略前导空白和尾部空白</p><p>其实java这些类很多方法和python十分类似，学习成本不高</p><h3 id="StringBuffer和StringBuilder类"><a href="#StringBuffer和StringBuilder类" class="headerlink" title="StringBuffer和StringBuilder类"></a>StringBuffer和StringBuilder类</h3><p>当对字符串进行修改的时候，需要使用StringBuffer和StringBuilder类</p><p>和String类不同，StringBuffer和StringBuilder类的对象能被多次修改，并且不产生新的未使用对象</p><p>StringBuilder不是线程安全的，不能同步访问，但是StringBuilder相较于StringBuffer有速度优势，所以多数情况下建议使用StringBuilder类。但在应用程序要求线程安全的情况下，必须使用StringBuilder类。这个类的方法如下：</p><p>Append：将指定的字符串追加到此字符序列</p><p>reverse：将此字符串序列用反转形式取代</p><p>delete：移除此序列的字符串中的字符，原型为public delete(int start, int end)</p><p>Insert：将int参数的字符串表示形式插入序列中，原型为public insert(int offset, in i)</p><p>replace：用String字符串替换此序列的子字符串中的字符，原型为replace(int start, int end, String str)</p><p>Capacity：返回当前容量</p><p>charAt：获取此序列指定索引处的char值</p><p>indexOf：返回第一次出现的指定字符串在该字符串中的索引，有两种重构，indexOf(str)和indexOf(String str, int fromIndex)。第一种从头开始找，第二种从指定索引出开始找，返回第一次出现的指定子字符串在该字符串中的索引</p><p>length：返回长度</p><p>toString：返回序列中数据的字符串表示形式</p><h3 id="Java数组"><a href="#Java数组" class="headerlink" title="Java数组"></a>Java数组</h3><p>Java语言提供的数组是用来存储固定大小的同类型元素</p><p>声明数组变量：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">dataType[] arrayRefVar;<span class="comment">//首选方法</span></span><br><span class="line">dataType arrayReVar[]<span class="comment">//效果相同，但不是首选</span></span><br></pre></td></tr></table></figure><p>后面一种风格是C/C++风格，Java程序员建议使用第一种风格</p><p>创建数组：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">arrayReVar = <span class="keyword">new</span> dataType[arraySize];</span><br></pre></td></tr></table></figure><p>上面语法语句做了两件事：</p><ol><li>用dataType[arraySize]创建了一个数组</li><li>把新创建的<strong>数组的引用</strong>赋值给变量arrayReVar（Java对象变量是引用）</li></ol><p>当然数组声明和创建可以用一条语句来完成：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataType[] arrayReVar = <span class="keyword">new</span> dataType[arraySize];</span><br></pre></td></tr></table></figure><p>也可以直接初始化：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataType[] arrayRefVar = &#123;value0, value1, ..., valuek&#125;;</span><br></pre></td></tr></table></figure><p>数组的元素是通过引用访问的。索引从0开始，一直到arrayRefVar.length-1</p><p>处理数组：</p><p>通常使用基本循环或者foreach循环（也成为增强型for循环，之前提到过，也能从目录直接导引过去，是从JDK 1.5开始引进的）</p><p>增强型for循环的优点在于可以不使用下标的情况下遍历数组</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestArray</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        <span class="keyword">double</span>[] myList = &#123;<span class="number">1.9</span>, <span class="number">2.9</span>, <span class="number">3.4</span>, <span class="number">3.5</span>&#125;;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//打印所有元素</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">double</span> element:myList)&#123;</span><br><span class="line">            System.out.println(element);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>输出结果为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1.9</span></span><br><span class="line"><span class="number">2.9</span></span><br><span class="line"><span class="number">3.4</span></span><br><span class="line"><span class="number">3.5</span></span><br></pre></td></tr></table></figure><p>数组作为函数参数（传引用）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">printArray</span><span class="params">(<span class="keyword">int</span>[] array)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; array.length; i++)&#123;</span><br><span class="line">        System.out.print(array[i] + <span class="string">" "</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">//调用</span></span><br><span class="line">printArray(<span class="keyword">new</span> <span class="keyword">int</span>[]&#123;<span class="number">3</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">4</span>, <span class="number">2</span>&#125;);</span><br></pre></td></tr></table></figure><p>数组作为函数返回值：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span>[] reverse(<span class="keyword">int</span>[] list)&#123;</span><br><span class="line">    <span class="keyword">int</span>[] result = <span class="keyword">new</span> <span class="keyword">int</span>[list.length];</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i = <span class="number">0</span>, j = result.length - <span class="number">1</span>; i &lt; list.length; i++, j--)</span><br><span class="line">        result[j] = list[i];</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//result数组作为函数的返回值</span></span><br></pre></td></tr></table></figure><p>多维数组（数组的数组）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">String str[][] = <span class="keyword">new</span> String[<span class="number">3</span>][<span class="number">4</span>];<span class="comment">//二维数组是一个特殊的一维数组，每一个元素都是一维数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//分配空间</span></span><br><span class="line">type arrayName = <span class="keyword">new</span> type[arraylength1][arraylength2];</span><br><span class="line"><span class="keyword">int</span> a[][] = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">2</span>][<span class="number">3</span>];</span><br><span class="line"></span><br><span class="line"><span class="comment">//引用</span></span><br><span class="line">num[<span class="number">1</span>][<span class="number">0</span>];</span><br></pre></td></tr></table></figure><h4 id="Arrays类"><a href="#Arrays类" class="headerlink" title="Arrays类"></a>Arrays类</h4><p>java.util.Arrays类能方便操作数组，它提供的方法都是静态的</p><p>功能有：</p><ul><li>给数组赋值：通过fill方法</li><li>对数组排序：通过sort方法，按升序</li><li>比较数组：通过equals方法比较数组中元素值是否相等</li><li>查找数组元素：通过binarySearch方法能对排序好的数组进行二分查找法操作</li></ul><p>函数原型：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">binarySearch</span><span class="params">(Object[] a, Object key)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(<span class="keyword">long</span>[] a, <span class="keyword">long</span>[] a2)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">fill</span><span class="params">(<span class="keyword">int</span>[] a, <span class="keyword">int</span> val)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Object[] a)</span></span>;</span><br></pre></td></tr></table></figure><h3 id="日期和时间"><a href="#日期和时间" class="headerlink" title="日期和时间"></a>日期和时间</h3><p>Java.util包提供了Date类来封装当前的日期和时间。Date类提供两个构造函数来实例化Date对象。</p><p>第一个构造函数使用当前日期和时间来初始化对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Date()</span><br><span class="line">Date(<span class="keyword">long</span> millisec)</span><br></pre></td></tr></table></figure><p>Date对象的方法：</p><p>after：若调用此方法的对象在指定日期之前返回true，否则返回false。</p><p>before：和上面的反一下</p><p>clone：返回此对象的副本</p><p>compareTo：比较当前调用此方法的Date对象和指定日期。相等则返回0。</p><p>equals：子类重载，判断调用此方法的Date对象和指定日期是否相等，相等则返回true，否则返回false。</p><p>getTime：返回1970年1月1日00:00:00 GMT以来此Date对象表示的毫秒数</p><p>hashCode：返回此对象的哈希码值</p><p>setTime：用自1970年1月1日00:00:00 GMT以来time毫秒数来设置时间和日期</p><p>toString：把此Date对象转换为下面格式的String：dow mon dd hh:mm:ss zzz yyyy</p><p>其中dow是一周中的某一天(Sun, Mon, Tue, Wed, Thu, Fri, Sat)</p><p>日期比较：</p><p>1、使用getTime方法获取两个日期（自1970年1月1日经历的毫秒数值），然后比较这两个值</p><p>2、使用方法before(), after()和equals()。</p><p>3、使用compareTo方法，它是由comparable接口定义的，Date类实现了这个接口</p><p><strong>SimpleDateFormat</strong>格式化日期：</p><p>这是一个以语言环境敏感的方式来格式化和分析日期的类。SimpleDateFormat允许用户选择任何自定义日期时间格式来运行。</p><p>这个还挺好用的</p><p>格式化转换需要格式，在创建对象的时候指定格式</p><p>休眠：</p><p>Sleep()使当前线程进入停滞状态（阻塞当前线程），让出CPU的使用，不是让当前线程独自占用CPU资源，以留时间给其他线程执行的机会。</p><p>Calendar类：</p><p>设置和获取日期数据的特定部分：</p><p>是一个抽象类，在实际使用时实现特定的子类的对象，方法是使用getInstance方法</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Calendar c = Calendar.getInstance();<span class="comment">//默认是当前日期</span></span><br><span class="line">c.set(<span class="number">2009</span>, <span class="number">6</span>, -<span class="number">1</span>, <span class="number">12</span>);</span><br></pre></td></tr></table></figure><h3 id="正则表达式"><a href="#正则表达式" class="headerlink" title="正则表达式"></a>正则表达式</h3><p>正则表达式定义了字符串的模式</p><p>可以用来搜索、编辑或处理文本</p><p>正则表达式不仅限于某一种语言</p><p>java.util.regex类包括下面的类：</p><ul><li>Pattern类：pattern对象是一个正则表达式的编译表示。Pattern类没有公用构造方法。要创建Pattern对象，必须首先调用公用静态编译方法，返回一个Pattern对象，该方法接受一个正则表达式作为它的第一个参数</li><li>Matcher类：对输入字符串进行解释和匹配操作的引擎。和Pattern类一样，Matcher没有公用构造，需要调用Pattern对象的matcher方法来获取一个Matcher对象</li><li>PatternSystaxException：非强制异常类，表示一个正则表达式模式中的语法错误</li></ul><p>这部分和所有其他的正则表达式一样，特别复杂，等待学习</p><h3 id="Java方法"><a href="#Java方法" class="headerlink" title="Java方法"></a>Java方法</h3><p>System.out.println()</p><p>println()是一个方法</p><p>System是系统类</p><p>out是标准输出对象</p><p>方法是语句的集合，在一起执行一个功能</p><p>方法命名规则：第一个单词以小写字母作为开头，后面的单词用大写字母开头写，不用连接符。如：addPerson</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">修饰符 返回值类型 方法名(参数类型 参数名)&#123;</span><br><span class="line">    ...</span><br><span class="line">    方法体</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> 返回值;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方法包含一个方法头和一个方法体。方法的所有部分包括：</p><ul><li>修饰符：可选，告诉编译器如何调用该方法。定义了该方法的访问类型</li><li>返回值类型：方法可能有返回值</li><li>方法名：方法的实际名称。方法名和参数表共同构成方法签名</li><li>参数类型：参数像一个占位符。方法被调用时，传递值给参数。这个值被称为实参或变量。参数列表是指方法的参数类型、顺序和参数的个数。参数可选，方法可以无参</li><li>方法体：方法体包含具体的语句，定义该方法的功能</li></ul><p>方法调用：根据方法是否返回值来选择</p><p>值传递参数：和引用传递不同，对象变量存的是对象引用，也正是因为有引用，才支持了Java的垃圾回收机制</p><p>变量作用域：</p><p>变量作用域是程序中该变量可以被引用的部分</p><p>方法内定义的变量称为局部变量</p><p>局部变量的作用域从声明开始，直到包含它的块结束</p><p>局部变量必须声明后才可以使用</p><p>方法参数范围涵盖整个方法。参数实际上是一个局部变量</p><p>for循环的初始化部分声明的变量，其作用范围在整个循环</p><p>循环体内声明的变量其适用范围是从它声明到循环体结束。</p><p><strong>所以在for里面int i可以省内存</strong></p><p>命令行参数：如果希望运行一个程序的时候再传递给它消息，就要靠命令行参数给main函数实现。</p><p>构造方法：当一个对象被创建的时候，构造方法用来初始化该对象。构造方法和它所在类的名字相同，但构造方法没有返回值（可以有参数列表）</p><p>通常用构造方法给一个类的实例变量赋初值，或者执行其他步骤来创建一个完整对象。</p><p>不定义也有默认构造方法，它把所有成员初始化为0</p><h3 id="可变参数"><a href="#可变参数" class="headerlink" title="可变参数"></a>可变参数</h3><p>typeName… parameterName</p><p>在方法声明中，在指定参数类型后加一个省略号(…)。</p><p><strong>一个方法中只能指定一个可变参数，它必须是方法的最后一个参数。任何普通参数必须在它之前声明。</strong></p><p>finalize()方法：</p><p>类似于析构函数，它在对象呗垃圾收集器析构（回收）之前被调用，这个方法叫做finalize()，它用来清除回收对象。</p><p>例如，可以使用finalize来确保一个对象打开的文件夹被关闭了。</p><p>在finalize()方法里，用户需要制定对象被销毁时要执行的操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">finalize</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">//source code</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>关键字protected是一个限定符，它确保finalize方法不会被该类外的代码调用</p><p><strong>Java的垃圾回收可以由JVM自动完成，如果选择手动回收垃圾，就可以用上面的方法</strong></p><p>System.gc()：显式调用Java垃圾收集器</p><h3 id="Java流-Stream-、文件-File-和IO"><a href="#Java流-Stream-、文件-File-和IO" class="headerlink" title="Java流(Stream)、文件(File)和IO"></a>Java流(Stream)、文件(File)和IO</h3><p>Java.io包几乎包含了所有操作输入、输出需要的类。流类代表了输入源和输出目标</p><p>Java.io包中的流支持很多格式，比如：基本类型、对象、本地化字符集等</p><p>一个流可以理解为一个数据的序列。输入流表示从一个源读取数据，输出流表示向一个目标写数据</p><p>Java为I/O提供了强大的灵活的支持，使得其广泛应用于文件IO和网络编程中</p><p>读取控制台输入：</p><p>Java控制台输入由System.in完成</p><p>获得一个绑定到控制台的字符流：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">BufferedReader br = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(System.in));</span><br></pre></td></tr></table></figure><p>BufferedReader对象创建后，可以用read()方法从控制台读取一个字符，或者用readLine()方法读取一个字符串</p><p>每次调用read方法，它从输入流读取一个字符并把该字符作为整数值返回。流结束的时候返回-1。</p><p>从控制台读取字符串：</p><p>从标准输入读取一个字符串需要使用BufferedReader的readLine方法</p><p>它的一般格式是：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">String <span class="title">readLine</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span></span><br></pre></td></tr></table></figure><p>JDK 5以后的版本也可以使用Java Scanner类来获取控制台输入，也是更简单的方法</p><p>控制台输出;</p><p>print和println：这些方法都由类PrintStream定义，System.out是该类对象的一个引用</p><p>PrintStream实现write的最简单格式为：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">write</span><span class="params">(<span class="keyword">int</span> byteval)</span></span></span><br></pre></td></tr></table></figure><p>下面演示使用write输出字符”A”和换行符：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.io.*</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WriteDemo</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> b;</span><br><span class="line">        b = <span class="string">'A'</span>;</span><br><span class="line">        System.out.write(b);</span><br><span class="line">        System.out.write(<span class="string">'\n'</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意write方法不经常使用，因为print和println方法用起来更方便</p><p>读写文件：</p><p>流被定义为一个数据序列。输入流用于从源读取数据，输出流用于向目标写数据</p><p>文件输入输出流：</p><p>FileInputStream:</p><p>该流用于从文件读取数据，它的对象可以用关键字new来创建</p><p>可以使用字符串类型的文件名来创建一个输入流对象来读取文件：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">InputStream f = <span class="keyword">new</span> FileInputStream(<span class="string">"C:/java/hello"</span>);</span><br></pre></td></tr></table></figure><p>也可以用一个文件对象来创建一个输入流对象来读取文件，首先要用File()方法来创建一个文件对象：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">File f = <span class="keyword">new</span> File(<span class="string">"C:/java/hello"</span>);</span><br><span class="line"><span class="function">InputStream out new <span class="title">FileInputStream</span><span class="params">(f)</span></span>;</span><br></pre></td></tr></table></figure><p>创建文件输入流之后，就可以使用下面的方法来操作流了：</p><p>Close：关闭文件输入流并释放与此流有关的所有系统资源。抛出IOException异常</p><p>finalize：清除与该文件的连接。确保在不再引用文件输入流时调用其close方法。抛出IOException异常</p><p>read：从InputStream对象读取指定字节数据。返回整数值，表示下一字节数据。结尾则返回-1</p><p>read重载：read(byte[] r) 从输入流读取r.length长度的字节。返回读取的字节数，文件结尾则返回-1</p><p>available：不受阻塞地读流</p><p>FileOutputStream：</p><p>该流在打开文件进行输出前，如果目标文件不存在，那么该流会创建该文件</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">OutputStream f = <span class="keyword">new</span> FileOutputStream(<span class="string">"C:/hava/hello"</span>);</span><br><span class="line">File f = <span class="keyword">new</span> File(<span class="string">"C:/java/hello"</span>);</span><br><span class="line">OutputStream f = <span class="keyword">new</span> FileOutputStream(f);</span><br></pre></td></tr></table></figure><p>流操作：</p><p>Close：关闭此文件输出流并释放与此流有关的所有系统资源。抛出IOException异常</p><p>finalize：清除与该文件的连接，确保不再引用文件输入流时调用其close方法。抛出IOException异常</p><p>write：把指定字节写到输出流中</p><p>write(byte[] w)：重载，把指定数组中w.length长度的字节写到OutputStream中</p><p>在读写的时候注意一下数据编码即可，不要出现乱码</p><p>创建目录：</p><p>File类中有两个方法创建文件夹：</p><ul><li>mkdir()方法创建一个文件夹，成功则返回true，失败则返回false。</li><li>mkdirs()方法创建一个文件夹和它的所有父文件夹</li></ul><p>读取目录：</p><p>创建一个File对象并且如果它是一个目录，那么调用isDirectory方法会返回true</p><p>可以调用该对象上的list方法，来提取它包含的文件和文件夹列表</p><p>删除目录：</p><p>可以使用java.io.File.delete方法</p><p>需要保证该目录下没有其他文件才能正确删除，否则删除失败</p><p>可以用上面的这些类和方法来实现展示目录结构、递归删除目录的功能</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//一级展开目录:/tmp</span></span><br><span class="line"><span class="keyword">import</span> java.io.*;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">main</span></span>&#123;</span><br><span class="line"><span class="comment">//data</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">String dirname = <span class="string">"/tmp"</span>;</span><br><span class="line">File f1 = <span class="keyword">new</span> File(dirname);</span><br><span class="line"><span class="keyword">if</span>(f1.isDirectory())&#123;</span><br><span class="line">System.out.println(<span class="string">"Directory: "</span> + dirname);</span><br><span class="line">String[] s1 = f1.list();</span><br><span class="line"><span class="keyword">for</span>(String s:s1)&#123;</span><br><span class="line">File f = <span class="keyword">new</span> File(dirname + <span class="string">"/"</span> + s);</span><br><span class="line"><span class="keyword">if</span>(f.isDirectory())</span><br><span class="line">System.out.println(s + <span class="string">" is a directory!"</span>);</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">System.out.println(s + <span class="string">" is a file!"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">System.out.println(dirname + <span class="string">" is not a directory!"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Java-Scanner类"><a href="#Java-Scanner类" class="headerlink" title="Java Scanner类"></a>Java Scanner类</h3><p>java.util.Scanner是Java5之后出现的新特性，可以直接通过Scanner类来获取用户的输入，而不用前面那些复杂的IO类（前面那些IO类主要是为了了解和学习）</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Scanner s = <span class="keyword">new</span> Scanner(System.in);</span><br></pre></td></tr></table></figure><p>Scanner类的next和nextLine方法可以获取输入字符串，在读取之前需要使用hasNext和hasNextLine来判断是否还有输入的数据</p><p>next方法的核心代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(scan.hasNext())&#123;</span><br><span class="line">    System str1 = scan.next();</span><br><span class="line">    System.out.println(<span class="string">"输入的数据为: "</span> + str1);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>nextLine方法的核心代码基本类似</p><p>next和nextLine的区别：</p><p>next():</p><ul><li>一定要读取到有效字符后才可以结束输入</li><li>对输入有效字符之前遇到的空白，next方法会自动将其去掉</li><li>只有输入有效字符后才能将后面输入的空白作为分隔符或者结束符</li><li>next不能得到带有空格的字符串</li></ul><p>nextLine():</p><ul><li>以Enter为结束符，也就是说nextLine方法返回的是输入回车之前的所有字符</li><li>可以获得空白</li></ul><p>如果要读入int或float类型的数据，在Scanner类中也有对应支持，输入之前可以用hasNextXxx()方法检测数据类型，判断用户的输入char是否可以转换为小数或者整数格式</p><h3 id="Java-异常处理"><a href="#Java-异常处理" class="headerlink" title="Java 异常处理"></a>Java 异常处理</h3><p>异常指的是程序中的一些错误，并不是所有错误都是异常，错误有时候是可以避免的。</p><p>异常引发的原因有多种，通常包含：</p><ul><li>用户输入了非法数据</li><li>要打开的文件不存在</li><li>网络通信时连接中断，或者JVM内存溢出</li></ul><p>程序员需要掌握三种类型异常：</p><ul><li>检查性异常：用户错误或问题引起的异常，是程序员无法预见的，比如打开一个不存在的文件</li><li>运行时异常：运行异常是可能被程序员避免的异常。运行时异常可以在编译时被忽略</li><li>错误：错误不是异常，而是脱离程序员控制的问题。比如当栈溢出时，一个错误就发生了，它们在编译时是检查不到的。</li></ul><p>Exception类：</p><p>所有异常都是从java.lang.Exception类继承的子类</p><p>捕获异常可以用try catch代码块：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="comment">//程序代码</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(ExceptionName e1)&#123;</span><br><span class="line">    <span class="comment">//catch块</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>多重捕获：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="comment">//程序代码</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(ExceptionName1)&#123;</span><br><span class="line">    </span><br><span class="line">&#125;<span class="keyword">catch</span>(ExceptionName2)&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当try中的保护代码块发生一个异常时，try后面的catch块就会检查是不是要捕获的异常，如果异常发生在catch块，异常会传递到该catch块</p><p>throws/throw关键字：</p><p>如果一个方法没有捕获到一个检查性异常，那么该方法使用throws关键字来声明异常，然后在方法实现体里面用throw抛出异常</p><p>finally关键字用在创建try代码块后面执行的代码块，无论是否发生异常，finally代码块中的代码总是被执行，在finally代码块中，可以运行清理类型等收尾善后性质的语句。格式如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="comment">//程序代码</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(异常类型<span class="number">1</span> 异常变量名<span class="number">1</span>)&#123;</span><br><span class="line">    <span class="comment">//程序代码</span></span><br><span class="line">&#125;<span class="keyword">catch</span>(异常类型<span class="number">2</span> 异常变量名<span class="number">2</span>)&#123;</span><br><span class="line">    <span class="comment">//程序代码</span></span><br><span class="line">&#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">    <span class="comment">//程序代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其他关于异常没有什么好说的，日常写很少用到，用到再查就可以了</p><h2 id="Java面向对象"><a href="#Java面向对象" class="headerlink" title="Java面向对象"></a>Java面向对象</h2><h3 id="Java继承"><a href="#Java继承" class="headerlink" title="Java继承"></a>Java继承</h3><p>允许创建分等级层次的类</p><p>类的继承格式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> 父类</span>&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> 子类 <span class="keyword">extends</span> 父类</span>&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>继承用来解决代码重复的问题</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;<span class="comment">//动物的名字</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;<span class="comment">//动物身份标签</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Animal</span><span class="params">(String myName, <span class="keyword">int</span> myid)</span></span>&#123;</span><br><span class="line">        name = myName;</span><br><span class="line">        id = myid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(name + <span class="string">"正在吃"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(name + <span class="string">"正在睡"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">introduction</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"大家好！我是"</span> + id + <span class="string">"号"</span> + name + <span class="string">"."</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个animal类可以作为其他动物类的父类</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//企鹅类</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Penguin</span> <span class="keyword">extends</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Penguin</span><span class="params">(String myName, <span class="keyword">int</span> myid)</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(myName, myid);<span class="comment">//调用父类构造函数</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//老鼠类</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Mouse</span> <span class="keyword">extends</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Mouse</span><span class="params">(String myName, <span class="keyword">int</span> myid)</span></span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(myName, myid);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>继承的特性：</p><ul><li>子类拥有父类非private属性，方法（）实际上子类也有父类的private属性和方法，只不过被隐藏了</li><li>子类可以拥有自己的属性和方法，即子类可以对父类进行扩展</li><li>子类可以用自己的方式实现父类的方法，这个称为重载</li><li>Java的继承是单继承，但是可以多重继承，单继承就是一个子类只能继承一个父类，多重继承就是祖宗关系</li><li>提高了类之间的耦合性（这个是继承带来的坏处，耦合度高会造成代码间联系太过紧密，代码独立性差）</li></ul><p>继承可以用extends和implements这两个关键字来实现，且所有类都是继承于java.lang.Object，这个Object是所有类的祖宗，当一个类没有继承关键字，则默认继承Object，这个特性在C++里面是没有的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//extends</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> id;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Animal</span><span class="params">(Stirng myName, String myid)</span></span>&#123;</span><br><span class="line">        <span class="comment">//初始化属性值</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Penguin</span> <span class="keyword">extends</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>implements关键字主要用来实现接口，可以同时继承多个接口：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">A</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">B</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">show</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">C</span> <span class="keyword">implements</span> <span class="title">A</span>, <span class="title">B</span></span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>super和this关键字：</p><p>super关键字可以通过这个来实现对父类成员的访问，用来引用当前对象的父类</p><p>this关键字：指向自己的引用</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"animal : eat"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span> <span class="keyword">extends</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="comment">//overload</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> eat&#123;&#125;&#123;</span><br><span class="line">        System.out.println(<span class="string">"dog : eat"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eatTest</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.eat();<span class="comment">//this自调用</span></span><br><span class="line">        <span class="keyword">super</span>.eat();<span class="comment">//调用父类方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Test</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        Animal a = <span class="keyword">new</span> Animal();</span><br><span class="line">        a.eat();<span class="comment">//父类吃</span></span><br><span class="line">        Dog d = <span class="keyword">new</span> Dog();</span><br><span class="line">        d.eatTest();<span class="comment">//调用子类吃和父类吃</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>final关键字：</p><p>可以把类定义为不能继承的，即是最终类；或者用于修饰方法，表示该方法不能被子类重写，主要用作保护</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="class"><span class="keyword">class</span> 类名</span>&#123;&#125;</span><br><span class="line">修饰符(<span class="keyword">public</span>/<span class="keyword">private</span>/<span class="keyword">default</span>/<span class="keyword">protected</span>) <span class="keyword">final</span> 返回值类型 方法名()&#123;&#125;</span><br></pre></td></tr></table></figure><p>构造器：</p><p>子类不继承父类的构造器，只是调用。<strong>如果父类的构造器带有参数，必须在子类的构造器中显式通过super关键字调用父类的构造器并给出参数。</strong></p><p>如果父类是默认构造器，那么在子类构造器中可以不用管父类构造</p><h3 id="Java重写-Override-与重载-Overload"><a href="#Java重写-Override-与重载-Overload" class="headerlink" title="Java重写(Override)与重载(Overload)"></a>Java重写(Override)与重载(Overload)</h3><p>重写(Override)：</p><p>重写是子类对父类允许访问的方法的实现过程进行重新编写，返回值和形参都不变。重写的好处是子类可以个性化定制属于自己的方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">move</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"动物可以移动"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Dog</span> <span class="keyword">extends</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">move</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"狗可以跑和走"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestDog</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span></span>&#123;</span><br><span class="line">        Animal a = <span class="keyword">new</span> Animal();<span class="comment">//Animal对象</span></span><br><span class="line">        Animal b = <span class="keyword">new</span> Dog();<span class="comment">//Dog对象</span></span><br><span class="line">        </span><br><span class="line">        a.move(); <span class="comment">//执行Animal类的方法</span></span><br><span class="line">        </span><br><span class="line">        b.move();<span class="comment">//执行Dog类的方法</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>方法的重写规则：</p><ul><li>参数列表必须完全和被重写的方法相同</li><li>返回类型必须完全与被重写的方法的返回值类型相同</li><li>访问权限不能比父类中被重写的方法的访问权限更低。一般都是一样的权限，这一点倒是很少会注意到，既然有这么一条就写着吧</li><li>父类的成员方法只能被它的子类重写</li><li>声明为final的方法不能被重写，因为final是保护方法和类的</li><li>声明为static的方法不能被重写，因为static的是属于类的</li><li>子类和父类在同一个包中，则子类可以重写父类的所有方法，除了声明为private和final的方法。private的话子类也不能访问，final本身提供了保护</li><li>子类和父类不在同一个包中，则相比上一条，子类不能重写父类的friendly方法了，因为friendly表示同包访问权限</li><li>构造方法不能重写</li><li>如果不能继承，就不重写</li></ul><p>重载(Overload)：</p><p>重载是在同一个类中，方法名字相同而参数不同，返回值类型可以相同可以不同</p><p>每个重载的方法（或构造函数）都必须有一个独一无二的参数型列表</p><p>最常见的重载是构造函数的重载</p><p>重载规则:</p><ul><li>被重载的方法必须改变参数列表（参数个数或类型不同）</li><li>被重载的方法可以改变返回值类型</li><li>被重载的方法可以改变访问修饰符</li><li>方法可以在同一个类中或者在一个子类中被重载</li><li>无法以返回值作为重载函数的区分标准</li></ul><p>方法的重写和重载是Java多态性的不同表现</p><h3 id="Java多态"><a href="#Java多态" class="headerlink" title="Java多态"></a>Java多态</h3><p>多态是同一个行为具有多个不同表现形式或形态的能力</p><p>多态是一个接口，使用不同的实例而执行不同操作</p><p>多态的优点：</p><ul><li>消除类型之间的耦合关系</li><li>可替换性</li><li>可扩充性</li><li>接口性</li><li>灵活性</li><li>简化性</li></ul><p>多态存在的三个必要条件：</p><ul><li>继承</li><li>重写</li><li>父类引用指向子类对象</li></ul><p>虚方法子类可以重写父类的方法，当子类调用重写的方法时，调用的是子类的方法，而不是父类中被重写的方法，被重写的方法是可以动态绑定的，如果像调用父类中被重写的方法，则必须使用关键字super</p><p>多态的实现方式：</p><ul><li>重写overwtire</li><li>接口interface</li><li>抽象类和抽象方法</li></ul><h3 id="Java抽象类"><a href="#Java抽象类" class="headerlink" title="Java抽象类"></a>Java抽象类</h3><p>在面向对象中，所有的对象都是通过类来描绘的，但不是所有类都是用来描绘对象的，如果一个类没有包含足够的信息来描绘一个具体的对象，这样的类就是抽象类</p><p>抽象类除了不能实例化对象之外，类的其它功能依然存在，成员变量，成员方法和构造方法的访问方式和普通类一样</p><p>抽象类不能实例化对象，所以抽象类必须被继承，才能使用</p><p>通过abstract来定义抽象类：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String address;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> number;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Employee</span><span class="params">(String name, String address, <span class="keyword">int</span> number)</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Constructing an Employee"</span>);</span><br><span class="line">        <span class="keyword">this</span>.name = name;</span><br><span class="line">        <span class="keyword">this</span>.address = address;</span><br><span class="line">        <span class="keyword">this</span>.number = number;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">double</span> <span class="title">computePay</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Inside Employee computePay"</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">mailCheck</span><span class="params">()</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">"Mailing a check to "</span> + <span class="keyword">this</span>.name + <span class="string">" "</span> + <span class="keyword">this</span>.address);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">toString</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name + <span class="string">" "</span> + address + <span class="string">" "</span> + number;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getName</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">getAddress</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> address;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAddress</span><span class="params">(String newAddress)</span></span>&#123;</span><br><span class="line">        address = newAddress;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getNumber</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> number;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>抽象方法：</p><p>如果该方法的具体实现可以由它的子类确定，那么可以在父类中声明该方法为抽象方法</p><p>Abstract关键字可以用来声明抽象方法，抽象方法只包含一个方法名，没有方法体</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Employee</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> String address;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> number;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">double</span> <span class="title">computePay</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>声明抽象方法会造成以下两个结果：</p><ul><li>如果一个类包含抽象方法，那么该类必须是抽象类</li><li>任何子类必须重写父类的抽象方法，或者声明自身为抽象类</li></ul><p>继承抽象方法的子类必须重写该方法。否则，该子类也必须声明为抽象类。实现后才能实例化对象</p><h3 id="Java封装"><a href="#Java封装" class="headerlink" title="Java封装"></a>Java封装</h3><p>Encapsulation是一种将抽象是函式接口的实现细节部分包装、隐藏起来的方法。</p><p>封装被认为是一个保护屏障，防止该类的代码和数据被外部类定义的代码随机访问。</p><p>封装的优点</p><ul><li>良好的封装能减少耦合</li><li>类内部的结构可以自由修改</li><li>可以对成员变量进行更精确的控制</li><li>隐藏信息，实现细节</li></ul><p>实现封装的步骤：</p><p>修改属性的可见性：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> age;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将name和age属性设置为私有，只能本类才能访问，其他类访问不了，这样就实现了对信息的隐藏</p><h3 id="Java接口"><a href="#Java接口" class="headerlink" title="Java接口"></a>Java接口</h3><p>Interface，在Java语言中是一个抽象类型，是抽象方法的集合，接口通常以interface来声明。一个雷通过继承接口的方式，从而来继承接口的抽象方法。接口不是类，编写接口的方式和类很相似，但它们属于不同概念。类描述对象的属性和方法。接口则包含类要实现的方法。</p><p>除非实现接口的类是抽象类，否则该类要定义接口中的所有方法。</p><p>接口无法被实例化，但是可以被实现。一个实现接口的类，必须实现接口内描述的所有方法，否则就必须声明为抽象类。另外，Java中接口类型可用来声明一个变量，他们可以成为一个空指针，或者绑定一个以此接口实现的对象。</p><p>接口与类的相似点：</p><ul><li>一个接口可以有多个方法</li><li>接口文件保存在.java结尾的文件中，文件名使用接口名</li><li>接口的字节码文件保存在.class结尾的文件中</li><li>接口相应的字节码文件必须在于包名称相匹配的目录结构中</li></ul><p>接口与类的区别：</p><ul><li>接口不能用于实例化对象</li><li>接口没有构造方法</li><li>接口中所有方法必须是抽象方法</li><li>接口中所有方法必须是抽象方法</li><li>接口不能包含成员变量，除了static和final变量</li><li>接口不是被类继承了，而是要被类实现</li><li>接口支持多继承</li></ul><p>接口特性：</p><ul><li>接口中每一个方法也是隐式抽象的，接口中的方法会被隐式指定为public abstract</li><li>接口中可以含有变量，但是接口中的变量会被隐式指定为public static final变量</li><li>接口中的方法是不能在接口中实现的，只能由实现接口的类来实现接口中的方法</li></ul><p>抽象类和接口的区别：</p><ul><li>抽象类中的方法可以有方法体，但是接口中的方法不行</li><li>抽象类中的成员变量可以是多种类型的，而接口类中的变量只能是public static final类型的</li><li>接口中不能含有静态代码块以及静态方法，而抽象类可以有静态代码块和静态方法</li><li>一个类只能继承一个抽象类，而一个类却可以实现多个接口</li></ul><p>接口声明：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">interface 接口名称 [extends 其他的接口名]&#123;</span><br><span class="line">    <span class="comment">//声明变量</span></span><br><span class="line">    <span class="comment">//声明抽象方法</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接口隐式抽象，当声明一个接口的时候，不必使用abstract关键字</p><p>接口中每个方法也是隐式抽象的，声明不需要abstract关键字</p><p>接口中的方法都是公有的</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">Animal</span></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">eat</span><span class="params">()</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">travel</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接口的实现：</p><p>当类实现接口的时候，需要实现接口中的所有方法，否则，类必须声明为抽象的类。</p><p>类使用implements关键字实现接口。类声明中，implements关键字放在class声明后面</p><p>实现一个接口的语法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">...implements 接口名称</span><br></pre></td></tr></table></figure><p>实现接口方法的时候记住要保持一致的方法名，和相同或兼容的返回值类型</p><p>如果实现接口的类是抽象类，那么就没有必要实现接口的方法</p><p>一个接口可以继承另一个接口，和类之间的继承方式比较相似。接口的继承用extends关键字，子接口继承父接口的方法</p><h3 id="Java包"><a href="#Java包" class="headerlink" title="Java包"></a>Java包</h3><p>Package</p><p>为了更好地组织类，Java提供了包机制，用于区别类名的命名空间</p><p>包的作用：</p><ul><li>把功能相似或相关的接口组织在同一个包中，方便类的查找和使用</li><li>如同文件夹一样，包也采用了树形目录的存储方式。同一个包中的类名字是不同的，不同的包中的类的名字可以相同，当调用不同包中相同类名的类时，应该加上包名加以区分</li><li>包限定了访问权限，拥有包访问权限的类才能访问某个包中的类</li></ul><p>Java使用包这种机制是为了防止命名冲突，访问控制，提供搜索和定位类、接口、枚举和注释等</p><p>包语法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> pkg;</span><br></pre></td></tr></table></figure><p>包声明应该放在第一行</p><p>import关键字：导入包</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pkg;</span><br></pre></td></tr></table></figure><h2 id="Java高级主题"><a href="#Java高级主题" class="headerlink" title="Java高级主题"></a>Java高级主题</h2><h3 id="Java数据结构"><a href="#Java数据结构" class="headerlink" title="Java数据结构"></a>Java数据结构</h3><ul><li>枚举（Enumeration）</li><li>位集合（BitSet）</li><li>向量（Vector）</li><li>栈（Stack）</li><li>字典（Dictionary）</li><li>哈希表（Hashtable）</li><li>属性（Properties）</li></ul><p>上面的数据结构是传统遗留的，在Java2中引入了一种新的框架-集合框架（Collection）</p><h3 id="枚举（Enumeration）"><a href="#枚举（Enumeration）" class="headerlink" title="枚举（Enumeration）"></a>枚举（Enumeration）</h3><p>枚举接口虽然本身不属于任何数据结构，但它在其他数据勾结的范畴里应用很广。枚举接口定义了一种从数据结构取回连续元素的方式。</p><p>枚举定义了一个叫nextElement的方法，该方法用来得到一个包含多个元素的数据结构的下一个元素。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Vector;</span><br><span class="line"><span class="keyword">import</span> java.util.Enumeration;</span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EnumerationTester</span> </span>&#123;</span><br><span class="line"> </span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String args[])</span> </span>&#123;</span><br><span class="line">      Enumeration&lt;String&gt; days;</span><br><span class="line">      Vector&lt;String&gt; dayNames = <span class="keyword">new</span> Vector&lt;String&gt;();</span><br><span class="line">      dayNames.add(<span class="string">"Sunday"</span>);</span><br><span class="line">      dayNames.add(<span class="string">"Monday"</span>);</span><br><span class="line">      dayNames.add(<span class="string">"Tuesday"</span>);</span><br><span class="line">      dayNames.add(<span class="string">"Wednesday"</span>);</span><br><span class="line">      dayNames.add(<span class="string">"Thursday"</span>);</span><br><span class="line">      dayNames.add(<span class="string">"Friday"</span>);</span><br><span class="line">      dayNames.add(<span class="string">"Saturday"</span>);</span><br><span class="line">      days = dayNames.elements();</span><br><span class="line">      <span class="keyword">while</span> (days.hasMoreElements())&#123;</span><br><span class="line">         System.out.println(days.nextElement()); </span><br><span class="line">      &#125;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="位集合（BitSet）"><a href="#位集合（BitSet）" class="headerlink" title="位集合（BitSet）"></a>位集合（BitSet）</h3><p>位集合实现了一组可以单独设置和清除的位或标志</p><p>该类在处理一组布尔值的时候非常有用</p><h3 id="向量（Vector）"><a href="#向量（Vector）" class="headerlink" title="向量（Vector）"></a>向量（Vector）</h3><p>向量（Vector）类和传统数组非常相似，但是Vector的大小能根据需要动态变化。</p><p>和数组一样，Vector对象的元素也能通过索引访问。</p><p>使用Vector类最主要的好处就是在创建对象的时候不必给对象指定大小，它的大小会根据需要动态变化。</p><p>Vector类实现了一个动态数组，和ArrayList类似，但是两者是不同的：</p><ul><li>Vector是同步访问的</li><li>Vector包含了许多传统方法，这些方法不属于集合框架</li></ul><p>Vector主要用在事先不知道数组的大小，或者只需要一个可以改变大小的数组的情况</p><p>Vector类支持四种构造方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Vector();</span><br><span class="line">Vector(<span class="keyword">int</span> size);</span><br><span class="line">Vector(<span class="keyword">int</span> size, <span class="keyword">int</span> incr);</span><br><span class="line">Vector(Collection c);</span><br></pre></td></tr></table></figure><p>除了从父类继承的方法外Vector还定义了以下方法：</p><p>add：在向量的指定位置插入指定的元素，add(int index, Object element)</p><p>add：提供了末尾添加的重载方法，add(Object element)</p><p>capacity：返回此向量当前的容量</p><p>clear：从向量中移除所有元素</p><p>clone：返回向量的一个副本</p><p>contains：如果此向量包含指定的元素，则返回true</p><p>equals：比较指定对象与此对象的相等性</p><p>get：返回向量中指定位置的元素，参数为索引值</p><p>indexOf：返回此向量中第一次出现的指定元素的索引，从index处正向搜索，如果未找到该元素，则返回-1</p><p>lastIndexOf：返回向量中最后一次出现指定元素的索引，如果未找到则返回-1</p><p>isEmpty：判断是否为空</p><p>firstElement：返回向量的第一个组件</p><p>lastElement：返回向量的最后一个组件</p><p>remove：移除指定位置的元素</p><p>size：和capacity不同，返回的是现在向量中的组件数</p><p>toString：返回此向量的字符串表示形式，其中包含每个元素的String表示形式</p><p>elements：返回此向量组件的枚举，可以直接赋值给枚举变量</p><p>remove:两类重载，接受index参数或者Object参数，移除指定位置的元素或者移除指定元素的第一个匹配项</p><p>removeAll：移除所有指定元素，接受Collection参数</p><p>toArray：返回一个数组</p><p>toString：返回一个字符串</p><h3 id="栈（Stack）"><a href="#栈（Stack）" class="headerlink" title="栈（Stack）"></a>栈（Stack）</h3><p>栈（Stack）实现了一个后进先出（LIFO）的数据结构</p><p>可以把栈理解为垂直分布的栈，当添加一个元素时，就将新元素放在其他元素的顶部</p><p>当从栈中取出元素的时候，就从栈顶取一个元素。换句话说，最后进栈的元素最先被取出。</p><p>是Vector一个子类，Stack定义了默认构造用来创建空栈</p><ul><li>empty:测试堆栈是否为空</li><li>peek:查看栈顶对象并不移除</li><li>pop:移除栈顶对象并返回</li><li>push:把项压入堆栈顶部</li><li>search:返回对象在栈中的位置，以1位基数</li></ul><h3 id="字典（Dictionary）"><a href="#字典（Dictionary）" class="headerlink" title="字典（Dictionary）"></a>字典（Dictionary）</h3><p>字典（Dictionary）类是一个抽象类，它定义了键值映射到值的数据结构</p><p>当想要通过特定的键而不是整数索引来访问数据的时候，应该使用Dictionary</p><p>由于Dictionary类是抽象类，所以它只提供了键映射到值的数据结构，而没有提供特定的实现</p><p>和Map类相似。</p><ul><li>element:返回值的枚举</li><li>get:返回指定键对应的值</li><li>isEmpty:测试字典是否为空</li><li>keys:返回键的枚举</li><li>remove:接受key参数，从字典中移除指定key</li><li>put:put(Object key, Object value),将指定key映射到该字典中指定的value</li><li>size:返回条目的数量</li></ul><p>Dictionary类已经过时了，在实际的开发中，常常使用Map</p><h3 id="哈希表（Hashtable）"><a href="#哈希表（Hashtable）" class="headerlink" title="哈希表（Hashtable）"></a>哈希表（Hashtable）</h3><p>Hashtable类提供了一种在用户键结构的基础上来组织数据的手段</p><p>Hashtable现已经集成到集合框架中。和HashMap类似，但是支持同步</p><p>构造方法：</p><ul><li>Hashable()</li><li>Hashtable(int size) //创建指定大小的哈希表</li><li>Hashtable(int size, float fillRatio) //创建指定大小的哈希表，并根据fillRate填充</li><li>Hashtable(Map m) //以m中元素为初始化元素的哈希表</li></ul><p>Hashtable除了实现Map接口中定义的方法之外，还自定义了其他的方法</p><ul><li>clear: 清空哈希表，使其不包含任何键值</li><li>contains: 给的参数是值，测试是否存在对应的键</li><li>isEmpty: 判断哈希表是否为空</li><li>size: 返回键的数量</li><li>toString: 返回Hashtable的字符串形式</li></ul><h3 id="属性（Properties）"><a href="#属性（Properties）" class="headerlink" title="属性（Properties）"></a>属性（Properties）</h3><p>Properties继承于Hashtable.Properties类表示一个持久的属性集，水星列表中每个键及其对应值都是一个字符串</p><p>Properties类被许多Java类使用。</p><h2 id="集合框架"><a href="#集合框架" class="headerlink" title="集合框架"></a>集合框架</h2><p>Java的集合框架主要包括两种类型的容器，一种是集合(Collection)，存储一个元素集合，另一种是图(Map),存储键值映射。Collection接口有三种子类型：List, Set和Queue，再下面是抽象类，再下面是具体实现类，常用的有ArrayList, LinkedList, HashSet, LinkedHashset。集合框架提供了一套性能优良，使用方便的接口和类。Java集合框架位于java.util包里，所以使用集合框架的时候需要导包。</p><h3 id="集合接口"><a href="#集合接口" class="headerlink" title="集合接口"></a>集合接口</h3><ul><li><p>Collection接口：是最基本的集合接口，一个Collection代表一组Object，存储一组不唯一，无序的对象</p></li><li><p>List接口：是一个有序的Collection，支持0索引。存储不唯一，有序的对象</p></li><li><p>Set接口：与Collection一样，只是不允许重复</p></li><li><p>SortedSet接口：继承于Set保存有序集合</p></li><li><p>Map接口：存储键值对，提供key到value的映射</p></li><li><p>SortedMap：继承于Map，使Map保证升序排列</p></li></ul><p>Set和List相比，Set无序不重复，List有序可以重复</p><p>Set访问效率低，删除和插入效率高</p><p>List和数组类似，可以动态增长。其实现类有ArrayList，LinkedList，Vector</p><p>使用迭代器进行遍历：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;String&gt; ite = list.iterator();</span><br><span class="line"><span class="keyword">while</span>(ite.hasNext())&#123;</span><br><span class="line">System.out.println(ite.next());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>把链表变成相关容器再遍历：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String strArray = <span class="keyword">new</span> String[list.size()];</span><br><span class="line">list.toArray(strArray);</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;strArray.length;i++)&#123;</span><br><span class="line">System.out.println(strArray[i]);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Java泛型"><a href="#Java泛型" class="headerlink" title="Java泛型"></a>Java泛型</h2><p>generics。和C++泛型差不多，具体要用可以再查，平时练习是用不到的。</p><h3 id="泛型方法："><a href="#泛型方法：" class="headerlink" title="泛型方法："></a>泛型方法：</h3><p>方法在调用时可以接收不同类型的参数。根据传递给泛型方法的参数类型。编译器适当地处理每个方法的调用</p><h3 id="泛型类："><a href="#泛型类：" class="headerlink" title="泛型类："></a>泛型类：</h3><p>在类名后面加上类型参数声明部分</p><h3 id="类型通配符："><a href="#类型通配符：" class="headerlink" title="类型通配符："></a>类型通配符：</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">getData</span><span class="params">(List&lt;?&gt; data)</span></span>&#123;&#125;</span><br></pre></td></tr></table></figure><p>差不多就完结了，后面一些比如序列化，网络编程之类的，平常也用不到，只有特定的开发场景中才可能会用到。另外Java Mooc笔记没有上传，因为没有全部看完。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;参考菜鸟教程、实验楼、ZJU翁凯MOOC然后做的一些比较入门级的笔记&lt;/p&gt;
    
    </summary>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title>正则表达式</title>
    <link href="http://yoursite.com/2018/11/24/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"/>
    <id>http://yoursite.com/2018/11/24/正则表达式/</id>
    <published>2018-11-25T00:30:43.000Z</published>
    <updated>2019-03-08T20:14:54.344Z</updated>
    
    <content type="html"><![CDATA[<p>正则表达式是一种文本模式，包括普通字符和特殊字符(也称为元字符)。正则表达式使用单个字符来描述、匹配一系列匹配某个句法规则的字符串。</p><p>在练Codewars的时候，意识到了正则表达式的重要性，尤其是在字符串处理方面。另外正则表达式在Linux文件操作上也比较重要。</p><p>之前多多少少接触过一点，但是也意识到了他的复杂性。如果说shell编程那一套是鬼画符，那么这个应该也是差不多的。</p><p>但是正则表达式在某些情况下真的特别好用(听说学会正则表达式还能提升成就感)，于是就下定决心入这个坑了。</p><a id="more"></a><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>?通配符匹配文件名中的0个或1个字符，而*通配符匹配0个或多个字符。相比于通配符，正则表达式功能更强大，而且更加灵活。<br>实例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">^[0-9]+abc$</span><br></pre></td></tr></table></figure><p>说明：</p><p>^匹配输入字符串的开始位置</p><p>[0-9]+匹配多个数字，[0-9]匹配单个，+匹配一个或多个</p><p>abc$匹配字母abc并以abc结尾，$表示输入字符串的结束位置</p><p>为什么要用正则表达式？</p><ul><li>测试字符串内的模式。称为数据验证</li><li>替换文本。使用正则表达式来识别文档中的特定文本，完全删除该文本或者用其他文本来替换他</li><li>基于模式匹配从字符串中提取子字符串</li></ul><p>发展历史：</p><p>可以追溯到对人类神经系统如何工作的早期研究，科学家提出数学的方式描述神经网络。后来有科学家发表神经网络方面的文章正式提出了正则表达式的概念。</p><p>应用领域：</p><p>目前，正则表达式在众多软件中得到广泛应用，包括*nix(Linux, Unix等)、HP操作系统、PHP、C#、Java开发环境</p><h3 id="语法"><a href="#语法" class="headerlink" title="语法"></a>语法</h3><p>正则表达式描述了一种字符串匹配的模式(pattern)，可以用来检查一个串中是否含有某种子串、将匹配的子串替换或者从某个串中提取出符合某个条件的子串等。</p><p>正则表达式的组件可以是单个字符、字符集合、字符范围、字符间的选择或者所有这些组件的任意组合</p><p>普通字符：</p><p>没有显式指定为元字符的所有可打印和不可打印字符。包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。</p><p>非打印字符：</p><ul><li>\cx: 匹配由x指明的控制字符</li><li>\f: 匹配一个换页符，等价于\x0c和\cL</li><li>\n: 匹配一个换行符，等价于\x0a和\cJ</li><li>\r: 匹配匹配一个回车符，等价于\x0d和\cM</li><li>\s: 匹配任何空白字符，包括空格、制表符、换页符等等</li><li>\S: 匹配任何非空白字符</li><li>\t: 匹配一个制表符，等价于\x09和\cl</li><li>\v: 匹配一个垂直制表符，等价于\x0b和\cK</li></ul><p>特殊字符：</p><p>如果要匹配特殊字符，要进行转义</p><ul><li>$: 匹配输入字符串的结尾位置</li><li>(): 标记一个子表达式的开始和结束位置</li><li>*: 匹配前面的子表达式零次或多次</li><li>+: 匹配前面的子表达式一次或多次</li><li>.: 匹配除换行符之外的任何单字符</li><li>[: 标记一个中括号表达式的开始</li><li>?: 匹配前面的子表达式零次或一次</li><li>\: 将下一个字符标记为特殊字符</li><li>^: 匹配输入表达式的开始位置</li><li>{: 标记限定表达式的开始</li><li>|: 指明两项之间的一个选择</li></ul><p>限定符：</p><p>指定正则表达式的一个给定组件必须出现多少次才能满足匹配</p><ul><li>*: 匹配前面的子表达式零次或多次</li><li>+: 匹配前面的子表达式一次或多次</li><li>?: 匹配前面的子表达式零次或一次</li><li>{n}: n是一个非负整数，匹配确定的n次。例如’o{2}’用来匹配两个o</li><li>{n,}: n是一个非负整数，至少匹配n次，例如’o{2,}’用来匹配两个或多个o</li><li>{n,m}: m和n均为非负整数，最少匹配n次且最多匹配m次，例如’o{1,3}’匹配1-3个o</li></ul><p>实例：</p><p>以章节号为例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">//任何位数的章节标题</span><br><span class="line">/chapter [1-9][0-9]*/</span><br><span class="line"></span><br><span class="line">//匹配0-99章</span><br><span class="line">/chapter [0-9]&#123;1,2&#125;/</span><br><span class="line"></span><br><span class="line">//匹配1-99章</span><br><span class="line">/chapter [1-9][0-9]?/</span><br></pre></td></tr></table></figure><p>定位符：</p><p>定位符能够将正则表达式固定到行首或行尾，定位符用来描述字符串或单词的边界</p><ul><li>^: 匹配输入字符串开始的位置</li><li>$: 匹配输入字符串结尾的位置</li><li>\b: 匹配一个单词边界，即字与空格间的位置</li><li>B: 非单词边界匹配</li></ul><p>限定符和定位符不能一起用</p><p>选择：</p><p>用圆括号将所有选择项括起来</p><p>反向引用：</p><p>不太明白</p><h3 id="元字符"><a href="#元字符" class="headerlink" title="元字符"></a>元字符</h3><ul><li><p>\: 将下一个字符标记为特殊字符、或一个原义字符、或一个向后引用、或一个八进制转义符</p></li><li><p>^: 匹配输入字符串的开始位置</p></li><li><p>$: 匹配输入字符串的结束位置</p></li><li><p>*: 匹配前面的子表达式零次或多次</p></li><li><p>+: 匹配前面的子表达式一次或多次</p></li><li><p>?: 匹配前面的子表达式零次或一次</p></li><li><p>{n}: n是一个非负整数，匹配确定的n次</p></li><li><p>{n,}: n是一个非负整数，至少匹配n次</p></li><li><p>{n,m}: 至少匹配n次，最多m次</p></li><li><p>.: 匹配换行符\n \r之外的任何单个字符</p></li><li><p>(pattern): 匹配pattern并获取这一匹配 </p></li><li><p>(?:pattern): 非获取匹配</p></li><li><p>(?=pattern): 正向匹配预查</p></li><li><p>(?!pattern): 正向否定预查</p></li><li><p>(?&lt;=pattern): 反向肯定预查</p></li><li><p>(?&lt;!pattern): 反向否定预查</p></li><li><p>x|y: 匹配x或y</p></li><li><p>[xyz]: 字符集合，匹配所包含的任意一个字符</p></li><li><p>[^xyz]: 负值字符集合，匹配未包含的任意单个字符 </p></li><li><p>[a-z]: 字符范围，匹配指定范围内的任意字符</p></li><li><p>[^a-z]: 负值字符范围，匹配任何不在指定范围内的任意字符</p></li><li><p>\b: 匹配一个单词边界，也就是单词和空格间的位置</p></li><li><p>\B: 匹配非单词边界</p></li><li><p>\cx: 匹配由x指明的控制字符</p></li><li><p>\d: 匹配一个数字字符，等价于[0-9]</p></li><li><p>\D: 匹配一个非数字字符，等价于[^0-9]</p></li><li><p>\f: 匹配一个换页符 </p></li><li><p>\n: 匹配一个换行符</p></li><li><p>\r: 匹配一个回车符</p></li><li><p>\s: 匹配任何空白字符，包括空白、制表符、换页符等</p></li><li><p>\S: 匹配任何非空白字符</p></li><li><p>\t: 匹配一个制表符 </p></li><li><p>\v: 匹配一个垂直制表符</p></li><li><p>\w: 匹配字母、数字、下划线。等价于[A-Za-z0-9_]</p></li><li><p>\W: 匹配非字母、数字、下划线。等价于[^A-Za-z0-9_]</p></li><li><p>\xn: 匹配n，其中n为十六进制转义值</p></li><li><p>\num: 匹配num，其中num是一个正整数</p></li><li><p>\nm: 标志一个八进制转义值或向后引用</p></li><li><p>\un: 匹配n，n是一个用四个十六进制数字表示的Unicode字符</p></li></ul><h3 id="运算符优先级"><a href="#运算符优先级" class="headerlink" title="运算符优先级"></a>运算符优先级</h3><p>从左到右计算，并遵循运算符优先级</p><p>优先级由高到低：</p><ul><li>\: 转义符</li><li>(),(?:),(?=),[]: 圆括号和方括号 </li><li>*,+,?,{n},{n,},{n,m}: 限定符</li><li>^,$,\,任何元字符，任何字符: 定位点和序列</li><li>|: 替换</li></ul><h3 id="匹配规则"><a href="#匹配规则" class="headerlink" title="匹配规则"></a>匹配规则</h3><p>基本模式匹配</p><p>模式是正则表达式最基本的元素，是一组描述字符串特征的字符。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">^once</span><br></pre></td></tr></table></figure><p>这个模式包含^，表示字符串开头，用来匹配那些以once为开头的字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bucket$</span><br></pre></td></tr></table></figure><p>这个模式包含$，表示字符串结尾，用来匹配以bucket为结尾的字符串</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">^bucket$</span><br></pre></td></tr></table></figure><p>表示只匹配bucket</p><p>字符簇：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[AaEeIiOoUu]</span><br></pre></td></tr></table></figure><p>确定重复出现：</p><p>{x}的意思是前面的字符或字符簇只出现x次，{x,}的意思是前面的内容出现x或更多的次数，{x,y}表示前面的内容至少出现x次，至多出现y次。特殊字符*和{0,}是等价的，+和{1,}是等价的。</p><h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>简单表达式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/a7M/</span><br></pre></td></tr></table></figure><p>匹配a7M</p><p>字符匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/a.7/</span><br><span class="line">/filename\.txt/</span><br></pre></td></tr></table></figure><p>中括号表达式：</p><p>创建匹配字符组的一个列表</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/Chapter [12345]/</span><br><span class="line">/Chapter [1-5]/</span><br></pre></td></tr></table></figure><p>中括号表达式的典型应用是指定任何大写或小写字母或数字匹配：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/[A-Za-z0-9]/</span><br></pre></td></tr></table></figure><h2 id="实验楼"><a href="#实验楼" class="headerlink" title="实验楼"></a>实验楼</h2><h3 id="正则表达式基础"><a href="#正则表达式基础" class="headerlink" title="正则表达式基础"></a>正则表达式基础</h3><p>grep, expr, sed, awk或vi中会经常用到正则表达式</p><p>正则表达式的特殊符号：</p><ul><li><p>[:alnum:]: 代表英文大小写字母和数字</p></li><li><p>[:alpha:]: 代表英文大小写字母</p></li><li><p>[:blank:]: 代表空格和tab键</p></li><li><p>[:cntrl:]: 代表键盘上的控制按键，如CR,LF,TAB,DEL</p></li><li><p>[:digit:]: 代表数字</p></li><li><p>[:graph:]: 代表空白字符以外的其他</p></li><li><p>[:lower:]: 代表小写字母</p></li><li><p>[:print:]: 代表可以被打印出来的任何字符</p></li><li><p>[:punct:]: 代表标点符号</p></li><li><p>[:upper:]: 代表大写字母</p></li><li><p>[:space:]: 代表会产生空白的字符如空格，tab，CR等</p></li><li><p>[:xdigt:]: 代表十六进制数字类型</p></li></ul><p>在使用正则表达式时需要留意语系，不同语系同一模式匹配结果可能有差异</p><h3 id="通过grep命令使用正则表达式"><a href="#通过grep命令使用正则表达式" class="headerlink" title="通过grep命令使用正则表达式"></a>通过grep命令使用正则表达式</h3><p>grep参数</p><ul><li>-a: 将binary档案以text档案的形式搜索</li><li>-c: 计算找到“搜索字符串”的次数</li><li>-i: 忽略大小写，所以大小写视为相同</li><li>-n: 顺便输出行号</li><li>-v: 反向选择，即输出不包含搜索字符串的内容</li></ul><p>[]中包含的字符，只能是一个，-用来表示字符范围，[^…]排除型字符组，跟反向选择是一样的。例如：</p><ul><li><p>[abc]: 表示a或b或c</p></li><li><p>[0-9]: 表示0-9中任意一个数字，等价于0123456789</p></li><li><p>[^a1&lt;]: 表示除a，1，&lt;外的任意一个字符</p></li><li><p>[^a-z]: 表示除小写字母外的任意一个字符</p></li></ul><p>行首行尾控制，例如：</p><ul><li>^[A-Z]: 表示以大写字母开头</li><li>$[A-Z]: 表示以大写字母结尾</li></ul><p>重复次数控制：</p><p>{}可以用来限定字符重复出现的次数</p><ul><li>{n}: 表示只匹配n次</li><li>{n,}: 表示至少匹配n次</li><li>{n,m}: 表示至少匹配n次，至多匹配m次</li></ul><h3 id="通过sed命令使用正则表达式"><a href="#通过sed命令使用正则表达式" class="headerlink" title="通过sed命令使用正则表达式"></a>通过sed命令使用正则表达式</h3><p>sed是非交互式编辑器。它不会修改文件。sed编辑器逐行处理文件，并将结果发送到屏幕。处理过程为：把当前正在处理的行保存到一个临时缓冲区中（也称为模式空间），然后处理临时缓冲区中的行，完成后发送到屏幕上，sed每处理好一行就把它从临时缓冲区中删除，然后读入下一行，进行处理和显示。处理完最后一行后，sed就结束运行。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nl regular_express.txt | sed <span class="string">'2,5d'</span></span><br></pre></td></tr></table></figure><p>2,5表示2到5行，d表示删除</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nl regular_express.txt | sed <span class="string">'2,$d'</span></span><br></pre></td></tr></table></figure><p>删除2到最后一行</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -i <span class="string">'1d'</span> regular_express</span><br></pre></td></tr></table></figure><p>在源文件中删除第一行</p><h3 id="扩展正则表达式"><a href="#扩展正则表达式" class="headerlink" title="扩展正则表达式"></a>扩展正则表达式</h3><p>知识点:egrep命令</p><p>可以使用grep -E 来使用扩展正则表达式，效果和egrep相同</p><h3 id="挑战"><a href="#挑战" class="headerlink" title="挑战"></a>挑战</h3><ol><li>找到登录shell为bash的用户:</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n <span class="string">'bash'</span> user</span><br></pre></td></tr></table></figure><ol><li>找到UID或GID是5位数或以上的用户行记录</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n <span class="string">'[0-9]\&#123;5,\&#125;'</span> user</span><br></pre></td></tr></table></figure><ol><li>有主目录在/var/spo??l下的用户，但想不起来spo后面到底有几个o，找出满足条件的用户行记录</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n <span class="string">'/var/spo\+l'</span> user</span><br></pre></td></tr></table></figure><ol><li>已知有个用户其用户名形如 ‘mi..M’，中间有未知多个mi，找出该用户的用户行记录</li></ol><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -n <span class="string">'[mi]\+M'</span> user</span><br></pre></td></tr></table></figure><p>至于输出到文件，简单重定向就完事了</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;正则表达式是一种文本模式，包括普通字符和特殊字符(也称为元字符)。正则表达式使用单个字符来描述、匹配一系列匹配某个句法规则的字符串。&lt;/p&gt;
&lt;p&gt;在练Codewars的时候，意识到了正则表达式的重要性，尤其是在字符串处理方面。另外正则表达式在Linux文件操作上也比较重要。&lt;/p&gt;
&lt;p&gt;之前多多少少接触过一点，但是也意识到了他的复杂性。如果说shell编程那一套是鬼画符，那么这个应该也是差不多的。&lt;/p&gt;
&lt;p&gt;但是正则表达式在某些情况下真的特别好用(听说学会正则表达式还能提升成就感)，于是就下定决心入这个坑了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/10/30/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A/"/>
    <id>http://yoursite.com/2018/10/30/卷积神经网络编程作业/</id>
    <published>2018-10-31T02:23:07.000Z</published>
    <updated>2018-10-31T02:23:07.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络编程作业"><a href="#卷积神经网络编程作业" class="headerlink" title="卷积神经网络编程作业"></a>卷积神经网络编程作业</h1><h2 id="第一周编程作业"><a href="#第一周编程作业" class="headerlink" title="第一周编程作业"></a>第一周编程作业</h2><p>搭建卷积神经网络模型及应用</p><h3 id="assignment1"><a href="#assignment1" class="headerlink" title="assignment1"></a>assignment1</h3><p>搭建卷积神经网络</p><p>conv层的函数：</p><ul><li>zero padding</li><li>conv window</li><li>conv forward</li><li>conv backward</li></ul><p>pool层的函数：</p><ul><li>pool forward</li><li>create mask</li><li>distribute value</li><li>pool backward</li></ul><p>先写zero padding，它的好处是不会缩减图片的尺寸，以及保留图片的边缘信息</p><p>后面是单次conv是一次conv forward，其中要注意的是conv forward里面有两个channel信息，其中一个chanel其实表示的是filter的个数</p><p>pooling layer的反传也要计算，是因为计算前层的反传的时候会用到，因此pooling反传不可忽略。pooling layer反传策略基本上是创建一个mask译码，然后去filter无关项，把有用的项向前层反传，比如max pooling则把最大值反传，average pooling则把平均值反传</p><h3 id="assignment2"><a href="#assignment2" class="headerlink" title="assignment2"></a>assignment2</h3><p>用tensorflow框架搭建卷积神经网络</p><h2 id="第二周编程作业"><a href="#第二周编程作业" class="headerlink" title="第二周编程作业"></a>第二周编程作业</h2><h3 id="assignment1-1"><a href="#assignment1-1" class="headerlink" title="assignment1"></a>assignment1</h3><p>学习使用Keras，能够运行在Tensorflow和CNTK之上</p><p>Keras相比于Tensorflow，是更高层次的深度学习框架</p><p>Keras写出来的还蛮简洁的</p><h3 id="assignment2-1"><a href="#assignment2-1" class="headerlink" title="assignment2"></a>assignment2</h3><p>Residual Networks</p><p>残差网络</p><p>在任务中，我们将完成：实现残差网络的基本模块，用所有模块组件一个先进的残差网络来做图像分类</p><p>shortcut || skip connection</p><p>Indentity block和Convolutional block</p><p>前者用在输入输出维度一致的情况下，后者在skip connection的时候加上了卷积，用在输入输出维度不一致的情况下</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;卷积神经网络编程作业&quot;&gt;&lt;a href=&quot;#卷积神经网络编程作业&quot; class=&quot;headerlink&quot; title=&quot;卷积神经网络编程作业&quot;&gt;&lt;/a&gt;卷积神经网络编程作业&lt;/h1&gt;&lt;h2 id=&quot;第一周编程作业&quot;&gt;&lt;a href=&quot;#第一周编程作业&quot; class
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/10/24/%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A/"/>
    <id>http://yoursite.com/2018/10/24/改善深层神经网络编程作业/</id>
    <published>2018-10-25T04:39:34.000Z</published>
    <updated>2018-10-25T04:39:34.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="改善深层神经网络编程作业"><a href="#改善深层神经网络编程作业" class="headerlink" title="改善深层神经网络编程作业"></a>改善深层神经网络编程作业</h1><h2 id="第一周编程作业"><a href="#第一周编程作业" class="headerlink" title="第一周编程作业"></a>第一周编程作业</h2><h3 id="assignment1"><a href="#assignment1" class="headerlink" title="assignment1"></a>assignment1</h3><p>Initialization</p><p>之前那种随机权重初始化的方法已经work out了，一个好的初始化可以；加快梯度收敛，减小训练误差</p><p>zero initialization: break symmetry。导致的结果是对称性破坏，每层的所有神经元学习一样的东西，这就相当于每层只有一个神经元，这样的话，神经网络和简单logistic regression比起来就毫无优越性</p><p>random initialization: 破坏对称性。如果是scale(*10)随机初始化，可能导致的结果是起始梯度爆炸</p><p>He initialization: 改变乘子，适用于ReLU的随机初始化。这个可以明显看到train set上的准确率和test set上的准确率好了很多</p><p>随机初始化式用来破坏神经元的对称性，保证不同层的不同神经元可以学习到不同的特征。并且要注意到不要把权重初始化过大，否则cost初始值会爆炸，然后He initialization在ReLU激活时表现非常好</p><h3 id="assignment2"><a href="#assignment2" class="headerlink" title="assignment2"></a>assignment2</h3><p>Regularization</p><p>L2 正则化：</p><p>解决过拟合的问题，在数据集较小的情况下，模型可也许能很好地拟合训练样本，但是缺少泛化能力</p><p>非正则化模型的锐化程度比较严重，对于噪声数据集会明显表现出overfitting</p><p>在算正则损失项的时候，主要要把每一层的正则损失加起来</p><p>加上正则项后，反向传播也要改写过，就在dW后面加上一个正则项导数就行了，比较简单</p><p>使用$$\lambda=0.7$$做尝试，可以发现测试准确率提升到了93%，成功拯救法国队</p><p>绘图也可以看到，加上正则项后明显减小了过拟合程度</p><p>需要注意的是，正则化系数是需要tuning的超参数，正则项带来的效应是weight decay</p><p>dropout：</p><p>shutdown neurons对正向传播和反向传播没有贡献</p><p>没有dropout的话可能会出现有神经元过度依赖于某个输入特征</p><p>在做dropout的时候每层的筛选矩阵D要与当前层的激活A维度保持一直，然后element wise乘法就可以筛选神经元了</p><p>dropout的反向传播：只要在对应的dA上作用D就行了，比较简单，主要要保证预测输出scale过，也就是dA=dA/keep_prob</p><p>这边我要吐槽一下这个作业的一个bug了，百分比算错，减法都不会算，应该是14%，具体哪里自己去找</p><p>结果可以看到是dropout之后模型在测试集上表现的准确率达到了95%，不过在训练集上却只有93%哈哈哈</p><p><strong>关于dropout一个常见的问题是在训练和测试的时候都用了dropout，实际上应该只在训练集上用dropout，从而提升模型的泛化能力，在测试集的时候再随机dropout的话就有点玄学了啊</strong></p><h3 id="assignment3"><a href="#assignment3" class="headerlink" title="assignment3"></a>assignment3</h3><p>grad check</p><p>梯度检验</p><p>梯度检验是建立在forward propagation是100%正确的基础上的，否则就是扯淡，如果是cost function都没算对，那还做啥梯度检验</p><p>检验的话就是用gradapprox去校准计算的grad值</p><p>学到的东西：<strong>numpy计算范数：numpy.linalg.norm()</strong>，貌似默认计算2范数</p><p>后面就是高维输入的梯度检验</p><p>区别在于高维梯度校验需要把每层的需要校验的梯度先处理一下，方法是从字典里面拿出来，然后连接在一起，然后一起校验</p><p><strong>这部分高维梯度检验做的有点迷糊，以后还需要再深入学习</strong></p><h2 id="第二周编程作业"><a href="#第二周编程作业" class="headerlink" title="第二周编程作业"></a>第二周编程作业</h2><h3 id="assignment"><a href="#assignment" class="headerlink" title="assignment"></a>assignment</h3><p>Optimization methods</p><p>GD: gradient descent</p><p>对于m个sample同时进行梯度下降也称为batch gradient descent</p><p>SGD: GD的一个变种，stochastic gradient descent，等价于mini batch中batch size为1的情况</p><p>SGD在大样本量的情况下迭代更快，但是会有更多的震荡</p><p>mini-batch gradient descent</p><p>steps：先shuffle，保证每次取的batch中的样本都比较随机，但是需要注意是shuffle要同时对X和Y做，否则就错了。然后做partition，因为样本数不一定被mini batch size整除，最后一个样本可能size会相对小</p><p>partition：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">first_mini_batch_X = shuffled_X[:, <span class="number">0</span> : mini_batch_size]</span><br><span class="line">second_mini_batch_X = shuffled_X[:, mini_batch_size : <span class="number">2</span> * mini_batch_size]</span><br></pre></td></tr></table></figure></p><p>只要注意处理一下最后一个batch的size就行了</p><p>怎么做shuffle：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">permutation = list(np.random.permutation(m))</span><br><span class="line">shuffled_X = X[:, permutation]</span><br><span class="line">shuffled_Y = Y[:, permutation].reshape((<span class="number">1</span>,m))</span><br></pre></td></tr></table></figure></p><p>怎么做sample：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mnini_batches = []</span><br><span class="line">mini_batch_X = shuffled_X[:,mini_batch_size*k:mini_batch_size*(k+<span class="number">1</span>)]</span><br><span class="line">mini_batch_Y = shuffled_Y[:,mini_batch_size*k:mini_batch_size*(k+<span class="number">1</span>)]</span><br><span class="line"></span><br><span class="line">mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">mini_batches.append(mini_batch)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> m % mini_batch_size != <span class="number">0</span>:</span><br><span class="line">mini_batch_X = shuffled_X[:,mini_batch_size*(k+<span class="number">1</span>):]</span><br><span class="line">    mini_batch_Y = shuffled_Y[:,mini_batch_size*(k+<span class="number">1</span>):]</span><br><span class="line">    </span><br><span class="line">   mini_batch = (mini_batch_X, mini_batch_Y)</span><br><span class="line">    mini_batches.append(mini_batch)</span><br></pre></td></tr></table></figure></p><p>Momentum，动量梯度下降：</p><p>动量梯度下降利用之前梯度下降的方向来使Update更加平滑</p><p>怎么写注释：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">Initializes the velocity as a python dictionary with:</span></span><br><span class="line"><span class="string">            - keys: "dW1", "db1", ..., "dWL", "dbL" </span></span><br><span class="line"><span class="string">            - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.</span></span><br><span class="line"><span class="string">Arguments:</span></span><br><span class="line"><span class="string">parameters -- python dictionary containing your parameters.</span></span><br><span class="line"><span class="string">                parameters['W' + str(l)] = Wl</span></span><br><span class="line"><span class="string">                parameters['b' + str(l)] = bl</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">Returns:</span></span><br><span class="line"><span class="string">v -- python dictionary containing the current velocity.</span></span><br><span class="line"><span class="string">                v['dW' + str(l)] = velocity of dWl</span></span><br><span class="line"><span class="string">                v['db' + str(l)] = velocity of dbl</span></span><br><span class="line"><span class="string">"""</span></span><br></pre></td></tr></table></figure></p><p>动量梯度下降，动量项用指数加权平均来更新，防止爆炸，然后参数项用类似之前的法则去更新即可，如果有必要就进行一下bias correction就行了</p><p>需要注意的一点是，速度项初始化为0，所以算法需要迭代几次之后才能把速度项build起来，然后迈更大的步子，$$\beta$$是动量系数，如果在意初值太小，可以做偏差校正，但是貌似不那么重要</p><p>然后下面给出一个经验性法则：<br>$$\beta$$取值在0.8-0.999之间，通常0.9是一个比较常用取值</p><p>用动量梯度下降需要tune两个超参数：动量系数$$\beta$$和学习速率$$\alpha$$</p><p>Adam:</p><p>Adam是最有效的优化算法之一，它结合了RMSprop和Momentum的思想</p><p>它计算了前层所有梯度的指数加权平均，然后做bias correction。另外就是计算前层梯度的均方指数加权平均，同时也做了偏差校正。然后用前面两项去做Update</p><p>做矩阵初始化时候的奇技淫巧：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">np.zeros_like(parameters[<span class="string">"W"</span> + str(l + <span class="number">1</span>)])</span><br></pre></td></tr></table></figure></p><p>再做adam的时候v和s分别做出一个字典来存</p><p>后面貌似都比较简单，就是给的代码模板里面有bug，真的想吐槽</p><p>第二周作业完结</p><h2 id="第三周编程作业"><a href="#第三周编程作业" class="headerlink" title="第三周编程作业"></a>第三周编程作业</h2><h3 id="assignment-1"><a href="#assignment-1" class="headerlink" title="assignment"></a>assignment</h3><p>TensorFlow tutorial</p><p>在这个编程作业中所要做的东西：</p><ul><li>初始化参数</li><li>创建session</li><li>训练算法</li><li>构建一个神经网络</li></ul><p>TensorFlow的整体步骤：</p><ol><li>创建Tensor</li><li>写定义这些Tensor的操作</li><li>初始化Tensor</li><li>创建会话session</li><li>跑session</li></ol><p>也就是说在define lost的时候是不会evaluate的，在init=tf.global_variables_initilizer()这句话中才会evaluate。然后再session.run的时候才会真正做好初始化</p><p>在没有run之前，给出的结果都是tensor，例如<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant(<span class="number">2</span>)</span><br><span class="line">b = tf.constant(<span class="number">10</span>)</span><br><span class="line">c = tf.multiply(a,b)</span><br><span class="line">print(c)</span><br><span class="line"><span class="comment"># output: Tensor("Mul:0", shape=(), dtype=int32)</span></span><br></pre></td></tr></table></figure></p><p>要计算tensor需要：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sess = tf.Session()</span><br><span class="line">print(sess.run(c))</span><br></pre></td></tr></table></figure></p><p>然后是placeholder，这是一个可以在后面指定值的对象，通过feed_dict来指定，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change the value of x in the feed_dict</span></span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.int64, name = <span class="string">'x'</span>)</span><br><span class="line">print(sess.run(<span class="number">2</span> * x, feed_dict = &#123;x: <span class="number">3</span>&#125;))</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure><p>在run的时候feed data就行了</p><p>然后后面开始真正的练习了</p><p>先是计算线性函数</p><p>然后计算sigmoid，tf有内置的sigmoid, softmax</p><p>placeholder更可以看成是一种参数传递的方法</p><p>然后是用tf内置函数计算了sigmoid激活和交叉熵损失的cost function，算是对placeholder的概念更加熟悉了，也明白了tf其实有很多高度封装的API</p><p>再后面试one hot，也就是热位编码器</p><p>one_hot热位编码是把行向量变成了矩阵，暂时不知道有啥用，不过矩阵的确是稀疏的</p><p>后面是用0和1进行初始化，就是用tf.ones和tf.zeros，接受参数是shape，vector形式的即可</p><p>再后面就算是一个大作业了，用TensorFlow构建一个神经网络</p><p>分为两大步：构建计算图和run</p><p>开始的时候要把label行向量one hot化成矩阵</p><p>然后做initialization，这部分有些API没有怎么看懂，因为同样道理，封装程度有点高</p><p>再后面就是前向传播，但是用tensorflow进行前向传播的时候要记住要停止在最后一层的激活之前，因为最后一层的激活是tensorflow计算损失的一个参数，这一步是在计算损失的时候做的。但不得不说的是tensorflow在做tensor运算的时候代码风格也TM太丑了，如果不是有运算符重载就要被我骂死了</p><p>再做完前向传播后就需要计算cost了，一行代码就搞定了</p><p>再后面就是计算反向传播，所有反向传播和权值更新都被封装好了</p><p>计算完cost后需要创建一个optimier对象，例如：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(cost)</span><br><span class="line">_ , c = sess.run([optimizer, cost], feed_dict=&#123;X: minibatch_X, Y: minibatch_Y&#125;)</span><br></pre></td></tr></table></figure><p>然后吐槽一下model的参数说明写错了</p><p>最后就是构建整个模型和训练测试，可以发现训练集上的准确率接近于100%，但是测试集上的准确率却只有71%，这TM的明显是过拟合了，加上regularization和dropout就行了</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;改善深层神经网络编程作业&quot;&gt;&lt;a href=&quot;#改善深层神经网络编程作业&quot; class=&quot;headerlink&quot; title=&quot;改善深层神经网络编程作业&quot;&gt;&lt;/a&gt;改善深层神经网络编程作业&lt;/h1&gt;&lt;h2 id=&quot;第一周编程作业&quot;&gt;&lt;a href=&quot;#第一周编程作
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/10/24/%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/10/24/改善深层神经网络课堂笔记/</id>
    <published>2018-10-24T11:30:46.000Z</published>
    <updated>2018-10-24T12:02:21.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="改善深层神经网络课堂笔记"><a href="#改善深层神经网络课堂笔记" class="headerlink" title="改善深层神经网络课堂笔记"></a>改善深层神经网络课堂笔记</h1><p>超参数调试、正则化及优化</p><h2 id="课时1-1"><a href="#课时1-1" class="headerlink" title="课时1.1"></a>课时1.1</h2><p>训练/开发/测试集</p><p>内容涉及hyperparameter tuning, set up date</p><p>decisions:</p><ul><li>layers</li><li>hidden units</li><li>learning rates</li><li>activation functions</li></ul><p>go round the cycle many times</p><p>总的数据分为几个部分，一部分是训练数据，一部分是简单的交叉验证集，这部分有时候也被称为development set(dev set)，最后一部分作为测试集</p><p>通过训练数据训练模型，通过验证集验证模型的效果，然后最后再测试集上进行评估</p><p>验证集的目的是验证哪种算法有效</p><p>在大数据时代，验证集和测试集不需要那么多数据，比如100万条数据，可能只需要1万条用来验证，1万条用来测试就可以了</p><p>建议保证验证集和测试集的数据来自于同一分布，因为训练模型需要很大的数据量，可能的结果就是训练集和测试/验证集不是来源于同一数据分布。这条是经验法则</p><p>有时候没有测试集，只有训练集和验证集，这样的话训练集还是训练集，但是验证集有时候就被称为测试集了</p><h2 id="课时1-2"><a href="#课时1-2" class="headerlink" title="课时1.2"></a>课时1.2</h2><p>偏差、方差</p><p>bias and variance trade-off</p><p>方差高：过拟合</p><p>偏差高：欠拟合</p><p>train set error</p><p>dev set error</p><p>数据在训练样本上表现好，在验证集上表现得很差：高方差</p><p>数据在训练集上表现差，在验证集上表现差：高偏差</p><p>数据在训练集上表现差，在验证集上表现特别差：高方差且高偏差</p><p>高偏差直观表现在没有比较好地拟合数据，高方差表现在局部拟合效果太好，表现太灵活</p><h2 id="课时1-3"><a href="#课时1-3" class="headerlink" title="课时1.3"></a>课时1.3</h2><p>机器学习基础</p><p>basic recipe for machine learning</p><p>评估的步骤：</p><ul><li>看看模型的是否高偏差，如果高偏差，就要试着评估一下模型在训练集上的表现。解决方法是用新的网络，用更深层的网络，训练更长的时间</li><li>偏差降低到一定程度后，再检查方差有没有问题，就要查看验证集性能。如果方差高，解决方法是：获取更多的数据，正则化</li><li>一直试一直试，知道找到一个低偏差和低方差的模型框架framework</li></ul><p>现在有工具和方法来只降低bias和variance的一方，而不会显著影响另一方，这也是深度学习现在能流行的重要原因之一</p><h2 id="课时1-4"><a href="#课时1-4" class="headerlink" title="课时1.4"></a>课时1.4</h2><p>正则化Regularization</p><p>解决高方差(过度拟合)的问题</p><p>正则化的方法是在cost function里面加上一个正则项</p><p>L2正则化：$$\frac{\lambda}{2m}||w||_{2}^{2}$$，欧几里得二范数</p><p>为什么不加b？因为W一般是高维的矩阵，加上他的正则项之后一般已经可以解决过拟合的问题了，就不需要加b了</p><p>L2正则化也是最常见的正则化方式</p><p>如果用L1正则化，W会是稀疏的</p><p>$$\lambda$$称为正则化参数</p><p>通常用验证集(交叉验证)来选择这个参数。python中lambda是保留字，用lambd即可</p><p>深度神经网络中的正则项是所有层正则项之和</p><p>矩阵(非向量)的2范数称为Frobenium Norm，下标用F，而不用2，区别于2范数。鉴于大家不可的原因，才有了这个规定。。。。</p><p>正则项的引入会到dW的计算带上一个正则项导数，然后用新的dW来进行反向传播和权值更新</p><p>引入正则项会引起权值递减(weight decay)。所以有时候L2正则化也被称为weight decay</p><h2 id="课时1-5"><a href="#课时1-5" class="headerlink" title="课时1.5"></a>课时1.5</h2><p>为什么正则项可以防止过拟合</p><p>添加正则项有助于防止权值矩阵的权重过大 </p><p>说实话关于正则化的解释我没有怎么看懂，这部分还需查询其他相关资料以及看看知乎才行</p><h2 id="课时1-6"><a href="#课时1-6" class="headerlink" title="课时1.6"></a>课时1.6</h2><p>Dropout</p><p>有多种实现Dropout的方法：</p><p>Inverted dropout：反向随机失活</p><p>对于l=3，设置d3 = np.random.rand(a3.shape[0],a3.shape[1])&lt;keep_prop</p><p>最后那个项表示保留某个神经元的概率，这个最后返回一个boolean矩阵</p><p>然后a3 = np.multiply(a3,d3)就可以过滤掉那些false的神经元</p><p>最后a3 /= keep_prop，是为了保证再计算z4的时候其期望值不变，这部分视频里没有解释得比较清楚</p><p>反向随机失活也是现在深度学习领域最常用的dropout方法</p><p>在测试阶段的话，就不要用dropout了，然后一个trick是在a/=keep_drop这一步cache住dropout之前的值，这样在测试的时候就不用浪费时间再去多算一遍了，是用空间换时间</p><h2 id="课时1-7"><a href="#课时1-7" class="headerlink" title="课时1.7"></a>课时1.7</h2><p>理解dropout</p><p>intuition</p><p>从之前的经验来理解的话dropout可以减小神经网络复杂度，从而减小过拟合的可能性。从另一个角度来看，即从单个神经元的角度来看，dropout减少了单个神经元的输入特征，这意味了这个神经元不能依赖于某个特定的特征，因为它们都可能被随机清除</p><p>dropout的效果类似于L2正则化</p><p>强调一下不同层的keep_prop设定可以不同，如果是参数密集的层，keep_prop可以设得相对小一点。0.5/0.7。如果某一层不用担心过拟合的问题，可以设置keep_prop为1</p><p>通常输入层不去做dropout。另外的话一个原则是如果算法不会出现过拟合，就不要用dropout。在CV中会经常用到dropout，但是在其他领域使用相对较少</p><p>使用dropout带来的后果是cost function不再有显式定义，所以很难double check，这样我们就失去了调试工具，<strong>所以Ag给出的一个经验是在调试back propagation看梯度下降的时候先关闭dropout，然后等调试好了再开启dropout</strong></p><h2 id="课时1-8"><a href="#课时1-8" class="headerlink" title="课时1.8"></a>课时1.8</h2><p>其他正则化方法</p><p>这就涉及图像处理之类的知识了，比如图片的翻转，随机裁剪</p><p>数据扩增可以作为正则化手段之一</p><p>另一种方法叫做early stopping</p><p>因为训练集误差通过 梯度下降可以一直递减，但是验证集误差可能是先递减后递增，early stopping选择在某个迭代次数之后停止</p><p>Orthogonalization正交化：独立处理cost function优化的问题和减小过拟合的问题</p><p>early stopping也存在缺点：会变成一个trade-off问题，因为模型在训练集上训练的效果可能不佳</p><p>不同人会用不同的dropout方法，Ag说他喜欢用L2正则化，后果是计算量会很大</p><h2 id="课时1-9"><a href="#课时1-9" class="headerlink" title="课时1.9"></a>课时1.9</h2><p>归一化输入，可以有效加快训练速度。normalize input</p><p>归一化输入有两步：</p><ol><li>零均值化(移动训练数据，直到零均值化) </li><li>归一化方差，也就是做一次scaling</li></ol><p>为什么要归一化输入特征：归一化函数可以让cost function看起来更加匀称，然后可能学习速率就更容易选择，归一化之前可能学习速率要很小才行</p><p>如果输入特征的scale不太一致，归一化就比较有用，如果是相似的scale，那么归一化可能也没啥用，但是也没啥坏处</p><h2 id="课时1-10"><a href="#课时1-10" class="headerlink" title="课时1.10"></a>课时1.10</h2><p>梯度消失和梯度爆炸</p><p>vanishing/exploding gradients</p><p>这个主要是深层神经网络会遇到的问题</p><p>这两个问题可以通过合适的随机权重初始化来解决</p><h2 id="课时1-11"><a href="#课时1-11" class="headerlink" title="课时1.11"></a>课时1.11</h2><p>深层神经网络权重初始化</p><p>vanishing and exploding gradients</p><p>直接理解：输入特征越多的话，希望W的scale小一点，因为z是累加值</p><p>合适的做法是：</p><p>$$W^{[l]}=np.random.randn(shape)*np.sqrt(\frac{1}{n^{[l-1]}})$$</p><p>这边有个引用方差的问题，Ag说Relu激活可以选的引用方差源是$$\frac{2}{n}$$</p><p>不过这个貌似是经验法则了，我目前任然不太理解，或许这个也是一个超参数吧</p><p>后面讲了如何选择这些引用方差是有相关paper证明的，就总结一下：</p><ul><li>relu: $$np.sqrt(\frac{2}{n})$$。最常用</li><li>tanh: $$np.sqrt(\frac{1}{n})$$。被称为<strong>Xavier初始化</strong></li></ul><p>方差参数是一个另外需要tune的hyperparameter。<strong>不过这个超参数的调优的优先级比较低，因为常常效果不明显</strong></p><h2 id="课时1-12"><a href="#课时1-12" class="headerlink" title="课时1.12"></a>课时1.12</h2><p>梯度的数值逼近</p><p>是为了做梯度检验</p><p>在做梯度检验的时候，多用双边误差而少用单边误差</p><h2 id="课时1-13"><a href="#课时1-13" class="headerlink" title="课时1.13"></a>课时1.13</h2><p>梯度检验</p><p>帮助发现反向传播中存在的bug</p><p>gradient checking -&gt; grad check</p><p>做梯度检验就是做一个loop，然后对每个d的element做双边误差检验</p><p>check：计算欧式距离，然后用向量长度做归一化 -&gt; into ratio</p><p>给出一个标准：一般10^-7量级是没啥问题的；如果是10^-5就要稍微小心了；10^-3量级，那基本就是有bug了</p><p><strong>Ag说梯度检验帮他发现了很多bug</strong></p><h2 id="课时1-14"><a href="#课时1-14" class="headerlink" title="课时1.14"></a>课时1.14</h2><p>关于梯度检验的实操技巧</p><ul><li>不要在训练的时候用梯度检验，只有在debug的时候需要进行梯度检验，检验完成后就可以关闭梯度检验了</li><li>如果梯度检验出错，那么要检查所有项</li><li>在做梯度检验的时候记住还有正则项，因为正则项也会带来梯度</li><li>梯度检验不能和dropout一起用，这一点在dropout的时候已经说过了，dropout和梯度有点不太兼容，所以一般都是先做好bg，做好gc，然后再去做dropout</li></ul><h2 id="课时2-1"><a href="#课时2-1" class="headerlink" title="课时2.1"></a>课时2.1</h2><p>优化算法</p><p>mini-batch</p><p>每个batch的X用$$X^1$$表示</p><p>epoch: 一代</p><h2 id="课时2-2"><a href="#课时2-2" class="headerlink" title="课时2.2"></a>课时2.2</h2><p>batch gradient descent的具体实现</p><p>SGD：每次一个样本</p><p>batch gradient descent：一次全部样本</p><p>分别是mini-batch的两个极端情况</p><p>在mini batch的时候一个epoch是整个数据集，即所有batch都进行过一遍梯度下降，称为一代</p><h2 id="课时2-3"><a href="#课时2-3" class="headerlink" title="课时2.3"></a>课时2.3</h2><p>指数加权平均，快于梯度下降</p><p>exponentially weighted averages</p><p>统计学中也叫指数移动加权平均</p><p>$$V_{t}=\beta V_{t-1}+(1-\beta)\theta_{t}$$</p><p>其中$$\beta$$为加权参数，$$\beta$$很大的时候可以看到曲线很平滑，因为平滑的天数很多，很小的时候噪声很大，起伏很大，能更好地拟合数据，但是缺乏泛化能力</p><p>通常$$\beta$$取某个中间值会更好</p><h2 id="课时2-4"><a href="#课时2-4" class="headerlink" title="课时2.4"></a>课时2.4</h2><p>指数加权平均的本质</p><p>从计算和内存的角度讲，指数加权平均是一个非常高效的算法</p><h2 id="课时2-5"><a href="#课时2-5" class="headerlink" title="课时2.5"></a>课时2.5</h2><p>指数加权平均中的偏差修正</p><p>目的是让平均数计算更精确</p><p>需要进行偏差修正的原因是初始化会被放小很多</p><p>在预测初期，指数加权平均很难预测正确</p><p>修正策略是用$$\frac{V_{t}}{1-\beta^{t}}$$来修正</p><p>偏差修正能让模型在早期的时候表现更出色</p><h2 id="课时2-6"><a href="#课时2-6" class="headerlink" title="课时2.6"></a>课时2.6</h2><p>动量梯度下降</p><p>momentum</p><p>出现这个方法的原因是传统梯度下降会有摆动，从而限制了学习速率不能太快</p><p>区别在于权值更新的时候用动量值去更新，动量的计算就是根据指数加权平均来算</p><p>在动量梯度下降里，常用的$$\beta$$是0.9，也就是平均了过去十天的迭代梯度</p><p>在这个方法里，偏差修正不常用，因为迭代十次之后可以认为是度过了迭代初期</p><p>现在有两种动量梯度下降的公式，其中一种要注意scale，一种则不需要，因为是线性加权(指数加权平均)</p><h2 id="课时2-7"><a href="#课时2-7" class="headerlink" title="课时2.7"></a>课时2.7</h2><p>RMSprop</p><p>root mean square prop</p><p>这个和动量梯度下降相似，都是在全值更新策略那一步做了修改</p><p>目的同样是减小无关方向上的摆动</p><p>这个方向主要是利用微分，而上个方法主要是利用指数加权平均，这样就比较好理解了</p><p>均方根</p><p>在保证数值稳定的时候会在分母的地方加上一个小项，防止出现爆炸的值</p><h2 id="课时2-8"><a href="#课时2-8" class="headerlink" title="课时2.8"></a>课时2.8</h2><p>Adam优化算法，结合Momentum和RMSprop</p><p>实现：初始化方均根项和动量项都为0</p><p>可以使用偏差修正</p><p>这是一种非常常用的优化算法，被证明了泛化能力强，能适用于不同的神经网络</p><p>超参数：学习速率，$$\beta_{1} = 0.9, \beta_{2} = 0.999, \epsilon = 10e(-8)$$</p><h2 id="课时2-9"><a href="#课时2-9" class="headerlink" title="课时2.9"></a>课时2.9</h2><p>learning rate decay</p><p>学习率衰减</p><p>decay rate是另一个需要tune的超参数</p><p>衰减公式有多种选择</p><h1 id="课时2-10"><a href="#课时2-10" class="headerlink" title="课时2.10"></a>课时2.10</h1><p>局部最优问题 local optima</p><p>成本函数的零梯度点是鞍点</p><p>problem of plateaus</p><h2 id="课时3-1"><a href="#课时3-1" class="headerlink" title="课时3.1"></a>课时3.1</h2><p>调试处理</p><p>调试优先级</p><p>随机取点而不要用grid</p><p>由粗到细的策略</p><h2 id="课时3-2"><a href="#课时3-2" class="headerlink" title="课时3.2"></a>课时3.2</h2><p>选择合适的scale</p><p>线性指标和对数指标</p><p>学习速率用对数指标来采样</p><p>$$\beta$$是另一个比较麻烦的超参数，表示指数加权参数</p><p>也不能用线性取值，考虑$$1-\beta$$</p><p>在某些区域取值需要密集，有些区域取值要松散</p><h2 id="课时3-3"><a href="#课时3-3" class="headerlink" title="课时3.3"></a>课时3.3</h2><p>超参数训练实践</p><p>每间隔几个月要重新调一次超参数</p><p>两种基本策略：一种是babysit一个module，另一种是训练多个模型</p><p>由拥有的计算资源决定，如果有多个网络</p><h2 id="课时3-4"><a href="#课时3-4" class="headerlink" title="课时3.4"></a>课时3.4</h2><p>normalization</p><p>归一化</p><p>batch normalization</p><p>数据归一化normalization的作用是把狭长的数据变成圆的东西</p><p>归一化是用均值和方差来进行归一化</p><p>对于深层神经网络，问题在于是否能归一化中间的激活值，从而使后面的权重系统矩阵训练得更快</p><p>上面的是batch normalization</p><p>对隐藏层的z计算均值和方差，然后做归一化就行了，归一化成0均值和1方差</p><p>我们所指的normalization指的是输入数据的归一化，batch normalization指的是对所有层的z进行归一化</p><p>但是隐藏单元可能不希望归一化成0均值和1方差，这个可以自由设定</p><h2 id="课时3-5"><a href="#课时3-5" class="headerlink" title="课时3.5"></a>课时3.5</h2><p>应用batch normalization</p><p>每个神经元上对应着两步：计算z和计算a</p><p>实际上framework会帮我们做好batch normalization而不需要手动去实现</p><p>$$\beta和\gamma$$是用来进行均值和方差缩放的系数</p><p>在batch normalization中，因为要处理均值和缩放，所以在计算线性函数的时候偏执项基本没用，因为BN的时候会把偏差均衡掉，bias的作用由$$\gamma$$来体现</p><p>带BN的反向传播部需要计算db，原因之前已经讲过了</p><h2 id="课时3-6"><a href="#课时3-6" class="headerlink" title="课时3.6"></a>课时3.6</h2><p>BN为什么能加速训练模型训练</p><p>这个问题的直观理解是tranfer上的问题，在一类集上如果分类表现得很好，在另一类集上可能就表现得不那么好，解决的方法是进行BN，在同样的scale上处理这个问题，改变数据分布，叫做covariate shift</p><p>中间隐藏值的分布可能会出现变化，BN的作用就是减小这部分的变化，使得后面的权重矩阵鲁棒性更强，因为BN说不管你前面的数据分布怎么变化，我可以让这一层的均值和方差保持不变，它限制了前层参数更新对后层的影响</p><p>BN和dropout的相似之处在于在每个层的神经元上增加了噪音</p><p>BN有轻微正则化的效果</p><h2 id="课时3-7"><a href="#课时3-7" class="headerlink" title="课时3.7"></a>课时3.7</h2><p>测试时的BN</p><p>注意一个样本的均值是对样本中的所有数据而言的，但是很多个batch的均值就是用到指数加权平均了，当然这只是建议做法，估算均值完全是怎么想怎么做</p><h2 id="课时3-8"><a href="#课时3-8" class="headerlink" title="课时3.8"></a>课时3.8</h2><p>Softmax回归</p><p>之前是二分分类 binary classification</p><p>多分类的概率问题</p><p>多个输出单元，显示各个类的概率</p><p>Softmax分类在没有隐藏层的情况下能够给出线性分类边界区分各个类</p><p>带隐藏层和激活函数可以有非线性决策边界</p><h2 id="课时3-9"><a href="#课时3-9" class="headerlink" title="课时3.9"></a>课时3.9</h2><p>深入学习Softmax分类</p><p>hardmax</p><p>Softmax把概率映射变得更加温和</p><p>如果C=2，那么Softmax就变成了logistic regression</p><p>怎么训练Softmax的神经网络：</p><p>Softmax的损失函数</p><p>最大似然估计</p><h2 id="课时3-10"><a href="#课时3-10" class="headerlink" title="课时3.10"></a>课时3.10</h2><p>深度学习框架</p><p>使用一些框架可以提高效率</p><h2 id="课时3-11"><a href="#课时3-11" class="headerlink" title="课时3.11"></a>课时3.11</h2><p>Tensorflow</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">coefficients = np.array([[<span class="number">1.</span>],[<span class="number">-10.</span>],[<span class="number">25.</span>]])</span><br><span class="line"></span><br><span class="line">w = tf.Variable(<span class="number">0</span>,dtype=tf.float32)</span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="number">3</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># cost = tf.add(tf.add(w**2,tf.multiply(-10,w)),25)</span></span><br><span class="line">cost = x[<span class="number">0</span>][<span class="number">0</span>]*w**<span class="number">2</span>+x[<span class="number">1</span>][<span class="number">0</span>]*w+x[<span class="number">2</span>][<span class="number">0</span>]</span><br><span class="line">tf = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cost)</span><br><span class="line"></span><br><span class="line">init = tf.global_initilizer()</span><br><span class="line">session = tf.Sessions()</span><br><span class="line">session.run(init)</span><br><span class="line">print(session.run(w))</span><br><span class="line"></span><br><span class="line">session.run(train, feed_dict=[x:coefficients]) <span class="comment">#one iteration</span></span><br><span class="line">print(session.run(w))</span><br></pre></td></tr></table></figure><p>tensorflow重载了运算符，写公式可以更简单一点</p><p>placeholder是一个之后要赋值的变量，这种方式便于把数据加入cost function</p><p>创建session，session初始化和session.run是常用表达</p><p>常用with语句来写这三条常用表达</p><p>第二个课到此完结了！</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;改善深层神经网络课堂笔记&quot;&gt;&lt;a href=&quot;#改善深层神经网络课堂笔记&quot; class=&quot;headerlink&quot; title=&quot;改善深层神经网络课堂笔记&quot;&gt;&lt;/a&gt;改善深层神经网络课堂笔记&lt;/h1&gt;&lt;p&gt;超参数调试、正则化及优化&lt;/p&gt;
&lt;h2 id=&quot;课时1-1
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/10/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%AF%BE%E5%A0%82%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2018/10/21/神经网络和深度学习课堂笔记/</id>
    <published>2018-10-21T12:24:17.000Z</published>
    <updated>2018-10-21T12:24:28.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络和深度学习课堂笔记"><a href="#神经网络和深度学习课堂笔记" class="headerlink" title="神经网络和深度学习课堂笔记"></a>神经网络和深度学习课堂笔记</h1><p>Goal:</p><ul><li>理解驱动深度学习的主要技术趋势</li><li>能够搭建、训练并运用全连接的深层网络</li><li>了解如何实现高效的（向量化）神经网络</li><li>理解神经网络架构中的关键参数</li></ul><h2 id="课时2-1"><a href="#课时2-1" class="headerlink" title="课时2.1"></a>课时2.1</h2><p>学习神经网络编程的基础知识</p><p>正向传播过程和反向传播过程forward, backward</p><p>二分类问题</p><p>计算机保存一张图片要用三个矩阵，分别表示三个通道</p><p>矩阵向量化：变成特征向量，如果是64*64的矩阵。则向量化后向量的维度是64*64*3</p><p>用m表示训练样本数</p><p>设计矩阵用列向量堆叠的方式会好很多：</p><p>X.shape</p><p>标签的向量化矩阵是1*m的，其中m表示样本数。Y.shape = (1, m)</p><h2 id="课时2-2"><a href="#课时2-2" class="headerlink" title="课时2.2"></a>课时2.2</h2><p>logistic regression</p><p>给定x，希望计算出y的预测值 y = P(1|x)</p><p>$$\hat{y} = w^{T}x+b$$</p><p>由于y的值不在0-1之间，希望要把它进行概率归一化</p><p>需要使用sigmoid函数</p><p>$$\hat{y} = \sigma(w^{T}x+b)$$</p><p>$$\sigma(z)=\frac{1}{1+e^{-z}}$$</p><p>如果z是很大的负数，则概率接近于0。如果z是很大的正数，则概率接近于1</p><p>预测函数里的b项是intercepter</p><p>$$\theta$$是列向量，用$$\theta_{0}$$来表示常数项b。然后在样本项x中引入一个1即可</p><h2 id="课时2-3"><a href="#课时2-3" class="headerlink" title="课时2.3"></a>课时2.3</h2><p>loss funciton 和 cost function不一样</p><p>表示第i个样本的预测值<br>$$\hat{y}^{(i)} = \sigma(w^{T}x^{(i)}+b)$$</p><p>$$\sigma(z)=\frac{1}{1+e^{-z}}$$</p><p>用上标指明数据样本</p><p>在logistic中使用的损失函数loss function：<br>$$L(\hat{y},y) = -(ylog\hat{y}+(1-y)log(1-\hat{y}))$$</p><p>选修视频中会讲为什么这么选损失函数</p><p>cost function:</p><p>$$J(w,b) = \frac{1}{m}\sum_{i=1}^{m}L(\hat{y,y})$$</p><p>loss funtion应用于单个训练样本，计算单个样本的损失程度</p><p>cost function是成本函数，计算整个训练集的总体损失</p><p>目标是找w，b，使得cost function尽量小</p><h2 id="课时2-4"><a href="#课时2-4" class="headerlink" title="课时2.4"></a>课时2.4</h2><p>梯度下降法</p><p>训练和学习w和b</p><p>凸函数可以更好地进行梯度下降</p><p>对logistic回归而言，几乎任何初始化值都是可行的</p><p>minimize J(w,b)</p><p>梯度下降的过程：</p><p>$$w := w-\alpha\frac{dJ(w)}{dw}$$</p><p>$$\alpha$$表示学习速率。之后会讲如何选择learning rate</p><p>在表示上，用dw表示导数项</p><p>$$w := w - \alpha dw$$</p><p>梯度表示切线斜率</p><p>后面的课讲导数和微积分</p><h2 id="课时2-5"><a href="#课时2-5" class="headerlink" title="课时2.5"></a>课时2.5</h2><p>讲导数</p><h2 id="课时2-6"><a href="#课时2-6" class="headerlink" title="课时2.6"></a>课时2.6</h2><p>讲导数</p><h2 id="课时2-7"><a href="#课时2-7" class="headerlink" title="课时2.7"></a>课时2.7</h2><p>Computation Graph计算图</p><p>前向传播用来计算神经网路的输出，反向传播用来计算出对应的梯度或导数</p><p>根据运算符优先级计算</p><h2 id="课时2-8"><a href="#课时2-8" class="headerlink" title="课时2.8"></a>课时2.8</h2><p>计算图的导数计算</p><p>链式法则计算导数的反向传播</p><p>chain rule</p><p>在编程的时候，就用dvar表示目标输出对于var的导数</p><p>分析梯度就是给变量一个微小增量，看目标输出变量的变化情况</p><h2 id="课时2-9"><a href="#课时2-9" class="headerlink" title="课时2.9"></a>课时2.9</h2><p>logistic回归中的梯度下降法</p><p>表示输出<br>$$\hat{y} = a = \sigma(z)$$</p><p>$$z = w^{T}x+b$$</p><p>步骤：<br>w1,w2,x1,x2,b</p><p>$$z = w_{1}x_{1}+w_{2}x_{2}+b$$ 计算输出</p><p>$$\hat{y} = a = \sigma(z)$$ 计算概率输出，也即计算激活函数值</p><p>$$L(a,y)$$ 计算损失函数</p><p>需要做的是修正w和b，从而减少损失函数L</p><h2 id="课时2-10"><a href="#课时2-10" class="headerlink" title="课时2.10"></a>课时2.10</h2><p>m个样本的梯度下降</p><p>$$a^{(i)}=\hat{y}^{(i)}=\sigma(z^{i})=\sigma(w^{T}x^{(i)}+b)$$</p><p>累加器，全局成本函数cost function，然后对训练样本数做平均，计算完后，做全局更新</p><p>这节课还没讲向量化。向量化之后就会好很多。</p><p>后面的视频会讲向量化</p><h1 id="课时2-11"><a href="#课时2-11" class="headerlink" title="课时2.11"></a>课时2.11</h1><p>向量化</p><p>numpy：z = np.dot(w,x)</p><p>向量化版本比非向量化版本快很多</p><p>numpy可以自己执行并行化</p><h2 id="课时2-12"><a href="#课时2-12" class="headerlink" title="课时2.12"></a>课时2.12</h2><p>讲了logistic的向量化</p><p>recap了一下</p><p>对于正向传播，每个样本都需要计算激活函数值，sigmoid激活到0-1之间</p><h2 id="课时2-13-2-14"><a href="#课时2-13-2-14" class="headerlink" title="课时2.13-2.14"></a>课时2.13-2.14</h2><p>设计矩阵列堆叠，也是横向堆叠<br> 一次性计算所有z：</p><p> 构建一个1*m的矩阵</p><p> $$Z = np.dot(w.T,X)+b$$</p><p> numpy会将b自动广播为一个行向量</p><p> 然后计算a：激活函数值</p><p> 无论是正向传播还是反向传播，向量化都可以加速计算</p><p>$$dZ = A-Y$$</p><p>$$dw = \frac{1}{m}XdZ^{T}$$</p><p>$$db = \frac{1}{m}np.sum(dZ)$$</p><p>迭代次数的for没有办法去掉</p><h2 id="课时2-15"><a href="#课时2-15" class="headerlink" title="课时2.15"></a>课时2.15</h2><p>axis表示竖向</p><h2 id="课时2-16"><a href="#课时2-16" class="headerlink" title="课时2.16"></a>课时2.16</h2><p>python numpy</p><p>broadcasting</p><p>tricks来排除问题，简化程序</p><p>建议不要用(5,)或(n,)这种秩为1的结构</p><p>用(5,1)，不要用(5,)</p><p>用assert(a.shape == (5,1))来保证不出错，检查矩阵维度</p><p>图片属于非结构化数据？</p><p>神经元节点先计算线性函数再算激活函数</p><h2 id="课时3-1"><a href="#课时3-1" class="headerlink" title="课时3.1"></a>课时3.1</h2><p>神经网络概览</p><p>表示：用[1] [2]来表示神经网络的各个层</p><h2 id="课时3-2"><a href="#课时3-2" class="headerlink" title="课时3.2"></a>课时3.2</h2><p>神经网络的表示</p><p>输入层，隐藏层，输出层</p><p>$$a^{[0]}$$表示输入层的激活值</p><p>$$a^{[1]}<em>{1} a^{[1]}</em>{2}$$表示隐藏层的激活值</p><p>$$a^{[1]}$$是一个多维列向量</p><p>计算网络的层数的时候不管输入层</p><h2 id="课时3-3"><a href="#课时3-3" class="headerlink" title="课时3.3"></a>课时3.3</h2><p>计算神经网络的输出</p><p>recat表示方法：上标表示神经网路的层数，下标表示第几个神经元</p><p>向量化表示：把w的转置进行行堆叠，作为左乘矩阵，然后输入向量x是特征列堆叠，得到一个列向量，b向量也是一个列向量</p><p>把激活函数值也可以堆叠成列向量</p><p>$$z^{[1]} = W^{[1]}x+b^{[1]}$$</p><p>$$a^{[1]}=\sigma(z^{[2]}) $$</p><h2 id="课时3-4"><a href="#课时3-4" class="headerlink" title="课时3.4"></a>课时3.4</h2><p>多个例子中的向量化（举例）</p><p>$$a^{<a href="1">2</a>}$$表示第二层神经元中的第一个样本激活值</p><p>数据输入X还是进行列向量堆叠，同样将Z，a都进行列向量堆叠</p><p>以A为例，由于是列堆叠，横向看表示不同的样本的激活值。纵向看是同一个样本在同一层中不同神经元上的激活值。纵向different hidden unions，横向different training examples。</p><h2 id="课时3-5"><a href="#课时3-5" class="headerlink" title="课时3.5"></a>课时3.5</h2><p>向量化的直观解释</p><p>多样本向量化的解释</p><p>把X(列堆叠成的输入向量)看成是$$A^{[0]}$$</p><p>然后就可以完全向量化表示了</p><h2 id="课时3-6"><a href="#课时3-6" class="headerlink" title="课时3.6"></a>课时3.6</h2><p>使用不同的激活函数</p><p>之前一直用的是$$\sigma$$激活函数，但有时候其他的激活函数的效果会更好</p><p>$$z^{[1]}=W^{[1]}x+b^{[1]}$$</p><p>$$a^{[1]} = \sigma(z^{[1]})$$</p><p>tanh函数总是比sigmoid函数表现好，即双曲正弦函数</p><p>$$tanh(z) = \frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$$</p><p>实际上tanh函数是sigmoid函数平移后的结果</p><p>tanh函数的一个好处是有数据中心化的效果</p><p>Ag说tanh函数几乎在任何场合下都比sigmoid函数表现优越</p><p> 例外是在输出层，二分类问题中可能会在输出层用到sigmoid函数来进行激活</p><p>有时候在激活函数上面加上上标用来表示不同层的激活函数是不同的</p><p>sigmoid函数和tanh函数的共同缺点是梯度可能消失</p><p>另外一个比较受欢迎的激活函数是纠正线性单元：ReLU，Rectifier linear unit</p><p>$$a = max(0,z)$$</p><p>讲了选择激活函数的经验法则：</p><p>如果输出值时0或1，即如果做二元分类，那么sigmoid函数比较适合做输出层的激活函数，然后其他单元用ReLU做激活函数。这种组合也变成了现在默认的激活函数选择方案。ReLU有一个修正版本：leaky ReLU：当z为负数时，给予一个比较小的导数，而不是令导数为0。使用ReLU的一个好处也是训练神经网络速度会更快，主要原因是ReLU没有导数接近于0这种效应，所以学习速率不会被减慢</p><p>Ag在这节课严重批判了sigmoid函数</p><h2 id="课时3-7"><a href="#课时3-7" class="headerlink" title="课时3.7"></a>课时3.7</h2><p>讲了一下为什么总是要用非线性激活函数，这个问题机器学习课老师也讲了</p><p>因为非线性函数激活理论上可以用来拟合任意非线性可分问题</p><h2 id="课时3-8"><a href="#课时3-8" class="headerlink" title="课时3.8"></a>课时3.8</h2><p>激活函数的导数</p><p>backpropagation</p><p>导数的表示：<br>$$g^{‘}(z)$$叫做g prime of z</p><h2 id="课时3-9"><a href="#课时3-9" class="headerlink" title="课时3.9"></a>课时3.9</h2><p>据说是激动人心的一个课时。。。</p><p>实现back propagation / gradient descent</p><p>表示：</p><p>参数：</p><p>$$n^{[0]}, n^{[1]}, n^{[2]}$$</p><p>分别表示输入量个数，隐藏单元个数，输出单元个数</p><p>损失函数cost function：</p><p>$$J(W^{[1]},b^{[1]}, W^{[2]}, b^{[2]}) = \frac{1}{m}\sum{L(y,\hat{y})}$$</p><p>训练参数就用梯度下降</p><p>在训练神经网络的时候，随机初始化参数很重要</p><p>Update:</p><p>$$ W^{[1]} = W^{[2]} - \alpha dW^{[1]}$$</p><p>$$ b^{[1]} = b^{[2]} - \alpha db^{[1]}$$</p><p>关于dW和db的含义，之前讲过的，就不重复了</p><p>正向传播：反正就是计算线性函数，计算激活值，然后从前面向后面逐层传递</p><p>反向传播：计算导数</p><p>然后np中keepdims = true这个参数的作用是防止numpy输出秩为1的矩阵：(n,)这种，而是命令它保持维度，输出(n,1)这样的</p><p>如果不调用keepdims参数，则要用reshape来调整维度</p><h2 id="课时3-10-选修"><a href="#课时3-10-选修" class="headerlink" title="课时3.10(选修)"></a>课时3.10(选修)</h2><p>看看反向传播的灵感来源</p><p>由流程图推导出梯度公式</p><p>这个视频中有一个等式写错了，当然可能是我钻牛角尖了才觉得它错了，在01:19</p><h2 id="课时3-11"><a href="#课时3-11" class="headerlink" title="课时3.11"></a>课时3.11</h2><p>如何初始化参数</p><p>随机初始化</p><p>全0初始化会导数symmetric的问题，无论训练时间多长，每个神经元的权重参数都是一样的，这样的话，多个隐藏神经元就没有啥用了</p><p>solution:</p><p>$$W^{[1]} = np.random.randn(…)*0.01$$</p><p> b不会导致对称问题，所以是可以把b初始化成0的</p><p>将权重乘一个很小的系数是为了防止激活函数的参数绝对值比较大，而导致梯度平缓的问题，也叫做饱和</p><h2 id="课时4-1"><a href="#课时4-1" class="headerlink" title="课时4.1"></a>课时4.1</h2><p><strong>看这一章的收获还是非常大的，对向量化的概念有了更加深入的理解</strong></p><p>深度神经网络</p><p>目标是把学习的综合起来，build your own deep neural network</p><p>做一个编程大作业</p><p>logistic regression —- shallow model</p><p>denotion: 用L表示层数</p><p>用$$n^{[i]}$$表示第i个层上的单元数量</p><p>$$a^{[l]} = g^{[l]}(z^{[l]})$$表示l层中的的激活函数</p><p>$$W^{[l]}$$表示</p><h2 id="课时4-2"><a href="#课时4-2" class="headerlink" title="课时4.2"></a>课时4.2</h2><p>深层网络中的前向传播和反向传播</p><p>前向传播公式：</p><p>$$Z^{[n+1]}=W^{[n+1]}a^{[n]}+b^{[n+1]}$$</p><p>$$A^{[n+1]}=g^{[n+1]}(Z^{[n]})$$</p><p>这边02:26的地方一个公式又写错了</p><p>Z是一层上单个样本的所有Z，然后所有样本竖向堆叠而成的</p><p>正向传播中用for loop没问题</p><p>防止程序bug的方法是想办法检查矩阵的维度</p><h2 id="课时4-3"><a href="#课时4-3" class="headerlink" title="课时4.3"></a>课时4.3</h2><p>核对矩阵的维数</p><p>是拿出一张纸，然后确保各个地方计算的矩阵维度没有问题</p><p>$$W^{[l]}$$的维度是$$(n^{[l]}, n^{[l-1]})$$</p><p>a和z的维度是相同的</p><p>聚合所有样本之后的向量化：</p><p>$$Z^{[1]} = W^{[1]}X+b^{[1]}$$</p><p>其中Z是所有小z的列堆叠，每个小z代表一个样本在一个层上所有输出的堆叠向量，W维度不变，而X变成了所有输入向量的列堆叠，b也随之广播成了列堆叠</p><p>和之前的比一下：</p><p>$$z^{[l]}$$和$$a^{[l]}$$的维度原来都是$$(n^{[l]},1)$$</p><p>后来变成了$$(n^{[l]},m)$$。是把所有样本进行列堆叠而成的结果</p><h2 id="课时4-4"><a href="#课时4-4" class="headerlink" title="课时4.4"></a>课时4.4</h2><p>为什么深度神经网络表现得比浅层神经网络好？</p><p>深度网络的前几层学习低层次的特征，在后面几层，就会把简单的特征结合起来，去探测更加复杂的东西</p><p>deep learning: great brand</p><h2 id="课时4-5"><a href="#课时4-5" class="headerlink" title="课时4.5"></a>课时4.5</h2><p>搭建深度网络块</p><p>把过程中计算得到的a，z之类的缓存起来</p><h2 id="课时4-6"><a href="#课时4-6" class="headerlink" title="课时4.6"></a>课时4.6</h2><p>正向传播和反向传播的具体实现过程</p><h2 id="课时4-7"><a href="#课时4-7" class="headerlink" title="课时4.7"></a>课时4.7</h2><p>参数和超参数</p><p>超参数：比如学习速率和迭代次数、隐藏层数、隐藏单元数、激活函数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经网络和深度学习课堂笔记&quot;&gt;&lt;a href=&quot;#神经网络和深度学习课堂笔记&quot; class=&quot;headerlink&quot; title=&quot;神经网络和深度学习课堂笔记&quot;&gt;&lt;/a&gt;神经网络和深度学习课堂笔记&lt;/h1&gt;&lt;p&gt;Goal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解驱动深度学
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/10/21/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A/"/>
    <id>http://yoursite.com/2018/10/21/神经网络和深度学习编程作业/</id>
    <published>2018-10-21T12:23:57.000Z</published>
    <updated>2018-10-21T12:24:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络和深度学习编程作业"><a href="#神经网络和深度学习编程作业" class="headerlink" title="神经网络和深度学习编程作业"></a>神经网络和深度学习编程作业</h1><h2 id="第二周编程作业"><a href="#第二周编程作业" class="headerlink" title="第二周编程作业"></a>第二周编程作业</h2><h3 id="assignment1"><a href="#assignment1" class="headerlink" title="assignment1"></a>assignment1</h3><p>学习numpy和iPython notebook</p><p>学习np.exp, np.log, np.reshape的使用</p><p>如果x = (x1, x2, …xn)是行向量，那么np.exp会按元素进行指数运算</p><p>也可以使用np.exp?来快速获取关于该函数的帮助</p><p>后面用numpy写了sigmoid函数以及计算sigmoid函数的原始梯度，比较简单</p><p>然后是矩形的形状变换：np.shape, np.reshape()</p><p>三个维度的图像的reshape:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">v =  image.reshape((image.shape[<span class="number">0</span>]*image.shape[<span class="number">1</span>],image.shape[<span class="number">2</span>]))</span><br></pre></td></tr></table></figure></p><p>然后讲了归一化技巧，normalize</p><p>行归一化，这里需要使用一个新的np函数</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: normalizeRows</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalizeRows</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement a function that normalizes each row of the matrix x (to have unit length).</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Argument:</span></span><br><span class="line"><span class="string">    x -- A numpy matrix of shape (n, m)</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    x -- The normalized (by row) numpy matrix. You are allowed to modify x.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    <span class="comment"># Compute x_norm as the norm 2 of x. Use np.linalg.norm(..., ord = 2, axis = ..., keepdims = True)</span></span><br><span class="line">    x_norm = np.linalg.norm(x,ord = <span class="number">2</span>, axis = <span class="number">1</span>, keepdims = <span class="keyword">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Divide x by its norm.</span></span><br><span class="line">    x = x/x_norm</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>说明一下np.linalg.norm中的ord参数原为order，即表示范数的阶数</p><p>这个函数可以计算总共8阶范数</p><p>再后面就是讲了numpy的广播机制，看到过无数次了</p><p>以softmax激活函数为例，练习了这个广播机制如何使用</p><p>后面就不讲numpy了，开始练向量化vectorization</p><p>然后注意一下np.dot执行的是矩阵和矩阵或者矩阵和向量之间的乘法，而np.multiply或者*执行的是矩阵的按元素乘法</p><p>后面就是写损失函数，要写L1损失和L2损失</p><p>trick: 用np.dot(x,x)可以用来计算按元素平方</p><h3 id="assignment2"><a href="#assignment2" class="headerlink" title="assignment2"></a>assignment2</h3><p>做一个能够识别猫的简单神经网络</p><p>将学会：</p><ul><li><p>初始化参数</p></li><li><p>计算损失函数和梯度</p></li><li><p>使用一个优化算法(梯度下降)</p></li></ul><p>h5py包用来处理 H5 file</p><p>training set说明：一共208张训练的图片，每张图片被展开成一个行向量，一起拼接成一个矩阵</p><p>testing set说明：一共49个测试样本，每个样本也是被展开成一个行向量，一起拼接成一个矩阵</p><p>在读取到的数据样本后面加上_orig表示后面还要处理</p><p>读取到的每个训练样本都是一个64*64*3的矩阵，表示一张图片，其中3表示共有3个颜色通道</p><p>然后后面就简单练习一下可视化图片，提供numpy矩阵的维度特征，reshape，reshape之后就获得了列堆叠的二维向量，列数表示样本数，行数表示一个样本的特征数</p><p><strong>这边有必要说一个reshape的trick</strong></p><p>下面代码可以将X展平成列堆叠，当然X.shape[0]需要是样本总数才行，-1表示从原矩形剩下维度推测并进行展平，比较实用的一个技巧，不用麻烦自己去算剩下的维chu度<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_flatten = X.reshape(X.shape[<span class="number">0</span>], <span class="number">-1</span>).T</span><br></pre></td></tr></table></figure></p><p>对于图像数据集，做归一化处理的更简便方法是同时除255</p><p>总结一下数据集预处理所做的工作：导入数据，找出数据的维度特征，然后进行reshape，然后再进行归一化处理</p><p>然后后面开始正式写神经网络了，要做的工作如下：</p><ul><li>初始化模型的参数</li><li>通过最小化损失来学习模型参数</li><li>使用学习到的参数来做预测</li><li>分析结果并进行总结</li></ul><p>先写了一个向量化的sigmoid函数</p><p>写了参数初始化函数，这边比较值得注意的一个点是np.zeros函数接受的shape为元组格式，千万不要自作聪明传了两个数字进去</p><p>前向和反向传播</p><p>写propagate来计算损失函数和梯度</p><p>把progage算法贴一下，还是比较有价值的，其中计算了前向传播和反向传播梯度<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: propagate</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">propagate</span><span class="params">(w, b, X, Y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Implement the cost function and its gradient for the propagation explained above</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span></span><br><span class="line"><span class="string">    b -- bias, a scalar</span></span><br><span class="line"><span class="string">    X -- data of size (num_px * num_px * 3, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Return:</span></span><br><span class="line"><span class="string">    cost -- negative log-likelihood cost for logistic regression</span></span><br><span class="line"><span class="string">    dw -- gradient of the loss with respect to w, thus same shape as w</span></span><br><span class="line"><span class="string">    db -- gradient of the loss with respect to b, thus same shape as b</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Tips:</span></span><br><span class="line"><span class="string">    - Write your code step by step for the propagation. np.log(), np.dot()</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    m = X.shape[<span class="number">1</span>]  <span class="comment"># number of samples</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># FORWARD PROPAGATION (FROM X TO COST)</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    A = sigmoid(np.dot(w.T,X)+b)            <span class="comment"># compute activation</span></span><br><span class="line">    cost = <span class="number">1</span>/m*np.sum(Y*A+(<span class="number">1</span>-Y)*np.log(<span class="number">1</span>-A))         <span class="comment"># compute cost</span></span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># BACKWARD PROPAGATION (TO FIND GRAD)</span></span><br><span class="line">    <span class="comment">### START CODE HERE ### (≈ 2 lines of code)</span></span><br><span class="line">    dw = <span class="number">1</span>/m*np.dot(X,(A-Y).T)</span><br><span class="line">    db = <span class="number">1</span>/m*np.sum(A-Y)</span><br><span class="line">    <span class="comment">### END CODE HERE ###</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">assert</span>(dw.shape == w.shape)</span><br><span class="line">    <span class="keyword">assert</span>(db.dtype == float)</span><br><span class="line">    cost = np.squeeze(cost)</span><br><span class="line">    <span class="keyword">assert</span>(cost.shape == ())</span><br><span class="line">    </span><br><span class="line">    grads = &#123;<span class="string">"dw"</span>: dw,</span><br><span class="line">             <span class="string">"db"</span>: db&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> grads, cost</span><br></pre></td></tr></table></figure></p><p>优化：</p><p>要做的事情：</p><p>计算当前参数的cost和gradient（使用之前写的propogate函数）</p><p>使用梯度下降法更新参数</p><p>把优化optimazation函数也贴一下，总体也算是比较有用的</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GRADED FUNCTION: optimize</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">optimize</span><span class="params">(w, b, X, Y, num_iterations, learning_rate, print_cost = False)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    This function optimizes w and b by running a gradient descent algorithm</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Arguments:</span></span><br><span class="line"><span class="string">    w -- weights, a numpy array of size (num_px * num_px * 3, 1)</span></span><br><span class="line"><span class="string">    b -- bias, a scalar</span></span><br><span class="line"><span class="string">    X -- data of shape (num_px * num_px * 3, number of examples)</span></span><br><span class="line"><span class="string">    Y -- true "label" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)</span></span><br><span class="line"><span class="string">    num_iterations -- number of iterations of the optimization loop</span></span><br><span class="line"><span class="string">    learning_rate -- learning rate of the gradient descent update rule</span></span><br><span class="line"><span class="string">    print_cost -- True to print the loss every 100 steps</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Returns:</span></span><br><span class="line"><span class="string">    params -- dictionary containing the weights w and bias b</span></span><br><span class="line"><span class="string">    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function</span></span><br><span class="line"><span class="string">    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Tips:</span></span><br><span class="line"><span class="string">    You basically need to write down two steps and iterate through them:</span></span><br><span class="line"><span class="string">        1) Calculate the cost and the gradient for the current parameters. Use propagate().</span></span><br><span class="line"><span class="string">        2) Update the parameters using gradient descent rule for w and b.</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    </span><br><span class="line">    costs = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(num_iterations):</span><br><span class="line">        </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Cost and gradient calculation (≈ 1-4 lines of code)</span></span><br><span class="line">        <span class="comment">### START CODE HERE ### </span></span><br><span class="line">        grads, cost = propagate(w, b, X, Y)</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Retrieve derivatives from grads</span></span><br><span class="line">        dw = grads[<span class="string">"dw"</span>]</span><br><span class="line">        db = grads[<span class="string">"db"</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># update rule (≈ 2 lines of code)</span></span><br><span class="line">        <span class="comment">### START CODE HERE ###</span></span><br><span class="line">        w = w - learning_rate * dw</span><br><span class="line">        b = b - learning_rate * db</span><br><span class="line">        <span class="comment">### END CODE HERE ###</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Record the costs</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            costs.append(cost)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Print the cost every 100 training examples</span></span><br><span class="line">        <span class="keyword">if</span> print_cost <span class="keyword">and</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="keyword">print</span> (<span class="string">"Cost after iteration %i: %f"</span> %(i, cost))</span><br><span class="line">    </span><br><span class="line">    params = &#123;<span class="string">"w"</span>: w,</span><br><span class="line">              <span class="string">"b"</span>: b&#125;</span><br><span class="line">    </span><br><span class="line">    grads = &#123;<span class="string">"dw"</span>: dw,</span><br><span class="line">             <span class="string">"db"</span>: db&#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> params, grads, costs</span><br></pre></td></tr></table></figure><p>下面就是写预测(假设)函数predict了，用m来表示训练样本数，比较简单</p><p>最后就是集成前面所有写的函数到一个model里面了</p><p>最后测试了一下模型，发现在训练集上的准确率是99%多，但是在测试集上的准确率只有70%，题目也说了这个logistic回归这个东西的准确率本身就不高，也就是说写了这么多就是玩玩而已的</p><p>训练集准确率上升而测试集准确率下降称为overfit</p><p>总结来说cost函数不是越小越好，因为可能是overfit的情况</p><p>在深度学习中，通常是选择学习率使得代价函数尽可能小，然后选择用其他的策略来解决overfit的问题</p><p>从这次编程作业中学习到的东西：</p><p>数据集预处理是很重要的</p><p>分开写每个函数：initialize(),propogate(),optimize(),然后model(),改变学习速率learning_rate可以改变算法性能</p><h2 id="第三周编程作业"><a href="#第三周编程作业" class="headerlink" title="第三周编程作业"></a>第三周编程作业</h2><p>带有一个隐藏层的平面数据分类</p><p>构建具有单隐藏层的2分类神经网络</p><p>值得注意的一点是里面那个神经网络的结构图和实际构建的图是有出入的，数据规模是不一样的</p><p>使用非线性激活函数</p><p>计算交叉熵损失</p><p>实现前向和后向传播</p><p>数据格式：</p><p>X: 2*400，表示的是每个数据有两个特征，一共有400个训练样本</p><p>Y：表示数据标签，规模是1*400，400个<br>训练样本</p><p>X:(x1, x2)</p><p>Y: red为0，blue为1</p><p>然后后面先做了简单logistic回归，再做单隐层神经网络</p><p>sklearn有内置做logisdic回归的函数</p><p>logistic regression准确率只有47%左右，因为数据集不是线性可分的，表现不佳</p><p>后面试神经网络模型</p><p>Recap一下：</p><p>Steps：</p><ol><li>定义神经网络结构</li><li>初始化模型参数</li><li>循环：完成前向传播，计算损失函数，完成后向传播获得梯度，更新参数(梯度下降)</li></ol><p>先是定义各个层神经元结构，输入层几个，隐藏层几个，输出层几个</p><p>然后做初始化</p><p>方法是在初始化函数里对权值W做高斯随机初始化，然后偏执b初始化为0</p><p>真TM的坑，numpy的zeros函数接受参数是两个，random.randn接受的参数是元祖，这TM是哪个白痴设计的</p><p>后面开始前向传播</p><p>np.tanh函数可以直接用，它是内置在numpy里面的</p><p>从字典中取出元素：</p><p>parameters[“..”]</p><p>然后用正向传播的方法计算了逐层的输出</p><p>np.squeeze函数</p><p>后面计算了cost function，简单用一下np.log和sum，进行向量化计算就行了</p><p>cache：缓存着各层神经元的线性输出值和激活值</p><p>反向传播的难点在于公式，如果公式知道了，反向传播也就很容易了</p><p>当然模板好在有公式可以套用，写起来就简单了</p><p>然后后面就是写Optimize函数了，梯度下降更新参数</p><p>最后写完了所有函数就是integratge into a complete model了</p><p>这边说一下我遇到的一个大坑，我在W初始化的时候W2忘记乘上一个小的系数了，最后导致在计算sigmoid的时候exp里面的参数特别大，但是我后来乘上0.01那个数还是特别大就不知道是怎么回事。因为如果那个值特别大的话，可能导致的结果是梯度消失，但numpy报错，说明那个已经大得离谱了，已经超时计算机表示范围了</p><h2 id="第四周编程作业"><a href="#第四周编程作业" class="headerlink" title="第四周编程作业"></a>第四周编程作业</h2><p>其中assignment1实现深层神经网络，然后assignment2应用此神经网络进行图像分类</p><h3 id="assignment1-1"><a href="#assignment1-1" class="headerlink" title="assignment1"></a>assignment1</h3><p>实现构建深度神经网络的所有函数</p><p>使用非线性激活单元如ReLU</p><p>创建一个容易使用的神经网络类(编程中的代码规范问题)</p><p>表示：用[l]上标表示第l层的参数，用(i)表示第i个样本的对应值，用下标i表示某一层的某一个神经元单元</p><p>dnn_utils提供了必要的函数，是作者提供的</p><p>testCase提供了一些测试样例，用来评估整个网络的正确性</p><p>Outline：</p><p>对2层和L层神经网络implement initialization</p><p>完成前向传递模块，包括：线性，ReLU激活，整合，完成整个前向传播过程，然后最后用sigmoid来处理输出</p><p>计算cost function</p><p>完成反向传播模块，包括：线性，梯度导数，整合，完成整个反向传播过程</p><p>最后更新参数</p><p>后面正式开始写了</p><p>先是完成两层和多层神经网络参数初始化</p><p>注意在多层神经网络中，各层的神经元数被存放在layer_dims中。模板给的实现方法很简介，我特别喜欢</p><p>前向传播模块：</p><p>公式：$$Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]}$$</p><p>前向传播模块它只做了一步，没有一下子全部传播完，就是计算了一次传播，并把中间值：前层激活，当前层W，b缓存起来。然后另开一个函数去计算当前层的激活</p><p>关于激活函数，除了计算出当前层的激活值外，还缓存当前层激活和Z</p><p>linear_activation_forward函数：接受前层激活，W，b和激活函数，计算传播并缓存中间量。LINEAR-&gt;ACTIVATION layer。缓存分为线性缓存和激活缓存</p><p>这部分代码我也比较喜欢，它把线性前传和缓存分开成一个单独的函数，总的就有两个函数，看起来比较舒服，不会是一个很长的函数的</p><p>然后对于L层深度神经网络，就是把上面的linear_activation_forward前传L-1次，模块化去实现，真的特别棒，这边需要稍微注意一下的一个point是完成L层前向传播的时候注意字典索引，每层的W和b是不同的</p><p>后面计算cost function，简单交叉熵损失</p><p>输入的是预测的概率向量(1,numofex)，以及给定的训练样本标签</p><p>后面计算后向传播，跟前面的前向传播类似，也是完成一层的后传，然后再完成L层后传。用来计算损失函数相对于parameters的各个梯度。三步走：线性后传，线性到激活(同层激活函数导数计算)，整体总和完成L-1次后传</p><p>第一个是线性后向传递，接受参数是损失函数对当前Z的计算导数，以及前传中获得的缓存cache，记录A,W,b，要返回dA,dW,db。这里要注意的一个点是在计算db的时候记得在np.sum里面加上选项keepdims=True，不加的话返回结果会是一个纯量，或者类似于(n,)这种形式，但是要求返回的是(1,1)的ndarry格式数据，这里也体现出了keepdims选项还是非常重要的</p><p>后面就是完成线性-&gt;激活后传，也就是在前面加上激活函数对原变量的导数项而已，没什么麻烦的，然后原作者已经把sigmoid和relu的导数分别封装成函数了，这种代码风格也非常棒。参数：dA，缓存项，以及激活函数值。这部分代码真的写得非常棒，值得学习，我估计得到积累很久才能写出这样水平的代码</p><p>后面就是写L层后传了，这个和L层前传不一样的地方是L层后传的初始化参数需要计算出来：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dAL = - (np.divide(Y, AL) - np.divide(<span class="number">1</span> - Y, <span class="number">1</span> - AL)) <span class="comment"># derivative of cost with respect to AL</span></span><br></pre></td></tr></table></figure></p><p>这里就出现一个大坑了，L后传的整合函数里面涉及到前面一个shape的问题，在linear_back的地方，有个db在计算的时候需要制定axis=1和keepdims=True，如果不指定axis=1，前面测试不会出错，但是但这里，所有样本堆叠测试的时候就会出现shape不匹配的问题，所以这个给我的教训是任何时候要注意shape，在任何时候记住有axis和keepdims这两个选项！！！</p><p>后面简单写一个更新参数的函数，比较简单，update W和b就行了</p><h3 id="assignment2-1"><a href="#assignment2-1" class="headerlink" title="assignment2"></a>assignment2</h3><p>本课程的最后一个作业，用assignment1里完成的各个模块搭建一个完整的神经网络。要求搭建一个2层的和一个深层的</p><p>给定数据集包含了猫和非猫的数据，猫标签为1，非猫标签为0</p><p>每张图片的shape是(num_px,num_px,3)，3表示有3个通道</p><p>一共有209张训练的图片和50张测试的图片</p><p>在训练之前，需要对每张图片的数据进行标准化(列向量化)，也即flattern，标准化意味着把RGB值归一化到0-1之间，除以255即可。最后train的数据就是列向量堆叠，每一列代表一张图片，test也类似</p><p>通用方法学：</p><ol><li>初始化参数/定义超参数</li><li>循环迭代若干次：前向传播，计算损失，反向传播，更新参数</li><li>使用训练好的模型来进行预测</li></ol><p>关于浅层神经网络，需要注意的一点是在训练集上的准确率几乎到了100%，但是到测试集上只有72%，但是至少比logistic regression要好</p><p>5层神经网络在测试集上的准确率达到了80%</p><p>在下一节课中会讲如何系统选取超参数来提升神经网络的表现： learning_rate, layers_dims, num_iterations, and others</p><p>到此为此，第一个课的所有编程作业已经完成，接下来学习如何选择神经网路的参数，后面再学卷积神经网络，进度还算不错</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经网络和深度学习编程作业&quot;&gt;&lt;a href=&quot;#神经网络和深度学习编程作业&quot; class=&quot;headerlink&quot; title=&quot;神经网络和深度学习编程作业&quot;&gt;&lt;/a&gt;神经网络和深度学习编程作业&lt;/h1&gt;&lt;h2 id=&quot;第二周编程作业&quot;&gt;&lt;a href=&quot;#第二
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title></title>
    <link href="http://yoursite.com/2018/10/17/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2018/10/17/神经网络和深度学习/</id>
    <published>2018-10-18T02:21:49.000Z</published>
    <updated>2018-10-18T02:21:49.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="神经网络和深度学习课堂笔记"><a href="#神经网络和深度学习课堂笔记" class="headerlink" title="神经网络和深度学习课堂笔记"></a>神经网络和深度学习课堂笔记</h1><p>Goal:</p><ul><li>理解驱动深度学习的主要技术趋势</li><li>能够搭建、训练并运用全连接的深层网络</li><li>了解如何实现高效的（向量化）神经网络</li><li>理解神经网络架构中的关键参数</li></ul><h2 id="课时2-1"><a href="#课时2-1" class="headerlink" title="课时2.1"></a>课时2.1</h2><p>学习神经网络编程的基础知识</p><p>正向传播过程和反向传播过程forward, backward</p><p>二分类问题</p><p>计算机保存一张图片要用三个矩阵，分别表示三个通道</p><p>矩阵向量化：变成特征向量，如果是64*64的矩阵。则向量化后向量的维度是64*64*3</p><p>用m表示训练样本数</p><p>设计矩阵用列向量堆叠的方式会好很多：</p><p>X.shape</p><p>标签的向量化矩阵是1*m的，其中m表示样本数。Y.shape = (1, m)</p><h2 id="课时2-2"><a href="#课时2-2" class="headerlink" title="课时2.2"></a>课时2.2</h2><p>logistic regression</p><p>给定x，希望计算出y的预测值 y = P(1|x)</p><p>$$\hat{y} = w^{T}x+b$$</p><p>由于y的值不在0-1之间，希望要把它进行概率归一化</p><p>需要使用sigmoid函数</p><p>$$\hat{y} = \sigma(w^{T}x+b)$$</p><p>$$\sigma(z)=\frac{1}{1+e^{-z}}$$</p><p>如果z是很大的负数，则概率接近于0。如果z是很大的正数，则概率接近于1</p><p>预测函数里的b项是intercepter</p><p>$$\theta$$是列向量，用$$\theta_{0}$$来表示常数项b。然后在样本项x中引入一个1即可</p><h2 id="课时2-3"><a href="#课时2-3" class="headerlink" title="课时2.3"></a>课时2.3</h2><p>loss funciton 和 cost function不一样</p><p>表示第i个样本的预测值<br>$$\hat{y}^{(i)} = \sigma(w^{T}x^{(i)}+b)$$</p><p>$$\sigma(z)=\frac{1}{1+e^{-z}}$$</p><p>用上标指明数据样本</p><p>在logistic中使用的损失函数loss function：<br>$$L(\hat{y},y) = -(ylog\hat{y}+(1-y)log(1-\hat{y}))$$</p><p>选修视频中会讲为什么这么选损失函数</p><p>cost function:</p><p>$$J(w,b) = \frac{1}{m}\sum_{i=1}^{m}L(\hat{y,y})$$</p><p>loss funtion应用于单个训练样本，计算单个样本的损失程度</p><p>cost function是成本函数，计算整个训练集的总体损失</p><p>目标是找w，b，使得cost function尽量小</p><h2 id="课时2-4"><a href="#课时2-4" class="headerlink" title="课时2.4"></a>课时2.4</h2><p>梯度下降法</p><p>训练和学习w和b</p><p>凸函数可以更好地进行梯度下降</p><p>对logistic回归而言，几乎任何初始化值都是可行的</p><p>minimize J(w,b)</p><p>梯度下降的过程：</p><p>$$w := w-\alpha\frac{dJ(w)}{dw}$$</p><p>$$\alpha$$表示学习速率。之后会讲如何选择learning rate</p><p>在表示上，用dw表示导数项</p><p>$$w := w - \alpha dw$$</p><p>梯度表示切线斜率</p><p>后面的课讲导数和微积分</p><h2 id="课时2-5"><a href="#课时2-5" class="headerlink" title="课时2.5"></a>课时2.5</h2><p>讲导数</p><h2 id="课时2-6"><a href="#课时2-6" class="headerlink" title="课时2.6"></a>课时2.6</h2><p>讲导数</p><h2 id="课时2-7"><a href="#课时2-7" class="headerlink" title="课时2.7"></a>课时2.7</h2><p>Computation Graph计算图</p><p>前向传播用来计算神经网路的输出，反向传播用来计算出对应的梯度或导数</p><p>根据运算符优先级计算</p><h2 id="课时2-8"><a href="#课时2-8" class="headerlink" title="课时2.8"></a>课时2.8</h2><p>计算图的导数计算</p><p>链式法则计算导数的反向传播</p><p>chain rule</p><p>在编程的时候，就用dvar表示目标输出对于var的导数</p><p>分析梯度就是给变量一个微小增量，看目标输出变量的变化情况</p><h2 id="课时2-9"><a href="#课时2-9" class="headerlink" title="课时2.9"></a>课时2.9</h2><p>logistic回归中的梯度下降法</p><p>表示输出<br>$$\hat{y} = a = \sigma(z)$$</p><p>$$z = w^{T}x+b$$</p><p>步骤：<br>w1,w2,x1,x2,b</p><p>$$z = w_{1}x_{1}+w_{2}x_{2}+b$$ 计算输出</p><p>$$\hat{y} = a = \sigma(z)$$ 计算概率输出，也即计算激活函数值</p><p>$$L(a,y)$$ 计算损失函数</p><p>需要做的是修正w和b，从而减少损失函数L</p><h2 id="课时2-10"><a href="#课时2-10" class="headerlink" title="课时2.10"></a>课时2.10</h2><p>m个样本的梯度下降</p><p>$$a^{(i)}=\hat{y}^{(i)}=\sigma(z^{i})=\sigma(w^{T}x^{(i)}+b)$$</p><p>累加器，全局成本函数cost function，然后对训练样本数做平均，计算完后，做全局更新</p><p>这节课还没讲向量化。向量化之后就会好很多。</p><p>后面的视频会讲向量化</p><h1 id="课时2-11"><a href="#课时2-11" class="headerlink" title="课时2.11"></a>课时2.11</h1><p>向量化</p><p>numpy：z = np.dot(w,x)</p><p>向量化版本比非向量化版本快很多</p><p>numpy可以自己执行并行化</p><h2 id="课时2-12"><a href="#课时2-12" class="headerlink" title="课时2.12"></a>课时2.12</h2><p>讲了logistic的向量化</p><p>recap了一下</p><p>对于正向传播，每个样本都需要计算激活函数值，sigmoid激活到0-1之间</p><h2 id="课时2-13-2-14"><a href="#课时2-13-2-14" class="headerlink" title="课时2.13-2.14"></a>课时2.13-2.14</h2><p>设计矩阵列堆叠，也是横向堆叠<br> 一次性计算所有z：</p><p> 构建一个1*m的矩阵</p><p> $$Z = np.dot(w.T,X)+b$$</p><p> numpy会将b自动广播为一个行向量</p><p> 然后计算a：激活函数值</p><p> 无论是正向传播还是反向传播，向量化都可以加速计算</p><p>$$dZ = A-Y$$</p><p>$$dw = \frac{1}{m}XdZ^{T}$$</p><p>$$db = \frac{1}{m}np.sum(dZ)$$</p><p>迭代次数的for没有办法去掉</p><h2 id="课时15"><a href="#课时15" class="headerlink" title="课时15"></a>课时15</h2><p>axis表示竖向</p><h2 id="课时16"><a href="#课时16" class="headerlink" title="课时16"></a>课时16</h2><p>python numpy</p><p>broadcasting</p><p>tricks来排除问题，简化程序</p><p>建议不要用(5,)或(n,)这种秩为1的结构</p><p>用(5,1)，不要用(5,)</p><p>用assert(a.shape == (5,1))来保证不出错，检查矩阵维度</p><p>图片属于非结构化数据？</p><p>神经元节点先计算线性函数再算激活函数</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;神经网络和深度学习课堂笔记&quot;&gt;&lt;a href=&quot;#神经网络和深度学习课堂笔记&quot; class=&quot;headerlink&quot; title=&quot;神经网络和深度学习课堂笔记&quot;&gt;&lt;/a&gt;神经网络和深度学习课堂笔记&lt;/h1&gt;&lt;p&gt;Goal:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;理解驱动深度学
      
    
    </summary>
    
    
  </entry>
  
</feed>
