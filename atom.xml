<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Qingliu</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-09-28T03:06:37.159Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Qingliu</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ACM算法笔记</title>
    <link href="http://yoursite.com/2019/09/25/ACM%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/"/>
    <id>http://yoursite.com/2019/09/25/ACM算法笔记/</id>
    <published>2019-09-26T02:15:34.000Z</published>
    <updated>2019-09-28T03:06:37.159Z</updated>
    
    <content type="html"><![CDATA[<p>ACM算法笔记</p><a id="more"></a><h1 id="欧拉回路"><a href="#欧拉回路" class="headerlink" title="欧拉回路"></a>欧拉回路</h1><p>欧拉回路存在的充要条件：</p><ul><li>无向图：连通并且最多存在两个奇点（奇点：度数为奇数的点）</li><li>有向图：底图连通并且一个点入度比出度大1，一个点出度比入度大1，其他点入度等于出度</li></ul><p>编程的时候DFS，最后判断一遍是否访问到所有节点就行了，用邻接矩阵表示图（因为要随时看边是否被访问过，邻接矩阵效率更高）</p><h1 id="枚举排列"><a href="#枚举排列" class="headerlink" title="枚举排列"></a>枚举排列</h1><p>升序枚举：</p><p>递归调用，一个参数为当前序列，一个参数为可选元素集合，在不可重集时没问题，在可重集的时候要保证下标不重复</p><p>关于升序排列，也可以利用C++ STL里面的<code>next_permutation</code>函数来执行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line">...;</span><br><span class="line"><span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)<span class="built_in">printf</span>(<span class="string">"%d "</span>, p[i]);</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"\n"</span>);</span><br><span class="line">&#125; <span class="keyword">while</span>(next_permutation(p,p+n));</span><br><span class="line">...;</span><br></pre></td></tr></table></figure><p>而且<code>next_permutaiton</code>适用于可重集（那还自己写干啥-.-）</p><h1 id="子集生成"><a href="#子集生成" class="headerlink" title="子集生成"></a>子集生成</h1><h2 id="位向量法"><a href="#位向量法" class="headerlink" title="位向量法"></a>位向量法</h2><p>用一个位向量表示是否选取某个元素</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print_subset</span><span class="params">(<span class="keyword">int</span> n, <span class="keyword">int</span>* B, <span class="keyword">int</span> cur)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(cur == n) &#123;</span><br><span class="line">        <span class="comment">// print</span></span><br><span class="line">    &#125;</span><br><span class="line">    B[cur] = <span class="number">1</span>;</span><br><span class="line">    print_subset(n, B, cur+<span class="number">1</span>);<span class="comment">// 选第cur个元素</span></span><br><span class="line">    B[cur] = <span class="number">0</span>;</span><br><span class="line">    print_subset(n, B, cur+<span class="number">1</span>);<span class="comment">// 不选cur个元素</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>有点回溯剪枝的感觉</p><h2 id="二进制法"><a href="#二进制法" class="headerlink" title="二进制法"></a>二进制法</h2><p>部分没看懂。。。</p><h1 id="回溯"><a href="#回溯" class="headerlink" title="回溯"></a>回溯</h1><p>深度优先</p><h2 id="八皇后"><a href="#八皇后" class="headerlink" title="八皇后"></a>八皇后</h2><p>但是时间复杂度比较难算</p><h2 id="素数环"><a href="#素数环" class="headerlink" title="素数环"></a>素数环</h2><p>问题描述：把整数1，2，3，…，n组成一个环，使相邻整数和为素数</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> cur)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(cur==n &amp;&amp; isp(A[<span class="number">0</span>]+A[n<span class="number">-1</span>])) &#123;</span><br><span class="line">        <span class="comment">//print</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">2</span>; i&lt;=n; i++) &#123;<span class="comment">// 1固定为环起点，位置无所谓，所以从2开始试</span></span><br><span class="line">        <span class="keyword">if</span>(!vis[i] &amp;&amp; isp[i+A[cur<span class="number">-1</span>]]) &#123;</span><br><span class="line">            A[cur] = i;</span><br><span class="line">            vis[i] = <span class="number">1</span>;<span class="comment">// 记录访问，递归到下一层</span></span><br><span class="line">            dfs(cur+<span class="number">1</span>);</span><br><span class="line">            vis[i] = <span class="number">0</span>;<span class="comment">//清除访问，试下一个(回溯剪枝)</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;ACM算法笔记&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="C++" scheme="http://yoursite.com/tags/C/"/>
    
      <category term="Algorithm" scheme="http://yoursite.com/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>OCaml Learning Notes</title>
    <link href="http://yoursite.com/2019/09/12/OCaml%20Learning%20Notes/"/>
    <id>http://yoursite.com/2019/09/12/OCaml Learning Notes/</id>
    <published>2019-09-12T23:54:34.000Z</published>
    <updated>2019-09-21T19:58:44.487Z</updated>
    
    <content type="html"><![CDATA[<p>OCaml Notes</p><a id="more"></a><h1 id="Core-Language"><a href="#Core-Language" class="headerlink" title="Core Language"></a>Core Language</h1><p>First of all, the best REPL choice is <code>utop</code> program running under the terminal. Under this interactive environment, the OCaml phrases terminated with <code>;;</code> will be evaluated. User inputs (system command) are specified with <code>#</code>  at the beginning.</p><p>Type assertion: <code>exp : typ</code>. The type assertion is said to be valid iff the expression <code>exp</code> has type <code>typ</code>.</p><h2 id="Binding"><a href="#Binding" class="headerlink" title="Binding"></a>Binding</h2><p>Binding is permanent and can not be changed within specific scope of the program (normally the global scope).</p><p>Syntax of <strong>type binding</strong>:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> tycon = typ</span><br></pre></td></tr></table></figure><p>Semantics: <code>tycon</code> is a type constructor, bound to type <code>typ</code></p><p>Syntax of <strong>value binding</strong>:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> var : typ = exp</span><br></pre></td></tr></table></figure><p>Semantics: <code>var</code> is a variable, introduced the type <code>typ</code> and value <code>exp</code>. Notice that we must specify both the type and value of this type. There will be type-checking when binding, if succeed, expression <code>exp</code> will be evaluated first, and then its value is bound to variable <code>var</code>. If <code>exp</code> does not have a value, then binding never happens. (Notice that <code>None</code> is a value.)</p><p>Variable name must start with a lowercase letter or an underscore and excludes other punctuations.</p><p><strong>Purpose of binding</strong>: Make a variable or type constructor available for use within its scope.</p><p><strong>Substitution principle</strong>: A bound variable or type constructor is implicitly <em>replaced</em> by its binding prior to type checking and evaluation.</p><p><strong>Compound Declarations (Bindings)</strong>: This is defined by sequential bindings of the form <em>dec1, dec2, …decn</em>, with nested scope.</p><p><strong>Binding is not assignment</strong>: The binding of a variable never changes, once bound to a value, it is always bound to that value (within the scope of the binding). But we can <em>shadow</em> a binding by introducing a second binding for a variable within the scope of the first binding. One might say that old bindings never die, they just fade away.</p><p><strong>Type environment records the types of variables. Value environment records their values.</strong></p><p><strong>local binding</strong>: </p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> x = u <span class="keyword">in</span> v</span><br></pre></td></tr></table></figure><p>The binding of <code>x</code> to the result of <code>u</code> is only visible within the expression <code>v</code>. The semantics is to evaluate <code>u</code> first and bind to variable <code>x</code>, finally evaluate <code>v</code> with this bounded variable <code>x</code>.</p><p>Notes: local binding shadowing only happens during that binding period, for example:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> x = <span class="number">1</span></span><br><span class="line"><span class="keyword">let</span> y = <span class="keyword">let</span> x = <span class="number">2</span> <span class="keyword">in</span> x</span><br><span class="line"><span class="keyword">let</span> z = x + <span class="number">2</span></span><br><span class="line"><span class="comment">(* z will be binded to 3, not 4 because the global binding of x becomes visible again *)</span></span><br></pre></td></tr></table></figure><h2 id="Primitive-Data-Types"><a href="#Primitive-Data-Types" class="headerlink" title="Primitive Data Types"></a>Primitive Data Types</h2><ul><li>int (31-bit sign int on 32-bit processors or 63-bit sign int on 64-bit processors)</li><li>float (IEEE double-precision floating point)</li></ul><ul><li>booleans</li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># (<span class="number">1</span> &lt; <span class="number">2</span>) = <span class="literal">false</span>;;</span><br><span class="line">- : <span class="built_in">bool</span> = <span class="literal">false</span></span><br><span class="line"></span><br><span class="line"># <span class="keyword">let</span> one = <span class="keyword">if</span> <span class="literal">true</span> <span class="keyword">then</span> <span class="number">1</span> <span class="keyword">else</span> <span class="number">2</span>;;</span><br><span class="line"><span class="keyword">val</span> one : <span class="built_in">int</span> = <span class="number">1</span></span><br></pre></td></tr></table></figure><ul><li>characters (8-bit)</li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="string">'a'</span>;;</span><br><span class="line">- : <span class="built_in">char</span> = <span class="string">'a'</span></span><br><span class="line"></span><br><span class="line"># int_of_char <span class="string">'\n'</span></span><br><span class="line">- : <span class="built_in">int</span> = <span class="number">10</span></span><br></pre></td></tr></table></figure><ul><li>unit ()</li></ul><p>Unit type is useful in signaling the completion of some program. Ex:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">match</span> print_endline <span class="string">"first string"</span> <span class="keyword">with</span></span><br><span class="line">| <span class="literal">()</span> -&gt; print_endline <span class="string">"second string"</span></span><br></pre></td></tr></table></figure><ul><li>immutable character strings</li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="string">"Hello"</span> ^ <span class="string">" "</span> ^ <span class="string">"world"</span>;;</span><br><span class="line">- : <span class="built_in">string</span> = <span class="string">"Hello world"</span></span><br></pre></td></tr></table></figure><ul><li>list (constructed data type)</li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">let</span> l = [<span class="string">"is"</span>; <span class="string">"a"</span>; <span class="string">"tale"</span>; <span class="string">"told"</span>; <span class="string">"etc."</span>];;</span><br><span class="line"><span class="keyword">val</span> l : <span class="built_in">string</span> <span class="built_in">list</span> = [<span class="string">"is"</span>; <span class="string">"a"</span>; <span class="string">"tale"</span>; <span class="string">"told"</span>; <span class="string">"etc."</span>]</span><br><span class="line"></span><br><span class="line"># <span class="string">"Life"</span> :: l;;</span><br><span class="line">- : <span class="built_in">string</span> <span class="built_in">list</span> = [<span class="string">"Life"</span>; <span class="string">"is"</span>; <span class="string">"a"</span>; <span class="string">"tale"</span>; <span class="string">"told"</span>; <span class="string">"etc."</span>]</span><br></pre></td></tr></table></figure><h2 id="Compound-Data-Types"><a href="#Compound-Data-Types" class="headerlink" title="Compound Data Types:"></a>Compound Data Types:</h2><ul><li>Tuples</li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">let</span> a_tuple : <span class="built_in">int</span> * <span class="built_in">string</span> = (<span class="number">3</span>, <span class="string">"three"</span>);;</span><br></pre></td></tr></table></figure><p>A tuple is an ordered collection of values that can each be of a different type.</p><ul><li>Lists</li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># [<span class="number">1</span>; <span class="number">2</span>; <span class="number">3</span>];;</span><br><span class="line"># <span class="number">1</span> :: (<span class="number">2</span> :: (<span class="number">3</span> :: <span class="literal">[]</span>));;</span><br><span class="line"># <span class="number">1</span> :: <span class="number">2</span> :: <span class="number">3</span> :: <span class="literal">[]</span>;;</span><br></pre></td></tr></table></figure><p>The bracket notation is a syntax sugar for <code>::</code>. <code>::</code> is right-associative.</p><p><code>@</code> can be used to concatenate two lists. (not a constant-time operation)</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># [<span class="number">1</span>; <span class="number">2</span>; <span class="number">3</span>] @ [<span class="number">4</span>; <span class="number">5</span>; <span class="number">6</span>];;</span><br></pre></td></tr></table></figure><ul><li>Options</li></ul><p>An option is used to express that a value might or might not be present.</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">let</span> divide x y =</span><br><span class="line"><span class="keyword">if</span> y = <span class="number">0</span> <span class="keyword">then</span> <span class="type">None</span> <span class="keyword">else</span> <span class="type">Some</span> (x/y) ;;</span><br></pre></td></tr></table></figure><p>Keywords <code>Some</code> and <code>None</code> are construtors that let us build optional values. To examine the contents of an option, we use pattern matching.</p><p>The <code>None</code> type is useful in many situations, for example, when allocating memory, if the allocation fails, return <code>None</code> value is usually a good choice.</p><ul><li>Records</li></ul><p>We can also define our own data type.</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">type</span> point2d = &#123; x : <span class="built_in">float</span>; y : <span class="built_in">float</span>&#125;;;</span><br></pre></td></tr></table></figure><p>Dot notation for accessing record fields:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> magnitude &#123; x; y&#125; = sqrt (x ** <span class="number">2.</span> +. y ** <span class="number">2.</span>);;</span><br><span class="line"># <span class="keyword">let</span> distance v1 v2 =</span><br><span class="line">magnitude &#123; x = v1.x -. v2.x; y = v1.y -. v2.y&#125;;;</span><br></pre></td></tr></table></figure><h2 id="Function"><a href="#Function" class="headerlink" title="Function"></a>Function</h2><p>OCaml use <em>typer inference</em> to work out the types.</p><p>OCaml doesn’t do any implicit casting nor do any automatic conversion.</p><p>A function which takes input of type <code>a</code> and can often give an output of type <code>b</code> may declare itself as type <code>a -&gt; b option</code>, indicating that it may give a <code>None</code> value for some reason.</p><h3 id="Function-Expression"><a href="#Function-Expression" class="headerlink" title="Function Expression"></a>Function Expression</h3><p>Function is an expression which can be evaluated.</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">(* syntax for a function expression*)</span></span><br><span class="line"><span class="keyword">fun</span> n -&gt; n + <span class="number">1</span>;;</span><br><span class="line"></span><br><span class="line"><span class="comment">(* applying a function to a value *)</span></span><br><span class="line">(<span class="keyword">fun</span> n -&gt; n + <span class="number">1</span>) <span class="number">2</span>;;</span><br></pre></td></tr></table></figure><h3 id="Function-type"><a href="#Function-type" class="headerlink" title="Function type"></a>Function type</h3><p>Each function has a type, which can be writen as:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a -&gt; b</span><br></pre></td></tr></table></figure><p>Where <code>a</code> is its domain, and <code>b</code> is its codoman.</p><p>The arrow operation is right-associative, so the following two type specifications are the same:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">int</span> -&gt; (<span class="built_in">int</span> -&gt; (<span class="built_in">bool</span> -&gt; <span class="built_in">int</span>))</span><br><span class="line"><span class="built_in">int</span> -&gt; <span class="built_in">int</span> -&gt; <span class="built_in">bool</span> -&gt; <span class="built_in">int</span></span><br></pre></td></tr></table></figure><h3 id="Annotations"><a href="#Annotations" class="headerlink" title="Annotations"></a>Annotations</h3><p>There may be some ambiguity for function annotation, for example:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fun</span> x : <span class="built_in">int</span> -&gt; exp</span><br></pre></td></tr></table></figure><p>actually means</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fun</span> x -&gt; (exp : <span class="built_in">int</span>)</span><br></pre></td></tr></table></figure><p>To annotate the parameter, we have to include a parathesis:</p><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">fun</span> (x : <span class="built_in">int</span>) -&gt; exp</span><br></pre></td></tr></table></figure><h3 id="Function-with-Multiple-Parameters"><a href="#Function-with-Multiple-Parameters" class="headerlink" title="Function with Multiple Parameters"></a>Function with Multiple Parameters</h3><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">(* syntax, the parameter type and expression type is auto-checked by type checking mechanism*)</span></span><br><span class="line"><span class="keyword">fun</span> x y -&gt; x +. y;;</span><br><span class="line"></span><br><span class="line"><span class="comment">(* apply to 2 arguments *)</span></span><br><span class="line">(<span class="keyword">fun</span> x y -&gt; x +. y) <span class="number">3.</span> <span class="number">4.</span> ;;</span><br></pre></td></tr></table></figure><h3 id="Bind-Function-to-Variable"><a href="#Bind-Function-to-Variable" class="headerlink" title="Bind Function to Variable"></a>Bind Function to Variable</h3><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> f = <span class="keyword">fun</span> n -&gt; n + <span class="number">1</span>;;</span><br><span class="line">f <span class="number">2</span>;;</span><br></pre></td></tr></table></figure><h3 id="Define-Named-Function-another-syntax"><a href="#Define-Named-Function-another-syntax" class="headerlink" title="Define Named Function (another syntax)"></a>Define Named Function (another syntax)</h3><ul><li><code>let f = fun p1 p2 ... -&gt; expr</code></li><li><code>let f p1 p2 ... = expr</code></li></ul><figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> f x = x + <span class="number">1</span>;;</span><br><span class="line">f <span class="number">3</span>;;</span><br><span class="line"><span class="keyword">let</span> f x y = x + y;;</span><br><span class="line">f <span class="number">3</span> <span class="number">4</span>;;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;OCaml Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Ocaml" scheme="http://yoursite.com/tags/Ocaml/"/>
    
      <category term="Functional Programming" scheme="http://yoursite.com/tags/Functional-Programming/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch Tutorial</title>
    <link href="http://yoursite.com/2019/05/11/PyTorch%20Tutorial/"/>
    <id>http://yoursite.com/2019/05/11/PyTorch Tutorial/</id>
    <published>2019-05-11T16:28:34.000Z</published>
    <updated>2019-05-14T04:16:39.712Z</updated>
    
    <content type="html"><![CDATA[<p>PyTorch</p><p>Tutorial</p><a id="more"></a><h1 id="Defining-network"><a href="#Defining-network" class="headerlink" title="Defining network"></a>Defining network</h1><p>PyTorch has a standard way to create your own models. The entire definition should stay inside an object that is a child of the class <strong>nn.Module</strong>. Inside this class, there are only two methods that must be implemented. These methods are <strong><strong><strong>init</strong></strong></strong> and <strong>forward</strong>.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Net, self).__init__()</span><br><span class="line">        <span class="comment"># Defining 3 linear layers but not the way they should be connected</span></span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">240</span>,<span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>,<span class="number">60</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">60</span>,<span class="number">10</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self,x)</span>:</span></span><br><span class="line">        <span class="comment"># Defining the way that the layers of the model should be connected</span></span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><p>You can put inside the <strong>forward</strong> method all the layers that do not have any weights to be updated. On the other hand, you should put all the layers that have weights to be updated inside the <strong><strong><strong>init</strong></strong></strong>.</p><h1 id="Loading-data-Dataset-and-Data-Loaders"><a href="#Loading-data-Dataset-and-Data-Loaders" class="headerlink" title="Loading data: Dataset and Data Loaders"></a>Loading data: Dataset and Data Loaders</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ExampleDataset</span><span class="params">(Dataset)</span>:</span></span><br><span class="line">    <span class="string">"""Example Dataset"""</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, csv_file)</span>:</span></span><br><span class="line">        <span class="string">""" </span></span><br><span class="line"><span class="string">        csv_file (string): Path to the csv file containing data.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.data_frame = pd.read_csv(csv_file)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> len(self.data_frame)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span><span class="params">(self, idx)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> self.data_frame[idx]</span><br><span class="line"></span><br><span class="line"><span class="comment"># instantiates the dataset  </span></span><br><span class="line">example_dataset = ExampleDataset(<span class="string">'my_data_file.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># batch size: number of samples returned per iteration</span></span><br><span class="line"><span class="comment"># shuffle: Flag to shuffle the data before reading so you don't read always in the same order</span></span><br><span class="line"><span class="comment"># num_workers: used to load the data in parallel</span></span><br><span class="line">example_data_loader = DataLoader(example_dataset, batch_size=<span class="number">4</span>, shuffle=<span class="keyword">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Loops over the data 4 samples at a time</span></span><br><span class="line"><span class="keyword">for</span> batch_index, batch <span class="keyword">in</span> enumerate(example_data_loader):</span><br><span class="line">    print(batch_index, batch)</span><br></pre></td></tr></table></figure><ul><li><strong><strong>init</strong></strong>:</li></ul><p>In the initialization, you should put your directories information and other things that would allow to access it.</p><ul><li><strong><strong>len</strong></strong>:</li></ul><p>You should implement a way to get the entire size of your dataset.</p><ul><li><strong><strong>getitem</strong></strong>:</li></ul><p>This is where you implement how to get a single item from your dataset.</p><p>In order to more efficiently access your dataset, we use the <strong>DataLoader</strong> class. This class simply reads a batch of data at a time in parallel while optionally shuffling your data.</p><h1 id="Training-Updating-the-Network-Weights"><a href="#Training-Updating-the-Network-Weights" class="headerlink" title="Training: Updating the Network Weights"></a>Training: Updating the Network Weights</h1><p>An optimizer goes over all the weights and update them for you. The optimizer must have a criterion to use for optimization. This is where you need to define your loss function.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="comment"># instantiate your network that should be defined by you</span></span><br><span class="line">net = Net()</span><br><span class="line"><span class="comment"># create your optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># define your criterion for optimization</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"><span class="comment"># dat_set comes from somewhere</span></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> data_set:</span><br><span class="line">  <span class="comment"># zero the gradient buffers</span></span><br><span class="line">  optimizer.zero_grad()  </span><br><span class="line">  <span class="comment"># Passes the data through your network</span></span><br><span class="line">  output = net.forward(data)</span><br><span class="line">  <span class="comment"># calculates the loss</span></span><br><span class="line">  loss = criterion(output, target)</span><br><span class="line">  <span class="comment"># Propagates the loss back</span></span><br><span class="line">  loss.backward()</span><br><span class="line">  <span class="comment"># Updates all the weights of the network</span></span><br><span class="line">  optimizer.step()</span><br></pre></td></tr></table></figure><h1 id="Summarizing-Steps"><a href="#Summarizing-Steps" class="headerlink" title="Summarizing Steps"></a>Summarizing Steps</h1><ol><li>Define your Network class by placing the layers with weights that can be updated inside the <strong><strong><strong>init</strong></strong></strong> method. Then define how the data flows through the layers inside the <strong>forward</strong> method.</li><li>Define how your data should be loaded using the <strong>Dataset</strong> class. Then use <strong>DataLoader</strong> class to loop over your data.</li><li>Choose an optimizer and a loss function. Loop over your training data and let the optimizer update the weights of your network.</li></ol><h1 id="Cleaned-up-code-of-model-with-nn-Sequential"><a href="#Cleaned-up-code-of-model-with-nn-Sequential" class="headerlink" title="Cleaned up code of model with nn.Sequential"></a>Cleaned up code of model with nn.Sequential</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NetSeq</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(NetSeq, self).__init__()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># conv layers: feature extractor</span></span><br><span class="line">        self.conv_layers = nn.Sequential(</span><br><span class="line">        nn.Conv2d(<span class="number">1</span>, <span class="number">10</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Conv2d(<span class="number">10</span>, <span class="number">20</span>, kernel_size=<span class="number">5</span>),</span><br><span class="line">            nn.Dropout2d(),</span><br><span class="line">            nn.MaxPool2d(<span class="number">2</span>),</span><br><span class="line">            nn.ReLU()</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># fc layers: classifier</span></span><br><span class="line">        self.fc_layers = nn.Sequential(</span><br><span class="line">        nn.Linear(<span class="number">320</span>, <span class="number">50</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Dropout(),</span><br><span class="line">            nn.Linear(<span class="number">50</span>, <span class="number">10</span>),</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        x = self.conv_layers(x)</span><br><span class="line">        x = x.view(<span class="number">-1</span>, <span class="number">320</span>)</span><br><span class="line">        x = self.fc_layers(x)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">model = NetSeq().cuda()</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br></pre></td></tr></table></figure><h1 id="Credits"><a href="#Credits" class="headerlink" title="Credits"></a>Credits</h1><p><a href="https://medium.com/deeplearningbrasilia/deep-learning-introduction-to-pytorch-5bd39421c84" target="_blank" rel="noopener">https://medium.com/deeplearningbrasilia/deep-learning-introduction-to-pytorch-5bd39421c84</a></p><p><a href="https://www.kaggle.com/azure0102/pytorch-tutorial-for-deep-learning-lovers" target="_blank" rel="noopener">https://www.kaggle.com/azure0102/pytorch-tutorial-for-deep-learning-lovers</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;PyTorch&lt;/p&gt;
&lt;p&gt;Tutorial&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
  </entry>
  
  <entry>
    <title>CS231n</title>
    <link href="http://yoursite.com/2019/05/10/CS231n/"/>
    <id>http://yoursite.com/2019/05/10/CS231n/</id>
    <published>2019-05-10T20:53:34.000Z</published>
    <updated>2019-05-14T23:14:32.683Z</updated>
    
    <content type="html"><![CDATA[<p>Stanford University</p><p>CS231n: Convolutional Neural Networks for Visual Recognition</p><p>Course Notes</p><a id="more"></a><h1 id="Lecture-1-Introduction-to-Convolutional-Neural-Networks-for-Visual-Recognition"><a href="#Lecture-1-Introduction-to-Convolutional-Neural-Networks-for-Visual-Recognition" class="headerlink" title="Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition"></a>Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition</h1><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture1-1.png" style="zoom:60%"><br></center><p><strong>Camera Obscure</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture1-2.png" style="zoom:60%"><br></center><p><strong>Object Detection Benchmark</strong></p><p>PASCAL Visual Object Challenge</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture1-3.png" style="zoom:60%"><br></center><p><strong>Image Classification Benchmark</strong></p><p>ImageNet</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture1-4.png" style="zoom:60%"><br></center><ul><li><p>Image classification</p></li><li><p>Object detection</p></li><li><p>Action classification</p></li><li><p>Image captioning</p></li></ul><p>Convolutional Neural Networks (CNN) have become an important tool for object recognition</p><p>Computer Vision Technology Can Better Our Lives</p><h1 id="Lecture-2-Image-Classification"><a href="#Lecture-2-Image-Classification" class="headerlink" title="Lecture 2 | Image Classification"></a>Lecture 2 | Image Classification</h1><p><strong>Image Classification</strong></p><p>A core task in Computer Vision</p><p>The Problem: Semantic Gap</p><p>Challenges: Viewpoint variation, Illumination, Deformation, Occlusion, Background Clutter, Intraclass variation</p><p><strong>Data-Driven Approach</strong></p><ol><li>Collect a dataset of images and labels</li><li>Use Machine Learning to train a classifier</li><li>Evaluate the classifier on new images</li></ol><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-1.png" style="zoom:60%"><br></center><p>First classifier: <strong>Nearest Neighbor</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-2.png" style="zoom:60%"><br></center><p>Example Dataset: <strong>CIFAR10</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-3.png" style="zoom:60%"><br></center><p><strong>Distance Metric</strong> to compare images</p><p>L1 distance:<br>$$<br>d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p|<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-4.png" style="zoom:60%"><br></center><p>Train O(1), predict O(N).</p><p>This is bad: we want classifiers that are <strong>fast</strong> at prediction; <strong>slow</strong> for training is ok</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-6.png" style="zoom:60%"><br></center><p><strong>K-Nearest Neighbors</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-5.png" style="zoom:60%"><br></center><p>k and distance matrix are hyperparameters: choice about the algorithm that we set rather than learn</p><p><strong>Setting Hyperparameters</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-7.png" style="zoom:60%"><br></center><p>Cross Validation is commonly used in small dataset, not commonly used in deep learning</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-8.png" style="zoom:60%"><br></center><p>k-Nearest Neighbor on images <strong>never used</strong>.</p><ul><li>Very slow at test time</li><li>Distance metrics on pixels are not informative</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-9.png" style="zoom:60%"><br></center><ul><li>Curse of dimensionality</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-10.png" style="zoom:60%"><br></center><p><strong>K-Nearest Neighbors: Summary</strong></p><p>In <strong>Image classification</strong> we start with a <strong>training set</strong> of images and labels, and must predict labels on the <strong>test set</strong></p><p>The <strong>K-Nearest Neighbors</strong> classifier predicts labels based on nearest training examples</p><p>Distance metric and K are <strong>hyperparameters</strong></p><p>Choose hyperparameters using the <strong>validation set</strong>; only run on the test set once at the very end!</p><p><strong>Linear Classification</strong> (Parametric Approach)</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-12.png" style="zoom:60%"><br></center><p>Sometimes we add a biased term $b$</p><p><strong>Interpreting a Linear Classifier</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-13.png" style="zoom:60%"><br></center><p><strong>Hard cases for a linear classifier</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-11-Lecture2-14.png" style="zoom:60%"><br></center><h1 id="Lecture-3-Loss-Functions-and-Optimization"><a href="#Lecture-3-Loss-Functions-and-Optimization" class="headerlink" title="Lecture 3 | Loss Functions and Optimization"></a>Lecture 3 | Loss Functions and Optimization</h1><ol><li>Define a <strong>loss function</strong> that quantifies our unhappiness with the score across the training data.</li><li>Come up with a way of efficiently finding the parameters that minimize the loss function (<strong>optimization</strong>)</li></ol><p>Loss over the dataset is a sum of loss over examples:<br>$$<br>L = \frac1N\sum_iL_i(f(x_i,W),y_i)<br>$$</p><p><strong>Multiclass SVM loss:</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-1.png" style="zoom:60%"><br></center><p>Numpy implementatin</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">L_i_vectorized</span><span class="params">(x, y, W)</span>:</span></span><br><span class="line">    scores = W.dot(x)</span><br><span class="line">    margins = np.maximum(<span class="number">0</span>, scores-scores[y]+<span class="number">1</span>)</span><br><span class="line">    margins[y] = <span class="number">0</span></span><br><span class="line">    loss_i = np.sum(margins)</span><br><span class="line">    <span class="keyword">return</span> loss_i</span><br></pre></td></tr></table></figure><p><strong>Data loss</strong>: Model predictions should match training data</p><p><strong>regularization loss</strong>: Model should be “simple”, so it works on test data</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-2.png" style="zoom:60%"><br></center><p><strong>Regularization</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-3.png" style="zoom:60%"><br></center><p><strong>Softmax Classifier</strong> (Multinomial Logistic Regression)</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-4.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-5.png" style="zoom:60%"><br></center><p><strong>Recap</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-6.png" style="zoom:60%"><br></center><p><strong>Optimization</strong></p><p>Follow the slope</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-7.png" style="zoom:60%"><br></center><ul><li>Numerical gradient: approximate, slow, easy to write</li><li>Analytic gradient: exact, fast, error-prone</li></ul><p>In practice: Always use analytic gradient, but check implementation with numerical gradient. This is called a <strong>gradient check.</strong></p><p><strong>Gradient Descent</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">    weights_grad = evaluate_gradient(loss_fun, data, weights)</span><br><span class="line">    weights += - step_size * weights_grad</span><br></pre></td></tr></table></figure><p><strong>Stochastic Gradient Descent (SGD)</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-8.png" style="zoom:60%"><br></center><p><strong>Histogram of Oriented Gradients (HoG)</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-9.png" style="zoom:60%"><br></center><p><strong>Bag of Words</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-12-Lesson3-10.png" style="zoom:60%"><br></center><h1 id="Assignment-1"><a href="#Assignment-1" class="headerlink" title="Assignment 1"></a>Assignment 1</h1><ul><li>understand the basic <strong>Image Classification pipeline</strong> and the data-driven approach (train/predict stages)</li><li>Understand the train/val/test <strong>splits</strong> and the use of validation data for <strong>hyperparameter tuning</strong></li><li>Develop proficiency in writing efficient <strong>vectorized</strong> code with numpy</li><li>Implement and apply k-Nearest Neighbor (<strong>kNN</strong>) classifier</li><li>Implement and apply a Multiclass Support Vector Machine (<strong>SVM</strong>) classifier</li><li>Implement and apply <strong>Softmax</strong> classifier</li><li>Implement and apply a <strong>Two layer neural network</strong> classifier</li><li>Understand the differences and tradeoffs between these classifiers</li><li>get a basic understanding of performance improvements from using <strong>higher-level representations</strong> than raw pixels (e.g. color histograms, Histogram of Gradient (HOG) features)</li></ul><h1 id="Lecture-4-Introduction-to-Neural-Networks"><a href="#Lecture-4-Introduction-to-Neural-Networks" class="headerlink" title="Lecture 4 | Introduction to Neural Networks"></a>Lecture 4 | Introduction to Neural Networks</h1><p><strong>computational graphs</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-1.png" style="zoom:60%"><br></center><p><strong>Backpropagation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-3.png" style="zoom:60%"><br></center><p><strong>sigmoid function</strong><br>$$<br>\sigma(x) = \frac{1}{1+e^{-x}}<br>$$</p><p>$$<br>\frac{d\sigma(x)}{dx}=(1-\sigma(x))\sigma(x)<br>$$</p><p>We can group any node we want as long we can write down their local gradient</p><p><strong>add</strong> gate: gradient distributor</p><p><strong>max</strong> gate: gradient router</p><p><strong>mul</strong> gate: gradient switcher</p><p><strong>Gradients for vectorized code: Jacobian matrix</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-4.png" style="zoom:60%"><br></center><p>Always check: The gradient with respect to a variable should have the same shape as the variable</p><p><strong>Modularized implementation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-5.png" style="zoom:60%"><br></center><p><strong>Neural networks</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-6.png" style="zoom:60%"><br></center><p><strong>Activation functions</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-7.png" style="zoom:60%"><br></center><p><strong>Neural networks Architectures</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-13-Lecture4-8.png" style="zoom:60%"><br></center><h1 id="Lecture-5-Convolutional-Neural-Networks"><a href="#Lecture-5-Convolutional-Neural-Networks" class="headerlink" title="Lecture 5 | Convolutional Neural Networks"></a>Lecture 5 | Convolutional Neural Networks</h1><p>Mark I Perceptron:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-1.png" style="zoom:60%"><br></center><p><strong>Convolution Layer</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-3.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-4.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-5.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-6.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-7.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-8.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-9.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-10.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture5-11.png" style="zoom:60%"><br></center><h1 id="Lecture-6-Training-Neural-Networks-I"><a href="#Lecture-6-Training-Neural-Networks-I" class="headerlink" title="Lecture 6 | Training Neural Networks I"></a>Lecture 6 | Training Neural Networks I</h1><p><strong>Mini-batch SGD</strong></p><ol><li><strong>Sample</strong> a batch of data</li><li><strong>Forward</strong> prop it through the graph (network), get loss</li><li><strong>Backprop</strong> to calculate the gradients</li><li><strong>Update</strong> the parameters using the gradient</li></ol><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-1.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-3.png" style="zoom:60%"><br></center><p>People like to initialzie ReLU neurons with slightly positive biases (e.g. 0.01)</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-4.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-5.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-6.png" style="zoom:60%"><br></center><p><strong>In practice:</strong></p><ul><li>Use ReLU. Be careful with your learning rates</li><li>Try out Leaky ReLU / Maxout / ELU</li><li>Try out tanh but don’t expect much</li><li>Don’t use sigmoid</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-7.png" style="zoom:60%"><br></center><p><strong>Reasonable initialization</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-8.png" style="zoom:60%"><br></center><p><strong>Batch Normalization</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-9.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-10.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-11.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-12.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-13.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-14.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture6-15.png" style="zoom:60%"><br></center><h1 id="Lecture-7-Training-Neural-Networks-II"><a href="#Lecture-7-Training-Neural-Networks-II" class="headerlink" title="Lecture 7 | Training Neural Networks II"></a>Lecture 7 | Training Neural Networks II</h1><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-1.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-2.png" style="zoom:60%"><br></center><ul><li>Fancier optimization</li><li>Regularization</li><li>Transfer Learning</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-3.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-4.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-5.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-6.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-7.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-8.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-9.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-12.png" style="zoom:60%"><br></center><p>Learning rate decay is common with SGD momentum but less common with Adam</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-13.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-14.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-15.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-16.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-17.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-18.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-19.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-20.png" style="zoom:60%"><br></center><p><strong>Data Augmentation</strong></p><ul><li>translation</li><li>rotation</li><li>stretching</li><li>shearing</li><li>lens distorions</li></ul><p><strong>Transfer Learning</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture7-21.png" style="zoom:60%"><br></center><h1 id="Lecture-8-Deep-Learning-Software"><a href="#Lecture-8-Deep-Learning-Software" class="headerlink" title="Lecture 8 | Deep Learning Software"></a>Lecture 8 | Deep Learning Software</h1><p><strong>CPU vs GPU</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-1.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-3.png" style="zoom:60%"><br></center><p><strong>The point of deep learning frameworks</strong></p><ul><li>Easily build big computational graphs</li><li>Easily compute gradients in computational graphs</li><li><p>Run it all efficiently on GPU (wrap cuDNN, cuBLAS, etc)</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-4.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-5.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-6.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-7.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-8.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-9.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-10.png" style="zoom:60%"><br></center></li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-11.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-12.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-13.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-14.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-15.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-16.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-17.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-18.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-19.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-20.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-21.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-14-Lecture8-22.png" style="zoom:60%"><br></center><h1 id="Lecture-9-CNN-Architectures"><a href="#Lecture-9-CNN-Architectures" class="headerlink" title="Lecture 9 | CNN Architectures"></a>Lecture 9 | CNN Architectures</h1><h1 id="Lecture-10-Recurrent-Neural-Networks"><a href="#Lecture-10-Recurrent-Neural-Networks" class="headerlink" title="Lecture 10 | Recurrent Neural Networks"></a>Lecture 10 | Recurrent Neural Networks</h1><h1 id="Lecture-11-Detection-and-Segmentation"><a href="#Lecture-11-Detection-and-Segmentation" class="headerlink" title="Lecture 11 | Detection and Segmentation"></a>Lecture 11 | Detection and Segmentation</h1><h1 id="Lecture-12-Visualizing-and-Understanding"><a href="#Lecture-12-Visualizing-and-Understanding" class="headerlink" title="Lecture 12 | Visualizing and Understanding"></a>Lecture 12 | Visualizing and Understanding</h1><h1 id="Lecture-13-Generative-Models"><a href="#Lecture-13-Generative-Models" class="headerlink" title="Lecture 13 | Generative Models"></a>Lecture 13 | Generative Models</h1><h1 id="Lecture-14-Deep-Reinforcement-Learning"><a href="#Lecture-14-Deep-Reinforcement-Learning" class="headerlink" title="Lecture 14 | Deep Reinforcement Learning"></a>Lecture 14 | Deep Reinforcement Learning</h1><h1 id="Lecture-15-Efficient-Methods-and-Hardware-for-Deep-Learning"><a href="#Lecture-15-Efficient-Methods-and-Hardware-for-Deep-Learning" class="headerlink" title="Lecture 15 | Efficient Methods and Hardware for Deep Learning"></a>Lecture 15 | Efficient Methods and Hardware for Deep Learning</h1><h1 id="Lecture-16-Adversarial-Examples-and-Adversarial-Training"><a href="#Lecture-16-Adversarial-Examples-and-Adversarial-Training" class="headerlink" title="Lecture 16 | Adversarial Examples and Adversarial Training"></a>Lecture 16 | Adversarial Examples and Adversarial Training</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Stanford University&lt;/p&gt;
&lt;p&gt;CS231n: Convolutional Neural Networks for Visual Recognition&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Computer Vision" scheme="http://yoursite.com/tags/Computer-Vision/"/>
    
  </entry>
  
  <entry>
    <title>Practical Deep Learning for Coders</title>
    <link href="http://yoursite.com/2019/05/06/Practical%20Deep%20Learning%20for%20Coders/"/>
    <id>http://yoursite.com/2019/05/06/Practical Deep Learning for Coders/</id>
    <published>2019-05-06T05:17:34.000Z</published>
    <updated>2019-05-10T20:34:12.799Z</updated>
    
    <content type="html"><![CDATA[<p>Fast.ai</p><p>Course Notes</p><a id="more"></a><h1 id="Lesson-1"><a href="#Lesson-1" class="headerlink" title="Lesson 1"></a>Lesson 1</h1><p>Jupyter Notebook: Interactive environment for Python</p><p>Import necessary libraries:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastai <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> fastai.vision <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplob <span class="keyword">as</span> plt</span><br></pre></td></tr></table></figure><p>Tips: Don’t try to stop and understand the first time</p><p>Making Deep Learning Accessible</p><ul><li><strong>Software</strong>: To make these available to use quickly, reliably, and with minimal code</li><li><strong>Education</strong>: So that as many people as possible can use these</li><li><strong>Research</strong>: Ways to make state of the art deep learning techniques more accessible</li><li><strong>Community</strong>: So that we can all help each other</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-08-Lesson1-1.png" style="zoom:60%"><br></center><p>We can do a lot more quickly with PyTorch than with TensorFlow</p><p>Resources:</p><ul><li><a href="https://docs.fast.ai/" target="_blank" rel="noopener">fast.ai docs</a></li><li><a href="https://pytorch.org/" target="_blank" rel="noopener">PyTorch</a></li></ul><p>Fastai provides four application areas:</p><ul><li>Computer Vision</li><li>Natural Language Text</li><li>Tabular Data</li><li>Collaborative Filtering</li></ul><p>Fine-grained classification: distinguish between similar categories</p><p><strong>Some key functions</strong></p><p>Download and untar data: <code>path = untar_data(URLs.PETS); path</code></p><p>List the directory: <code>path.ls()</code></p><p>Path objects (of Python3): <code>path_anno = path/&#39;annotations&#39;</code>, <code>path_img = path/&#39;images&#39;</code></p><p>Grab an array of all image files: <code>fname = get_image_files(path_img)</code></p><p>Create a data bunch and normalize it:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pat = <span class="string">r'/([^/]+\d+.jpg$)'</span></span><br><span class="line">data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=<span class="number">224</span>, bs=<span class="number">64</span>)<span class="comment"># bs represents the batch size</span></span><br><span class="line">data.normalize(imagenet_stats)</span><br></pre></td></tr></table></figure><p>224x224 for a image generally works</p><p>A data bunch contains typically 2 or 3 datasets</p><p>Show the data bunch: <code>data.show_batch(row=3, figsize=(7,6))</code></p><p>Labels: <code>data.classes</code>, <code>data.c</code> attributes</p><p>Training: resnet34 <code>learn = ConvLearner(data, models.resnet34, metrics=error_rate)</code></p><p>ResNet34 and ResNet50 are always good for choosing</p><p>Fit: <code>learn.fit_one_cycle(4)</code> the best way at the present for training</p><p> Save the trained model: <code>learn.save(&#39;stage-1&#39;)</code></p><p>What comes out: <code>interp = ClassificationInterpretation.from_learner(learn)</code></p><p>Plot top losses: <code>interp.plot_top_losses(9, figsize=(15,11))</code> (for error analysis)</p><p>See the documentation: <code>doc(interp.plot_top_losses)</code></p><p>Plot the confusion matrix: <code>interp.plot_confusion_matrix(figsize=(12,12), dpi=60)</code></p><p>The most confused examples: <code>interp.most_confused(min_val=2)</code></p><p>Unfreezing: <code>learn.unfreeze()</code> (train the whole model to get high accuracy)</p><p>Learning_rate find: <code>learn.lr_find()</code></p><p>Plot the learning_rate finder: <code>learn.recorder.plot()</code></p><p>Learning_rate slice: <code>learn.fit_one_cycle(2, max_lr=slice(1e-6,1e-4))</code>, distribute the learning_rate equally accross layers</p><p> ImageDataBunch from folder: <code>data = ImageDataBunch.from_folder(path, ds_tfms=tfms, size=26)</code></p><p>ImageDataBunch from csv: <code>df = pd.read_csv(path/&#39;labels.csv&#39;)</code> <code>data = ImageDataBunch.from_csv(path, ds_tfms=tfms, size=28)</code></p><p>Dataset: <a href="http://www.robots.ox.ac.uk/~vgg/data/pets/" target="_blank" rel="noopener">Oxford-IIIT Pet Dataset</a></p><h1 id="Lesson-2"><a href="#Lesson-2" class="headerlink" title="Lesson 2"></a>Lesson 2</h1><p><strong>Create an image dataset through Google Images</strong></p><ul><li><p>Starting point: Find some example pictures</p></li><li><p>Save the urls <code>folder = &#39;black&#39;</code> , <code>file = urls_black.txt</code>, <code>path = Path(&#39;data/bears&#39;)</code></p></li><li><p>Download images <code>download_iamges(path/file, dest, max_pics=200)</code></p></li><li>Verify the images <code>verify_images(path/c, delete=True, max_workers=8)</code></li></ul><p>Set random state: <code>np.random.seed(42)</code> (Make sure the solution is stable)</p><p>Create a databunch: <code>data = ImageDataBunch.from_folder(path, train=&#39;.&#39;, valid_pct=0.2, ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)</code></p><p>See the size of training set: <code>len(data.train_ds)</code></p><p>See the size of validation set: <code>len(data.valid(ds))</code></p><p>Picking the learning rate: picking the most steep part of the learning rate find curve</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-08-Lesson2-1.png" style="zoom:60%"><br></center><p><strong>Cleaning Up the data</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> fastai.widgets <span class="keyword">import</span> *</span><br><span class="line">losses, idxs = interp.top_losses()</span><br><span class="line">top_loss_paths = data.valid_ds.x[idxs]</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">fd = FileDeleter(file_paths=top_loss_paths)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-08-Lesson2-2.png" style="zoom:60%"><br></center><p><a href="https://ipywidgets.readthedocs.io/en/stable/" target="_blank" rel="noopener">ipywidgets</a></p><p><strong>Putting your model in production</strong></p><p>Use a CPU rather than GPU to do inference</p><p>Set CPU as defalut: <code>fastai.defaults.device = torch.device(&#39;cpu&#39;)</code></p><p>Create a single image data bunch: <code>data = ImageDataBunch.single_from_classes(path, classes, tfms=get_transforms(), size=224).normalize(imagenet)</code></p><p>Load the model: <code>learn = create_cnn(data, models.resnet34)</code> <code>learn.load(&#39;stage-2&#39;)</code></p><p>Make prediction: <code>pred_class, pred_idx, outputs = learn.predict(img)</code></p><p>Deployment: <a href="https://www.starlette.io/" target="_blank" rel="noopener">Starlette</a> (Web app)</p><p><strong>Problems</strong></p><p>Most likely are:</p><ul><li>Learning rate</li><li>Number of epochs</li></ul><p>Learning rate too high:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-08-Lesson2-3.png" style="zoom:60%"><br></center><p>Learning rate too low:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-08-Lesson2-4.png" style="zoom:60%"><br></center><p>If this kind of things happen, we have to redo again from the scratch</p><p>Another problem is that the training loss is higher than the validation loss, that always means that you haven’t fit enough (learning rate is too low or number of epochs is too low)</p><p>Any model that is trained correctly will have a lower training loss than the validation loss</p><p><strong>x@a</strong>: Matrix product</p><p>Tensor: Array with regular shape</p><p>Rank: How many dimensions are in the tensor</p><p>In PyTorch, any function with an underscore: don’t return to me but replace in place</p><p>type check: <code>a.type()</code></p><p>Gradient descent:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">a = nn.Parameters(a)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span><span class="params">()</span>:</span></span><br><span class="line">    y_hat = x@a</span><br><span class="line">    loss = mse(y, y_hat)</span><br><span class="line">    <span class="keyword">if</span> t % <span class="number">10</span> == <span class="number">0</span>: print(loss)</span><br><span class="line">    loss.backward()</span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        a.sub_(lr * a.grad)</span><br><span class="line">        a.grad.zero_()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">lr = <span class="number">1e-1</span></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> range(<span class="number">100</span>): update()</span><br></pre></td></tr></table></figure><h1 id="Lesson-3"><a href="#Lesson-3" class="headerlink" title="Lesson 3"></a>Lesson 3</h1><p><a href="https://www.kaggle.com/c/planet-understanding-the-amazon-from-space" target="_blank" rel="noopener">Planet Dataset</a></p><p>Multiple labels classification</p><p><strong>Download Data from Kaggle</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pip install kaggle --upgrade</span><br><span class="line">mkdir -p ~/.kaggle/</span><br><span class="line">mv kaggle.json ~/.kaggle</span><br></pre></td></tr></table></figure><p><a href="https://colab.research.google.com/drive/10vM1Sr6nn-1hv0kMrJsTLpmnl-DsWK81" target="_blank" rel="noopener">Instructions in detail</a></p><p><strong>Multiclassification</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-10-Week3-1.png" style="zoom:60%"><br></center><p><a href="https://docs.fast.ai/data_block.html" target="_blank" rel="noopener">data block API</a></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-10-Week3-2.png" style="zoom:60%"><br></center><p><code>Dataset</code> class for PyTorch (methods to manipulate data from the source):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-10-Week3-3.png" style="zoom:60%"><br></center><p><code>DataLoader</code> class for PyTorch (load data from dataset):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-10-Week3-4.png" style="zoom:60%"><br></center><p><code>DataBunch</code> class for fastai (split train and validation data):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-10-Week3-5.png" style="zoom:60%"><br></center><p><strong>Transforms</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tfms = get_transforms()</span><br></pre></td></tr></table></figure><p><strong>Image Segmentation with CamVid</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">path = untar_data(URLs.CAMVID)</span><br><span class="line">fname = get_image_files(path_img)</span><br></pre></td></tr></table></figure><h1 id="Lesson-4"><a href="#Lesson-4" class="headerlink" title="Lesson 4"></a>Lesson 4</h1><h1 id="Lesson-5"><a href="#Lesson-5" class="headerlink" title="Lesson 5"></a>Lesson 5</h1><h1 id="Lesson-6"><a href="#Lesson-6" class="headerlink" title="Lesson 6"></a>Lesson 6</h1><h1 id="Lesson-7"><a href="#Lesson-7" class="headerlink" title="Lesson 7"></a>Lesson 7</h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Fast.ai&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="PyTorch" scheme="http://yoursite.com/tags/PyTorch/"/>
    
      <category term="Fast.ai" scheme="http://yoursite.com/tags/Fast-ai/"/>
    
  </entry>
  
  <entry>
    <title>Algorithms, Part 2</title>
    <link href="http://yoursite.com/2019/05/05/Algorithms-Part-2/"/>
    <id>http://yoursite.com/2019/05/05/Algorithms-Part-2/</id>
    <published>2019-05-06T04:42:34.000Z</published>
    <updated>2019-05-10T20:37:27.098Z</updated>
    
    <content type="html"><![CDATA[<p>Princeton Algorithm course on coursera. Part 2</p><a id="more"></a><ul><li>Intermediate-level survey course</li><li>Programming and problem solving, with applications</li></ul><p>Learning Purpose: </p><ul><li>Being specialized in Java. </li><li>Having fun with algorithms.</li></ul><p>Reference Books:</p><ul><li><a href="https://algs4.cs.princeton.edu/home/" target="_blank" rel="noopener">Algorithms, 4th Edition</a></li><li><a href="https://introcs.cs.princeton.edu/java/home/" target="_blank" rel="noopener">Computer Science:   An Interdisciplinary Approach</a></li></ul><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Undirected-Graphs"><a href="#Undirected-Graphs" class="headerlink" title="Undirected Graphs"></a>Undirected Graphs</h2><h2 id="Directed-Graphs"><a href="#Directed-Graphs" class="headerlink" title="Directed Graphs"></a>Directed Graphs</h2><h2 id="Programming-Assignment-WordNet"><a href="#Programming-Assignment-WordNet" class="headerlink" title="Programming Assignment: WordNet"></a>Programming Assignment: WordNet</h2><p><a href>WordNet</a></p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Minimum-Spanning-Trees"><a href="#Minimum-Spanning-Trees" class="headerlink" title="Minimum Spanning Trees"></a>Minimum Spanning Trees</h2><h2 id="Shortest-Paths"><a href="#Shortest-Paths" class="headerlink" title="Shortest Paths"></a>Shortest Paths</h2><h2 id="Programming-Assignment-Seam-Carving"><a href="#Programming-Assignment-Seam-Carving" class="headerlink" title="Programming Assignment: Seam Carving"></a>Programming Assignment: Seam Carving</h2><p><a href>Seam Carving</a></p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Maximum-Flow-and-Minimum-Cut"><a href="#Maximum-Flow-and-Minimum-Cut" class="headerlink" title="Maximum Flow and Minimum Cut"></a>Maximum Flow and Minimum Cut</h2><h2 id="Programming-Assignment-Baseball-Elimination"><a href="#Programming-Assignment-Baseball-Elimination" class="headerlink" title="Programming Assignment: Baseball Elimination"></a>Programming Assignment: Baseball Elimination</h2><p><a href>Baseball Elimination</a></p><h2 id="Radix-Sorts"><a href="#Radix-Sorts" class="headerlink" title="Radix Sorts"></a>Radix Sorts</h2><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Tries"><a href="#Tries" class="headerlink" title="Tries"></a>Tries</h2><h2 id="Substring-Search"><a href="#Substring-Search" class="headerlink" title="Substring Search"></a>Substring Search</h2><h2 id="Programming-Assignment-Boggle"><a href="#Programming-Assignment-Boggle" class="headerlink" title="Programming Assignment: Boggle"></a>Programming Assignment: Boggle</h2><p><a href>Boggle</a></p><h1 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5"></a>Week 5</h1><h2 id="Regular-Expressions"><a href="#Regular-Expressions" class="headerlink" title="Regular Expressions"></a>Regular Expressions</h2><h2 id="Data-Compression"><a href="#Data-Compression" class="headerlink" title="Data Compression"></a>Data Compression</h2><h2 id="Programming-Assignment-Burrows-Wheeler"><a href="#Programming-Assignment-Burrows-Wheeler" class="headerlink" title="Programming Assignment: Burrows-Wheeler"></a>Programming Assignment: Burrows-Wheeler</h2><p><a href>Burrows-Wheeler</a></p><h1 id="Week-6"><a href="#Week-6" class="headerlink" title="Week 6"></a>Week 6</h1><h2 id="Reductions"><a href="#Reductions" class="headerlink" title="Reductions"></a>Reductions</h2><h2 id="Linear-Programming"><a href="#Linear-Programming" class="headerlink" title="Linear Programming"></a>Linear Programming</h2><h2 id="Intractability"><a href="#Intractability" class="headerlink" title="Intractability"></a>Intractability</h2>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Princeton Algorithm course on coursera. Part 2&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
  </entry>
  
  <entry>
    <title>Sequence Models</title>
    <link href="http://yoursite.com/2019/05/04/Sequence%20Models/"/>
    <id>http://yoursite.com/2019/05/04/Sequence Models/</id>
    <published>2019-05-05T01:51:34.000Z</published>
    <updated>2019-05-08T03:34:05.246Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai Specialization</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Recurrent-Neural-Networks"><a href="#Recurrent-Neural-Networks" class="headerlink" title="Recurrent Neural Networks"></a>Recurrent Neural Networks</h2><p>Speech recognition</p><p>Music generation</p><p>Sentiment classification</p><p>DNA sequence analysis</p><p>Machine translation</p><p>Video activity recognition</p><p>Name entity recognition</p><p><strong>Representing words</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-1.png" style="zoom:60%"><br></center><p>Problem of a standard network:</p><ul><li>Inputs, outputs can be different lengths in different examples.</li><li>Doesn’t share features learned across different positions of text.</li></ul><p><strong>Recurrent Neural Networks</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-2.png" style="zoom:60%"><br></center><p>Bidirectional RNN (BRNN)</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-3.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-4.png" style="zoom:60%"><br></center><p><strong>RNN architectures</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-5.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-6.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-7.png" style="zoom:60%"><br></center><p><strong>Language model</strong></p><p>Given a sentence, tell you the probability of that setence.</p><p>Training set: large corpus of English text</p><p>Tolenize: form a vocabulary and map each individual word into this vocabulary. The unknown is replaced with a unique token \&lt;UNK></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-07-Week1-8.png" style="zoom:60%"><br></center><p><strong>Sampling sequence from a trained RNN</strong></p><h2 id="Programming-Assignment-Building-a-recurrent-neural-network-step-by-step"><a href="#Programming-Assignment-Building-a-recurrent-neural-network-step-by-step" class="headerlink" title="Programming Assignment: Building a recurrent neural network - step by step"></a>Programming Assignment: Building a recurrent neural network - step by step</h2><p><a href>Building a recurrent neural network - step by step</a></p><h2 id="Programming-Assignment-Dinosaur-Island-Character-Level-Language-Modeling"><a href="#Programming-Assignment-Dinosaur-Island-Character-Level-Language-Modeling" class="headerlink" title="Programming Assignment: Dinosaur Island - Character-Level Language Modeling"></a>Programming Assignment: Dinosaur Island - Character-Level Language Modeling</h2><p><a href>Dinosaur Island - Character-Level Language Modeling</a></p><h2 id="Programming-Assignment-Jazz-improvisation-with-LSTM"><a href="#Programming-Assignment-Jazz-improvisation-with-LSTM" class="headerlink" title="Programming Assignment: Jazz improvisation with LSTM"></a>Programming Assignment: Jazz improvisation with LSTM</h2><p><a href>Jazz improvisation with LSTM</a></p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Natural-Language-Processing-amp-Word-Embeddings"><a href="#Natural-Language-Processing-amp-Word-Embeddings" class="headerlink" title="Natural Language Processing &amp; Word Embeddings"></a>Natural Language Processing &amp; Word Embeddings</h2><h2 id="Programming-Assignment-Oprations-on-word-vectors-Debiasing"><a href="#Programming-Assignment-Oprations-on-word-vectors-Debiasing" class="headerlink" title="Programming Assignment: Oprations on word vectors - Debiasing"></a>Programming Assignment: Oprations on word vectors - Debiasing</h2><p><a href>Operations on word vectors - Debiasing</a></p><h2 id="Programming-Assignment-Emojify"><a href="#Programming-Assignment-Emojify" class="headerlink" title="Programming Assignment: Emojify"></a>Programming Assignment: Emojify</h2><p><a href>Emojify</a></p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Sequence-models-amp-Attention-mechanism"><a href="#Sequence-models-amp-Attention-mechanism" class="headerlink" title="Sequence models &amp; Attention mechanism"></a>Sequence models &amp; Attention mechanism</h2><h2 id="Programming-Assignment-Neural-Machine-Translation-with-Attention"><a href="#Programming-Assignment-Neural-Machine-Translation-with-Attention" class="headerlink" title="Programming Assignment: Neural Machine Translation with Attention"></a>Programming Assignment: Neural Machine Translation with Attention</h2><p><a href>Neural Machine Translation with Attention</a></p><h2 id="Programming-Assignment-Trigger-word-detection"><a href="#Programming-Assignment-Trigger-word-detection" class="headerlink" title="Programming Assignment: Trigger word detection"></a>Programming Assignment: Trigger word detection</h2><p><a href>Trigger word detection</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai Specialization&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Convolutional Neural Networks</title>
    <link href="http://yoursite.com/2019/04/25/Convolutional%20Neural%20Networks/"/>
    <id>http://yoursite.com/2019/04/25/Convolutional Neural Networks/</id>
    <published>2019-04-26T04:11:34.000Z</published>
    <updated>2019-05-05T01:42:08.574Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai Specialization</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Foundations-of-Convolutional-Neural-Networks"><a href="#Foundations-of-Convolutional-Neural-Networks" class="headerlink" title="Foundations of Convolutional Neural Networks"></a>Foundations of Convolutional Neural Networks</h2><ul><li>Image Classification</li><li>Object detection</li><li>Neural Style Transfer</li></ul><p>With so many parameters, it’s difficult to get enough data for a model to get rid of overfitting.</p><p><strong>Edge Detection</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-1.png" style="zoom:60%"><br></center><p><strong>Convolution</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-3.png" style="zoom:60%"><br></center><p><strong>Padding</strong></p><p>Two problems:</p><ul><li>The image may shrink after some convolution</li><li>The blocks in the middle of image have a higher chance to be utilized than the ones on the border</li></ul><p>For a deep neural network, we really don’t want the image to shrink because we have many convolution operations. Without padding, the image may shrink after every layer and after maybe 100 layers, we end up with a very small matrix like 1 by 1. The other problem is that we throw away information from the edges of the image.</p><p>Traditionally without padding, if the original matrix is $n$ by $n$ and the filter is $f$ by $f$. Then the matrix after convolution will have a shape of $n-f+1$ by $n-f+1$</p><p>p: padding size</p><p>After padding, the final output matrix will have shape $n+2p-f+1$ by $n+2p-f+1$</p><p><strong>Valid and Same convolutions</strong></p><p>“Valid”: no padding, p = 0, nxn * fxf -&gt; n-f+1 x n-f+1</p><p>“Same”: Pad so that output size is the same as the input size. $p=\frac{f-1}{2}$</p><p>By convention, f is usually odd. The reasons:</p><ul><li>padding convience</li><li>Odd dimensional filter has a central position</li></ul><p><strong>Strided convolution</strong></p><p>shape formula:</p><p>nxn * fxf with padding p and stride s</p><p>output shape (square):<br>$$<br>\frac{n+2p-f}{s} + 1<br>$$</p><p><strong>Cross-correlation vs. convolution</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-4.png" style="zoom:60%"><br></center><p>In computer vision, we don’t bother to use the non-flipped one because the flip operation is redundant in real computer vision applications.</p><p><strong>Convolution over volumes</strong></p><p>For example, convolutions on RGB images</p><p>Notation:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-5.png" style="zoom:60%"><br></center><p>The number of the channels of a image must match the number of channels of the filter.</p><p>Each time, do the 27 multiplications and add up the 27 numbers and get one entry.</p><p><strong>Multiple filters</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-6.png" style="zoom:60%"><br></center><p>Summary: $n\times n\times n_c$ <em> $f\times f \times n_c$ - &gt; $n-f+1$ </em> $n-f+1$ $\times n_c’$</p><p>$n_c’$ is the number of filters we use.</p><p>It seems that the more filters we use, the more features we can extract from an image. (like detecting two features simultaneously, vertical lines and horizontal lines…)</p><p><strong>One layer of convolutional network</strong></p><p>The number of parameters has nothing to do with the input images.</p><p>If layer l is a convolution layer:</p><p>$f^{[l]}$ = filter size</p><p>$p^{[l]}$ = padding</p><p>$s^{[l]}$ = stride</p><p>$n_c^{[l]}$ = number of filters</p><p>Each filter is: $f^{[l]}\times f^{[l]}\times n_c^{[l-1]}$</p><p>Activations: $a^{[l]}-&gt;n_H^{[l]} \times n_W^{[l]} \times n_C^{[l]}$</p><p>Weights: $f^{[l]}\times f^{[l]}\times n_c^{[l-1]}\times n_C^{[l]}$</p><p>Bias: $n_c^{[l]}$ - (1,1,1,$n_c^{[l]}$)</p><p>Input: $n_H^{[l-1]}\times n_W^{[l-1]}\times n_c{[l-1]}$</p><p>Output: $n_H^{[l]}\times n_W^{[l]}\times n_c^{[l]}$<br>$$<br>n^{[l]} = \lfloor \frac{n^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1    \rfloor<br>$$<br>$A^{[l]}$ -&gt; $m\times n_H^{[l]}\times n_W^{[l]} \times n_C^{[l]}$</p><p><strong>Example ConvNet</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-7.png" style="zoom:60%"><br></center><p>Types of layer in a convolutional network:</p><ul><li>Convolution (CONV)</li><li>Pooling (POOL)</li><li>Fully connnected (FC)</li></ul><p><strong>Pooling layers</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-8.png" style="zoom:60%"><br></center><p>Max pooling has no parameters to learn.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-9.png" style="zoom:60%"><br></center><p>Max pooling is used much more in the neural network than average pooling.</p><p>Summary of pooling:</p><p>Hyperparameters:</p><ul><li>f: filter size</li><li><p>s: stride</p></li><li><p>Max or average pooling</p></li></ul><p>Common choice: f=2, s=2. Roughly shrink the height and width by a factor of 2. f=3, s=3 is also used sometimes.</p><p>padding is very very rare used when we do max pooling</p><p>Pooling layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input.</p><p>No parameters to learn!</p><p><strong>Neural network example</strong></p><p>Common patterns when we go deeper and deeper:</p><ul><li>The height and width will decrease</li><li>The number of channels will increase</li><li>One or more conv layers follow by a pooling layer. At the end follow by FC</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-10.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-03-Week1-11.png" style="zoom:60%"><br></center><p>A lot of the parameters tend to be in FC. The activation tends to go down gradually when going deeper and deeper. If it drops too fast, that’s usually not great performance.</p><p><strong>Why convolution?</strong></p><p>Parameter sharing and sparsity of connections.</p><p>Reducing the number of parameters significantly</p><p>Parameter sharing: A feature detector (such as a vertical edge detector) that’s useful in one part of the image is probably useful in another part of the image such as the vertical edge detector.</p><p>Sparsity of connections: In each layer, each output value depends only on a small number of inputs.</p><p>Translation invariance</p><h2 id="Programming-Assignment-Convolutional-Model-step-by-step"><a href="#Programming-Assignment-Convolutional-Model-step-by-step" class="headerlink" title="Programming Assignment: Convolutional Model: step by step"></a>Programming Assignment: Convolutional Model: step by step</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 1/Convolution%2Bmodel%2B-%2BStep%2Bby%2BStep%2B-%2Bv2.ipynb" target="_blank" rel="noopener">Convolutional Model: step by step</a></p><h2 id="Programming-Assignment-Convolutional-model-application"><a href="#Programming-Assignment-Convolutional-model-application" class="headerlink" title="Programming Assignment: Convolutional model: application"></a>Programming Assignment: Convolutional model: application</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 1/Convolution%2Bmodel%2B-%2BApplication%2B-%2Bv1.ipynb" target="_blank" rel="noopener">Convolutional model: application</a></p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Deep-convolutional-models-case-studies"><a href="#Deep-convolutional-models-case-studies" class="headerlink" title="Deep convolutional models: case studies"></a>Deep convolutional models: case studies</h2><p>Read some research papers from the field of computer vision.</p><p>Classic networks:</p><ul><li>LeNet-5</li><li>AlexNet</li><li>VGG</li></ul><p>ResNet (152 layers)</p><p>Inception</p><p><strong>LeNet-5</strong></p><p>Goal: recognize hand written digits</p><p>Trained on grey scale images</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-1.png" style="zoom:60%"><br></center><p>Go from left to right, $n_H$ and $n_W$ tend to go down and $n_C$ tend to go up.</p><p><strong>AlexNet</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-2.png" style="zoom:60%"><br></center><p><strong>VGG-16</strong></p><p>CONV = 3x3 filters, s = 1, same</p><p>MAX-POOL = 2x2, s = 2</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-3.png" style="zoom:60%"><br></center><p><strong>Residual network (ResNet)</strong></p><p>skip connections (“short cut”)</p><p>Residual block:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-4.png" style="zoom:60%"><br></center><p>Using residual block, we can train a much deeper neural networks.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-5.png" style="zoom:60%"><br></center><p>In ResNet, there are a lot of “SAME” convolution to preserve dimension so at to carry out skip connection.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-6.png" style="zoom:60%"><br></center><p><strong>Network in Network and 1x1 convolutions</strong></p><p>Imagine this like a “fully connected” layer</p><p>[Lin et al., 2013. Network in network]</p><p>This idea influence many other network architectures.</p><p>One useful example:</p><p>Shrinking the number of channels</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-7.png" style="zoom:60%"><br></center><p>This is very useful for building Inception neural network.</p><p><strong>Inception network</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-8.png" style="zoom:60%"><br></center><p>Do all the possible computation and concat them together.</p><p>The problem: computational cost</p><p>“Bottleneck layer”</p><p>Shrink the representation before increasing the size</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-9.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-10.png" style="zoom:60%"><br></center><p>So long as you implement this bottleneck layer with reason, you can shrink down the representation significant and don’t hurt the performance of the model.</p><p><strong>Inception module</strong></p><p>To deal with the problem of vanishing gradients: very deep network often have a gradient signal that goes to zero quickly, thus making gradient descent unbearably slow.</p><p>Two types of block:</p><ul><li>Identity block</li><li>Convolutional block</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-21.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-22.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-11.png" style="zoom:60%"><br></center><p><strong>Inception network</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-12.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-13.png" style="zoom:60%"><br></center><p><strong>Transfer learning (a better strategy)</strong></p><p>ImageNet, MS COCO</p><p>When the training set is rather small, transfer learning is a good strategy.</p><p>Small training set (freeze more layers):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-14.png" style="zoom:60%"><br></center><p>Large training set (freeze less layers):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-15.png" style="zoom:60%"><br></center><p>A lot of data (freeze 0 layer):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-16.png" style="zoom:60%"><br></center><p>Transfer is very worth consideration</p><p><strong>Data Augmentation</strong></p><p>Common augmentation method:</p><ul><li>Mirroring (frequently used)</li><li><p>Random Cropping (isn’t a perfect method while frequently used)</p></li><li><p>Rotation</p></li><li>Shearing</li><li><p>Local warping</p></li><li><p>Color shifting</p></li><li>PCA color augmentation</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-17.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-18.png" style="zoom:60%"><br></center><p>Implementation details</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-19.png" style="zoom:60%"><br></center><p>Data augmentation also has many hyperparameters.</p><p>Two sources of knowledge in deep learning:</p><ul><li>Labeled data</li><li>Hand engineered features/network architecture/other components</li></ul><p><strong>Tips for doing well on benchmarks/winning competitions</strong></p><ul><li><p>Ensembling: Train several networks independently and average their outputs (3-15 networks typically, so slow, almost never used in a product)</p></li><li><p>Multi-crop at test time: Run classifier on multiple versions of test images and average results</p></li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week2-20.png" style="zoom:60%"><br></center><ul><li>Use architectures of networks published in the literature</li><li><p>Use open sourcfe implementations if possible</p></li><li><p>Use pretrained models and fine-tune on your dataset</p></li></ul><h2 id="Programming-Assignment-Keras-Tutorial"><a href="#Programming-Assignment-Keras-Tutorial" class="headerlink" title="Programming Assignment: Keras Tutorial"></a>Programming Assignment: Keras Tutorial</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 2/Keras%2B-%2BTutorial%2B-%2BHappy%2BHouse%2Bv2.ipynb" target="_blank" rel="noopener">Keras Tutorial</a></p><h2 id="Programming-Assignment-Residual-Networks"><a href="#Programming-Assignment-Residual-Networks" class="headerlink" title="Programming Assignment: Residual Networks"></a>Programming Assignment: Residual Networks</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 2/Residual%2BNetworks%2B-%2Bv2.ipynb" target="_blank" rel="noopener">Residual Networks</a></p><ul><li>Very deep “plain” networks don’t work in practice because they are hard to train due to vanishing gradients.</li><li>The skip-connections help to address the Vanishing Gradient problem. They also make it easy for a ResNet block to learn an identity function.</li><li>There are two main types of blocks: The identity block and the convolutional block.</li><li>Very deep Residual Networks are built by stacking these blocks together.</li></ul><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Object-detection"><a href="#Object-detection" class="headerlink" title="Object detection"></a>Object detection</h2><p>Object localization</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-3.png" style="zoom:60%"><br></center><p>Defining the target label y</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-4.png" style="zoom:60%"><br></center><p><strong>Landmark detection</strong></p><p>Key position detection</p><p>Basis of emotion detection, computer graphics and pose detection</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-5.png" style="zoom:60%"><br></center><p>If you can hire labelers or label yourself a big enough data set to do the detection task, then a neural network can perform very well</p><p><strong>Sliding windows object detection algorithm</strong></p><ol><li><p>Choosing a window size</p></li><li><p>Slide the window accross the image with a fixed stride</p></li><li><p>Make detection on each position (feed into the ConvNet and make prediction)</p></li><li><p>Repeat with larger window</p></li></ol><p>Huge disadvantage: Computation cost</p><p><strong>Convolutional implementation of sliding window</strong></p><p>Turning FC layer into convolutional layers</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-6.png" style="zoom:60%"><br></center><p>Share computation:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-7.png" style="zoom:60%"><br></center><p><strong>Bounding box predictions</strong></p><p>YOLO algorithm: You only look once</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-8.png" style="zoom:60%"><br></center><p>One single convolutional implementation</p><p>Efficient, works well for real-time object detection</p><p>Specify the bounding boxes: relative to the grid cell</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-9.png" style="zoom:60%"><br></center><p>YOLO: One of the hardest papers to read</p><p><strong>Intersection over Union (IoU)</strong></p><p>Evaluating object localization</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-10.png" style="zoom:60%"><br></center><p><strong>Non-max Suppression</strong></p><p>The problem is that some objects might be detected multiple times</p><p>Non-max Suppression make sure each object is detected only once</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-11.png" style="zoom:60%"><br></center><p><strong>Anchor boxes</strong></p><p>One grid detect multiple objects, overlapping objects</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-12.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-13.png" style="zoom:60%"><br></center><p><strong>YOLO algorithm</strong></p><p>None-max suppression in YOLO:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-14.png" style="zoom:60%"><br></center><h2 id="Region-proposals"><a href="#Region-proposals" class="headerlink" title="Region proposals"></a>Region proposals</h2><p>R-CNN, Region with CNN, picking some regions to run CNN</p><p>The ways to choose regions: <strong>semantic segmentation</strong></p><p>Still quite slow</p><h2 id="Programming-Assignment-Car-detection-with-YOLOv2"><a href="#Programming-Assignment-Car-detection-with-YOLOv2" class="headerlink" title="Programming Assignment: Car detection with YOLOv2"></a>Programming Assignment: Car detection with YOLOv2</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 3/Autonomous%2Bdriving%2Bapplication%2B-%2BCar%2Bdetection%2B-%2Bv3.ipynb" target="_blank" rel="noopener">Car detection with YOLOv2</a></p><p>YOLO model is very computationally expensive to train</p><p>Find intersection:</p><ul><li>You’ll also need to find the coordinates <code>(xi1, yi1, xi2, yi2)</code> of the intersection of two boxes. Remember that:<ul><li>xi1 = maximum of the x1 coordinates of the two boxes</li><li>yi1 = maximum of the y1 coordinates of the two boxes</li><li>xi2 = minimum of the x2 coordinates of the two boxes</li><li>yi2 = minimum of the y2 coordinates of the two boxes</li></ul></li><li>In order to compute the intersection area, you need to make sure the height and width of the intersection are positive, otherwise the intersection area should be zero. Use <code>max(height, 0)</code> and <code>max(width, 0)</code>.</li></ul><p><strong>What you should remember</strong>:</p><ul><li>YOLO is a state-of-the-art object detection model that is fast and accurate</li><li>It runs an input image through a CNN which outputs a 19x19x5x85 dimensional volume. </li><li>The encoding can be seen as a grid where each of the 19x19 cells contains information about 5 boxes.</li><li>You filter through all the boxes using non-max suppression. Specifically: <ul><li>Score thresholding on the probability of detecting a class to keep only accurate (high probability) boxes</li><li>Intersection over Union (IoU) thresholding to eliminate overlapping boxes</li></ul></li><li>Because training a YOLO model from randomly initialized weights is non-trivial and requires a large dataset as well as lot of computation, we used previously trained model parameters in this exercise. If you wish, you can also try fine-tuning the YOLO model with your own dataset, though this would be a fairly non-trivial exercise. </li></ul><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Special-applications-Face-recognition-amp-Neural-style-transfer"><a href="#Special-applications-Face-recognition-amp-Neural-style-transfer" class="headerlink" title="Special applications: Face recognition &amp; Neural style transfer"></a>Special applications: Face recognition &amp; Neural style transfer</h2><p><strong>Face verification vs. face recognition</strong></p><p>Verification:</p><ul><li>Input image, name/ID</li><li>Output whether the input image is that of the claimed person</li><li>1:1</li></ul><p>Recognition</p><ul><li>Has a database of K persons</li><li>Get an input image</li><li>Output ID if the image is any of the K persons (or “not recognized”)</li></ul><p><strong>One-shot learning</strong></p><p>Learning from one example to recognize the person again</p><p>Strategy: Learning a “similarity” function</p><p>d(img1, img2) = degree of difference between images, and predict by difference</p><p><strong>Siamese network</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-15.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-16.png" style="zoom:60%"><br></center><p><strong>Triplet loss</strong></p><p>Always look at three images at a time: Anchor, Positive and Negative</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-17.png" style="zoom:60%"><br></center><p>Choosing the triplets A,P,N</p><p>During training, if A,P,N are chosen randomly, $d(A,P)+\alpha \le d(A,N)$ is easily satisfied.</p><p>Idea: Choose triplets that’re “hard” to train on. (refer to the paper FaceNet)</p><p>Popular way to name system:</p><ul><li>____ Net</li><li>Deep ____</li></ul><p><strong>Neural style transfer</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-18.png" style="zoom:60%"><br></center><p>Visualizing what a deep network is learning</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-19.png" style="zoom:60%"><br></center><p><strong>Cost function</strong><br>$$<br>J(G) = \alpha J_{content}(C,G)+\beta J_{style}(S,G)<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-20.png" style="zoom:60%"><br></center><p><strong>Content cost function</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-21.png" style="zoom:60%"><br></center><p><strong>Style cost function</strong></p><p>Define style as correlation between activations across channels</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-22.png" style="zoom:60%"><br></center><p><strong>Convolutions in 2D and 1D</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-23.png" style="zoom:60%"><br></center><p><strong>3D convolution</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-05-04-Week3-24.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Art-generation-with-Neural-Style-Transfer"><a href="#Programming-Assignment-Art-generation-with-Neural-Style-Transfer" class="headerlink" title="Programming Assignment: Art generation with Neural Style Transfer"></a>Programming Assignment: Art generation with Neural Style Transfer</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 4/Art%2BGeneration%2Bwith%2BNeural%2BStyle%2BTransfer%2B-%2Bv2.ipynb" target="_blank" rel="noopener">Art generation with Neural Style Transfer</a></p><p>Neural Style Transfer (NST) uses a previously trained convolutional network, and builds on top of that.</p><h2 id="Programming-Assignment-Face-Recognition-for-the-Happy-House"><a href="#Programming-Assignment-Face-Recognition-for-the-Happy-House" class="headerlink" title="Programming Assignment: Face Recognition for the Happy House"></a>Programming Assignment: Face Recognition for the Happy House</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Convolutional Neural Networks/Week 4/Face%2BRecognition%2Bfor%2Bthe%2BHappy%2BHouse%2B-%2Bv3.ipynb" target="_blank" rel="noopener">Face Recognition for the Happy House</a></p><ul><li>Face verification solves an easier 1:1 matching problem; face recognition addresses a harder 1:K matching problem.</li><li>The triplet loss is an effective loss function for training a neural network to learn an encoding of a face image.</li><li>The same encoding can be used for verification and recognition. Measuring distances between two images’ encodings allows you to determine whether they are pictures of the same person.</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai Specialization&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Scikit-learn Summary</title>
    <link href="http://yoursite.com/2019/04/24/Sklearn%20Summary/"/>
    <id>http://yoursite.com/2019/04/24/Sklearn Summary/</id>
    <published>2019-04-25T04:17:34.000Z</published>
    <updated>2019-05-03T18:55:56.773Z</updated>
    
    <content type="html"><![CDATA[<p>Scikit-learn</p><p>Summary</p><a id="more"></a><h1 id="ML-Methods"><a href="#ML-Methods" class="headerlink" title="ML Methods"></a>ML Methods</h1><ul><li><p>Decision tree </p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">model = DecisionTreeRegressor(random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>Random forest</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line">model = RandomForestRegressor(n_estimators=<span class="number">100</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li></ul><ul><li><p>Model selection</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">train_X, val_X, train_y, val_y = train_test_split(X, y, train_size=<span class="number">0.8</span>, test_size=<span class="number">0.2</span>, random_state=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></li><li><p>Evaluation metrics</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line">val_mae = mean_absolute_error(val_prediction, val_y)</span><br></pre></td></tr></table></figure></li><li><p>Save to csv</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">output = pd.DataFrame(&#123;<span class="string">'Id'</span>: test_data.Id, </span><br><span class="line">                       <span class="string">'SalePrice'</span>: test_preds&#125;)</span><br></pre></td></tr></table></figure></li><li><p>Imputation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="comment"># Imputation</span></span><br><span class="line">my_imputer = SimpleImputer()</span><br><span class="line">imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train))</span><br><span class="line">imputed_X_valid = pd.DataFrame(my_imputer.transform(X_valid))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Imputation removed column names; put them back</span></span><br><span class="line">imputed_X_train.columns = X_train.columns</span><br><span class="line">imputer_X_valid.columns = X_valid.columns</span><br><span class="line"></span><br><span class="line"><span class="comment"># Extension to Imputation</span></span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> cols_with_missing:</span><br><span class="line">    X_train_plus[col + <span class="string">'_was_missing'</span>] = X_train_plus[col].isnull()</span><br><span class="line">    X_valid_plus[col + <span class="string">'_was_missing'</span>] = X_valid_plus[val].isnull()</span><br></pre></td></tr></table></figure></li><li><p>Numerical selection</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = X_full.select_dtypes(exclude=[<span class="string">'object'</span>])</span><br></pre></td></tr></table></figure></li><li><p>Drop NA</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cols_with_missing = [col <span class="keyword">in</span> X_train.columns <span class="keyword">if</span> X_train[col].isnull().any()]</span><br><span class="line">X_train = X_train.drop(cols_with_missing, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p>Drop Categorical Variables (typically perform worst)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">drop_X_train = X_train.select_dtypes(exclude=[<span class="string">'object'</span>])</span><br><span class="line">drop_X_valid = X_valid.select_dtypes(exclude=[<span class="string">'object'</span>])</span><br></pre></td></tr></table></figure></li><li><p>Label Encoding (randomly)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line">label_X_train = X_train.copy()</span><br><span class="line">label_X_valid = X_valid.copy()</span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line"><span class="keyword">for</span> col <span class="keyword">in</span> object_cols:</span><br><span class="line">    label_X_train[col] = label_encoder.fit_transform(X_train[col])</span><br><span class="line">    label_X_valid[col] = label_encoder.transform(X_valid[col])</span><br></pre></td></tr></table></figure></li><li><p>One-Hot Encoding (typically perform best)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line">OH_encoder = OneHotEncoder(handle_unknown=<span class="string">'ignore'</span>, sparse=<span class="keyword">False</span>)</span><br><span class="line">OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))</span><br><span class="line">OH_cols_valid = pd.DataFrame(OH_encoder.transform(X_valid[object_cols]))</span><br><span class="line"><span class="comment"># One-hot encoding removed index; put it back</span></span><br><span class="line">OH_cols_train.index = X_train.index</span><br><span class="line">OH_cols_valid.index = X_valid.index</span><br><span class="line"><span class="comment"># Remove categorical columns</span></span><br><span class="line">num_X_train = X_train.drop(object_cols, axis=<span class="number">1</span>)</span><br><span class="line">num_X_valid = X_valid.drop(object_cols, axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Add one-hot encoded columns to numerical features</span></span><br><span class="line">OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=<span class="number">1</span>)</span><br><span class="line">OH_X_valid = pd.concat([num_X_train, OH_cols_valid], axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># pandas implementation</span></span><br><span class="line">X_train = pd.get_dummies(X_train)</span><br><span class="line">X_valid = pd.get_dummies(X_valid)</span><br><span class="line">X_test = pd.get_dummies(X_test)</span><br><span class="line">X_train, X_valid = X_train.align(X_valid, join=<span class="string">'left'</span>, axis=<span class="number">1</span>)</span><br><span class="line">X_train, X_test = X_train.align(X_test, join=<span class="string">'left'</span>, axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li><li><p>Remove rows with missing target</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X.dropna(axis=<span class="number">0</span>, subset=[<span class="string">'SalePrice'</span>, inplace=<span class="keyword">True</span>])</span><br></pre></td></tr></table></figure></li><li><p>Object columns selection</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">object_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> X_train.columns <span class="keyword">if</span> X_train[col].dtype == <span class="string">"object"</span>]</span><br><span class="line"><span class="comment"># Columns that can be safely label encoded</span></span><br><span class="line">good_label_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> object_cols <span class="keyword">if</span> set(X_train[col]) == set(X_valid[col])]</span><br><span class="line"><span class="comment"># Problematic columns that will be dropped from the dataset</span></span><br><span class="line">bad_label_cols = list(set(object_cols)-set(good_label_cols)</span><br></pre></td></tr></table></figure></li><li><p>Ont-Hot columns selection</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">low_cardinality_cols = [col <span class="keyword">for</span> col <span class="keyword">in</span> object_cols <span class="keyword">if</span> X_train[col].nunique() &lt; <span class="number">10</span>]</span><br><span class="line">high_cardinality_cols = list(set(object_cols)-set(low_cardinality_cols))</span><br></pre></td></tr></table></figure></li><li><p>Pipelines</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.compose <span class="keyword">import</span> ColumnTransformer</span><br><span class="line"><span class="keyword">from</span> sklearn.pipeline <span class="keyword">import</span> Pipeline</span><br><span class="line"><span class="comment"># from sklearn.pipeline import make_pipeline # used when there is no data preprocessing</span></span><br><span class="line"><span class="keyword">from</span> sklearn.impute <span class="keyword">import</span> SimpleImputer</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> mean_absolute_error</span><br><span class="line"><span class="comment"># Preprocessing for numerical data</span></span><br><span class="line">numerical_transformer = SimpleImputer(strategy=<span class="string">'constant'</span>)</span><br><span class="line"><span class="comment"># Preprocessing for categorical data</span></span><br><span class="line">categorical_transformer = Pipeline(steps=[</span><br><span class="line">    (<span class="string">'imputer'</span>, SimpleImputer(strategy=<span class="string">'most_frequent'</span>)),</span><br><span class="line">    (<span class="string">'onehot'</span>, OneHotEncoder(handdle_unknown=<span class="string">'ignore'</span>))</span><br><span class="line">])</span><br><span class="line"><span class="comment"># Bundle preprocessing for numerical and categorical data</span></span><br><span class="line">preprocessor = ColumnTransformer(</span><br><span class="line">transformers=[</span><br><span class="line">        (<span class="string">'num'</span>, numerical_transformer, numerical_cols),</span><br><span class="line">        (<span class="string">'cat'</span>, categorical_transformer, categorical_cols)</span><br><span class="line">    ]</span><br><span class="line">)</span><br><span class="line"><span class="comment"># Bundle preprocessing and modeling code in a pipeline</span></span><br><span class="line">my_pipeline = Pipeline(steps=[(<span class="string">'preprossor'</span>, preprocessor),</span><br><span class="line">                              (<span class="string">'model'</span>, model)</span><br><span class="line">                             ])</span><br><span class="line"><span class="comment"># Preprocessing of training data, fit model</span></span><br><span class="line">my_pipeline.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># Preprocessing of validation data, get predictions</span></span><br><span class="line">preds = my_pipeline.predict(X_valid)</span><br><span class="line"><span class="comment"># Evaluate the model</span></span><br><span class="line">score = mean_absolute_error(y_valid, preds)</span><br></pre></td></tr></table></figure></li><li><p>Proper columns selection</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Select categorical columns with relatively low cardinality</span></span><br><span class="line">categorical_cols = [cname <span class="keyword">for</span> cname <span class="keyword">in</span> X_train_full.columns <span class="keyword">if</span> </span><br><span class="line">                    X_train_full[cname].nunique() &lt; <span class="number">10</span> <span class="keyword">and</span></span><br><span class="line">                    X_train_full[cname].dtype == <span class="string">'object'</span>]</span><br><span class="line"><span class="comment"># Select numerical columns</span></span><br><span class="line">numerical_cols = [cname <span class="keyword">for</span> cname <span class="keyword">in</span> X_train_full.columns <span class="keyword">if</span></span><br><span class="line">                  X_train_full[cname].dtype <span class="keyword">in</span> [<span class="string">'int64'</span>, <span class="string">'float64'</span>]]</span><br></pre></td></tr></table></figure></li><li><p>Read in data</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_full = pd.read_csv(<span class="string">'../input/train.csv'</span>, index_col=<span class="string">'Id'</span>)</span><br></pre></td></tr></table></figure></li><li><p>Output data</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">output = pd.DataFrame(&#123;<span class="string">'Id'</span>: X_test.index,</span><br><span class="line">                       <span class="string">'SalePrice'</span>: preds_test&#125;)</span><br><span class="line">output.to_csv(<span class="string">'submission.csv'</span>, index=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></li><li><p>Cross validation</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line">score = <span class="number">-1</span> * cross_val_score(my_pipeline, X, y</span><br><span class="line">                             cv=<span class="number">5</span>,<span class="comment"># 5 folds cross validation</span></span><br><span class="line">                             scoring=<span class="string">'neg_mean_absolute_error'</span>) <span class="comment"># scoring='accuracy' for classification problem</span></span><br></pre></td></tr></table></figure></li><li><p><strong>XGBoost</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> xgboost <span class="keyword">import</span> XGBRegressor</span><br><span class="line"></span><br><span class="line">my_model = XGBRegressor()</span><br><span class="line"><span class="comment"># my_model = XGBRegressor(n_estimators=500)</span></span><br><span class="line"><span class="comment"># my_model.fit(X_train, y_train,</span></span><br><span class="line"><span class="comment">#   early_stopping_rounds=5,</span></span><br><span class="line"><span class="comment">#       eval_set=[(X_valid, y_valid)],</span></span><br><span class="line"><span class="comment">#              verbose=False)</span></span><br><span class="line"><span class="comment"># my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05)</span></span><br><span class="line"><span class="comment"># my_model = XGBRegressor(n_estimators=1000, learning_rate=0.05, n_jobs=4)</span></span><br><span class="line">my_model.fit(X_train, y_train)</span><br></pre></td></tr></table></figure><p>parameters:</p><ul><li><code>n_estimators</code>: specifies how many times to go through the modeling cycle. low: underfuttubg, high: overfitting. Typically value is 100-1000.</li><li><code>early_stopping_rounds</code>: this parameter causes the model to stop iterating when the validation scores stops improving. It’s smart to set a high value for <code>n_estimators</code> and then use <code>early_stopping_rounds</code> to find the optimal time to stop iterating. Since random chance sometimes causes a single round where validation scores don’t improve, you nedd to specify a number for how many rounds of straight deterioration to allow before stopping. Setting <code>early_stopping_rounds=5</code> is a reasonable choice. In this case, we stop after 5 straight rounds of deteriorating validation scores.</li><li><code>learning_rate</code>: Instead of getting predictions by simply adding up the predictions from each component model, we can multiply the predictions from each model by a small number (known as the <strong>learning rate</strong>) before adding them in. In general, a small learning rate and large number of estimators will yield more accurate XGBoost models, through it will also take the model longer to train since it does more iterations through the cycle. As default, XGBoost sets <code>learning_rate=0.1</code>.</li><li><code>n_jobs</code>: On large datasets where runtime is a consideration, you can use parallelism to build your model faster. It’s common to set the parameter <code>n_jobs</code> equal to the number of cores on your machine. On smaller datasets, this won’t help.</li></ul></li><li><p>Data leakage: target leakage and train-test contamination.</p><ul><li>Target leakage: Any variable updated (or created) after the target value is realized should be excluded. Data exploration can really help identify target leakage.</li><li>Train-test contamination: Happens when validation data affects the preprocessing behavior. If the validation is based on a simple train-test split, exclude the validation from any type of fitting, including the fitting of preprocessing steps. Careful separation of training and validation data can prevent train-test contamination and pipelines can help.</li></ul></li></ul><p><strong>Machine Learning Pipeline</strong></p><ol><li>Define Preprocessing Steps</li><li>Define the Model</li><li>Create and Evaluate the Pipeline</li></ol><h1 id="Pandas"><a href="#Pandas" class="headerlink" title="Pandas"></a>Pandas</h1><ul><li><p>Creating data: <strong>DataFrame</strong> and <strong>Series</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DataFrame</span></span><br><span class="line">pd.DataFrame(&#123;<span class="string">'Yes'</span>: [<span class="number">50</span>, <span class="number">21</span>], <span class="string">'No'</span>: [<span class="number">131</span>, <span class="number">2</span>]&#125;)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># DataFrame with customized index (row labels)</span></span><br><span class="line">pd.DataFrame(&#123;<span class="string">'Bob'</span>: [<span class="string">'I liked it.'</span>, <span class="string">'It was awful.'</span>], </span><br><span class="line">              <span class="string">'Sue'</span>: [<span class="string">'Pretty good.'</span>, <span class="string">'Bland.'</span>]&#125;,</span><br><span class="line">             index=[<span class="string">'Product A'</span>, <span class="string">'Product B'</span>])</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Series</span></span><br><span class="line">pd.Series([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="comment"># Series with a name</span></span><br><span class="line">pd.Series([<span class="number">30</span>, <span class="number">35</span>, <span class="number">40</span>], index=[<span class="string">'2015 Sales'</span>, <span class="string">'2016 Sales'</span>, <span class="string">'2017 Sales'</span>], name=<span class="string">'Product A'</span>)</span><br></pre></td></tr></table></figure></li><li><p>Read file</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine_reviews = pd.read_csv(<span class="string">"../input/wine-reviews/winemag-data-130k-v2.csv"</span>, index_col=<span class="number">0</span>) <span class="comment"># set the index column (otherwise pandas will create a default column)</span></span><br></pre></td></tr></table></figure></li><li><p>Summary functions (type-aware)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews.describe()</span><br></pre></td></tr></table></figure></li><li><p>List unique values</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reviews.taster_name.unique()</span><br><span class="line">reviews.taster_name.value_counts()<span class="comment"># unique value counts</span></span><br></pre></td></tr></table></figure></li><li><p>Maps</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Series.map</span></span><br><span class="line">review_point_mean = reviews.points.mean()</span><br><span class="line">reviews_points.map(<span class="keyword">lambda</span> p: p - review_point_mean)</span><br><span class="line"><span class="comment"># Apply to a whole DataFrame</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">remean_points</span><span class="params">(row)</span>:</span></span><br><span class="line">    row.points = row.points - review_points_mean</span><br><span class="line">    <span class="keyword">return</span> row</span><br><span class="line"></span><br><span class="line">reviews.apply(remean_points, axis=<span class="string">'columns'</span>)</span><br><span class="line"><span class="comment"># Alternative way (faster)</span></span><br><span class="line">review_points_mean = reviews.points.mean()</span><br><span class="line">review.points - review_points_mean</span><br></pre></td></tr></table></figure></li><li><p>Group and sorting</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">reviews.groupby(<span class="string">'points'</span>).points.count()</span><br><span class="line">reviews.groupby(<span class="string">'points'</span>).price.min()</span><br><span class="line"><span class="comment"># Value counts</span></span><br><span class="line">reviews_per_region = reviews.region_1.fillna(<span class="string">'Unknown'</span>).value_counts().sort_values(ascending=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">countries_reviewd = countries_reviewd.reset_index()</span><br><span class="line">countries_reviewd.sort_values(by=<span class="string">'len'</span>, ascending=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># Sort by index</span></span><br><span class="line">countries_reviewd.sort_index()</span><br><span class="line"><span class="comment"># Sort with multiple keys</span></span><br><span class="line">countries_reviewd.sort_values(by=[<span class="string">'country'</span>, <span class="string">'len'</span>])</span><br></pre></td></tr></table></figure></li><li><p>Data types</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reviews.price.dtype<span class="comment"># Get type for a single column</span></span><br><span class="line">reviews.dtypes<span class="comment"># Get types for all columns</span></span><br><span class="line">reviews.points.astype(<span class="string">'float64'</span>)<span class="comment"># Change data type</span></span><br></pre></td></tr></table></figure></li><li><p>Missing data</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">reviews[reviews.country.isnull()]</span><br><span class="line">reviews.region_2.fillna(<span class="string">"Unknown"</span>)<span class="comment"># Fill in NA data entries</span></span><br></pre></td></tr></table></figure></li><li><p>Rename (specifying a <code>index</code> or <code>column</code> keyword parameter)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">reviews.rename(columns=&#123;<span class="string">'points'</span>: <span class="string">'score'</span>&#125;)</span><br><span class="line">reviews.rename(index=&#123;<span class="number">0</span>: <span class="string">'firstEntry'</span>, <span class="number">1</span>: <span class="string">'secondEntry'</span>&#125;)<span class="comment"># Rarely</span></span><br><span class="line">reviews.rename_axis(<span class="string">"wines"</span>, axis=<span class="string">'rows'</span>).rename_axis(<span class="string">"fields"</span>, axis=<span class="string">'columns'</span>)<span class="comment"># Set names for row index and column index</span></span><br></pre></td></tr></table></figure></li><li><p>Combining (<code>concat</code>, <code>join</code>, <code>merge</code>)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pd.concat([canadian_youtube, british_youtube])</span><br></pre></td></tr></table></figure></li><li><p>Indexing</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Single row</span></span><br><span class="line">df.iloc[<span class="number">2</span>]<span class="comment"># Make sure to specify a number, zero index</span></span><br><span class="line">df.loc[<span class="string">'BADL'</span>]<span class="comment"># Make sure to pass a value from dataframes's index</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Multiple rows</span></span><br><span class="line">df.loc[[<span class="string">'BADL'</span>, <span class="string">'ARCH'</span>, <span class="string">'ACAD'</span>]]</span><br><span class="line">df.iloc[[<span class="number">2</span>, <span class="number">1</span>, <span class="number">0</span>]]</span><br><span class="line">df[:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Indexing columns</span></span><br><span class="line">df[<span class="string">'State'</span>].head(<span class="number">3</span>)</span><br><span class="line">df.State.head(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Clean the column names</span></span><br><span class="line">df.columns = [col.replace(<span class="string">' '</span>, <span class="string">'_'</span>).lower() <span class="keyword">for</span> col <span class="keyword">in</span> df.columns]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Indexing columns and rows</span></span><br><span class="line">df[[<span class="string">'state'</span>, <span class="string">'acres'</span>]][:<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># Indexing scalar value</span></span><br><span class="line">df.state.iloc[<span class="number">2</span>]<span class="comment"># return a scalar rather than a Series or DataFrame</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Boolean indexing</span></span><br><span class="line">df[df.state == <span class="string">'UT'</span>]</span><br><span class="line"><span class="comment"># Some helpful logical operations: ~: not; |: or; &amp;: and</span></span><br><span class="line"><span class="comment"># E.g.</span></span><br><span class="line">df[(df.latitude &gt; <span class="number">60</span>) | (df.acres &gt; <span class="number">10</span>**<span class="number">6</span>)].head(<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># isin and isnull</span></span><br><span class="line">df[df.state.isin([<span class="string">'WA'</span>, <span class="string">'OR'</span>, <span class="string">'CA'</span>])].head()</span><br></pre></td></tr></table></figure></li><li><p>Bar charts and categorical data (nominal categories and ordinal categories)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews[<span class="string">'province'</span>].value_counts().head(<span class="number">10</span>).plot.bar()</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-1.png" style="zoom:70%"><br></center></li><li><p>Line charts</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews[<span class="string">'points'</span>].value_counts().sort_index().plot.line()</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-2.png" style="zoom:70%"><br></center></li><li><p>Area charts (line charts with the bottom shaded in)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews[<span class="string">'point'</span>].value_count().sort_index().plot.area()</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-3.png" style="zoom:70%"><br></center></li><li><p>Histograms (work best for interval variables without skew or for ordinal categorical variables)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews[reviews[<span class="string">'price'</span>] &lt; <span class="number">200</span>][<span class="string">'price'</span>].plot.hist()</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-4.png" style="zoom:70%"><br></center></li><li><p>Scatter plot (remember to downsample to avoid duplicate), works best with relatively small datasets and large number of unique values</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">review[reviews[<span class="string">'price'</span>] &lt; <span class="number">100</span>].sample(<span class="number">100</span>).plot.scatter(x=<span class="string">'price'</span>, y=<span class="string">'points'</span>)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-5.png" style="zoom:70%"><br></center></li><li><p>Hexplot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reviews[reviews[<span class="string">'price'</span>] &lt; <span class="number">100</span>].plot.hexbin(x=<span class="string">'price'</span>, y=<span class="string">'points'</span>, gridsize=<span class="number">15</span>)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-6.png" style="zoom:70%"><br></center></li><li><p>Stacked plots (work best for nominal categorical or small ordinal categorical variables)</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-7.png" style="zoom:70%"><br></center><p>One categorical variable in the columns, one categorical variable in the rows, and counts of their intersection in the entries.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine_counts.plot.bar(stacked=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-8.png" style="zoom:70%"><br></center><p>Area plot</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-9.png" style="zoom:70%"><br></center></li><li><p>Bivariate line chart</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wine_counts.plot.line()</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-10.png" style="zoom:70%"><br></center></li></ul><h1 id="Seaborn"><a href="#Seaborn" class="headerlink" title="Seaborn"></a>Seaborn</h1><ul><li><p>Line charts</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"Daily Global Streams of Popular Songs in 2017-2018"</span>)</span><br><span class="line">sns.lineplot(daat=fifa_data)<span class="comment"># plot a line for every column in the dataset</span></span><br><span class="line"><span class="comment"># sns.lineplot(data=spotyfy_data['Shape of You'], label="Shape of You")# plot one column, label represents adding legend</span></span><br></pre></td></tr></table></figure></li><li><p>Bar charts</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">6</span>))</span><br><span class="line">plt.title(<span class="string">"..."</span>)</span><br><span class="line">sns.barplot(x=flight_data.index, y=flight_data=[<span class="string">'NK'</span>])</span><br></pre></td></tr></table></figure></li><li><p>Heatmap</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">plt.figure(figsize=(<span class="number">14</span>,<span class="number">7</span>))</span><br><span class="line">plt.title(<span class="string">"..."</span>)</span><br><span class="line">sns.heatmap(data=flight_data, annot=<span class="keyword">True</span>)</span><br></pre></td></tr></table></figure></li><li><p>Scatter plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.scatterplot(x=insurance_data[<span class="string">'bmi'</span>], y=[insurance_data[<span class="string">'charges'</span>]])</span><br><span class="line"><span class="comment"># Add a regression line</span></span><br><span class="line">sns.regplot(x=insurance_data[<span class="string">'bmi'</span>], y=insurance_data[<span class="string">'charges'</span>])</span><br><span class="line"><span class="comment"># Color code with a boolean/categorical column</span></span><br><span class="line">sns.scatterplot(x=insurance_data[<span class="string">'bmi'</span>], y=insurance_data[<span class="string">'charges'</span>], hue=insurance_data[<span class="string">'smoker'</span>])</span><br><span class="line"><span class="comment"># Two regression line</span></span><br><span class="line">sns.lmplot(x=<span class="string">"bmi"</span>, y=<span class="string">"charges"</span>, hue=<span class="string">"smoker"</span>, data=insurance_data)</span><br><span class="line"><span class="comment"># Categorical scatter plot</span></span><br><span class="line">sns.swarmplot(x=insurance_data[<span class="string">'smoker'</span>],</span><br><span class="line">              y=insurance_data[<span class="string">'charges'</span>])</span><br></pre></td></tr></table></figure><p><strong>One regression line</strong></p></li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-7.png" style="zoom:50%"><br></center><p>​        <strong>Two regression lines (hue specified, color coded)</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-8.png" style="zoom:50%"><br></center><p>​        <strong>Categorical scatter plot</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-9.png" style="zoom:50%"><br></center><ul><li><p>Histograms</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.distplot(a=iris_data[<span class="string">'Petal Length (cm)'</span>], kde=<span class="keyword">False</span>, bins=<span class="number">5</span>)</span><br><span class="line"><span class="comment"># a: choose the column we'd like to plot</span></span><br><span class="line"><span class="comment"># kde=False (always included in a histogram)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Histograms for multiple columns</span></span><br><span class="line">sns.distplot(a=iris_set_data[<span class="string">'Petal Length (cm)'</span>], label=<span class="string">'Iris-setosa'</span>, kde=<span class="keyword">False</span>)</span><br><span class="line">sns.distplot(a=iris_ver_data[<span class="string">'Petal Length (cm)'</span>], label=<span class="string">'Iris-versicolor'</span>, kde=<span class="keyword">False</span>)</span><br><span class="line">sns.distplot(a=iris_vir_data[<span class="string">'Petal Length (cm)'</span>], label=<span class="string">'Iris-virginica'</span>, kde=<span class="keyword">False</span>)</span><br><span class="line">plt.legend()<span class="comment"># Force legend to appear</span></span><br></pre></td></tr></table></figure><p>​        <strong>General higtogram</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-1.png" style="zoom:50%"><br></center><p><strong>Histogram of multiple columns</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-4.png" style="zoom:50%"><br></center></li><li><p>Density plots</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line">sns.kdeplot(data=iris_data[<span class="string">'Petal Length (cm)'</span>], shade=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment"># 2D kde plots</span></span><br><span class="line">sns.jointplot(x=iris_data[<span class="string">'Petal Length (cm)'</span>], y=iris_data[<span class="string">'Sepal Width (cm)'</span>], kind=<span class="string">"kde"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># KDE plot for multiple columns</span></span><br><span class="line">sns.kdeplot(data=iris_set_data[<span class="string">'Petal Length (cm)'</span>], label=<span class="string">'Iris-setosa'</span>, shade=<span class="keyword">True</span>)<span class="comment"># shade is used to fill in the color below the KDE plot</span></span><br><span class="line"><span class="comment"># and so on</span></span><br></pre></td></tr></table></figure><p>​        <strong>General KDE plot</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-2.png" style="zoom:50%"><br></center><p>​        <strong>2D KDE plot</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-3.png" style="zoom:50%"><br></center><pre><code>**KDE plot for multiple columns**</code></pre><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-29-5.png" style="zoom:50%"><br></center></li><li><p>Choosing the best type of chart</p><ul><li><strong>Trends</strong>: A trend is defined as a pattern of change.<ul><li><code>sns.lineplot</code> - <strong>Line charts</strong> are the best to show trends over a period of time, and multiple lines can be used to show trends in more than one  group.</li></ul></li><li><strong>Relationship</strong>: There are many different chart for show this.<ul><li><code>sns.barplot</code>- <strong>Bar charts</strong> are useful for comparing quantities corresponding to different groups.</li><li><code>sns.heatmap</code>- <strong>Heatmaps</strong> can be used to find color-coded patterns in table  of numbers.</li><li><code>sns.scatterplot</code>- <strong>Scatter plots</strong> show the relation between two continuous variables; if color-coded, we can also show the relationship with categorical variables.</li><li><code>sns.regplot</code>- Including a <strong>regression line</strong> in the  scatter plot makes it easier to see linear relationship between two variables.</li><li><code>sns.lmplot</code>- This command is useful for drawing multiple regression lines, if the scatter plot contains multiple, color-coded groups.</li><li><code>sns.swarmplot</code>- <strong>Categorical scatter plots</strong> show the relationship between a continuous variable and a categorical variable.</li></ul></li><li><strong>Distribution</strong>: We visualize distribution to show the possible values that we can expect to see in a variable.<ul><li><code>sns.distplot</code>- <strong>Histograms</strong> show the distribution of a single numerical variable.</li><li><code>sns.kdeplot</code>- <strong>KDE plots</strong> (or <strong>2D KDE plots</strong>) to show anestimated, smooth distribution of a single numerical variable (or two numerical variables).</li><li><code>sns.jointplot</code>- This command is useful for simultaneously displaying a 2D KDE plot with the correspoinding KDE plots for each individual variable.</li></ul></li></ul></li><li><p>Set styles for the figure</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(<span class="string">"dark"</span>)<span class="comment"># set dark style for the figure, five themes: "darkgrid", "whitegrid", "dark", "white", "ticks". The default theme is "darkgrid"</span></span><br><span class="line">plt.figure(figure=(<span class="number">12</span>,<span class="number">6</span>))<span class="comment"># change the figure size</span></span><br></pre></td></tr></table></figure></li><li><p>Countplot (doesn’t require us to shape the data)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.countplot(reviews[<span class="string">'points'</span>])</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-11.png" style="zoom:70%"><br></center></li><li><p>KDE plot (kernel density estimate), worse choice for ordinal categorical data, KDE plot will fit to something that doesn’t exist.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.kdeplot(reviews.query(<span class="string">'price &lt; 200'</span>).price)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-12.png" style="zoom:70%"><br></center></li><li><p>Bivariate hex plot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.jointplot(x=<span class="string">'price'</span>, y=<span class="string">'points'</span>, data=reviews[reviews[<span class="string">'price'</span>] &lt; <span class="number">100</span>], kind=<span class="string">'hex'</span>, gridsize=<span class="number">20</span>)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-13.png" style="zoom:70%"><br></center></li><li><p>Boxplot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">df = reviews[reviews.variety.isin(reviews.variety.value_counts().head(<span class="number">5</span>).index)]</span><br><span class="line"></span><br><span class="line">sns.boxplot(</span><br><span class="line">    x=<span class="string">'variety'</span>,</span><br><span class="line">    y=<span class="string">'points'</span>,</span><br><span class="line">    data=df</span><br><span class="line">)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-14.png" style="zoom:70%"><br></center><p>The center of the distributions shown above is the “box” in boxplot. The top of the box is the 75th percentile, while the bottom is the 25th percentile. In other words, half of the data is distributed within the box. The green line in the middle is the median. (50% of the data in the distribution is located within the box)</p><p>The other part of the plot, the “whiskers”, shows the extent of the points beyond the center of the distribution. Individual circles beyond that are outliers.</p><p>Boxplots are great for summarizing the shape of many datasets. They also don’t have a limit in terms of numeracy: you can place as many boxes in the plot as you feel comfortable squeezing onto the page.</p><p>However, they only work for interval variables and nomial variables and nominal variables with a large number of possible values and they don’t carry any information about individual values, only treating the distribution as a whole. </p></li><li><p>Violinplot</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sns.violinplot(</span><br><span class="line">    x=<span class="string">'variety'</span>,</span><br><span class="line">    y=<span class="string">'points'</span>,</span><br><span class="line">    data=reviews[reviews.variety.isin(reviews.variety.value_counts()[:<span class="number">5</span>].index)]</span><br><span class="line">)</span><br></pre></td></tr></table></figure><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-15.png" style="zoom:70%"><br></center><p>Harder to misinterpret and much prettier than the utilitarian boxplot</p></li><li><p>Facet</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-30-16.png" style="zoom:60%"><br></center></li></ul><h1 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h1><ul><li><p>Transfer Learning</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.python.keras.applications <span class="keyword">import</span> ResNet50</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.layers <span class="keyword">import</span> Dense, Flatten, GlobalAveragePooling2D</span><br><span class="line"></span><br><span class="line">num_classes = <span class="number">2</span></span><br><span class="line">resnet_weights_path = <span class="string">'../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'</span></span><br><span class="line"></span><br><span class="line">my_new_model = Sequential()</span><br><span class="line">my_new_model.add(ResNet50(include_top=<span class="keyword">False</span>, pooling=<span class="string">'avg'</span>, weights=resnet_weights_path))</span><br><span class="line">my_new_model.add(Dense(num_classes, activation=<span class="string">'softmax'</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Say not to train first layer (ResNet) model. It is already trained</span></span><br><span class="line">my_new_model.layers[<span class="number">0</span>].trainable = <span class="keyword">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Compipe model</span></span><br><span class="line">my_new_model.compile(optimizer=<span class="string">'sgd'</span>, loss=<span class="string">'categorical_crossentropy'</span>, metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.applications.resnet50 <span class="keyword">import</span> preprocess_input</span><br><span class="line"><span class="keyword">from</span> tensorflow.python.keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">image_size = <span class="number">224</span></span><br><span class="line">data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Fit model</span></span><br><span class="line">train_generator = data_generator.flow_from_directory(</span><br><span class="line">        <span class="string">'../input/urban-and-rural-photos/rural_and_urban_photos/train'</span>,</span><br><span class="line">        target_size=(image_size, image_size),</span><br><span class="line">        batch_size=<span class="number">24</span>,</span><br><span class="line">        class_mode=<span class="string">'categorical'</span>)</span><br><span class="line"></span><br><span class="line">validation_generator = data_generator.flow_from_directory(</span><br><span class="line">        <span class="string">'../input/urban-and-rural-photos/rural_and_urban_photos/val'</span>,</span><br><span class="line">        target_size=(image_size, image_size),</span><br><span class="line">        class_mode=<span class="string">'categorical'</span>)</span><br><span class="line"></span><br><span class="line">my_new_model.fit_generator(</span><br><span class="line">        train_generator,</span><br><span class="line">        steps_per_epoch=<span class="number">3</span>,</span><br><span class="line">        validation_data=validation_generator,</span><br><span class="line">        validation_steps=<span class="number">1</span>)</span><br></pre></td></tr></table></figure></li></ul><h1 id="Relate-CoLab-and-Google-Drive"><a href="#Relate-CoLab-and-Google-Drive" class="headerlink" title="Relate CoLab and Google Drive"></a>Relate CoLab and Google Drive</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">!apt-get install -y -qq software-properties-common python-software-properties module-init-tools</span><br><span class="line">!add-apt-repository -y ppa:alessandro-strada/ppa 2&gt;&amp;1 &gt; /dev/null</span><br><span class="line">!apt-get update -qq 2&gt;&amp;1 &gt; /dev/null</span><br><span class="line">!apt-get -y install -qq google-drive-ocamlfuse fuse</span><br><span class="line">from google.colab import auth</span><br><span class="line">auth.authenticate_user()</span><br><span class="line">from oauth2client.client import GoogleCredentials</span><br><span class="line">creds = GoogleCredentials.get_application_default()</span><br><span class="line">import getpass</span><br><span class="line">!google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125; &lt; /dev/null 2&gt;&amp;1 | grep URL</span><br><span class="line">vcode = getpass.getpass()</span><br><span class="line">!echo &#123;vcode&#125; | google-drive-ocamlfuse -headless -id=&#123;creds.client_id&#125; -secret=&#123;creds.client_secret&#125;</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># specify Google Drive root directory，名为drive</span><br><span class="line">!mkdir -p drive</span><br><span class="line">!google-drive-ocamlfuse drive</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">os.chdir(&quot;drive/Colab Notebooks&quot;)</span><br></pre></td></tr></table></figure><p>Success!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Scikit-learn&lt;/p&gt;
&lt;p&gt;Summary&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Keras" scheme="http://yoursite.com/tags/Keras/"/>
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Scikit-learn" scheme="http://yoursite.com/tags/Scikit-learn/"/>
    
  </entry>
  
  <entry>
    <title>Structuring Machine Learning Projects</title>
    <link href="http://yoursite.com/2019/04/24/Structuring%20Machine%20Learning%20Projects/"/>
    <id>http://yoursite.com/2019/04/24/Structuring Machine Learning Projects/</id>
    <published>2019-04-25T04:17:34.000Z</published>
    <updated>2019-04-26T14:46:56.955Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai Specialization</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="ML-Strategy"><a href="#ML-Strategy" class="headerlink" title="ML Strategy"></a>ML Strategy</h2><p>Ideas:</p><ul><li>Collect more data</li><li>Collect more diverse training set</li><li>Train algorithm longer with gradient descent</li><li>Try Adam instead of gradient descent</li><li>Try bigger network</li><li>Try smaller network</li><li>Try dropout</li><li>Add $L_2$ regularization</li><li>Network architecture<ul><li>Activation functions</li><li>Hidden units</li></ul></li></ul><p><strong>Orthogonalization</strong></p><p>Chain of assumptions in ML</p><ul><li>Fit training set well on cost function</li><li>Fit dev set well on cost function</li><li>Fit test set well on cost function</li><li>Performs well in real world</li></ul><p>Early stopping is not a good strategy</p><p><strong>Single number evaluation metric</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-25-Week1-1.png" style="zoom:60%"><br></center><p>$F_1$ Score can evaluate the model performance<br>$$<br>F_1 = \frac{2}{\frac1P+\frac1R}<br>$$</p><p><strong>Optimizing and satisficing</strong></p><p>E.g.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-25-Week1-2.png" style="zoom:60%"><br></center><p><strong>Splitting data</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-25-Week1-3.png" style="zoom:60%"><br></center><p>Set the test set to be big enough to give high confidence in the overall performance of your system</p><p>Model performance</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-25-Week1-4.png" style="zoom:60%"><br></center><p>So long as ML is worse than humans, you can:</p><ul><li>Get labeled data from humans</li><li>Gain insight from manual error analysis: Why did a person get this right?</li><li>Better analysis of bias/variance</li></ul><p>Human-level error as a proxy for Bayes error</p><p><strong>Surpassing human-level performance</strong></p><ul><li>Online advertising</li><li>Product recommendations</li><li>Logistics (predicting transit time)</li><li>Loan approvals</li><li>Speech recognition</li><li>Computer vision</li></ul><p><strong>Two fundamental assumptions of supervised learning</strong></p><ol><li>You can fit the training set pretty well.</li><li>The training set performance generalizes pretty well to the dev/test set.</li></ol><p>Avoidable bias: Train bigger model. Train longer/better optimization algorithms. NN architecture/hyperparameters search.</p><p>Variance: More data. Regularization. NN architecture/hyperparameters search.</p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="ML-Strategy-1"><a href="#ML-Strategy-1" class="headerlink" title="ML Strategy"></a>ML Strategy</h2><p><strong>Incorrectly labeld examples</strong></p><p>DL algorithms are quite robust to random errors in the training set. (so long as the total dataset is large enough and the error percentage is not too high)</p><p>DL are less robust to systematic errors</p><p>Error analysis:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-26-Week2-1.png" style="zoom:60%"><br></center><p>Effor evaluation</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-26-Week2-2.png" style="zoom:60%"><br></center><p><strong>Correcting incorrect dev/test set examples</strong></p><ul><li>Apply same process to your dev and test sets to make sure they continue come from the same distribution</li><li>Consider examining examples your algorithm got right as well as ones it got wrong</li><li>Train and dev/test data may now come slightly different distributions</li></ul><p>Tips for building a machine learning system</p><ul><li>Set up dev/test set and metric</li><li>Build initial system quickly</li><li>Use Bias/Variance analysis &amp; Error analysis to prioritize next steps</li></ul><p><strong>Build your first system quickly, then iterate!</strong></p><p><strong>Training and testing on different distributions</strong></p><p>To determine which aspect brings the effect of bias/variance, whether it’s the general reason or the reason caused by changing data distribution. It’s better to introduce a new set:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-26-Week2-3.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-26-Week2-4.png" style="zoom:60%"><br></center><p>Introducing this set helps us determine whether the problem is data mismatch or variance.</p><p><strong>Bias/variance on mismatched training and dev/test sets</strong></p><ul><li>Human level</li><li>Training set error</li><li>Training_dev set error</li><li>Dev error</li><li>Test error</li></ul><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-26-Week2-5.png" style="zoom:60%"><br></center><p><strong>Addressing data mismatch</strong></p><ul><li>Carry out manual error analysis to try to understand difference between training and dev/test sets</li><li>Making training data more similar; or collect more data similar to dev/test sets</li><li>Artificial data synthesis</li></ul><p><strong>Transfer learning</strong></p><p>Pre-training and fune-tuning</p><p>When transfer learning makes sense</p><ul><li>Task A and B have the same input x.</li><li>You have a lot more data for Task A than Task B.</li><li>Low level features from A could be helpful for learning B.</li></ul><p><strong>Multi-task learning</strong></p><p>Multiple labels</p><p>When multi-task learning makes sense</p><ul><li>Training on a set of tasks could benefit from having shared lower-level features.</li><li>Usually: Amount of data you have for each task is quite similar.</li><li>Can train a big enough neural network to do well on all the tasks.</li></ul><p>Transfer learning is used much more often than multi-task learning</p><p><strong>End-to-end learning</strong></p><p>Multiple stages —&gt; A single neural network</p><p>End-to-end network requires a lot of data to gain high performance</p><p><strong>Pros and cons of end-to-end deep learning</strong></p><p>Pros:</p><ul><li>Let the data speak</li><li>Less hand-designing of components needed</li></ul><p>Cons:</p><ul><li>May need large amount of data</li><li>Excludes potentially useful hand-designed components</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai Specialization&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Convolutional Neural Networks in TensorFlow</title>
    <link href="http://yoursite.com/2019/04/21/Convolutional%20Neural%20Networks%20in%20TensorFlow/"/>
    <id>http://yoursite.com/2019/04/21/Convolutional Neural Networks in TensorFlow/</id>
    <published>2019-04-22T01:03:34.000Z</published>
    <updated>2019-05-08T05:13:02.359Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai, Convolutional Neural Networks in TensorFlow</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Exploring-a-Larger-Dataset"><a href="#Exploring-a-Larger-Dataset" class="headerlink" title="Exploring a Larger Dataset"></a>Exploring a Larger Dataset</h2><p>data generation:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image</span><br><span class="line"><span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = train_datagen.flow_from_directory(</span><br><span class="line">train_dir,</span><br><span class="line">    target_size=(<span class="number">150</span>,<span class="number">150</span>),</span><br><span class="line">    batch_size=<span class="number">20</span>,</span><br><span class="line">    class_mode=<span class="string">'binary'</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">100</span>,</span><br><span class="line">    epochs=<span class="number">15</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">50</span>,</span><br><span class="line">    verbose=<span class="number">2</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>RMSProp optimization algorithm is preferable to stochastic gradient descent (SGD).</p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Augmentation-A-technique-to-avoid-overfitting"><a href="#Augmentation-A-technique-to-avoid-overfitting" class="headerlink" title="Augmentation: A technique to avoid overfitting"></a>Augmentation: A technique to avoid overfitting</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Updated to do image augmentation</span></span><br><span class="line">train_datagen = ImageDataGenerator(</span><br><span class="line">rescale = <span class="number">1.</span>/<span class="number">255</span>,</span><br><span class="line">    rotation_range=<span class="number">40</span>,</span><br><span class="line">    width_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    height_shift_range=<span class="number">0.2</span>,</span><br><span class="line">    shear_range=<span class="number">0.2</span>,</span><br><span class="line">    zoom_range=<span class="number">0.2</span>,</span><br><span class="line">    horizontal_flip=<span class="keyword">True</span>,</span><br><span class="line">    fill_mode=<span class="string">'nearest'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>We should do image augmentation both on training set and testing set.</p><p>Using keras API, all augmentation is done in memory, not in disk.</p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h2><p>Take existing model rather than train from scratch.</p><p>Inception</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.applications.inception_v3 <span class="keyword">import</span> InceptionV3</span><br><span class="line"></span><br><span class="line">local_weights_file = <span class="string">'/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'</span></span><br><span class="line"></span><br><span class="line">pre_trained_model = InceptionV3(input_shape = (<span class="number">150</span>,<span class="number">150</span>,<span class="number">3</span>),</span><br><span class="line">                               include_top = <span class="keyword">False</span>,</span><br><span class="line">                               weights = <span class="keyword">None</span>)</span><br><span class="line"></span><br><span class="line">pre_trained_model.load_weights(local_weights_file)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> layer <span class="keyword">in</span> pre_trained_model.layers:</span><br><span class="line">    layer.trainable = <span class="keyword">False</span><span class="comment"># lock layers</span></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line">last_layer = pre_trained_model.get_layer(<span class="string">'mixed7'</span>)</span><br><span class="line">last_output = last_layer.output</span><br><span class="line"></span><br><span class="line">x = layers.Flatten()(last_output)</span><br><span class="line">x = layers.Dense(<span class="number">1024</span>, activation=<span class="string">'relu'</span>)(x)</span><br><span class="line">x = layers.Dropout(<span class="number">0.2</span>)(x)</span><br><span class="line">x = layers.Dense(<span class="number">1</span>, activation=<span class="string">'sigmoid'</span>)(x)</span><br><span class="line"></span><br><span class="line">model = Model(pre_trained_model.input, x)</span><br><span class="line">model.compile(optimizer = RMSprop(lr=<span class="number">0.0001</span>),</span><br><span class="line">             loss = <span class="string">'binary_crossentropy'</span>,</span><br><span class="line">             metrics = [<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Multiclass-Classifications"><a href="#Multiclass-Classifications" class="headerlink" title="Multiclass Classifications"></a>Multiclass Classifications</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line"></span><br><span class="line">train_generator = tran_datagen.flow_from_directory(</span><br><span class="line">train_dir,</span><br><span class="line">    target_size=(<span class="number">300</span>,<span class="number">300</span>),</span><br><span class="line">    batch_size=<span class="number">128</span>,</span><br><span class="line">    class_mode=<span class="string">'categorical'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.optimizers <span class="keyword">import</span> RMSprop</span><br><span class="line"></span><br><span class="line">model.compile(loss=<span class="string">'categorical_crossentropy'</span>,</span><br><span class="line">             optimizer=RMSprop(lr=<span class="number">0.001</span>),</span><br><span class="line">             metrics=[<span class="string">'acc'</span>])</span><br></pre></td></tr></table></figure><p>Useful function:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># summary</span></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment"># visualization</span></span><br><span class="line">plot_model(model, to_file=<span class="string">'model.png'</span>)</span><br><span class="line">SVG(model_to_dot(happyModel).create(prog=<span class="string">'dot'</span>, format=<span class="string">'svg'</span>))</span><br><span class="line"><span class="comment"># evaluate</span></span><br><span class="line">model.evaluate(X_test, y_test)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai, Convolutional Neural Networks in TensorFlow&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Keras" scheme="http://yoursite.com/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>Improving Deep Neural Networks</title>
    <link href="http://yoursite.com/2019/04/20/Improving%20Deep%20Neural%20Networks/"/>
    <id>http://yoursite.com/2019/04/20/Improving Deep Neural Networks/</id>
    <published>2019-04-20T22:55:34.000Z</published>
    <updated>2019-04-25T02:47:39.632Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai Specialization</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Practical-aspects-of-Deep-Learning"><a href="#Practical-aspects-of-Deep-Learning" class="headerlink" title="Practical aspects of Deep Learning"></a>Practical aspects of Deep Learning</h2><p><strong>Train/dev/test sets</strong></p><p>Applied ML is a highly iterative process</p><ul><li>layers</li><li>Hidden units</li><li>Learning rates</li><li>Activation functions</li></ul><p>Idea - Code - Experiment</p><p>Make sure the dev and test come from the same distribution. Because we want to evaluate effects from the dev set.</p><p>Not having a test set might be okay. (Only dev set.)</p><p><strong>Bias and Variance</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-24-Week1-1.png" style="zoom:60%"><br></center><p><strong>Basic recipe for machine learning</strong></p><p>Hign bias -&gt; Bigger network</p><p>High variance -&gt; More data / Regularization / NN architecture</p><p>Training a bigger network almost never hurts if regularized well</p><p><strong>Regularization</strong></p><p>L2 regularization is used much more often</p><p>Frobenius norm is used in Neural network -&gt; weight decay</p><p>Another technical regularization method is dropout</p><p><strong>Inverted dropout</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">keep_prob = <span class="number">0.8</span> <span class="comment"># chosen by user</span></span><br><span class="line">d = np.random.rand(a.shape[<span class="number">0</span>],a.shape[<span class="number">1</span>]) &lt; keep_prob</span><br><span class="line">a = np.multiply(a,d)</span><br><span class="line">a /= keep_prob<span class="comment"># because the output will be reduced by ...</span></span><br></pre></td></tr></table></figure><p>At test time, we <strong>should not</strong> include drop out because we don’t want our prediction to be random. Otherwise, there will be noise.</p><p>We should apply dropout both during forward and backward propagation and shutdown the same neurons in each iteration and we should scale the output by divide keep_prob</p><p>Intuition: Cant’t rely on any one feature, so have to spread out weights.</p><p>Drop out is very frequently used by computer vision. But doesn’t generalize in other application areas.</p><p>We will lose gradient checking tool when including drop out.</p><p><strong>So in conclusion, we should plot the loss figure when including drop out. Because the cost function J is no longer well-defined (thinking about the dead neurons)</strong></p><p>Other regularization methods:</p><ul><li><p>Data augmentation</p></li><li><p>Early stopping</p></li></ul><p>L2 regularization is more useful but the search space for $\lambda$ is large</p><p><strong>Normalization</strong><br>$$<br>\mu=\frac1m\sum_{i=1}^mx^{(i)} \<br>\sigma=\frac1m\sum_{i=1}^mx^{(i)}**2<br>$$</p><p><strong>Normalize the training set and test set the same way</strong></p><p>Zero mean and variance one</p><p><strong>Vanishing / Exploding gradients</strong></p><p><strong>Random initialization</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Wl = np.random.randn(shape) * np.sqrt(<span class="number">2</span>/n)</span><br></pre></td></tr></table></figure><p>Different initialization lead to different results</p><p>Random initialization is used to break symmetry and make sure different hidden units can learn different things</p><p>We should not initialize to values that are too large</p><p>In the weight initialization procedure, we can also tuning the hyper parameter for the variance.</p><p>Poor initialization can lead to vanishing/exploding gradients, which also slow down the optimization algorithm.</p><p><strong>He initialization （designed for ReLU activation), of significant importance</strong></p><p>Multiply random initialization by<br>$$<br>\sqrt{\frac{2}{dimension\space of\space the\space previous \space layer}}<br>$$</p><p><strong>Gradient checking</strong><br>$$<br>\frac{f(\theta+\epsilon)-f(\theta-\epsilon)}{2\epsilon} \approx g(\theta)<br>$$<br>Two-side difference is prefered<br>$$<br>\epsilon = 10^{-7}<br>$$</p><p><strong>Tips for Grad check</strong></p><ul><li>Don’t use in training - only to debug</li><li><p>If algorithm fails grad check, look at components to try to identify bug</p></li><li><p>Remeber regularization</p></li><li>Doesn’t work with dropout (set keep_prob = 1.0 to do grad check)</li><li>Run at random initialization</li></ul><h2 id="Programming-Assignment-Initialization"><a href="#Programming-Assignment-Initialization" class="headerlink" title="Programming Assignment: Initialization"></a>Programming Assignment: Initialization</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Improving Deep Neural Networks/Week 1/Initialization.ipynb" target="_blank" rel="noopener">Initialization</a></p><h2 id="Programming-Assignment-Regularization"><a href="#Programming-Assignment-Regularization" class="headerlink" title="Programming Assignment: Regularization"></a>Programming Assignment: Regularization</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Improving Deep Neural Networks/Week 1/Regularization%2B-%2Bv2.ipynb" target="_blank" rel="noopener">Regularization</a></p><h2 id="Programming-Assignment-Gradient-Checking"><a href="#Programming-Assignment-Gradient-Checking" class="headerlink" title="Programming Assignment: Gradient Checking"></a>Programming Assignment: Gradient Checking</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Improving Deep Neural Networks/Week 1/Gradient%2BChecking%2Bv1.ipynb" target="_blank" rel="noopener">Gradient Checking</a></p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Optimization-algorithms"><a href="#Optimization-algorithms" class="headerlink" title="Optimization algorithms"></a>Optimization algorithms</h2><p><strong>Mini-batch gradient descent</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-24-Week2-1.png" style="zoom:60%"><br></center><p>Choosing mini-batch size:</p><ul><li>If mini-batch size = m : Batch gradient descend</li><li>If mini-batch size size = 1: Stochastic gradient descent: Every example is a mini-batch</li></ul><p>Tipds:</p><ul><li>If small training set: Use batch gradient descent —— 2000</li><li>Otherwise typical mini-batch size: 64, 128, 256, 512</li><li>Make sure mini batch fit in CPU/GPU memory</li><li>Shuffling and Partitioning are the two steps required to build mini-batches</li></ul><p><strong>Exponentially weighted averages</strong><br>$$<br>v_t=\beta v_{t-1}+(1-\beta)\theta_t<br>$$<br><strong>Bias correction</strong><br>$$<br>\frac{v_t}{1-\beta^t}<br>$$</p><p><strong>Graduebt descent with momentum</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-24-Week2-2.png" style="zoom:60%"><br></center><p>Hyperparameters: $\alpha,\beta$<br>$$<br>\beta = 0.9<br>$$<br>In practice, people don’t usually do bias correction in deep learning because after just ten iterations, moving average will warm up.</p><p><strong>RMSprop</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-24-Week2-3.png" style="zoom:60%"><br></center><p><strong>Adam</strong></p><p>Take momentum and RMSprop and put them together</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-24-Week2-4.png" style="zoom:60%"><br></center><p>Hyperparameters choice:<br>$$<br>\beta_1=0.9 \\<br>\theta_2=0.999 \\<br>\epsilon=10^{-8}<br>$$<br>And try different range of $\alpha $</p><p>Adam: Adaptive moment estimation</p><p>For complex problems there will be bigger gains</p><p><strong>Learning rate decay</strong><br>$$<br>\alpha=\frac{1}{1+decay-rate*epoch-num}\alpha_0 \\<br>\alpha = 0.95^{epoch-num}\alpha_0 \\<br>\alpha =\frac{k}{\sqrt{epoch-num}}\alpha_0<br>$$</p><p>Saddle point is different from local optimum. In high dimensional space, we are more likely to encounter saddle point.</p><ul><li>Unlikely to get stuck in a bad local optima</li><li>Plateaus can make learning slow</li></ul><h2 id="Programming-Assignment-Optimization"><a href="#Programming-Assignment-Optimization" class="headerlink" title="Programming Assignment: Optimization"></a>Programming Assignment: Optimization</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Improving Deep Neural Networks/Week 2/Optimization%2Bmethods.ipynb" target="_blank" rel="noopener">Optimization</a></p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Hyperparameter-tuning-Batch-Normalization-and-Programming-Frameworks"><a href="#Hyperparameter-tuning-Batch-Normalization-and-Programming-Frameworks" class="headerlink" title="Hyperparameter tuning, Batch Normalization and Programming Frameworks"></a>Hyperparameter tuning, Batch Normalization and Programming Frameworks</h2><p>In deep learning, choose the hyperparameter combination at random</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-24-Week3-1.png" style="zoom:60%"><br></center><p><strong>Batch Normalization</strong></p><p>Given some intermediate value in NN. $z^{(1)},…,z^{(m)}$<br>$$<br>\mu=\frac1m\sum z^{(i)} \\<br>\sigma^2=\frac1m\sum(z_i-\mu)^2 \\<br>z_{norm}^{(i)} = \frac{z^{(i)}-\mu}{\sqrt{\sigma^2+\epsilon}} \\<br>\hat{z^{(i)}} = \gamma z_{norm}^{(i)} + \beta<br>$$<br>$\gamma $ and $\beta$  are learnable parameters</p><p>BN deals with the situation of Covariate shift</p><p>BN weakens the coupling between earlier layer’s paramers abd later layer’s parameters</p><p>BN has a slight regularization effect, similar to dropout</p><p>BN speeds up training process</p><p><strong>Softmax regression</strong></p><p>Softmax regressuib generalizes logistic regression to C classes</p><p>Loss function<br>$$<br>L(\hat{y},y) = -\sum_{j=1}^cy_jlog\hat{y_j}<br>$$</p><p><strong>Choosing deep learning frameworks</strong></p><ul><li><p>Ease of programming (development and deployment)</p></li><li><p>Running speed</p></li><li>Truly open (open source with good governance)</li></ul><p><strong>TensorFlow</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.Variable(<span class="number">0</span>, dtype.float32)</span><br><span class="line">tf.placeholder(tf.float32, [<span class="number">3</span>,<span class="number">1</span>])</span><br></pre></td></tr></table></figure><p>Typical steps:</p><ul><li>Create a graph containing Tensors (Variables, Placeholders …) and Operations (tf.matmul, tf.add)</li><li>Create a session</li><li>Initialize the session</li><li>Run the session to execute the graph</li></ul><h2 id="Programming-Assignment-TensorFlow"><a href="#Programming-Assignment-TensorFlow" class="headerlink" title="Programming Assignment: TensorFlow"></a>Programming Assignment: TensorFlow</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Improving Deep Neural Networks/Week 3/Tensorflow%2BTutorial.ipynb" target="_blank" rel="noopener">TensorFlow</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai Specialization&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Neural Networks and Deep Learning</title>
    <link href="http://yoursite.com/2019/04/20/Neural%20Networks%20and%20Deep%20Learning/"/>
    <id>http://yoursite.com/2019/04/20/Neural Networks and Deep Learning/</id>
    <published>2019-04-20T06:55:34.000Z</published>
    <updated>2019-04-24T19:28:41.249Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai Specialization</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Introduction-to-deep-learning"><a href="#Introduction-to-deep-learning" class="headerlink" title="Introduction to deep learning"></a>Introduction to deep learning</h2><ul><li>AI is the new Electricity</li><li><p>Electricitty had once transformed countless industries: transportation, manufacturing, healthcare, communications, and more</p></li><li><p>AI will now bring about an equally big transformation</p></li></ul><p>ReLU: Rectified Linear Unit</p><p>Supervised Learning</p><p><strong>Structured Data vs. Unstructured Data</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-1.png" style="zoom:60%"><br></center><p>Keys in deep learning:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-2.png" style="zoom:60%"><br></center><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Neural-Networks-Basics"><a href="#Neural-Networks-Basics" class="headerlink" title="Neural Networks Basics"></a>Neural Networks Basics</h2><p><strong>Binary Classification</strong></p><p>Input group:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-8.png" style="zoom:60%"><br></center><p>output group:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-9.png" style="zoom:60%"><br></center><p><strong>Logistic Regression (again…)</strong><br>$$<br>\hat{y} = \sigma(w^Tx+b) \\<br>\sigma(z) = \frac{1}{1+e^{-z}}<br>$$</p><p><strong>Logistic Regression cost function</strong></p><p>When deciding which loss function to use, we should really consider if it is convex or not.</p><p>$$<br>L(\hat{y},y) = -(ylog\hat{y}+(1-y)log(1-\hat{y}))<br>$$</p><p>$$<br>J(w,b)=\frac{1}{m}\sum_{i=1}^mL(\hat{y}^{(i)},y^{(i)})<br>$$</p><p><strong>Gradient Descent</strong><br>$$<br>w:=w-\alpha\frac{\partial J(w,b)}{\partial w} \\<br>w:=w-\alpha dw \\<br>b:=b-\alpha\frac{\partial J(w,b)}{\partial b} \\<br>b:=b-\alpha db<br>$$</p><p><strong>Computation Graph</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-10.png" style="zoom:60%"><br></center><p><strong>Logistic regression derivatives</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-11.png" style="zoom:60%"><br></center><p><strong>Vectorization</strong></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line">a = np.array([1,2,3,4])</span><br><span class="line">print(a)</span><br><span class="line"></span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">a = np.random.rand(100000)</span><br><span class="line">b = np.random.rand(100000)</span><br><span class="line">tic = time.time()</span><br><span class="line">c = np.dot(a,b)</span><br><span class="line">toc = time.time()</span><br><span class="line"></span><br><span class="line">print(&quot;Vectorized version:&quot; + str(1000*(toc-tic) + &quot;ms&quot;))</span><br></pre></td></tr></table></figure><p>Whenever possible, avoid explicit for-loops.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-20-Week1-12.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Logistic-Regression-with-a-Neural-Network-mindset"><a href="#Programming-Assignment-Logistic-Regression-with-a-Neural-Network-mindset" class="headerlink" title="Programming Assignment: Logistic Regression with a Neural Network mindset"></a>Programming Assignment: Logistic Regression with a Neural Network mindset</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Neural Networks and Deep Learning/Week2/Python%2BBasics%2BWith%2BNumpy%2Bv3.ipynb" target="_blank" rel="noopener">Python Basics with numpy</a></p><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Neural Networks and Deep Learning/Week2/Logistic%2BRegression%2Bwith%2Ba%2BNeural%2BNetwork%2Bmindset%2Bv5.ipynb" target="_blank" rel="noopener">Logistic Regression with a Neural Network mindset</a></p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Shallow-neural-networks"><a href="#Shallow-neural-networks" class="headerlink" title="Shallow neural networks"></a>Shallow neural networks</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week3-1.png" style="zoom:60%"><br></center><p><strong>Neural Network Representation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week3-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week3-3.png" style="zoom:60%"><br></center><p><strong>Vectorization</strong></p><p>Convention: stacking by column</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week3-4.png" style="zoom:60%"><br></center><p><strong>Activation functions</strong><br>$$<br>sigmoid(z)=\frac{1}{1+e^{-z}}    \\<br>tanh(z) = \frac{e^z-e^{-z}}{e^z+e^{-z}} \\<br>ReLU(z) = max(0,z)<br>$$<br>Tanh function is superior than sigmoid function. (generally)</p><p>sigmoid: binary classification (used in the output layer)</p><p>suggestions: use relu in all other units except for the output unit.</p><p>If we are doing a binary classification, we use sigmoid in the output unit in most cases.</p><p><strong>Fornulas for propagation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week3-5.png" style="zoom:60%"><br></center><p><strong>Random initilization: Symmetry breaking</strong></p><p>Small initialization: make update faster</p><h2 id="Programming-Assignment-Planar-data-classification-with-a-hidden-layer"><a href="#Programming-Assignment-Planar-data-classification-with-a-hidden-layer" class="headerlink" title="Programming Assignment: Planar data classification with a hidden layer"></a>Programming Assignment: Planar data classification with a hidden layer</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Neural Networks and Deep Learning/Week3/Planar%2Bdata%2Bclassification%2Bwith%2Bone%2Bhidden%2Blayer%2Bv5.ipynb" target="_blank" rel="noopener">Planar data classification with a hidden layer</a></p><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Deep-Neural-Networks"><a href="#Deep-Neural-Networks" class="headerlink" title="Deep Neural Networks"></a>Deep Neural Networks</h2><p>Dimension:<br>$$<br>W^{[l]}:(n^{[l]},n^{[l-1]})<br>$$</p><p>$$<br>b^{[l]}:(n^{[l]},1)<br>$$</p><p>$$<br>z^{[l]},a^{[l]}:(n^{[l]},1)<br>$$</p><p>$$<br>Z^{[l]},A^{[l]}:(n^{[l]},m)<br>$$</p><p><strong>Circuit theory and deep learning</strong></p><p>Informally: There are functions you can compute with a “small”L-layer deep neural network that shallower networks require exponentially more hidden units to compute.</p><p><strong>Forward and backward functions</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week4-1.png" style="zoom:60%"><br></center><p><strong>Forward propagation for layer l</strong></p><p>Input $a^{[l-1]}$</p><p>Output $a^{[l]}$, cache ($z^{[l]}$)</p><p><strong>Backward propagation for layer l</strong></p><p>Input $da^{[l]}$</p><p>Output $da^{[l-1]}$, $dW^{[l]}$, $db^{[l]}$<br>$$<br>dz^{[l]}=da^{[l]}*g^{[l]’}(z^{[l]}) \\<br>dw^{[l]}=dz^{[l]} \cdot a^T  \\<br>db^{[l]} = dz^{[l]} \\<br>da^{[l-1]} = w^{[l]^T} \cdot dz^{[l]}<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-21-Week4-2.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Building-your-deep-neural-network-Step-by-Step"><a href="#Programming-Assignment-Building-your-deep-neural-network-Step-by-Step" class="headerlink" title="Programming Assignment: Building your deep neural network: Step by Step"></a>Programming Assignment: Building your deep neural network: Step by Step</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Neural Networks and Deep Learning/Week4/Building%2Byour%2BDeep%2BNeural%2BNetwork%2B-%2BStep%2Bby%2BStep%2Bv8.ipynb" target="_blank" rel="noopener">Building your deep neural network: Step by Step</a></p><h2 id="Programming-Assignment-Deep-Neural-Network-Application"><a href="#Programming-Assignment-Deep-Neural-Network-Application" class="headerlink" title="Programming Assignment: Deep Neural Network Application"></a>Programming Assignment: Deep Neural Network Application</h2><p><a href="https://github.com/Aden-Q/Deep-Learning/blob/master/Neural Networks and Deep Learning/Week4/Deep%2BNeural%2BNetwork%2B-%2BApplication%2Bv8.ipynb" target="_blank" rel="noopener">Deep Neural Network Application</a></p><p>Done!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai Specialization&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
  </entry>
  
  <entry>
    <title>Introduction to TensorFlow</title>
    <link href="http://yoursite.com/2019/04/12/Introduction%20to%20TensorFlow/"/>
    <id>http://yoursite.com/2019/04/12/Introduction to TensorFlow/</id>
    <published>2019-04-12T11:03:34.000Z</published>
    <updated>2019-04-16T03:59:28.952Z</updated>
    
    <content type="html"><![CDATA[<p>Deeplearning.ai, Introduction to TensorFlow</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="A-New-Programming-Paradigm"><a href="#A-New-Programming-Paradigm" class="headerlink" title="A New Programming Paradigm"></a>A New Programming Paradigm</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week1-1.png" style="zoom:60%"><br></center><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line">model = keras.Sequential([keras.layers.Dense(units=<span class="number">1</span>, input_shape=[<span class="number">1</span>])])</span><br><span class="line">model.compile(optimizer=<span class="string">'sgd'</span>, loss=<span class="string">'mean_squared_error'</span>)</span><br><span class="line">xs = np.array([<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>],dtype=float)</span><br><span class="line">ys = np.array([<span class="number">50</span>,<span class="number">100</span>,<span class="number">150</span>,<span class="number">200</span>,<span class="number">250</span>,<span class="number">300</span>],dtype=float)</span><br><span class="line">model.fit(xs,ys,epochs=<span class="number">1000</span>)</span><br><span class="line">print(model.predict([<span class="number">7.0</span>]))</span><br></pre></td></tr></table></figure><br><br># Week2<br><br>## Introduction to Computer Vision<br><br><strong>Fashion MNIST</strong><br><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">fashion_mnist = keras.datasets.fashion_mnist</span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()</span><br></pre></td></tr></table></figure><br><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model = keras.Sequential([</span><br><span class="line">    keras.layers.Flatten(input_shape=(28,28)),</span><br><span class="line">    keras.layers.Dense(128, actication=tf.nn.relu),</span><br><span class="line">    keras.layers.Dense(10, activation=tf.nn.softmax)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><br><br>Using callbacks to control training<br><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">class myCallback(tf.keras.callbacks.Callback):</span><br><span class="line">def on_epoch_end(self, epoch, logs=&#123;&#125;):</span><br><span class="line">if(logs.get(&apos;loss&apos;)&lt;0.4):# logs.get(&apos;acc&apos;) control by accuracy</span><br><span class="line">            print(&apos;\nLoss is low so cancelling training!&apos;)</span><br><span class="line">            self.model.stop_training = True</span><br><span class="line"></span><br><span class="line">callbacks = myCallback()</span><br><span class="line">mnist = tf.keras.datasets.fashion_mnist</span><br><span class="line">(training_images, training_labels), (test_images, test_labels) = mnist.load_data()</span><br><span class="line">training_images = training_images/255.0</span><br><span class="line">test_images = test_images/255.0</span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(512, activation = tf.nn.relu),</span><br><span class="line">    tf.keras.layers.Dense(10, activation = tf.nn.softmax)</span><br><span class="line">])</span><br><span class="line">model.compile(optimizer=&apos;adam&apos;, loss=&apos;sparse_categorical_crossentropy&apos;)</span><br><span class="line">model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])</span><br></pre></td></tr></table></figure><br><br># Week3<br><br>## Enhancing Vision with Convolutional Neural Networks<br><br>Effects of convolution<br><br><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-1.png" style="zoom:60%"><br></center><p>Pooling</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-2.png" style="zoom:60%"><br></center><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>,</span><br><span class="line">                            input_shape=(<span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>)),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>, <span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>), activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.MaxPooling2D(<span class="number">2</span>,<span class="number">2</span>),</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">'relu'</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">'softmax'</span>)</span><br><span class="line">])</span><br></pre></td></tr></table></figure><p><code>model.summary()</code></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-3.png" style="zoom:60%"><br></center><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Using-Real-world-Images"><a href="#Using-Real-world-Images" class="headerlink" title="Using Real-world Images"></a>Using Real-world Images</h2><p>Image generator in TensorFlow (directories structure):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-4.png" style="zoom:60%"><br></center><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.keras.preprocessing.image</span><br><span class="line"><span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">train_datagen = ImageDataGenerator(rescale=<span class="number">1.</span>/<span class="number">255</span>)</span><br><span class="line">train_generator = train_datagon.flow_from_directory(</span><br><span class="line">train_dir,</span><br><span class="line">    target_size = (<span class="number">300</span>, <span class="number">300</span>),</span><br><span class="line">    batch_size = <span class="number">128</span>,</span><br><span class="line">    class_mode = <span class="string">'binary'</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure><p>sigmoid is great for binary classification</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># learn from generator</span></span><br><span class="line">history = model.fit_generator(</span><br><span class="line">train_generator,</span><br><span class="line">    steps_per_epoch=<span class="number">8</span>,</span><br><span class="line">    epochs=<span class="number">15</span>,</span><br><span class="line">    validation_data=validation_generator,</span><br><span class="line">    validation_steps=<span class="number">8</span>,</span><br><span class="line">    verbose=<span class="number">2</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Deeplearning.ai, Introduction to TensorFlow&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Python" scheme="http://yoursite.com/tags/Python/"/>
    
      <category term="Deep Learning" scheme="http://yoursite.com/tags/Deep-Learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="Keras" scheme="http://yoursite.com/tags/Keras/"/>
    
  </entry>
  
  <entry>
    <title>Machine Learning</title>
    <link href="http://yoursite.com/2019/03/29/Machine%20Learning/"/>
    <id>http://yoursite.com/2019/03/29/Machine Learning/</id>
    <published>2019-03-29T20:03:34.000Z</published>
    <updated>2019-05-01T22:45:33.778Z</updated>
    
    <content type="html"><![CDATA[<p>Stanford University, Machine Learning</p><p>Course Notes</p><a id="more"></a><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><p>Facebook, Apple’s photo application.</p><p>Google’s page rank algorithm.</p><p>Email spam filter.</p><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Algorithms, math and how to get them work.</p><p>Machine Learning:</p><ul><li>Grew out of work in AI</li><li>New capability for computers</li></ul><p>Examples:</p><ul><li>Database mining, E.g., Web click data, medical records, biology, engineering.</li><li>Applications can’t program by hand. Helicopter, handwriting recognition, most of NLP, CV.</li><li>Self-customizing programs: E.g., Amazon, Netflix product recommendations.</li><li>Understanding human learning (brain, real AI).</li></ul><blockquote><p>  Arthur Samuel (1959). Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.</p></blockquote><blockquote><p>  Tom Mitchell (1998). Well-posed Learnining Problem: A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.</p></blockquote><p>Machine learning algorithms:</p><ul><li>Supervised learning</li><li>Unsupervised learning</li></ul><p>Others: Reinforcement learning, recommender systems.</p><p>Supervised learning</p><hr><p>E.g., housing price prediction (regression)</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-1.png" style="zoom:60%"><br></center><p>E.g., Breast cancer (malignant, benign) (classification)</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-2.png" style="zoom:60%"><br></center><p>Unsupervised learning</p><hr><p>Clustering</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-3.png" style="zoom:60%"><br></center><p>Applications:</p><ul><li>Organize computing clusters</li><li>Social network analysis</li><li>Market segmentation</li><li>Astronomical data analysis</li></ul><p>E.g.</p><p>Cocktail party algorithm</p><h2 id="Linear-Regression-with-One-Variable"><a href="#Linear-Regression-with-One-Variable" class="headerlink" title="Linear Regression with One Variable"></a>Linear Regression with One Variable</h2><h3 id="Linear-Regression-with-One-Variable-1"><a href="#Linear-Regression-with-One-Variable-1" class="headerlink" title="Linear Regression with One Variable"></a>Linear Regression with One Variable</h3><p>Housing Prices.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-31-Week1-4.png" style="zoom:60% /"><br></center><p>Traing set: housing prices</p><p>Notation:</p><ul><li>m = Number of training examples</li><li>x’s = “input” variable / features</li><li>y’s = “output” variable / “target” variable</li></ul><p>(x, y) – one training example</p><p>$(x^{(i)}, y^{(i)})$ – $i^{th}$ trainining example</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-31-Week1-6.png" style="zoom:60%"><br></center><p>$$<br>h_\theta(x)=\theta_0+\theta_1x<br>$$<br>Linear regression with one variable.</p><p>Univariate linear regerssion.</p><p>Cost function</p><hr><p>Idea: Choose $\theta_0, \theta_1$ so that $h_\theta(x)$ is close to $y$ for our training examples $(x, y)$</p><p>square error cost function:<br>$$<br>J(\theta_0,\theta_1)=\frac1{2m}\sum_1^m(h_\theta(x^{(1)})-y^{(1)})^2<br>$$<br>Target: choose $\theta_0, \theta_1 $ to minimize $J(\theta_0,\theta_1)$</p><p>Contour plots to show 3D surface:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-31-Week1-7.png" style="zoom:60%"><br></center><p>Gradient descent</p><hr><p>Have some function $J(\theta_0,\theta_1)$</p><p>Want $min_{\theta_0,\theta_1}J(\theta_0,\theta_1)$</p><p><strong>Outline:</strong></p><ul><li><p>Start with some $\theta_0, \theta_1 $</p></li><li><p>Keep changing $\theta_0, \theta_1$ to reduce $J(\theta_0,\theta_1) $ until we hopefully end up at a minimum</p></li></ul><p><strong>Gradient descent algorithm:</strong></p><p>repeat until convergence:<br>$$<br>\theta_j:=\theta_j-\alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)<br>$$<br>Note: Correct implementation is simultaneous update as following:<br>$$<br>temp0 :=\theta_0-\alpha\frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)<br>\\<br>temp1 :=\theta_1-\alpha\frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1)<br>\\<br>\theta_0:=temp0<br>\\<br>\theta_1:=temp1<br>$$</p><ul><li>:=    assignment</li><li>=         assertion</li><li>$\alpha$        step length</li></ul><p>If $\alpha$ is too small, gradient descent can be slow.</p><p>If $\alpha$ is too large, gradient descent can overshoot the minimum. It may fail to converge, or even diverge.</p><p>Gradient descent can converge to a local minimum, even with the learning rate $\alpha$ fixed.</p><p>As we approach a local minimum, gradient descent will automatically take smaller steps. So, no need to decrease $\alpha$ over time.</p><p>Gradient for linear regression:<br>$$<br>j = 0 : \frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1) = \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})<br>\\<br>j = 1 : \frac{\partial}{\partial\theta_1}J(\theta_0,\theta_1) = \frac1m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})\cdot x^{(i)}<br>$$<br>Note again: update $\theta_0$ and $\theta_1$ simultaneously.</p><p>Gradient descent always works with convex function (without local optimum).</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-01-Week1-7.png" style="zoom:60%"><br></center><p>Batch Gradient Descent:</p><p>Batch: Each step of gradient descent uses all the training examples. (Refer to the fact that the cost function is over the entire training set.)</p><h2 id="Linear-Algebra-Review"><a href="#Linear-Algebra-Review" class="headerlink" title="Linear Algebra Review"></a>Linear Algebra Review</h2><p><strong>Matrix:</strong> Rectangular array of numbers:<br>$$<br>\begin {pmatrix}<br>1402 &amp; 191 \\<br>1371 &amp; 821<br>\end {pmatrix}<br>$$<br>Dimension of matrix: number of rows x number of columns</p><p>$A_{ij}$ = “$i,j$ entry” in the $i^{th}$ row, $j^{th}$ column.</p><p><strong>Vector:</strong> An nx1 matrix.<br>$$<br>\begin {pmatrix}<br>1402 \\<br>901<br>\end {pmatrix}<br>$$<br>$y_i$ = $i^{th}$ element</p><p>1-indexed or 0-indexed<br>$$<br>\begin {pmatrix}<br>y_1 \\<br>y_2 \\<br>y_3 \\<br>y_4<br>\end {pmatrix}<br>\space \space<br>\begin {pmatrix}<br>y_0 \\<br>y_1 \\<br>y_2 \\<br>y_3<br>\end {pmatrix}<br>$$</p><p>Convention: upper case to refer to matrics and lower case to refer to numbers or vectors.</p><p><strong>Matrix Addition</strong></p><p>Element-wise addition.</p><p>Legal matrix addtion requires matrixes with same dimension.</p><p><strong>Scalar Multiplication</strong></p><p>$$<br>3 *<br>\begin {bmatrix}<br>1 &amp; 0 \\<br>2 &amp; 5 \\<br>3 &amp; 1<br>\end {bmatrix}<br>=<br>\begin {bmatrix}<br>3 &amp; 0 \\<br>6 &amp; 15 \\<br>9 &amp; 3<br>\end {bmatrix}<br>$$</p><p><strong>Matrix Multiplication: </strong></p><p>Matrix multiply vector: To get $y_i$, multiply A’s $i^{th} $ row with elements of vector$x$, and add them up.</p><p>Prediction = DataMatrix * parameters</p><p>Matrix-matrix multiplication:</p><p>$$<br>\begin {bmatrix}<br>1 &amp; 3 &amp; 2 \\<br>4 &amp; 0 &amp; 1<br>\end {bmatrix}</p><p>\begin {bmatrix}<br>1 &amp; 3 \\<br>0 &amp; 1 \\<br>5 &amp; 2<br>\end {bmatrix}<br>=<br>\begin {bmatrix}<br>11 &amp; 10 \\<br>9 &amp; 14<br>\end {bmatrix}<br>$$</p><p><strong>Details:</strong>  </p><ul><li>A m$\times $n matrix</li><li>B n$\times $o matrix</li><li>m$\times $o matrix</li></ul><p>The $i^{th}$ column of the matrix $C$ is obtained by multiplying $A$ with the $i^{th}$ column of $B$. (for $i$ = 1,2,…,o). Then convert to matrix-vector multiplication.</p><p>Multiple compeing hypotheses: let each hypotheses corespond to a column in the second matrix.</p><p>Let $A$ and $B$ be matrices. Then in general,<br>$$<br>A \times B \ne B \times A<br>$$</p><p>$$<br>A \times (B \times C) = (A \times B) \times C<br>$$</p><p><strong>Identity Matrix:</strong></p><p>Denoted $I$ (or $I_{n\times n}$)</p><p>Examples of identity matrices:<br>$$<br>\begin {bmatrix}<br>1 &amp; 0 \\<br>0 &amp; 1<br>\end {bmatrix}<br>\<br>\begin {bmatrix}<br>1 &amp; 0 &amp; 0 \\<br>0 &amp; 1 &amp; 0 \\<br>0 &amp; 0 &amp; 1<br>\end {bmatrix}<br>\<br>\begin {bmatrix}<br>1 &amp; 0 &amp; 0 &amp; 0 \\<br>0 &amp; 1 &amp; 0 &amp; 0 \\<br>0 &amp; 0 &amp; 1 &amp; 0 \\<br>0 &amp; 0 &amp; 0 &amp; 1<br>\end {bmatrix}<br>$$<br>For any matrix $A$<br>$$<br>A \cdot I = I \cdot A = A<br>$$</p><p><strong>Matrix inverse:</strong></p><p>Not all numbers have an inverse.</p><p>If $A$ is an m$\times $m matrix (square matrix), and if it has an inverse,<br>$$<br>AA^{-1}=A^{-1}A=I<br>$$<br>Matrices that don’t have an inverse are “singular” or “degenerate”.</p><p><strong>Matrix Transpose:</strong></p><p>Example:</p><p>$$<br>A =<br>\begin {bmatrix}<br>1 &amp; 2 &amp; 0 \\<br>3 &amp; 5 &amp; 9<br>\end {bmatrix}</p><p>\</p><p>A^T =<br>\begin {bmatrix}<br>1 &amp; 3 \\<br>2 &amp; 5 \\<br>0 &amp; 9<br>\end {bmatrix}<br>$$</p><p>Let $A$ be an m$\times $n matrix, and let $B=A^T$. Then $B$ is an n$\times $m matrix, and<br>$$<br>B_{ij}=A_{ji}<br>$$</p><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Linear-Regression-with-Multiple-Variables"><a href="#Linear-Regression-with-Multiple-Variables" class="headerlink" title="Linear Regression with Multiple Variables"></a>Linear Regression with Multiple Variables</h2><p>Multiple features (variables).</p><hr><p>Notation:</p><p>$n$ = number of features</p><p>$x^{(i)}$ = input (features) of $i^{th}$ training example.</p><p>$x_j^{(i)}$ = value of feature $j$ in $i^{th}$ training example.</p><p>Hypothesis:<br>$$<br>h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n<br>$$<br>For convenience of notation, define $x_0=1$. ($x_0^{(i)}=1$)<br>$$<br>x =<br>\begin {bmatrix}<br>x_0 \\<br>x_1 \\<br>… \\<br>x_n<br>\end {bmatrix}</p><p>\space<br>\space</p><p>\theta =<br>\begin {bmatrix}<br>\theta_0 \\<br>\theta_1 \\<br>… \\<br>\theta_n<br>\end {bmatrix}<br>\in<br>R^{n+1}<br>$$</p><p>$$<br>h_\theta(x)=\theta_0x_0+\theta_1x_1+\theta_2x_2+….+\theta_nx_n<br>=\theta^Tx<br>$$</p><p>Multivariate linear regression.</p><p>Gradient descent for multivariate linear regression</p><hr><p>$$<br>\theta_j:=\theta_j-\alpha \frac{\partial}{\partial\theta_j}J(\theta)<br>$$</p><p>$$<br>\theta_j:=\theta_j-\alpha \frac{1}{m}\sum_{i=1}^m<br>(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}<br>$$</p><p>Feature Scaling</p><hr><p>Idea: Make sure features are on a similar scale.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-1.png" style="zoom:60%"><br></center><p>Get every feature into approximately a $-1\leq x_i \leq 1$ range.</p><p><strong>Mean normalization</strong></p><p>Replace $x_i$ with $x_i-\mu_i$ to make features have approximately zero mean (Do not apply to $x_0=1$) and then divide it by its standard deviatioin (divide by max-min is also fine).</p><p>Convergence test:</p><p>Declare convergence if $J(\theta)$ decreases by less than $10^{-3}$ in one iteration.</p><ul><li>For sufficiently small $\alpha$, $J(\theta )$ should decrease on every iteration.</li><li>But if $\alpha$ is too small, gradient descent can be slow to converge.</li></ul><p><strong>Summary</strong></p><ul><li>If $\alpha$ is too small: slow convergence.</li><li>If $\alpha$ is too large: $J(\theta) $ may not decrease on every iteration; may not converge.</li></ul><p>To choose $\alpha$ , try: …, 0.001, 0.01, 0.1, 1, … (0.003, 0.03, 0.3), 3x each time.</p><p><strong>Polynomial regression</strong></p><p>Sometimes by defining new features we can get better data and model.</p><p>We can transform a polynomial regression into a mutlivariant linear regression model:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-2.png" style="zoom:60%"><br></center><p><strong>Normal Equation</strong></p><p>Method to solve for $\theta$ analytically.</p><p>Design matrix: each row represents a sample.</p><p>With normal equation, feature scaling is not necessary.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-3.png" style="zoom:60%"><br></center><p><strong>Comparasion</strong></p><p>Gradient Descent:</p><ul><li>Need to choose $\alpha$.</li><li>Needs many iterations.</li><li>Works well even when $n$ is large.</li></ul><p>Normal Equation:</p><ul><li>No need to choose $\alpha$.</li><li>Don’t need to iterate.</li><li>Need to compute $(X^TX)^{-1}$</li><li>Slow if $n$ is very large. (depending on the number of features, typically n ~ 1000)</li></ul><p><strong>Noninvertibility when using normal equation</strong></p><p>For normal equation method:<br>$$<br>\theta = (X^TX)^{-1}X^Ty<br>$$<br>What if $X^TX$ is non-invertible? (Singular/degenerate)</p><ul><li>pinv</li><li>inv</li></ul><p>What causes $X^TX$ non-invertible?</p><ul><li>Redundant features (linearly dependent).</li><li>Too many features (e.g. $m\leq n$). (delete some features, or use regularization).</li></ul><h2 id="Octave-Matlab-Tutorial"><a href="#Octave-Matlab-Tutorial" class="headerlink" title="Octave/Matlab Tutorial"></a>Octave/Matlab Tutorial</h2><p>Choices: Octave, MATLAB, Python Numpy and R.</p><ul><li>who: list all the variables.</li><li>whos: list all the variables in details.</li><li>max(A(:)): take the maximum element of matrix A.</li><li>disp(“…”): print a string.</li></ul><p>Function:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">function y = squareThisNumber(x)</span><br><span class="line">y = x^2;</span><br></pre></td></tr></table></figure><ul><li>addpath(): add search path.</li></ul><p>Vectorization</p><hr><p>$$<br>h_\theta(x)=\sum_{j=0}^n\theta_jx_j=\theta^Tx<br>$$</p><p>$$<br>\theta =<br>\begin {bmatrix}<br>\theta_0 \\<br>\theta_1 \\<br>\theta_2<br>\end {bmatrix}<br>\<br>x =<br>\begin {bmatrix}<br>x_0 \\<br>x_1 \\<br>x_2<br>\end {bmatrix}<br>$$</p><p>Unvectorized implementation:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">prediction = 0.0;</span><br><span class="line">for j = 1:n+1</span><br><span class="line">prediction = prediction + theta(j) * x(j)</span><br><span class="line">end;</span><br></pre></td></tr></table></figure><p>Vectorized implementation:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">prediction = theta&apos; * x;</span><br></pre></td></tr></table></figure><h2 id="Programming-Assignment-Linear-Regression"><a href="#Programming-Assignment-Linear-Regression" class="headerlink" title="Programming Assignment: Linear Regression"></a>Programming Assignment: Linear Regression</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week2" target="_blank" rel="noopener">Linear Regression</a></p><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><p><strong>Classification</strong></p><ul><li>Email: Spam / Not Spam?</li><li>Online Transactions: Fraudulent (Yes/ No)?</li><li>Tumor: Malignant / Benign?</li></ul><p>$$<br>y \in {0,1}<br>$$</p><p>0: “Negative Class”</p><p>1: “Positive Class”</p><p>Binary Classification by Linear Regression is easily affected by extreme value.</p><p><strong>Logistic Regression:</strong><br>$$<br>0 \leq h_\theta(x) \leq 1<br>$$<br>Hypothesis:<br>$$<br>h_\theta(x) = g(\theta^Tx)<br>\\<br>g(z) = \frac{1}{1+e^{-z}}<br>$$<br>g is called <strong>sigmoid function</strong> or <strong>logistic function</strong>.<br>$$<br>h_\theta(x)=\frac{1}{1+e^{-\theta^Tx}}<br>$$<br><strong>Interpretation of Hypothesis Output</strong></p><p>$h_\theta(x)$ = estimated probability that y = 1 on input x<br>$$<br>h_\theta(x)=P(y=1|x;\theta)<br>$$<br>“Probability that y = 1, given x, parameteruzed by $\theta $”<br>$$<br>P(y=0|x;\theta)+P(y=1|x;\theta)=1<br>$$<br><strong>Decision Boundary</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-05-Week3-1.png" style="zoom:60%"><br></center><p><strong>Cost Function</strong></p><p>If we use the same cost function as before, it would be non-convex. Thus it’s not a wise choice. So we tend to choose a convex function.</p><p>Logistic regression cost function:<br>$$<br>Cost(h_\theta(x),y)=<br>\begin{equation}<br>\left{<br>             \begin{array}{lr}<br>             -log(h_\theta(x)), &amp; if \space y =1  \\<br>             -log(1-h_\theta(x)), &amp;  if \space y = 0<br>             \end{array}<br>\right.<br>\end{equation}<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-05-Week3-2.png" style="zoom:60%"><br></center><p>$$<br>Cost(h_\theta(x),y)=-ylog(h_\theta(x))-(1-y)log(1-h_\theta(x))<br>$$</p><p>$$<br>J(\theta)=-\frac1m[\sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]<br>$$</p><p><strong>Gradient descent</strong><br>$$<br>\theta_j:=\theta_j - \alpha\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}<br>$$<br>It looks identical to linear regression! (only hypothesis changes)</p><p><strong>Advanced optimization</strong></p><ul><li>Conjugate gradient</li><li>BFGS</li><li>L-BFGS</li></ul><p>Advantages:</p><ul><li>No need to manually pick $\alpha $</li><li>Often faster than gradient descent</li></ul><p>Disadvantages:</p><ul><li>More complex</li></ul><p><strong>Multiclass classification</strong></p><p>Email foldering/tagging: Work, Friends, Family, Hobby</p><p>Medical diagrams: Nol ill, Cold, Flu</p><p>Weather: Sunny, Cloudy, Rain, Snow</p><p><strong>One-vs-all (one-vs-rest):</strong></p><p>Treat one multiple class problem as several binary classification problems.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-06-Week3-3.png" style="zoom:60%"><br></center><p>Train a logistic regression classifier $h_\theta^{(i)}(x)$ for each class $i$ to predict the probability that $y=i$.</p><p>On a new input $x$, to make a prediction, pick the class $i$ that maximizes<br>$$<br>max\space h_\theta^{(i)}(x)<br>$$<br>Which means the prediction takes the maximum probability the sample belongs to.</p><h2 id="Regularization"><a href="#Regularization" class="headerlink" title="Regularization"></a>Regularization</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-06-Week3-4.png" style="zoom:60%"><br></center><p>Underfit: High bias</p><p>Overfit: High variance</p><p><strong>Overfitting:</strong> If we have too many features, the learned hypothesis may fit the training set very well, but fail to generalize to new examples (predict prices on new examples).</p><p><strong>Addressing overfitting:</strong></p><ul><li>Reduce number of features<ul><li>Manually select which features to keep.</li><li>Model selection algorithm.</li></ul></li><li>Regularization<ul><li>Keep all the features, but reduce magnitude/values of parameters $\theta_j$.</li><li>Works well when we have a lot of features, each of which contributes a bit to predicting $y$.</li></ul></li></ul><p><strong>Regularization</strong></p><p>Small values for parameters $\theta_0,\theta_1,…,\theta_n$</p><ul><li>Simpler hypothesis</li><li>Less prone to overfitting</li></ul><p>$$<br>J(\theta)=\frac1{2m}[\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda \sum_{i=1}^m\theta_j^2]<br>$$</p><p>$\lambda$: regularization parameter, control the trade off between fitting the training set well and keeping parameters small (keeping hypothesis simple)</p><p>If $\lambda $ is extremely large, then $h_\theta(x)=\theta_0$. (end up with the simplest hypothesis and high bias)</p><p><strong>Gradient descent with regularization</strong><br>$$<br>\theta_0:=\theta_0-\alpha \frac1m<br>\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_0^{(i)}<br>$$</p><p>$$<br>\theta_j:=\theta_j-\alpha [\frac1m<br>\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}+\frac\lambda m\theta_j], \space for \space j = 1, 2, …, n<br>$$</p><p>Equivalent:<br>$$<br>\theta_j:=\theta_j(1-\alpha\frac\lambda m)-\alpha \frac1m<br>\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}<br>$$</p><p><strong>Normal equation with normalization</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-06-Week3-5.png" style="zoom:60%"><br></center><p><strong>Regularized logistic regression</strong></p><p>Cost function:<br>$$<br>J(\theta) = -[\frac1m \sum_{i=1}^my^{(i)}logh_\theta(x^{(i)})+(1-y^{(i)})log(1-h_\theta(x^{(i)}))]+<br>\frac{\lambda}{2m}\sum_{j=1}^{n}\theta_j^2<br>$$</p><p><strong>Regularized advanced optimization</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-06-Week3-6.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Logistic-Regression"><a href="#Programming-Assignment-Logistic-Regression" class="headerlink" title="Programming Assignment: Logistic Regression"></a>Programming Assignment: Logistic Regression</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week3" target="_blank" rel="noopener">Logistic Regression</a></p><p>One way to fit the data better is to create more features from each data point.</p><p>Logistic classifier prones to be overfitting  on higher-dimension features. (consider the decision boundary)</p><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Neural-Networks-Representation"><a href="#Neural-Networks-Representation" class="headerlink" title="Neural Networks: Representation"></a>Neural Networks: Representation</h2><p>Linear regression and logistic regression are not designed for Non-linear Classification problems and multiple features.</p><p><strong>Neural Networks</strong></p><p>Origins: Algorithms that try to mimic the brain.</p><p>Was very widely used in 80s and early 90s; popularity diminished in late 90s.</p><p>Recent resurgence: State-of-the-art technique for many applications</p><p><strong>Neuron model: Logistic unit</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-08-Week4-1.png" style="zoom:60%"><br></center><p>Sigmoid (logistic) activation function.<br>$$<br>g(z) = \frac{1}{1+e^{-z}}<br>$$<br>$\theta $: “weights”</p><p><strong>Neural Network</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-08-Week4-2.png" style="zoom:60%"><br></center><p>$a_i^{(j)}$ = “activation” of unit $i$ in layer $j$</p><p>$\theta^{(j)}$ = matrix of weights controlling function mapping from layer $j$ to layer $j+1$</p><p>If network has $s_j$ units in layer $j$, $s_{j+1}$ units in layer $j+1$, then $\theta^{(j)}$ will be of dimension $s_{j+1}*(s_j+1)$. The extra dimension represents the bias.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-08-Week4-3.png" style="zoom:60%"><br></center><p><strong>Forward propagation: Vectorized implementation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-08-Week4-4.png" style="zoom:60%"><br></center><p><strong>Neural Network learning its own features</strong></p><p>“Architectures” refers to how the different neurons are connected to each other.</p><p><strong>Handwritten digit classification</strong></p><p><strong>Multi-class Classification</strong></p><p>Multiple output units: One-vs-all.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-08-Week4-5.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Multi-class-Classification-and-Neural-Networks"><a href="#Programming-Assignment-Multi-class-Classification-and-Neural-Networks" class="headerlink" title="Programming Assignment: Multi-class Classification and Neural Networks"></a>Programming Assignment: Multi-class Classification and Neural Networks</h2><p><a href>Multile-class Classification and Neural Networks</a></p><h1 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5"></a>Week 5</h1><h2 id="Neural-Networks-Learning"><a href="#Neural-Networks-Learning" class="headerlink" title="Neural Networks: Learning"></a>Neural Networks: Learning</h2><p>$L$ = total no. of layers in network</p><p>$s_l$ = no. of units (not counting bias unit) in layer $l$</p><p><strong>Binary classification:</strong> $y$ = 0 or 1, 1 output unit</p><p><strong>Multi-class classification (K classes):</strong> $y \in R^K$</p><p><strong>Cost function</strong></p><p><strong>Gradient computation</strong></p><p>Given one training example $(x,y)$:</p><p>Forward propagation:<br>$$<br>a^{(1)} = x \\<br>z^{(2)}=\theta^{(1)}a^{(1)} \\<br>a^{(2)}=g(z^{(2)}) \space (add \space a_0^{(2)}) \\<br>z^{(3)}=\theta^{(2)}a^{(2)} \\<br>a^{(3)}=g(z^{(3)}) \space (add \space a_0^{(3)}) \\<br>z^{(4)}=\theta^{(3)}a^{(3)} \\<br>a^{(4)}=h_\theta(x)=g(z^{(4)})<br>$$<br><strong>Backpropagation algorithm</strong></p><p>Intuition: $\delta_j^{(l)}$ = “error” of node $j$ in layer $l$.<br>$$<br>\delta^{(4)} = a^{(4)}-y<br>$$</p><p>$$<br>\delta^{(3)}=(\theta^{(3)})^T\delta^{(4)}.*g’(z^{(3)})<br>$$</p><p>$$<br>\delta^{(2)}=(\theta^{(2)})^T\delta^{(3)}.*g’(z^{(2)})<br>$$</p><p>$$<br>\frac{\partial}{\partial\theta_{ij}^{(l)}}J(\theta) = a_j^{(l)}\delta_i^{(l+1)}<br>$$<br>Training set ${   (x^{(1)},y^{(1)}),…, (x^{(m)},y^{(m)})}$</p><p>Set $\Delta_{ij}^{(l)}=0 $ for all $l,i,j$.</p><p>For $i$ = 1 to $m$</p><p>​    Set $a^{(1)}=x^{(i)}$</p><p>​    Perform forward propagation to compute $a^{(l)}$ for $l$ = 2,3,…,L</p><p>​    Using $y^{(i)}$, compute $\delta^{(L)}=a^{(L)}-y^{(i)}$</p><p>​    Compute $\delta^{(L-1)},\delta^{(L-2)},…,\delta^{(2)}$    // backpropagation step</p><p>​    $\Delta_{ij}^{(l)}:=\Delta_{ij}^{(l)}+a_j^{(l)}\delta_i^{(l+1)}$<br>$$<br>D_{ij}^{(l)}:=\frac1m\Delta_{ij}^{(l)}+\lambda\theta_{ij}^{(l)} \space if \space j \neq0 \\<br>D_{ij}^{(l)}:=\frac1m\Delta_{ij}^{(l)} \space if \space j \ =0<br>$$</p><p><strong>Random initialization: Symmetry breaking</strong></p><p><strong>Training a neural network</strong></p><p>Pick a network architecture (connectivity pattern between neurons)</p><p>No. of input units: Dimension of features $x^{(i)}$</p><p>No. output units: Number of classes</p><p>Reasonable default: 1 hidden layer, or if &gt;1 hidden layer, have same no. of hidden units in every layer (usually the more the better)</p><ol><li>Randomly initialize weights</li><li>Implement forward propagation to get $h_\theta(x^{(i)})$ for any $x^{(i)}$</li><li>Implement code to compute cost function $J(\theta)$</li><li>Implement backprop to compute partial derivatives $\frac{\partial}{\partial\theta_{jk}^{(l)}}J(\theta)$</li><li>Use gradient checking to compare $\frac{\partial}{\partial\theta_{jk}^{(l)}}J(\theta)$ using backpropagation vs. using numerical estimate of gradient of $J(\theta)$, Then disable gradient checking code.</li><li>Use gradient descent or advanced optimization method with backpropagation to try to minimize $J(\theta)$ as a function of parameters $\theta$</li></ol><h2 id="Programming-Assignment-Neural-Network-Learning"><a href="#Programming-Assignment-Neural-Network-Learning" class="headerlink" title="Programming Assignment: Neural Network Learning"></a>Programming Assignment: Neural Network Learning</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week5" target="_blank" rel="noopener">Neural Network Learning</a></p><h1 id="Week-6"><a href="#Week-6" class="headerlink" title="Week 6"></a>Week 6</h1><h2 id="Advice-for-Applying-Machine-Learning"><a href="#Advice-for-Applying-Machine-Learning" class="headerlink" title="Advice for Applying Machine Learning"></a>Advice for Applying Machine Learning</h2><p><strong>Debuggin a learning algorithm:</strong></p><ul><li>Get more training examples</li><li>Try smaller sets of features</li><li>Try getting additional features</li><li>Try adding polynomial features $(x_1^2,x_2^2,x_1x_2,etc)$</li><li>Try decreasing $\lambda$</li><li>Try increasing $\lambda$</li></ul><p><strong>Evaluating your hypothesis</strong></p><p>Training set/ Test set split, typically 70% vs. 30% (remember to randomly shuffle)</p><ul><li>Learn parameter $\theta$ from training data (minimizing training error $J(\theta)$)</li><li>Compute test set error</li><li>Misclassification error (0/1 misclassification error)</li></ul><p><strong>Model selection</strong></p><p>Training set, cross validation set and test set split. Typically 60%, 20% and 20%</p><p>Select by validation set, and finally test on test set. Note that we should not select by test set. (Means that we fit an extra parameter to the validation set)</p><p><strong>Bias and variance</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-09-Week6-1.png" style="zoom:60%"><br></center><p><strong>Choosing the regularization parameter $\lambda$</strong></p><ol><li>Try $\lambda=0$</li><li>Try $\lambda=0.01$</li><li>Try $\lambda=0.02$</li><li>Try $\lambda=0.04$</li><li>…</li><li>Try $\lambda=10.24$</li></ol><p>Steps of choosing $\lambda $:</p><ol><li>Create a list of lambdas (i.e. λ∈{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24});</li><li>Create a set of models with different degrees or any other variants.</li><li>Iterate through the \lambda<em>λ</em>s and for each \lambda<em>λ</em> go through all the models to learn some Θ.</li><li>Compute the cross validation error using the learned Θ (computed with λ) on the JCV(Θ) <strong>without</strong> regularization or λ = 0.</li><li>Select the best combo that produces the lowest error on the cross validation set.</li><li>Using the best combo Θ and λ, apply it on Jtest(Θ) to see if it has a good generalization of the problem.</li></ol><p><strong>Learning curves</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-09-Week6-2.png" style="zoom:60%"><br></center><p><strong>High bias</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-09-Week6-3.png" style="zoom:60%"><br></center><p>If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much.</p><p><strong>High variance</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-09-Week6-4.png" style="zoom:60%"><br></center><p>If a learning algorithm is suffering from high variance, getting more training data is likely to help.</p><p>“Small” neural network (fewer parameters; more prone to underfitting): Computationally cheaper</p><p>“Large” neural network (more parameters; more prone to overfitting): Computationally more expensive</p><h2 id="Programming-Assignment-Regularized-Linear-Regression-and-Bias-Variance"><a href="#Programming-Assignment-Regularized-Linear-Regression-and-Bias-Variance" class="headerlink" title="Programming Assignment: Regularized Linear Regression and Bias/Variance"></a>Programming Assignment: Regularized Linear Regression and Bias/Variance</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week6" target="_blank" rel="noopener">Regularized Linear Regression and Bias/Variance</a></p><h2 id="Machine-Learning-System-Design"><a href="#Machine-Learning-System-Design" class="headerlink" title="Machine Learning System Design"></a>Machine Learning System Design</h2><p><strong>Building a spam classifier</strong></p><p>Supervised learning. $x$ = features of emails. $y$ = spam (1) or not spam (0).</p><p>Feature $x$: Choose 100 words indicative of spam/not spam.</p><p>Note: In practice, take most frequently occurring $n$ words (10,000 to 50,000) in training set, rather than manually pick 100 words.</p><p>How to improve model performance?</p><ul><li>Collect lots of data</li><li>Develop sophisticated features based on email routing information (from email header).</li><li>Develop sophisticated features for message body, e.g. should “discount” and “discounts” be treated as the same word? How about “deal” and “Dealer”? Features about punctuation?</li><li>Develop sophisticated algorithm to detect misspellings (e.g. m0rtgage, med1cine, w4tches.)</li></ul><p><strong>Error Analysis</strong></p><ul><li>Start with a simple algorithm that you can implement quickly. Implement it and test it on your cross-validation data.</li><li>Plot learning curves to decide if more data, more features, etc. are likely to help.</li><li>Error analysis: Manually examine the examples (in cross validation set) that your algorithm made errors on. See if you spot any systematic trend in what type of examples it is making errors on.</li></ul><p><strong>Precision/Recall</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-09-Week6-6.png" style="zoom:60%"><br></center><p>We prefer high <strong>Precision</strong> and high <strong>Recall</strong>.</p><p><strong>Trade off precision and recall</strong></p><p><strong>$F_1$ Score (F score)</strong><br>$$<br>2\frac{PR}{P+R}<br>$$</p><h1 id="Week-7"><a href="#Week-7" class="headerlink" title="Week 7"></a>Week 7</h1><h2 id="Support-Vector-Machines"><a href="#Support-Vector-Machines" class="headerlink" title="Support Vector Machines"></a>Support Vector Machines</h2><p>Cost:<br>$$<br>minC<br>\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+<br>\frac{1}{2}\sum_{i=0}^n\theta_j^2<br>$$<br>Trade-off<br>$$<br>CA+B<br>$$<br>Hypothesis<br>$$<br>h_\theta(x)=<br>\begin{equation}<br>\left{<br>             \begin{array}{lr}<br>             1, &amp; if \space \theta^Tx \geq0  \\<br>             0, &amp;  otherwise<br>             \end{array}<br>\right.<br>\end{equation}<br>$$</p><p><strong>SVM Decision Boundary: Linearly separable case</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-10-Week7-1.png" style="zoom:60%"><br></center><p><strong>Non-linear Decision Boundary</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-10-Week7-2.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-10-Week7-3.png" style="zoom:60%"><br></center><p>Each landmarks define a new feature thought all samples.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-10-Week7-4.png" style="zoom:60%"><br></center><p>Some intuition of the kernel function</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-10-Week7-5.png" style="zoom:60%"><br></center><p><strong>Choosing the landmarks</strong></p><p>Exactly the location as the training examples.</p><p>Given $(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})$.</p><p>choose $l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…,l^{(m)}=x^{(m)}$.</p><p>Given example $x$:<br>$$<br>f_1 = similarity(x,l^{(1)}) \\<br>f_2 = similarity(x,l^{(2)}) \\<br>…<br>$$</p><p>$$<br>f =<br>\begin {bmatrix}<br>f_0 \\<br>f_1 \\<br>f_2 \\<br>… \\<br>f_m<br>\end {bmatrix}<br>$$</p><p>Hypothesis: Given $x$, compute features $f \in R^{m+1}$</p><p>Predict “y=1” if $\theta^Tf \geq 0$</p><p>Training:<br>$$<br>minC<br>\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tf^{(i)})+(1-y^{(i)})cost_0(\theta^Tf^{(i)})]+<br>\frac{1}{2}\sum_{i=0}^n\theta_j^2<br>$$<br>C (=$\frac{1}{\lambda}$)</p><ul><li>Large C: Lower bias, high variance. (small $\lambda $)</li><li>Small C: Higher bias, lower variance. (Large $\lambda $)</li></ul><p>$\sigma^2$</p><ul><li>Large $\sigma^2$: Features $f_i$ vary more smoothly. High bias, lower variance.</li><li>Small $\sigma^2$: Features $f_i$ vary less smoothly. Lower bias, higher variance.</li></ul><p>Use SVM software package (e.g. liblinear, libsvm, …) to solve for parameters $\theta$.</p><p>Need to specify:</p><ul><li>Choice of parameter C.</li><li>Choice of kernel (similarity function): No kernel (“linear kernel”, apply for n large, m small), Gaussian kernel (Non-linear classifier, apply for n small, m large).</li></ul><p>Note: Not all similarity functions $similarity(x,l)$ make valid kernels. (Need to satisfy technical condition called “Mercer’s Theorem” to make sure SVM packages’ optimizations run correctly, and do not diverge).</p><p>Many off-the-shelf kernels available:</p><ul><li>Polynomial kernel: $k(x,l) = (x^Tl)^2, (x^Tl)^3,(x^Tl+1)^3, (x^Tl+constant)^{degree}$</li><li>More esoteric: String kernel, chi-square kernel, histogram intersection kernel, …</li></ul><p><strong>Multi-class classification</strong></p><p>Many SVM packages already have built-in multi-class classification functionality.</p><p>Otherwise, use one-vs.-all method. (Train $K$ SVMs, one to distinguish $y=i$ from the rest, for $i$ = 1,2,…,$K$), get $\theta^{(1)},\theta^{(2)},…,\theta^{(K)}$ Pick class $i$ with largest $(\theta^{(i)})^Tx$</p><p><strong>Logistic regression vs. SVMs</strong></p><p>If $n$ is large (relative to $m$): Use logistic regression, or SVM without a kernel (“linear kernel”)</p><p>If $n$ is small, $m$ is intermediate: Use SVM with Gaussian kernel</p><p>If $n$ is small, $m$ is large: Create/add more features, then use logistic regression or SVM without a kernel</p><p>Neural network likely to work well for most of these settings, but may be slower to train.</p><h2 id="Programming-Assignment-Support-Vector-Machines"><a href="#Programming-Assignment-Support-Vector-Machines" class="headerlink" title="Programming Assignment: Support Vector Machines"></a>Programming Assignment: Support Vector Machines</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week7" target="_blank" rel="noopener">Support Vector Machines</a></p><h1 id="Week-8"><a href="#Week-8" class="headerlink" title="Week 8"></a>Week 8</h1><h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h2><p>Training set: ${  x^{(1)},x^{(2)},x^{(3)},…,x^{(m)} }$</p><p><strong>Applications of clustering</strong></p><ul><li>Market segmentation</li><li>Social network analysis</li><li>Organize computing clusters</li><li>Astronomical data analysis</li></ul><p><strong>K-means algorithm</strong></p><p>cluster centroids</p><p>Input:</p><ul><li>$K$ (number of clusters)</li><li>Training set ${x^{(1)},x^{(2)},…,x^{(m)}}$</li></ul><p>$x^{(i)}\in R^n$ (drop $=x_0=1$ convention )</p><p>Randomly initialize $K$ cluster centroids $\mu_1,\mu_2,…,\mu_K \in R^n$</p><p>Repeat{</p><p>​    for i = 1 to m</p><p>​        $c^{(i)}$ := index (from 1 to $K$) of cluster centroid closest to $x^{(i)}$</p><p>​    for k = 1 to $K$</p><p>​        $\mu_k$ := average (mean) of points assigned to cluster $k$</p><p>}</p><p><strong>K-means optimization objective</strong></p><p>$c^{(i)}$ = index of cluster (1,2,…,$K$) to which example $x^{(i)}$ is currently assigned</p><p>$\mu_k$ = cluster centroid $k$ ($\mu_k \in R^n$)</p><p>$\mu_{c^{(i)}}$ = cluster centroid of cluster to which example $x^{(i)}$ has been assigned</p><p>Optimization objective:<br>$$<br>J = \frac1m\sum_{i=1}^{m}||x^{(i)}-\mu_{c^{(i)}}||^2<br>$$<br>Distortion cost function</p><p><strong>Random initialization</strong></p><p>Should have $K &lt; m$</p><p>Randomly pick $K$ training examples.</p><p>Set $\mu_1 ,…, \mu_K$ equal to these $K$ examples.</p><p><strong>Choosing the value of K</strong></p><p>Elbow method.</p><h2 id="Dimensionality-Reduction"><a href="#Dimensionality-Reduction" class="headerlink" title="Dimensionality Reduction"></a>Dimensionality Reduction</h2><p><strong>Data Compression</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week8-1.png" style="zoom:60%"><br></center><p><strong>Data Visulization</strong></p><p>Prefer 2-d or 3d data.</p><p><strong>Principal Component Analysis (PCA) problem formulation</strong></p><p>Reduce from 2-dimension to 1-dimension: Find a direction (a vector $u^{(1)}\in R^n$) onto which to project the data so as to minimize the projection error.</p><p>Reduce from n-dimension to k-dimension: Find $k$ vectors $u^{(1)},u^{(2)},…,u^{(k)}$ onto which to project the data, so as to minimize the projection error.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week8-2.png" style="zoom:60%"><br></center><p><strong>PCA is not linear regression</strong></p><p>Left: linear regression</p><p>Right: PCA</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week8-3.png" style="zoom:60%"><br></center><p><strong>Principal Component Analysis algorithm</strong></p><p>Data preprocessing:</p><p>Training set: $x^{(1)},x^{(2)},…,x^{(m)}$</p><p>Preprocessing (feature scaling/mean normalization)<br>$$<br>\mu_j=\frac1m\sum_{i=1}^mx_j^{(i)}<br>$$<br>Replace each $x_j^{(i)}$ with $x_j-\mu_j$.</p><p>If different features on different scales, scale features to have comparable range of values.<br>$$<br>x_j^{(i)}=\frac{x_j^{(i)}-\mu_j}{s_j}<br>$$<br>Algorithm steps:</p><ol><li><p>Mean normalization and feature scaling.</p></li><li><p>Compute “covariance matrix”:</p></li></ol><p>$$<br>\Sigma = \frac{1}{m}\sum_{i=1}^n(x^{(i)})(x^{(i)})^T<br>$$</p><ol start="3"><li>Compute “eigenvectors” of matrix $\Sigma$:</li></ol><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[U,S,V] = svd(Sigma);</span><br></pre></td></tr></table></figure><p>Sigma is a $n\times n$ matrix.</p><p>U is also a $n \times n$ matrix, with each column represents a eigenvector.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week8-4.png" style="zoom:60%"><br></center><ol start="4"><li><p>Ureduce = U(:, 1:k)</p><p>z = Ureduce’ * x;</p></li></ol><p><strong>Reconstruction from compressed representation</strong><br>$$<br>z = U^T_{reduce}x<br>$$</p><p>$$<br>x_{approx} = U_{reduce}*z<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week8-5.png" style="zoom:60%"><br></center><p><strong>Choosing $k$ (number of principal components)</strong></p><p>Average squared projection error: $\frac1m\sum_{i=1}^m||x^{(i)}-x_{approx}^{(i)}||^2$</p><p>Total variation in the data: $\frac1m\sum_{i=1}^m||x^{(i)}||^2$</p><p>Typically, choose $k$ to be smallest value so that<br>$$<br>\frac{Average \space error}{Variation} \leq0.01<br>$$<br>“99%” of variance is retained</p><p><strong>Application of PCA</strong></p><ul><li>Compression<ul><li>Reduce memory/disk needed to store data</li><li>Speed up learning algorithm</li></ul></li><li>Visualization</li></ul><p>Before implementing PCA, first try running whaever you want to do with the original/raw data. Only if that doesn’t do what you want, then implement PCA.</p><h2 id="Programming-Assignment-K-Means-Clustering-and-PCA"><a href="#Programming-Assignment-K-Means-Clustering-and-PCA" class="headerlink" title="Programming Assignment: K-Means Clustering and PCA"></a>Programming Assignment: K-Means Clustering and PCA</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week8" target="_blank" rel="noopener">K-Means Clustering and PCA</a></p><h1 id="Week-9"><a href="#Week-9" class="headerlink" title="Week 9"></a>Week 9</h1><h2 id="Anomaly-Detection"><a href="#Anomaly-Detection" class="headerlink" title="Anomaly Detection"></a>Anomaly Detection</h2><p><strong>Anomaly detection example</strong></p><p>Dataset: ${ x^{(1)},x^{(2)},…,x^{(m)} }$</p><p>Is $x_{test}$ anomalous?</p><p>$p(x_{test}) &lt; \epsilon$ -&gt; flag anomaly</p><p>$p(x_{test}) \geq \epsilon$ -&gt; OK</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-1.png" style="zoom:60%"><br></center><p>Fraud detection (Online website):</p><p>$x^{(i)}$ = features of user $i$’s activities</p><p>Model $p(x)$ from data.</p><p>Identify unusual users by checking which have $p(x) &lt; \epsilon$</p><p>Manufacturing</p><p>Monitoring computers in a data center.</p><p>$x^{(i)}$ = features of machine $i$</p><p>$x_1$ = memory use, $x_2$ = number of disk accesses/sec,</p><p>$x_3$ = CPU load, $x_4$ = CPU load/network traffic.</p><p>…</p><p><strong>Gaussian (Normal) distribution</strong></p><p>N ~ N($\mu$, $\sigma ^2$)</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-2.png" style="zoom:60%"><br></center><p>$$<br>p(x;\mu,\sigma ^2) = \frac{1}{\sqrt{2\pi}\sigma}exp(-\frac{(x-\mu)^2}{2\sigma^2})<br>$$</p><p><strong>Parameter estimation</strong><br>$$<br>\mu = \frac1m\sum_{i=1}^mx^{(i)} \\<br>\sigma^2 = \frac1m\sum_{i=1}^m(x^{(i)}-\mu)^2<br>$$</p><p><strong>Density estimation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-4.png" style="zoom:60%"><br></center><p>Data set split:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-5.png" style="zoom:60%"><br></center><p>Possible evaluation metrics:</p><ul><li>True positive, false positive, false negative, true negative</li><li>Precision/Recall</li><li>$F_1$-score</li></ul><p>Can also use cross validation set to choose parameter $\epsilon$</p><p><strong>Anomaly detection vs. Supervised learning</strong></p><p>Anomaly detection:</p><ul><li>Very small number of positive examples (y = 1). (0-20 is common).</li><li>Large number of negative (y = 0) examples.</li><li>Many different “tyles” of anomalies. Hard for any algorithm to learn from positive examples what the anomalies may look like; future anomalies may look nothing like any of the anomalous examples we’ve seen so far.</li><li>Fraud detection</li><li>Manufacturing (e.g. aircraft engines)</li><li>Monitoring machines in a data center</li></ul><p>Supervised learning:</p><ul><li>Large number of positive and negative examples.</li><li>Enough positive examples for algorithm to get sense of what positive examples are like, future positive examples likely to be similar to ones in training set.</li><li>Email spam classification</li><li>Weather prediction (sunny/rainy/etc).</li><li>Cancer classification</li></ul><p><strong>Feature selection and transformation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-6.png" style="zoom:60%"><br></center><p><strong>Error analysis for anomaly detection</strong></p><p>Want $p(x)$ large for normal examples $x$.</p><p>​      $p(x)$ small for anomalous examples $x$.</p><p>Most common problem:</p><p>​    $p(x)$ is comparable (say, both large) for normal and anomalous examples</p><p>Choosing features that might take on unusually large or small values in the event of an anomaly.</p><p><strong>Multivariate Gaussian (Normal) distribution</strong></p><p>$x\in R^n$. Don’t model $p(x_1),p(x_2),…,$ etc. separately. Model $p(x)$ all in one go.</p><p>Parameters: $\mu \in R^n$, $\Sigma \in R^{n\times n}$ (convariance matrix)<br>$$<br>p(x;\mu,\Sigma) = \frac{1}{(2\pi)^\frac n2 |\Sigma|^{\frac12}}exp(-\frac12(x-\mu)^T\Sigma^{-1}(x-\mu))<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-7.png" style="zoom:60%"><br></center><p><strong>Original model vs. Multivariate Gaussian</strong></p><p>Original: Manually create features to capture anomalies where $x_1,x_2$ take unusual combinations of values.</p><p>Multivariate: Automatically captures correlations between features. Have many constrains.</p><h2 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h2><p><strong>Content-based recommendations</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-8.png" style="zoom:60%"><br></center><p>For each user $j$, learn a parameter $\theta^{(j)}\in R^3$. Predict user $j$ as rating movie $i$ with $(\theta^{(j)})^Tx^{(i)} $ stars.</p><p>Problem formulation:</p><p>$r(i,j)=1$ if user $j$ has rated movie $i$ (0 otherwise)</p><p>$y^{(i,j)}$ = rating by user $j$ on movie $i$ (if defined)</p><p>$\theta^{(j)}$ = parameter vector for user $j$</p><p>$x^{(i)}$ = feature vector for movie $i$</p><p>For user $j$, movie $i$, predicted rating: $(\theta^{(j)})^Tx^{(i)} $</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-9.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-10.png" style="zoom:60%"><br></center><p><strong>Collaborative filtering</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-11.png" style="zoom:60%"><br></center><p><strong>Algorithm</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-12.png" style="zoom:60%"><br></center><p><strong>Low Rank Vectorization</strong></p><p><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-13.png" alt></p><p><strong>Finding related movies</strong><br>$$<br>small \space ||x^{(i)}-x^{(j)}|| -&gt; movie \space j \space and \space i \space are \space “similar”<br>$$</p><p><strong>Mean Normalization</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-11-Week9-14.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Anomaly-Detection-and-Recommender-Systems"><a href="#Programming-Assignment-Anomaly-Detection-and-Recommender-Systems" class="headerlink" title="Programming Assignment: Anomaly Detection and Recommender Systems"></a>Programming Assignment: Anomaly Detection and Recommender Systems</h2><p><a href="https://github.com/Aden-Q/Machine-Learning/tree/master/Week9" target="_blank" rel="noopener">Anomaly Detection and Recommender Systems</a></p><h1 id="Week-10"><a href="#Week-10" class="headerlink" title="Week 10"></a>Week 10</h1><h2 id="Large-Scale-Machine-Learning"><a href="#Large-Scale-Machine-Learning" class="headerlink" title="Large Scale Machine Learning"></a>Large Scale Machine Learning</h2><blockquote><p>  It’s not who has the best algorithm that wins. It’s who has the most data.</p></blockquote><p><strong>Stochatic gradient descent</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week10-1.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week10-2.png" style="zoom:60%"><br></center><p>Out loop typically 1-10 times.</p><p><strong>Mini-batch gradient descent</strong></p><p>Batch gradient descent: Use all $m$ examples in each iteration</p><p>Stochastic gradient descent: Use 1 example in each iteration</p><p>Mini-batch gradient descent: Use $b$ examples in each iteration</p><p>b = mini-batch size</p><p>b = 2~100</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week10-3.png" style="zoom:60%"><br></center><p>With vectorization, Mini-batch outperforms Stochastic as regard to computation efficiency.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week10-4.png" style="zoom:60%"><br></center><p>Learning rate decay:<br>$$<br>\alpha = \frac{const1}{iterationNumber+const2}<br>$$</p><p><strong>Online learning</strong></p><p><strong>Map-reduce and data parallelism</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week10-5.png" style="zoom:60%"><br></center><p>Many learning algorithms can be expressed as computing sums of functions over the training set.</p><h1 id="Week-11"><a href="#Week-11" class="headerlink" title="Week 11"></a>Week 11</h1><h2 id="Application-Example-Photo-OCR"><a href="#Application-Example-Photo-OCR" class="headerlink" title="Application Example: Photo OCR"></a>Application Example: Photo OCR</h2><p>Photo Optical Character Recognition</p><p><strong>Photo OCR pipeline</strong></p><ol><li>Text detection</li><li>Character segmentation</li><li>Character classification</li></ol><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week11-1.png" style="zoom:60%"><br></center><p><strong>Sliding window detection</strong></p><p>step-size / stride</p><p>These cencepts are related to computer vision which is introduced in the deeplearninng specialization. I should take notes for these in another course/specialization.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week11-2.png" style="zoom:60%"><br></center><p><strong>Artificial data systhesizing</strong></p><p>Make sure you have a low bias classifier before expanding the effor. (Plot learning curves). E.g. keep increasing the number  of features/number of hidden units in neural network until you have a low bias classifier.</p><p>“How much work would it be to get 10x as much data as we currently have?”</p><ul><li>Artificial data synthesis</li><li>Collect/label it yourself</li><li>“Crowd source” (E.g. Amazon Mechanical Turk)</li></ul><p><strong>Ceiling analysis</strong></p><p>Estimating the errors due to each component.</p><p>What part of the pipeline should you spend the most time trying to improve?</p><p>E.g.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week11-3.png" style="zoom:60%"><br></center><p>It is really important to do ceiling analysis.</p><p><strong>Summary</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-12-Week11-4.png" style="zoom:60%"><br></center>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Stanford University, Machine Learning&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Machine Learning" scheme="http://yoursite.com/tags/Machine-Learning/"/>
    
      <category term="Matlab" scheme="http://yoursite.com/tags/Matlab/"/>
    
  </entry>
  
  <entry>
    <title>Robotics: Perception</title>
    <link href="http://yoursite.com/2019/03/26/Robotics-Perception/"/>
    <id>http://yoursite.com/2019/03/26/Robotics-Perception/</id>
    <published>2019-03-27T00:30:34.000Z</published>
    <updated>2019-05-01T23:01:25.519Z</updated>
    
    <content type="html"><![CDATA[<p>University of Pennsylvania, Robotics: Perception</p><p>Course Notes</p><a id="more"></a><p>Cover:</p><ul><li>Geometry of Image Formation</li><li>Projective Transformations</li><li>Pose Estimation</li><li>Multi-View Geometry</li></ul><p>Learning Purpose: </p><ul><li>To be a candidate.</li><li>Self promotion.</li><li>Be familiar with Matlab again.</li></ul><p>Matlab help Videos are all from <a href="https://www.youtube.com/" target="_blank" rel="noopener">Youtube</a></p><h1 id="Week-1-Geometry-of-Image-Formation"><a href="#Week-1-Geometry-of-Image-Formation" class="headerlink" title="Week 1, Geometry of Image Formation"></a>Week 1, Geometry of Image Formation</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><ul><li>Projection center</li><li>Augmented reality</li><li>Where am I?</li></ul><h2 id="Camera-Modeling"><a href="#Camera-Modeling" class="headerlink" title="Camera Modeling"></a>Camera Modeling</h2><p>Gannet: Estimate distance from water.</p><p>Camera: imaging chip and a lens</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1ixautiffj31050ho118.jpg" style="zoom:60%"><br></center><p>$\frac 1f =  \frac 1a + \frac 1b$</p><p>blured picture (when we change the image plane by sticking on the mannual mode of the camera)</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1ixksq1fij30zh0hcdlk.jpg" style="zoom:60%"><br></center><ul><li>A point object of the same size coming closer results on a larger image.</li><li>A point moving on the same ray does not change its image. (regarding to fixed image plane)</li></ul><h2 id="Single-View-Geometry"><a href="#Single-View-Geometry" class="headerlink" title="Single View Geometry"></a>Single View Geometry</h2><p>World Coordinates: x, y, z locations.</p><p>Camera Coordinates: Two dimensional plane.</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1jawb2m00j30rn0httuj.jpg" style="zoom:60%"><br></center><p>Given the picture, how tall is the person in the picture?</p><p>“Single View Metrology”, ICCV 1999, CVPR 1998</p><p>Ideas 1: Measurements on planes. Moving “not vertical” to “vertical” and then measure.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jazxsamij30v70frk63.jpg" style="zoom:60%"><br></center><p>Ideas 2: Vanishing points.</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1jb2872qmj312n0cf7gm.jpg" style="zoom:60%"><br></center><p>Phical lines in the real world which are parallel will meet at the vanishing point when approaching infinity.</p><h2 id="More-on-Perspective-Projection"><a href="#More-on-Perspective-Projection" class="headerlink" title="More on Perspective Projection"></a>More on Perspective Projection</h2><p>Perspectography.</p><p>Strategy for projecting $P^*$ to $P$ on the same plane rather than on the image plane.</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1jbmbnrxyj30rs0efwjf.jpg" style="zoom:60%"><br></center><h2 id="Quiz-Introduction"><a href="#Quiz-Introduction" class="headerlink" title="Quiz: Introduction"></a>Quiz: Introduction</h2><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1jbxs8z4tj30hg0xs0v7.jpg" style="zoom:60%"><br></center><h2 id="Glimpse-on-Vanishing-Points"><a href="#Glimpse-on-Vanishing-Points" class="headerlink" title="Glimpse on Vanishing Points"></a>Glimpse on Vanishing Points</h2><p>Vanishing points</p><hr><p>Properties:</p><ul><li>Any two parallel lines have the same vanishing point.</li><li>The ray from C throught v point is parallel to the lines.</li><li>An image may have more than one vanishing point.</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jcjkxk8zj30k109fwgc.jpg" style="zoom:60%"><br></center><p>A single point can form a line between the optical center and that point, the ray can represent all the physical lines out there which are parallel.</p><p>Multiple Vanishing Points:</p><p>For every direction we have on the ground plane, there is a unique point in the image space. All the vanishing points will form a horizon.</p><ul><li>Any set of parallel lines on the plane define a vanishing point.</li><li>The union of all of these vanishing points is the horizon line (also called vanishing line)</li><li>Different planes define different vanishing lines.</li></ul><p>Computing vanishing lines:</p><ul><li>I is intersection of horizontal plane through C with image plane.</li><li>Compute I from two sets of parallel lines on ground plane.</li><li>All points at same height as C project to I.</li><li>Provided way of comaring height of objects in the scene.</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jcu72jdpj30f809tdi5.jpg" style="zoom:60%"><br></center><p>Measuring height:</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1jcz65661j30vg0gatj6.jpg" style="zoom:60%"><br></center><p>Trace a line from the bottom of the ruler throught feet of the person to infinity (intersect with the horizon).</p><h2 id="Quiz-Vanishing-Points"><a href="#Quiz-Vanishing-Points" class="headerlink" title="Quiz: Vanishing Points"></a>Quiz: Vanishing Points</h2><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1jggbshiuj30au0ytds5.jpg" style="zoom:60%"><br></center><h2 id="Perspective-Projection-I"><a href="#Perspective-Projection-I" class="headerlink" title="Perspective Projection I"></a>Perspective Projection I</h2><p>One-Point Perspective</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jgiybsamj30qf0jqnjg.jpg" style="zoom:60%"><br></center><p>Partial review.</p><p>Not all pictures should have the same vanishing points.</p><p>The projective plane:</p><ul><li>Represent points at infinity, homographies, perspective projection, multi-view relationships.</li><li>A point in the image is a ray in projective space.</li></ul><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1jgvo6y0kj30cg07w0ue.jpg" style="zoom:60%"><br></center><p>$$<br>\begin{bmatrix}<br>x \\<br>y \\<br>\end{bmatrix}<br>-homogeneous coords-&gt;<br>\begin{bmatrix}<br>x \\<br>y \\<br>1 \\<br>\end{bmatrix}<br>$$<br>Projective lines</p><p>Eg:</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1jhfkz7i1j30nx0h3e12.jpg" style="zoom:60%"><br></center><p>a, b and c are parameters in the 3D space but also related to the equation of the line.</p><p>3D plane equation:<br>$$<br>ax + by + cz = 0<br>$$</p><h2 id="Perspective-Projection-II"><a href="#Perspective-Projection-II" class="headerlink" title="Perspective Projection II"></a>Perspective Projection II</h2><p>Define a line: we use two points on the line to define it:</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1jj068t8sj30sa0khgrx.jpg" style="zoom:60%"><br></center><p>We have:<br>$$<br>x\cdot l = 0  ,\space x’\cdot l = 0<br>$$<br>So $l$  is the surface normal vector of the orange plane, which is coresponding to the line on the plane $P_1P_2$ . (Please think that points on the line can be represented as $(x,y,1)$, then it’s easy to understand)</p><p>Reference materials of projective view:</p><p>surface normal: a unit vector at a given point of a surface which is perpendicular to the tangent plane.</p><p>Intersection of lines:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jjr4ft8pj30pk0m8jxa.jpg" style="zoom:60%"><br></center><p><strong>Mistake in this video at arround 8:30.</strong></p><h2 id="Point-Line-Duality"><a href="#Point-Line-Duality" class="headerlink" title="Point-Line Duality"></a>Point-Line Duality</h2><p>When P has the form $(x,y,0)$:</p><p>We convert a 3D point into a 2D point by dividing the last element out. (Homogeous coords)</p><p>Some intuitions: $x/0 -&gt; infinity$. So very likely it’s a vanishing point.</p><p>Point at infinity:</p><p>Eg:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jkecg0hyj30oq0fnq6u.jpg" style="zoom:60%"><br></center><p>More general of intersection of parallel lines:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1jkgb5rb1j30tr0kp799.jpg" style="zoom:60%"><br></center><p>All parallel lines intersects at the point at infinity:<br>$$<br>line \space l = (a,b,c)^T \space intersects \space at \space (b,-a,0)^T<br>$$</p><p>Line at infinity (a line passing all points at infinity) :<br>$$<br>l_\infty=(0,0,1)^T<br>$$<br>Because:<br>$$<br>\begin {bmatrix}<br>0\<br>0\<br>1<br>\end {bmatrix}<br>\begin {bmatrix}<br>x_1 \\<br>x_2 \\<br>0<br>\end {bmatrix}<br>= 0<br>$$</p><p>Ideal points and lines (noting that there are two coords system, one for real space which is 3D, one for image space which is 2D):</p><ul><li>Ideal point (“point at infinity”)<ul><li>$p = (x,y,0)$ — parallel to image plane</li><li>It has ifinite image coordinates (2D coordinates for point)</li></ul></li><li>Ideal line<ul><li>$l = (a,b,0)$ — parallel to image plane</li><li>Corresponds to a line in the image (finite coordinates)</li></ul></li></ul><h2 id="Quiz-Perspective-Projection"><a href="#Quiz-Perspective-Projection" class="headerlink" title="Quiz: Perspective Projection"></a>Quiz: Perspective Projection</h2><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1jmpa8tatj30k210tn07.jpg" style="zoom:60%"><br></center><h2 id="Rotations-and-Translations"><a href="#Rotations-and-Translations" class="headerlink" title="Rotations and Translations"></a>Rotations and Translations</h2><p>Transformation between camera and world coordinates systems</p><hr><p>Convention: Red for X, Green for Y and Blue for Z.<br>$$<br>^cP = ^cR_w \space^wP+^cT_w<br>$$<br>Point P can be expressed with respect to “w” or “c” coordinate frames.</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-18.png" style="zoom:60%"><br></center><p>If we set $^wP$ to zero, then, $^cP=^cR_w+^cT_w$ is the vector from camera origin to world origin.<br>$$<br>^cR_w=(r_1 \ r_2 \ r_3)<br>$$<br>Set $^wP=(1,0,0)$ and imagine $^cT_w=0$. Then $^cP = r_1 $ whch means that <strong>the rotation columns are the world axis expressed in the camera coordinate system</strong>.</p><p>Eg:</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-19.png" style="zoom:60%"><br></center><p>The translation is easy from the picture:<br>$$<br>\begin {pmatrix}<br>0 \\<br>5 \\<br>10<br>\end {pmatrix}<br>$$<br>We have to make sure that the 3x3 matrix is a rotation matrix, which means $R^TR=I$ and det(R) = 1.</p><p>Transform between coordinate systems of three:</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-20.png" style="zoom:60%"><br></center><p>Inverse:</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-21.png" style="zoom:60%"><br></center><h2 id="Quiz-Rotations-and-Translations"><a href="#Quiz-Rotations-and-Translations" class="headerlink" title="Quiz: Rotations and Translations"></a>Quiz: Rotations and Translations</h2><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-22.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-23.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-29-Week1-24.png" style="zoom:60%"><br></center><h2 id="Pinhole-Camera-Model"><a href="#Pinhole-Camera-Model" class="headerlink" title="Pinhole Camera Model"></a>Pinhole Camera Model</h2><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-25.png" style="zoom:60%"><br></center><p>Pinhole Camera:</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-26.png" style="zoom:60%"><br></center><p>$1^{st}$ Person Camera world</p><hr><p>3D to 2D image:<br>$$<br>x’=f\frac X Z \ y’=f\frac Y Z<br>$$</p><h2 id="Focal-Length-and-Dolly-Zoom-Effect"><a href="#Focal-Length-and-Dolly-Zoom-Effect" class="headerlink" title="Focal Length and Dolly Zoom Effect"></a>Focal Length and Dolly Zoom Effect</h2><p>Focal length</p><p>Process of changing focal length: zooming</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-27.png" style="zoom:60%"><br></center><p>Focal length longer: field of view narrow</p><h2 id="Intrinsic-Camera-a-Parameter"><a href="#Intrinsic-Camera-a-Parameter" class="headerlink" title="Intrinsic Camera a Parameter"></a>Intrinsic Camera a Parameter</h2><p>3D to 2D image:<br>$$<br>x’=f\frac X Z \ y’=f\frac Y Z<br>$$</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-28.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-29.png" style="zoom:60%"><br></center><p>$$<br>x=P_0X<br>$$</p><p>$P_0$ is the camera projection matrix</p><p>Conversion from mm to pixels</p><p>Optical center on the image plane: Principal point</p><p>What we do is shifting and scaling by the measurement of pixels:</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-30.png" style="zoom:60%"><br></center><p>Map camera coordinate to pixel coordinate (matrix form):</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-31.png" style="zoom:60%"><br></center><p>$Px,P_y$ is the principle point (where optical axis hits image plane) (not exactly the center of the image)</p><p>s is the slant factor, when the image plane is not normal to the optical axis</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-32.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-33.png" style="zoom:60%"><br></center><p>Three factors:</p><ul><li>A scale factor that converts physical focal length to pixel unit.</li><li>Position of image center (principal point).</li><li>A skew factor between x and y axis of the image.</li></ul><h2 id="3D-World-to-First-Person-Transformation"><a href="#3D-World-to-First-Person-Transformation" class="headerlink" title="3D World to First Person Transformation"></a>3D World to First Person Transformation</h2><p>Multiple View Geometry</p><p>$3^{rd}$ person view measurement</p><p>Why: When we are moving around to see different objects from different point of view, which means  that the origin is always changing.</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-34.png" style="zoom:60%"><br></center><p>Convert the 3D representation into first person coordinate.</p><p>Every camera has its own first person coordinate system.</p><ol><li>Translate the world coordinate into the camera coordiante</li><li>Translate the camera coordinate into the pixel coordinate</li></ol><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-35.png" style="zoom:60%"><br></center><p>Combining them together, we get:<br>$$<br>x=K[R,t]X<br>$$<br>Comlete form:</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-36.png" style="zoom:60%"><br></center><p>$$<br>3D \space from \space 3^{rd} \space person –&gt;3D \space from \space 1^{rd} \space person –&gt;2D \space pixel \space domain<br>$$</p><p>Special cases</p><hr><p>Plnar objects: all x,y,z sits in a plane</p><p>We have freedom to choose how we measure 3D points from $3^{rd}$ person view.</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-37.png" style="zoom:60%"><br></center><p>Rotating camera: known optical center</p><p>panorama</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-38.png" style="zoom:60%"><br></center><h2 id="Quiz-Dolly-Zoom"><a href="#Quiz-Dolly-Zoom" class="headerlink" title="Quiz: Dolly Zoom"></a>Quiz: Dolly Zoom</h2><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week1-3.png" style="zoom:60%"><br></center><h2 id="Quiz-Feeling-of-Camera-Motion"><a href="#Quiz-Feeling-of-Camera-Motion" class="headerlink" title="Quiz: Feeling of Camera Motion"></a>Quiz: Feeling of Camera Motion</h2><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-41.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-42.png" style="zoom:60%"><br></center><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-43.png" style="zoom:60%"><br></center><h2 id="How-to-Compute-Intrinsics-from-Vanishing-Points"><a href="#How-to-Compute-Intrinsics-from-Vanishing-Points" class="headerlink" title="How to Compute Intrinsics from Vanishing Points"></a>How to Compute Intrinsics from Vanishing Points</h2><p>Compute focal length and image center from pure geometry without using projection equations.</p><p>Eg: Three orthogonal sets of parallel lines create three orthogonal vanishing points.</p><center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-44.png" style="zoom:60%"><br></center><p>What does the horizon between A and B tells us about the camera?</p><p>It gives us information about how the horizon is oriented with respect to the camera.</p><p>Because the camera is tilted, point C is not on the horizon.</p><p>Just knowledge of A and B doesn’t determine C. We need also the focal length and the image center in order to fix C.</p><p>Later for how to compute:</p> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-45.png" style="zoom:60%"><br></center><p>H is the orthocenter of ABC</p><p>Focal length computation, easy as following:</p> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-46.png" style="zoom:60%"><br></center><p>So f can be determined from $d_1$, $d_2$ and $d_3$, which are all known.</p><h2 id="Quiz-How-to-Compute-Intrinsics-from-Vanishing-Points"><a href="#Quiz-How-to-Compute-Intrinsics-from-Vanishing-Points" class="headerlink" title="Quiz: How to Compute Intrinsics from Vanishing Points"></a>Quiz: How to Compute Intrinsics from Vanishing Points</h2> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-47.png" style="zoom:60%"><br></center><h2 id="Camera-Calibration"><a href="#Camera-Calibration" class="headerlink" title="Camera Calibration"></a>Camera Calibration</h2> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-49.png" style="zoom:60%"><br></center><p>Cameras with large field of view have radial distortions.</p> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-48.png" style="zoom:60%"><br></center><p>A procedure called calibration (Estimates the intrinsic parameters)</p><ul><li>f focal length</li><li>($u_0$,$v_0$) image center</li><li>$k_1,k_2,…$ radial distortion parameters</li></ul><p>Matlab has calibration toolbox.</p><h2 id="Quiz-Camera-Calibration"><a href="#Quiz-Camera-Calibration" class="headerlink" title="Quiz: Camera Calibration"></a>Quiz: Camera Calibration</h2> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-50.png" style="zoom:60%"><br></center> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-51.png" style="zoom:60%"><br></center> <center><br><img src="https://azure-pictures.s3.amazonaws.com/blog/2019-03-30-Week1-53.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Dolly-Zoom"><a href="#Programming-Assignment-Dolly-Zoom" class="headerlink" title="Programming Assignment: Dolly Zoom"></a>Programming Assignment: Dolly Zoom</h2><p><a href="https://github.com/Aden-Q/Robotics-Perception/tree/master/Dolly-Zoom" target="_blank" rel="noopener">Dolly Zoom</a></p><h1 id="Week-2-Projective-Transformations"><a href="#Week-2-Projective-Transformations" class="headerlink" title="Week 2, Projective Transformations"></a>Week 2, Projective Transformations</h1><h2 id="Vanishing-Points-How-to-Compute-Camera-Orientation"><a href="#Vanishing-Points-How-to-Compute-Camera-Orientation" class="headerlink" title="Vanishing Points; How to Compute Camera Orientation"></a>Vanishing Points; How to Compute Camera Orientation</h2><p>$3^{rd}$ person perspective: World coordinate system</p><p>First person coordinate system: The person himself</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-1.png" style="zoom:60%"><br></center><p>How we orientate in the real world: $R$ and $t$</p><p>For $z_\infty=[0\space 0 \space 1 \space 0]^T$, $v_z=Kr_3$, K is the calibration matrix.</p><p>To fixed all rotation angles, we need 2 vanishing point in perpendicular direction.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-2.png" style="zoom:60%"><br></center><p>If we can recognize two perpendicular directions in the physical space, then we can recover the camera orientation relative to the world.</p><p>How to figure out both translation and rotation?</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-3.png" style="zoom:60%"><br></center><br>If we do  translation on the camera, the vanishing point remain itself. But when we rotate, the vanishing point will move.<br><br>We can recover rotation column $r_3$ from vanishing point z and $r_1$ from vanishiong point x. And using these two, we can figure out the camera orientation.<br><br>Rotation column $r_3$ tells us about the pan and tilt angles. (left and right, up and down)<br><br>Using K inverse transformation, we can transform from pixel-domain points into optical world.<br><br><br><br><br><br><br>## Quiz: Homogeneous Coordinates<br><br><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-4.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-5.png" style="zoom:60%"><br></center><h2 id="Compute-Projective-Transformations"><a href="#Compute-Projective-Transformations" class="headerlink" title="Compute Projective Transformations"></a>Compute Projective Transformations</h2><p>A perspective projection of a plane (like a camera image) is always a projective transformation.</p><p><strong>Definition</strong></p><p>A <strong>projective transformation</strong> is any invertible matrix transformation $P^2-&gt;P^2$</p><p>A projective transformation $A$ maps $p$ to $p’—Ap$</p><p>A projective transformation is also known as <strong>collineation or homography</strong></p><p>A projective transformation preserves incidence:</p><ul><li>Three collinear points are mapped to three collinear points.</li><li>And three concurrent lines are mapped to three concurrent lines.</li></ul><p>Projective transformation of lines</p><p>If $A$ maps a point to $Ap$, then where does a line $l$ map to?</p><p>Line equation in original plane<br>$$<br>l^Tp=0<br>$$<br>Line equation in image plane $p’—Ap$<br>$$<br>l^TA^{-1}p’=0<br>$$<br>implies that $l’=A^Tl$.</p><p>Computation of projective transformation:</p><hr><p>Assume that a mapping $A$ maps the three points<br>$$<br>\begin {pmatrix}<br>a \<br>b \<br>c<br>\end {pmatrix}<br>=<br>\begin {pmatrix}<br>a\alpha \<br>b\beta \<br>c\gamma<br>\end {pmatrix}<br>\begin {pmatrix}<br>1 &amp; 0 &amp; 0 \<br>0 &amp; 1 &amp; 0 \<br>0 &amp; 0 &amp; 1<br>\end {pmatrix}<br>$$<br>is a valid projective transformation, but 3 degrees of freedom so not sufficient.This transformation map (1,0,0), (0,1,0) and (0,0,1) to a,b and c correspondingly. We neeed to compute $\alpha,\beta$ and $ \gamma$.</p><p>Four points not three of them collinear suffice to recover unambiguously projective transformation.</p><p>With the forth point mapped point $d$, we can calculate as following:<br>$$<br>\begin {pmatrix}<br>a \<br>b \<br>c<br>\end {pmatrix}<br>\begin {pmatrix}<br>\alpha \\<br>\beta \\<br>\gamma<br>\end {pmatrix}<br>=d<br>$$</p><h2 id="Quiz-Projective-Transformations"><a href="#Quiz-Projective-Transformations" class="headerlink" title="Quiz: Projective Transformations"></a>Quiz: Projective Transformations</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-6.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-7.png" style="zoom:60%"><br></center><h2 id="Projective-Transformations-and-Vanishing-Points"><a href="#Projective-Transformations-and-Vanishing-Points" class="headerlink" title="Projective Transformations and Vanishing Points"></a>Projective Transformations and Vanishing Points</h2><p>Geometric interpretation of the projective transformations.</p><p>Projective transformation</p><ul><li>Aka Homography or Collineation</li><li>Represents the perspective projection from a ground plane to an image plane!</li><li>It is an invertible 3x3 matrix but has 8 independent parameters</li><li>For example if (X,Y) measured in meters on the ground and (u,v) in pixels</li></ul><p>$$<br>\begin {pmatrix}<br>u \\<br>v \\<br>1</p><h2 id="end-pmatrix"><a href="#end-pmatrix" class="headerlink" title="\end {pmatrix}"></a>\end {pmatrix}</h2><p>H<br>\begin {pmatrix}<br>X \\<br>Y \\<br>1<br>\end {pmatrix}<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-8.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-9.png" style="zoom:60%"><br></center><center><br>    &lt;img src = “<a href="https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-10.png&quot;" target="_blank" rel="noopener">https://azure-pictures.s3.amazonaws.com/blog/2019-04-02-Week2-10.png&quot;</a><br>         style = “zoom:60%”<br></center><h2 id="Quiz-Vanishing-Points-1"><a href="#Quiz-Vanishing-Points-1" class="headerlink" title="Quiz: Vanishing Points"></a>Quiz: Vanishing Points</h2><p>Note for question 2 and 3: When zooming, the calibration matrix K varies, so the K inverse transformation will change the location of vanishing points. While for translation, the vanishing points remain in their original position because translation disappear.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-11.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-13.png" style="zoom:60%"><br></center><p>Question 4 requires one more step “inverse”.</p><h2 id="Cross-Ratios-and-Single-View-Metrology"><a href="#Cross-Ratios-and-Single-View-Metrology" class="headerlink" title="Cross Ratios and Single View Metrology"></a>Cross Ratios and Single View Metrology</h2><p>The middle point of a segment preserved under parallel projection.</p><p>For a camera, the middle point of a segment doesn’t preserve. But the <strong>Cross-Ratio</strong> is preserved.</p><p>The cross-ratio remain the same under any projective transformation.</p><p>We can use this to measure distances in the real world.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-14.png" style="zoom:60%"><br></center><p>E.g.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-15.png" style="zoom:60%"><br></center><p>What happens when one of the points is at infinity?</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-16.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-17.png" style="zoom:60%"><br></center><p>And we can also compute the position of the vanishing point in the image.</p><p>Distance transfer:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-18.png" style="zoom:60%"><br></center><p>Single View Metrology via Cross Ratios:</p><ul><li>If we know a vanishing point we can compute any ratio along this direction!</li><li>We can transfer distances among parallel lines in the world if we know two vanishing points.</li><li>In none of these steps we used focal length or any other intrinsics.</li><li>We can do some image forensics on paintings or old photos!</li></ul><h2 id="Quiz-Cross-Ratios-and-Single-View-Metrology"><a href="#Quiz-Cross-Ratios-and-Single-View-Metrology" class="headerlink" title="Quiz: Cross Ratios and Single View Metrology"></a>Quiz: Cross Ratios and Single View Metrology</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-19.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-03-Week2-20.png" style="zoom:60%"><br></center><h2 id="Two-View-Soccer-Metrology"><a href="#Two-View-Soccer-Metrology" class="headerlink" title="Two View Soccer Metrology"></a>Two View Soccer Metrology</h2><p>The forth week of the course will focus on this problem.</p><h2 id="Programming-Assignment-Image-Projection-using-Homographies"><a href="#Programming-Assignment-Image-Projection-using-Homographies" class="headerlink" title="Programming Assignment: Image Projection using Homographies"></a>Programming Assignment: Image Projection using Homographies</h2><p><a href="https://github.com/Aden-Q/Robotics-Perception/tree/master/Image-Projection%20using%20Homographies" target="_blank" rel="noopener">Image Projection using Homographies</a></p><h1 id="Week-3-Pose-Estimation"><a href="#Week-3-Pose-Estimation" class="headerlink" title="Week 3, Pose Estimation"></a>Week 3, Pose Estimation</h1><h2 id="Visual-Features"><a href="#Visual-Features" class="headerlink" title="Visual Features"></a>Visual Features</h2><p>What we want from features?</p><ol><li>Detection repeatability: When they are detected in one image to be detected in another one from the same scene even if image differs in scale and orientation.</li><li>We should be able to match features using a descriptor of the neighborhood.</li><li>This descriptor should not change significantly under viewpoint changes like scale and rotation.</li><li>We call this property descriptor invariance.</li></ol><p>The notion of scale space</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-5.png" style="zoom:60%"><br></center><br>We can build a same scale by subsampling.<br><br><br><br>Scale selection<br><br><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-6.png" style="zoom:60%"><br></center><br>Laplacian of Gaussian (LoG)<br><br><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week3-10.png" style="zoom:60%"><br></center><p>Scale Space</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-10.png" style="zoom:60%"><br></center><p>SIFT: Scale Invariant Feature Transform</p><p>Laplacian</p><p>Each key point corresponds to a 4x4 grid of histograms.</p><h2 id="Quiz-Visual-Features"><a href="#Quiz-Visual-Features" class="headerlink" title="Quiz: Visual Features"></a>Quiz: Visual Features</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-11.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-12.png" style="zoom:60%"><br></center><h2 id="Singular-Value-Decomposition"><a href="#Singular-Value-Decomposition" class="headerlink" title="Singular Value Decomposition"></a>Singular Value Decomposition</h2><p>1890， Carl Friedrich Gauss</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-7.png" style="zoom:60%"><br></center><p>U/V: Column orthogonal matrix</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-8.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-9.png" style="zoom:60%"><br></center><p>D: Diagnal matrix:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-10.png" style="zoom:60%"><br></center><p>SVD as basis + transformed Address</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-11.png" style="zoom:60%"><br></center><p>Eigenface generation:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-12.png" style="zoom:60%"><br></center><p><strong>Rank</strong>:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-13.png" style="zoom:60%"><br></center><p><strong>Nullspace:</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-14.png" style="zoom:60%"><br></center><p><strong>Matrix Inversion with SVD</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-15.png" style="zoom:60%"><br></center><p><strong>Two types of Least Square Problem:</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-16.png" style="zoom:60%"><br></center><p><strong>Line fitting:</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-17.png" style="zoom:60%"><br></center><h2 id="Quiz-Singular-Value-Decomposition"><a href="#Quiz-Singular-Value-Decomposition" class="headerlink" title="Quiz: Singular Value Decomposition"></a>Quiz: Singular Value Decomposition</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-13.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-14.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-15.png" style="zoom:60%"><br></center><h2 id="RANSAC-Random-Sample-Consensus-I"><a href="#RANSAC-Random-Sample-Consensus-I" class="headerlink" title="RANSAC: Random Sample Consensus I"></a>RANSAC: Random Sample Consensus I</h2><p>Outlier effects (sensitivity):</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-20.png" style="zoom:60%"><br></center><p>Strategy: To find a model that accords with the maximum number of samples.</p><p>Assumptions:</p><ol><li>Majority of good samples agree with the underlying model (good apples are same and simple).</li><li>Bad samples does dot consistently agree with a single model (all bad apples are different and complicated).</li></ol><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-21.png" style="zoom:60%"><br></center><p>Each time choose two points, pick the ‘best’ two points pair.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-22.png" style="zoom:60%"><br></center><h2 id="Quiz-RANSAC"><a href="#Quiz-RANSAC" class="headerlink" title="Quiz: RANSAC"></a>Quiz: RANSAC</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-23.png" style="zoom:60%"><br></center><br>Answer for the 3rd question is “264”, a little strange.<br><br><br><br><br><br><br>## Where am I? Part 1<br><br><strong>Homography Linear Estimation</strong><br><br><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-24.png" style="zoom:60%"><br></center><h2 id="Where-am-I-Part-2"><a href="#Where-am-I-Part-2" class="headerlink" title="Where am I? Part 2"></a>Where am I? Part 2</h2><p><strong>Perspective-n-Point</strong></p><p>6 points can give 12 constrains</p><h2 id="Pose-from-3D-Point-Correspondences-The-Procrustes-Problem"><a href="#Pose-from-3D-Point-Correspondences-The-Procrustes-Problem" class="headerlink" title="Pose from 3D Point Correspondences: The Procrustes Problem"></a>Pose from 3D Point Correspondences: The Procrustes Problem</h2><p><strong>Procrustes Problem</strong></p><p>Given two shapes find the scaling, rotation, and translation that fits one into the other.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-25.png" style="zoom:60%"><br></center><h2 id="Quiz-3D-3D-Pose"><a href="#Quiz-3D-3D-Pose" class="headerlink" title="Quiz: 3D-3D Pose"></a>Quiz: 3D-3D Pose</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-26.png" style="zoom:60%"><br></center><h2 id="Pose-from-Projective-Transformations"><a href="#Pose-from-Projective-Transformations" class="headerlink" title="Pose from Projective Transformations"></a>Pose from Projective Transformations</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-27.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-13-Week3-28.png" style="zoom:60%"><br></center><h2 id="Pose-from-Point-Correspondences-P3P"><a href="#Pose-from-Point-Correspondences-P3P" class="headerlink" title="Pose from Point Correspondences P3P"></a>Pose from Point Correspondences P3P</h2><p>The perspective 3-Point problem of P3P or in photogrammetry the Resection problem: The Snellius-Pothenot problem.</p><h2 id="Quiz-Pose-Estimation"><a href="#Quiz-Pose-Estimation" class="headerlink" title="Quiz: Pose Estimation"></a>Quiz: Pose Estimation</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week3-30.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Image-Projection"><a href="#Programming-Assignment-Image-Projection" class="headerlink" title="Programming Assignment: Image Projection"></a>Programming Assignment: Image Projection</h2><p><a href="https://github.com/Aden-Q/Robotics-Perception/tree/master/Image%20Projection" target="_blank" rel="noopener">Image Projection</a></p><p>Pose Estimation</p><h1 id="Week-4-Multi-View-Geometry"><a href="#Week-4-Multi-View-Geometry" class="headerlink" title="Week 4, Multi-View Geometry"></a>Week 4, Multi-View Geometry</h1><h2 id="Epipolar-Geometry-I"><a href="#Epipolar-Geometry-I" class="headerlink" title="Epipolar Geometry I"></a>Epipolar Geometry I</h2><p>Given two pictures of the scene, calculate the relative transformation and rotation between the two.</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-1.png" style="zoom:60%"><br></center><p>Epipole &amp; Epipolar line</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-2.png" style="zoom:60%"><br></center><p><strong>Point correspondence</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-4.png" style="zoom:60%"><br></center><p>Epipole calculation -&gt; Least Square problem</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-5.png" style="zoom:60%"><br></center><br>$$<br>E = [t]_xR<br>$$<br><br>$E$ is called the essential matrix. It hides inside both transformation and rotation relations between the two cameras. So we can compute $E$ by a few point correspondence.<br><br><br><br><br>## Epipolar Geometry II<br><br>Fundamental matrix:<br><br><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-6.png" style="zoom:60%"><br></center><p>$$<br>x_1=KX_1 \space x_2=KX_2<br>$$</p><p><strong>Fundamental matrix</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-16.png" style="zoom:60%"><br></center><p>8 correspondences are needed to solve $F$ (one for scaling).</p><p><strong>8 Point Algorithm</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-18.png" style="zoom:60%"><br></center><h2 id="Epipolar-Geometry-III"><a href="#Epipolar-Geometry-III" class="headerlink" title="Epipolar Geometry III"></a>Epipolar Geometry III</h2><p><strong>Recovery of R,T from Fundamental Matrix</strong></p><p>Essential matrix and fundamental matrix transformation:<br>$$<br>E = K^TFK<br>$$</p><p>$$<br>E = [t]_xR<br>$$</p><p>First recover t:</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-19.png" style="zoom:60%"><br></center><p>SVD of E</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-14-Week4-20.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-21.png" style="zoom:60%"><br></center><p>if $det(R) =-1,t=-t,R=-R$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-22.png" style="zoom:60%"><br></center><p><strong>Point Triangulation</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-23.png" style="zoom:60%"><br></center><p>$$<br>C=-R^Tt<br>$$</p><h2 id="Quiz-Epipolar-Geometry"><a href="#Quiz-Epipolar-Geometry" class="headerlink" title="Quiz: Epipolar Geometry"></a>Quiz: Epipolar Geometry</h2><p>10.5/12 。。。。</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-24.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-25.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-28.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-27.png" style="zoom:60%"><br></center><h2 id="RANSAC-Random-Sample-Consensus-II"><a href="#RANSAC-Random-Sample-Consensus-II" class="headerlink" title="RANSAC: Random Sample Consensus II"></a>RANSAC: Random Sample Consensus II</h2><p>Error function:</p><p>distance to the Epipolar line<br>$$<br>\theta=\frac{|ax+by+c|}{\sqrt{a^2+b^2}}<br>$$</p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-29.png" style="zoom:60%"><br></center><h2 id="Nonlinear-Least-Squares-I"><a href="#Nonlinear-Least-Squares-I" class="headerlink" title="Nonlinear Least Squares I"></a>Nonlinear Least Squares I</h2><p><strong>The properti4es of linear least squares:</strong></p><ul><li>Has the global/unique solution.</li><li>Has the closed form solution (non-iterative solve).</li><li>Is solved efficiently (SVD).</li><li>Requires no extra parameters such as initialization.</li></ul><h2 id="Nonlinear-Least-Squares-II"><a href="#Nonlinear-Least-Squares-II" class="headerlink" title="Nonlinear  Least Squares II"></a>Nonlinear  Least Squares II</h2><p><strong>Reprojection Error (Geometric Error)</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-30.png" style="zoom:60%"><br></center><h2 id="Nonlinear-Least-Squares-III"><a href="#Nonlinear-Least-Squares-III" class="headerlink" title="Nonlinear Least Squares III"></a>Nonlinear Least Squares III</h2><p><strong>Jacobian matrix</strong></p><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-31.png" style="zoom:60%"><br></center><h2 id="Quiz-Nonlinear-Least-Squares"><a href="#Quiz-Nonlinear-Least-Squares" class="headerlink" title="Quiz: Nonlinear Least Squares"></a>Quiz: Nonlinear Least Squares</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-32.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-33.png" style="zoom:60%"><br></center><h2 id="Optical-Flow-2D-Point-Correspondences"><a href="#Optical-Flow-2D-Point-Correspondences" class="headerlink" title="Optical Flow: 2D Point Correspondences"></a>Optical Flow: 2D Point Correspondences</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-34.png" style="zoom:60%"><br></center><h2 id="3D-Velocities-from-Optical-Flow"><a href="#3D-Velocities-from-Optical-Flow" class="headerlink" title="3D Velocities from Optical Flow"></a>3D Velocities from Optical Flow</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-36.png" style="zoom:60%"><br></center><h2 id="Quiz-3D-Velocities-from-Optical-Flow"><a href="#Quiz-3D-Velocities-from-Optical-Flow" class="headerlink" title="Quiz: 3D Velocities from Optical Flow"></a>Quiz: 3D Velocities from Optical Flow</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-35.png" style="zoom:60%"><br></center><h2 id="3D-Motion-and-Structure-from-Multiple-Views"><a href="#3D-Motion-and-Structure-from-Multiple-Views" class="headerlink" title="3D Motion and Structure from Multiple Views"></a>3D Motion and Structure from Multiple Views</h2><h2 id="Visual-Odometry"><a href="#Visual-Odometry" class="headerlink" title="Visual Odometry"></a>Visual Odometry</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-40.png" style="zoom:60%"><br></center><h2 id="Bundle-Adjustment-I"><a href="#Bundle-Adjustment-I" class="headerlink" title="Bundle Adjustment I"></a>Bundle Adjustment I</h2><h2 id="Bundle-Adjustment-II"><a href="#Bundle-Adjustment-II" class="headerlink" title="Bundle Adjustment II"></a>Bundle Adjustment II</h2><h2 id="Bundle-Adjustment-III"><a href="#Bundle-Adjustment-III" class="headerlink" title="Bundle Adjustment III"></a>Bundle Adjustment III</h2><h2 id="Quiz-Bundle-Adjustment"><a href="#Quiz-Bundle-Adjustment" class="headerlink" title="Quiz: Bundle Adjustment"></a>Quiz: Bundle Adjustment</h2><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-41.png" style="zoom:60%"><br></center><center><br>    <img src="https://azure-pictures.s3.amazonaws.com/blog/2019-04-15-Week4-41.png" style="zoom:60%"><br></center><h2 id="Programming-Assignment-Structure-from-Motion"><a href="#Programming-Assignment-Structure-from-Motion" class="headerlink" title="Programming Assignment: Structure from Motion"></a>Programming Assignment: Structure from Motion</h2><p><a href="https://github.com/Aden-Q/Robotics-Perception/tree/master/Structure%20from%20Motion" target="_blank" rel="noopener">Structure from Motion</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;University of Pennsylvania, Robotics: Perception&lt;/p&gt;
&lt;p&gt;Course Notes&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Matlab" scheme="http://yoursite.com/tags/Matlab/"/>
    
      <category term="Robotics" scheme="http://yoursite.com/tags/Robotics/"/>
    
  </entry>
  
  <entry>
    <title>MathJax Formula</title>
    <link href="http://yoursite.com/2019/03/23/MathJax%20Formula/"/>
    <id>http://yoursite.com/2019/03/23/MathJax Formula/</id>
    <published>2019-03-23T22:48:34.000Z</published>
    <updated>2019-03-29T06:12:38.697Z</updated>
    
    <content type="html"><![CDATA[<p>MathJax Formula memo.</p><a id="more"></a><blockquote><p>  MathJax is an open-source JavaScript display engine for Latex, MathML, and AsciiMath notation that works in all modern browsers.</p></blockquote><p>Two modes:</p><ul><li>Inline: embedded into text.</li><li>Displayed: displayed individually.</li></ul><h1 id="Greek-alphabet"><a href="#Greek-alphabet" class="headerlink" title="Greek alphabet"></a>Greek alphabet</h1><table><thead><tr><th style="text-align:center">Name</th><th style="text-align:center">Upper</th><th style="text-align:center">Tex</th><th style="text-align:center">Lower</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">alpha</td><td style="text-align:center">$A$</td><td style="text-align:center">A</td><td style="text-align:center">$\alpha$</td><td style="text-align:center">\alpha</td></tr><tr><td style="text-align:center">beta</td><td style="text-align:center">$B$</td><td style="text-align:center">B</td><td style="text-align:center">$\beta$</td><td style="text-align:center">\beta</td></tr><tr><td style="text-align:center">gamma</td><td style="text-align:center">$\Gamma$</td><td style="text-align:center">\Gamma</td><td style="text-align:center">$\gamma$</td><td style="text-align:center">\gamma</td></tr><tr><td style="text-align:center">delta</td><td style="text-align:center">$\Delta$</td><td style="text-align:center">\Delta</td><td style="text-align:center">$\delta$</td><td style="text-align:center">\delta</td></tr><tr><td style="text-align:center">epsilon</td><td style="text-align:center">$E$</td><td style="text-align:center">E</td><td style="text-align:center">$\epsilon$</td><td style="text-align:center">\epsilon</td></tr><tr><td style="text-align:center">zeta</td><td style="text-align:center">$Z$</td><td style="text-align:center">Z</td><td style="text-align:center">$\zeta$</td><td style="text-align:center">\zeta</td></tr><tr><td style="text-align:center">eta</td><td style="text-align:center">$H$</td><td style="text-align:center">H</td><td style="text-align:center">$\eta$</td><td style="text-align:center">\eta</td></tr><tr><td style="text-align:center">theta</td><td style="text-align:center">$\Theta$</td><td style="text-align:center">\Theta</td><td style="text-align:center">$\theta$</td><td style="text-align:center">\theta</td></tr><tr><td style="text-align:center">iota</td><td style="text-align:center">$I$</td><td style="text-align:center">I</td><td style="text-align:center">$\iota$</td><td style="text-align:center">\iota</td></tr><tr><td style="text-align:center">kappa</td><td style="text-align:center">$K$</td><td style="text-align:center">K</td><td style="text-align:center">$\kappa$</td><td style="text-align:center">\kappa</td></tr><tr><td style="text-align:center">lambda</td><td style="text-align:center">$\Lambda$</td><td style="text-align:center">\Lambda</td><td style="text-align:center">$\lambda$</td><td style="text-align:center">\lambda</td></tr><tr><td style="text-align:center">mu</td><td style="text-align:center">$M$</td><td style="text-align:center">M</td><td style="text-align:center">$\mu$</td><td style="text-align:center">\mu</td></tr><tr><td style="text-align:center">nu</td><td style="text-align:center">$N$</td><td style="text-align:center">N</td><td style="text-align:center">$\nu$</td><td style="text-align:center">\nu</td></tr><tr><td style="text-align:center">xi</td><td style="text-align:center">$\Xi$</td><td style="text-align:center">\Xi</td><td style="text-align:center">$\xi$</td><td style="text-align:center">\xi</td></tr><tr><td style="text-align:center">omicron</td><td style="text-align:center">$O$</td><td style="text-align:center">O</td><td style="text-align:center">$\omicron$</td><td style="text-align:center">\omicron</td></tr><tr><td style="text-align:center">pi</td><td style="text-align:center">$\Pi$</td><td style="text-align:center">\Pi</td><td style="text-align:center">$\pi$</td><td style="text-align:center">\pi</td></tr><tr><td style="text-align:center">rho</td><td style="text-align:center">$P$</td><td style="text-align:center">P</td><td style="text-align:center">$\rho$</td><td style="text-align:center">\rho</td></tr><tr><td style="text-align:center">sigma</td><td style="text-align:center">$\Sigma$</td><td style="text-align:center">\Sigma</td><td style="text-align:center">$\sigma$</td><td style="text-align:center">\sigma</td></tr><tr><td style="text-align:center">tau</td><td style="text-align:center">$T$</td><td style="text-align:center">T</td><td style="text-align:center">$\tau$</td><td style="text-align:center">\tau</td></tr><tr><td style="text-align:center">upsilon</td><td style="text-align:center">$\Upsilon$</td><td style="text-align:center">\Upsilon</td><td style="text-align:center">$\upsilon$</td><td style="text-align:center">\upsilon</td></tr><tr><td style="text-align:center">phi</td><td style="text-align:center">$\Phi$</td><td style="text-align:center">\Phi</td><td style="text-align:center">$\phi$</td><td style="text-align:center">\phi</td></tr><tr><td style="text-align:center">chi</td><td style="text-align:center">$X$</td><td style="text-align:center">X</td><td style="text-align:center">$\chi$</td><td style="text-align:center">\chi</td></tr><tr><td style="text-align:center">psi</td><td style="text-align:center">$\Psi$</td><td style="text-align:center">\Psi</td><td style="text-align:center">$\psi$</td><td style="text-align:center">\psi</td></tr><tr><td style="text-align:center">omega</td><td style="text-align:center">$\Omega$</td><td style="text-align:center">\Omega</td><td style="text-align:center">$\omega$</td><td style="text-align:center">\omega</td></tr></tbody></table><h1 id="Superscript-and-Subscript"><a href="#Superscript-and-Subscript" class="headerlink" title="Superscript and Subscript"></a>Superscript and Subscript</h1><p>Group the notation by curly bracket “{}”, other wise, the script only count for the one consecutive letter.</p><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$x^{2}$</td><td style="text-align:center">x^{2}</td></tr><tr><td style="text-align:center">$x_0$</td><td style="text-align:center">x_0</td></tr><tr><td style="text-align:center">$\hat x$</td><td style="text-align:center">\hat x</td></tr><tr><td style="text-align:center">$\widehat {xy} $</td><td style="text-align:center">\widehat {xy}</td></tr><tr><td style="text-align:center">$\hat {xy} $</td><td style="text-align:center">\hat {xy}</td></tr><tr><td style="text-align:center">$\overline {xyz}$</td><td style="text-align:center">\overline {xyz}</td></tr><tr><td style="text-align:center">$\vec x$</td><td style="text-align:center">\vec x</td></tr><tr><td style="text-align:center">$\dot x$</td><td style="text-align:center">\dot x</td></tr><tr><td style="text-align:center">$\ddot x$</td><td style="text-align:center">\ddot x</td></tr></tbody></table><h1 id="Brackets"><a href="#Brackets" class="headerlink" title="Brackets"></a>Brackets</h1><table><thead><tr><th style="text-align:center">Left</th><th style="text-align:center">Tex</th><th style="text-align:center">Right</th><th style="text-align:center">Tex$$</th></tr></thead><tbody><tr><td style="text-align:center">$\lbrace$</td><td style="text-align:center">\lbrace</td><td style="text-align:center">$\rbrace$</td><td style="text-align:center">\rbrace</td></tr><tr><td style="text-align:center">$\langle$</td><td style="text-align:center">\langle</td><td style="text-align:center">$\rangle$</td><td style="text-align:center">\rangle</td></tr><tr><td style="text-align:center">$\lceil$</td><td style="text-align:center">\lceil</td><td style="text-align:center">$\rceil$</td><td style="text-align:center">\rceil</td></tr><tr><td style="text-align:center">$\lfloor$</td><td style="text-align:center">\lfloor</td><td style="text-align:center">$\rfloor$</td><td style="text-align:center">\rfloor</td></tr></tbody></table><h1 id="Fraction-and-Radical-expression"><a href="#Fraction-and-Radical-expression" class="headerlink" title="Fraction and Radical expression"></a>Fraction and Radical expression</h1><p>Similarly, we group numerator and denominator with “{}”, otherwise we only count the first digit or letter.</p><table><thead><tr><th style="text-align:center">Simple form</th><th style="text-align:center">Tex</th><th style="text-align:center">General form</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\frac ab$</td><td style="text-align:center">\frac ab</td><td style="text-align:center">$\frac{abc}{def}$</td><td style="text-align:center">\frac{abc}{def}</td></tr></tbody></table><p>Radical:</p><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\sqrt[2]{2}$</td><td style="text-align:center">\sqrt[2]{2}</td></tr></tbody></table><h1 id="Summation-and-Integral"><a href="#Summation-and-Integral" class="headerlink" title="Summation and Integral"></a>Summation and Integral</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\sum_1^n$</td><td style="text-align:center">\sum_1^n</td></tr><tr><td style="text-align:center">$\int_1^\infty$</td><td style="text-align:center">\int_1^\infty</td></tr><tr><td style="text-align:center">$\prod_1^n$</td><td style="text-align:center">\prod_1^n</td></tr></tbody></table><h1 id="Comparison"><a href="#Comparison" class="headerlink" title="Comparison"></a>Comparison</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\lt$</td><td style="text-align:center">\lt</td></tr><tr><td style="text-align:center">$\gt$</td><td style="text-align:center">\gt</td></tr><tr><td style="text-align:center">$\le$</td><td style="text-align:center">\leq</td></tr><tr><td style="text-align:center">$\geq$</td><td style="text-align:center">\geq</td></tr><tr><td style="text-align:center">$\neq$</td><td style="text-align:center">\neq</td></tr></tbody></table><h1 id="Arithmetic"><a href="#Arithmetic" class="headerlink" title="Arithmetic"></a>Arithmetic</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\times$</td><td style="text-align:center">\times</td></tr><tr><td style="text-align:center">$\div$</td><td style="text-align:center">\div</td></tr><tr><td style="text-align:center">$\pm$</td><td style="text-align:center">\pm</td></tr><tr><td style="text-align:center">$\mp$</td><td style="text-align:center">\mp</td></tr><tr><td style="text-align:center">$\cdot$</td><td style="text-align:center">\cdot</td></tr><tr><td style="text-align:center">$\approx$</td><td style="text-align:center">\approx</td></tr></tbody></table><h1 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\cup$</td><td style="text-align:center">\cup</td></tr><tr><td style="text-align:center">$\cap$</td><td style="text-align:center">\cap</td></tr><tr><td style="text-align:center">$\setminus$</td><td style="text-align:center">\setminus</td></tr><tr><td style="text-align:center">$\subset$</td><td style="text-align:center">\subset</td></tr><tr><td style="text-align:center">$\subseteq $</td><td style="text-align:center">\subseteq</td></tr><tr><td style="text-align:center">$\subsetneq$</td><td style="text-align:center">\subsetneq</td></tr><tr><td style="text-align:center">$\supset$</td><td style="text-align:center">\supset</td></tr><tr><td style="text-align:center">$\in$</td><td style="text-align:center">\in</td></tr><tr><td style="text-align:center">$\notin$</td><td style="text-align:center">\notin</td></tr></tbody></table><p>Empty set: $\emptyset ​$ , Text: \emptyset</p><h1 id="Combination"><a href="#Combination" class="headerlink" title="Combination"></a>Combination</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th><th style="text-align:center">Optional</th></tr></thead><tbody><tr><td style="text-align:center">${n+1 \choose 2k}$</td><td style="text-align:center">{n+1 \choose 2k}</td><td style="text-align:center">\binom{n+1}{2k}</td></tr></tbody></table><h1 id="Row"><a href="#Row" class="headerlink" title="Row"></a>Row</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\to$</td><td style="text-align:center">\rightarrow</td></tr><tr><td style="text-align:center">$\leftarrow$</td><td style="text-align:center">\leftarrow</td></tr><tr><td style="text-align:center">$\Rightarrow$</td><td style="text-align:center">\Rightarrow</td></tr><tr><td style="text-align:center">$\Leftarrow$</td><td style="text-align:center">\Leftarrow</td></tr></tbody></table><h1 id="Logical-operation"><a href="#Logical-operation" class="headerlink" title="Logical operation"></a>Logical operation</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$\land$</td><td style="text-align:center">\land</td></tr><tr><td style="text-align:center">$\lor$</td><td style="text-align:center">\lor</td></tr><tr><td style="text-align:center">$\lnot$</td><td style="text-align:center">\lnot</td></tr><tr><td style="text-align:center">$\forall$</td><td style="text-align:center">\forall</td></tr><tr><td style="text-align:center">$\exists $</td><td style="text-align:center">\exists</td></tr></tbody></table><h1 id="Modular-arithmetic"><a href="#Modular-arithmetic" class="headerlink" title="Modular arithmetic"></a>Modular arithmetic</h1><table><thead><tr><th style="text-align:center">Text</th><th style="text-align:center">Tex</th></tr></thead><tbody><tr><td style="text-align:center">$a\equiv b\pmod n$</td><td style="text-align:center">a\equiv b\pmod b</td></tr></tbody></table><h1 id="Table"><a href="#Table" class="headerlink" title="Table"></a>Table</h1><p>Eg1, Tex: <code>\begin {array}{c+|lcr} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\ 2 &amp; -1 &amp; 189 &amp; -8 \\ 3 &amp; -20 &amp; 2000 &amp; 1+10i \end {array}</code></p><p>$$<br>\begin {array} \text{n} &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\<br>1 &amp; 0.24 &amp; 1 &amp; 125 \\<br>2 &amp; -1 &amp; 189 &amp; -8 \\<br>3 &amp; -20 &amp; 2000 &amp; 1+10i<br>\end {array}<br>$$</p><p>Eg2: Tex: <code>\begin {array}{c+|lcr} n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\ \hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\ 2 &amp; -1 &amp; 189 &amp; -8 \\ 3 &amp; -20 &amp; 2000 &amp; 1+10i \end {array}</code></p><p>$$<br>\begin {array}{c+|lcr}<br>n &amp; \text{Left} &amp; \text{Center} &amp; \text{Right} \\<br>\hline 1 &amp; 0.24 &amp; 1 &amp; 125 \\<br>2 &amp; -1 &amp; 189 &amp; -8 \\<br>3 &amp; -20 &amp; 2000 &amp; 1+10i<br>\end {array}<br>$$</p><h1 id="Matrix"><a href="#Matrix" class="headerlink" title="Matrix"></a>Matrix</h1><h2 id="matrix"><a href="#matrix" class="headerlink" title="matrix"></a>matrix</h2><p> \begin {matrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{matrix}</p><p>$$<br>\begin {matrix}<br>1 &amp; x &amp; x^2 \\<br>1 &amp; y &amp; y^2 \\<br>1 &amp; z &amp; z^2<br>\end{matrix}<br>$$</p><h2 id="pmatrix"><a href="#pmatrix" class="headerlink" title="pmatrix"></a>pmatrix</h2><p>\begin {pmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{pmatrix}</p><p>$$<br>\begin {pmatrix}<br>1 &amp; x &amp; x^2 \\<br>1 &amp; y &amp; y^2 \\<br>1 &amp; z &amp; z^2<br>\end{pmatrix}<br>$$</p><h2 id="bmatrix"><a href="#bmatrix" class="headerlink" title="bmatrix"></a>bmatrix</h2><p>\begin {bmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{bmatrix}</p><p>$$<br>\begin {bmatrix}<br>1 &amp; x &amp; x^2 \\<br>1 &amp; y &amp; y^2 \\<br>1 &amp; z &amp; z^2<br>\end{bmatrix}<br>$$</p><h2 id="Bmatrix"><a href="#Bmatrix" class="headerlink" title="Bmatrix"></a>Bmatrix</h2><p>\begin {Bmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{Bmatrix}</p><p>$$<br>\begin {Bmatrix}<br>1 &amp; x &amp; x^2 \\<br>1 &amp; y &amp; y^2 \\<br>1 &amp; z &amp; z^2<br>\end{Bmatrix}<br>$$</p><h2 id="vmatrix"><a href="#vmatrix" class="headerlink" title="vmatrix"></a>vmatrix</h2><p> \begin {vmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{vmatrix}</p><p>$$<br>\begin {vmatrix}<br>1 &amp; x &amp; x^2 \\<br>1 &amp; y &amp; y^2 \\<br>1 &amp; z &amp; z^2<br>\end{vmatrix}<br>$$</p><h2 id="Vmatrix"><a href="#Vmatrix" class="headerlink" title="Vmatrix"></a>Vmatrix</h2><p> \begin {Vmatrix} 1 &amp; x &amp; x^2 \ 1 &amp; y &amp; y^2 \ 1 &amp; z &amp; z^2 \\ \end{Vmatrix}</p><p>$$<br>\begin {Vmatrix}<br>1 &amp; x &amp; x^2 \\<br>1 &amp; y &amp; y^2 \\<br>1 &amp; z &amp; z^2<br>\end{Vmatrix}<br>$$</p><h1 id="Reference-Hoocoln"><a href="#Reference-Hoocoln" class="headerlink" title="Reference: Hoocoln"></a>Reference: <a href="http://3iter.com/2015/10/14/Mathjax%E4%B8%8ELaTex%E5%85%AC%E5%BC%8F%E7%AE%80%E4%BB%8B/" target="_blank" rel="noopener">Hoocoln</a></h1>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;MathJax Formula memo.&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Math" scheme="http://yoursite.com/tags/Math/"/>
    
      <category term="MathJax" scheme="http://yoursite.com/tags/MathJax/"/>
    
  </entry>
  
  <entry>
    <title>Algorithms, Part 1</title>
    <link href="http://yoursite.com/2019/03/10/Algorithms-Part-1/"/>
    <id>http://yoursite.com/2019/03/10/Algorithms-Part-1/</id>
    <published>2019-03-10T19:06:34.000Z</published>
    <updated>2019-05-01T22:59:04.071Z</updated>
    
    <content type="html"><![CDATA[<p>Princeton Algorithm course on coursera. Part 1</p><a id="more"></a><p>Cover:</p><ul><li>Disjoint set</li><li>Analysis of Algorithms</li><li>Stack and Queue</li><li>Elementary Sorts</li><li>Mergesort</li><li>Quicksort</li><li>Priority Queue</li><li>Elementary Symbol Tables</li><li>BST</li><li>Hash Table</li></ul><p>Learning Purpose: </p><ul><li>Being familiar with Java. </li><li>Having fun with algorithms.</li></ul><p>Reference Books:</p><ul><li><a href="https://algs4.cs.princeton.edu/home/" target="_blank" rel="noopener">Algorithms, 4th Edition</a></li><li><a href="https://introcs.cs.princeton.edu/java/home/" target="_blank" rel="noopener">Computer Science:   An Interdisciplinary Approach</a></li></ul><h1 id="Week-1"><a href="#Week-1" class="headerlink" title="Week 1"></a>Week 1</h1><h2 id="Why-study-algorithms"><a href="#Why-study-algorithms" class="headerlink" title="Why study algorithms"></a>Why study algorithms</h2><p><em>“Great algorithms are the poetry of computation.” — Francis Sullivan</em></p><p><em>“Algorithms + Data Structures = Programs.” — Niklaus Wirth</em></p><h2 id="Union-Find"><a href="#Union-Find" class="headerlink" title="Union-Find"></a>Union-Find</h2><p>Steps to developing a usable algorithm</p><ul><li>Model the problem.</li><li><p>Find an algorithm to solve it.</p></li><li><p>Fast enough? Fits in memory?</p></li><li>If not, figure out why.</li><li>Find a way to address the problem.</li><li>Iterate until satisfied.</li></ul><h3 id="dynamic-connectivity"><a href="#dynamic-connectivity" class="headerlink" title="dynamic connectivity"></a>dynamic connectivity</h3><p>Given a set of N objects.</p><ul><li>Union command: connect two objects</li><li>Find/conneted query: is there a path connecting the two objects?</li></ul><center><br>    <img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0w2nx25iwj30jm06yjse.jpg" style="zoom:60%"><br></center><p><u><strong>Connectivity example</strong></u></p><font color="blue">Q. Is there a path connecting <em>p</em> and <em>q</em>?</font><center><br>    <img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0w31l36egj30nt0j2k6w.jpg" style="zoom:60%"><br></center><p>Some common understandings:</p><ul><li>Reflexive: <em>p</em> is connected to <em>p</em> itself.</li><li>Symmetric: if <em>p</em> is connected to <em>q</em>, then <em>q</em> is connected to <em>p</em>.</li><li>Transitive: if <em>p</em> is connected to <em>q</em> and <em>q</em> is connected to <em>r</em>, then <em>p</em> is connected to <em>r</em>.</li></ul><p><strong>Connected components.</strong> Maximal set of objects that are mutually connected.</p><p>e.g.</p><center><br>    <img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0w3d6dfv8j30co09zabx.jpg" style="zoom:60%"><br>    </center><p>​    </p><p><font color="blue"> Goal. </font> Design efficient data structure for union-find.</p><ul><li>Number of objects <em>N</em> can be huge.</li><li>Number of operations <em>M</em> can be huge.</li><li>Find queries and union commands may be intermixed.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// API</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UF</span> </span>&#123;</span><br><span class="line">    UF(<span class="keyword">int</span> N)<span class="comment">// initialize union-find data structure with N objects (0 to N-1)</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span><span class="comment">// add connection between p and q</span></span></span><br><span class="line"><span class="function">    <span class="keyword">boolean</span> <span class="title">connected</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span><span class="comment">// are p and q the same component?</span></span></span><br><span class="line"><span class="function">    <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> p)</span><span class="comment">//component identifier for p (0 to N-1)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">int</span> <span class="title">count</span><span class="params">()</span><span class="comment">// number of components</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><h3 id="quick-find"><a href="#quick-find" class="headerlink" title="quick find"></a>quick find</h3><p>Data structure</p><ul><li>Integer array id[] of size N.</li><li>Interpretation: <em>p</em> and <em>q</em> are connected iff they have the same id.</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0xaw2d1qzj30ok03lwfw.jpg" style="zoom:60%"><br></center><p>Find: Check if <em>p</em> and <em>q</em> have the same id</p><p>Union: To merge components containing <em>p</em> and <em>q</em>, change all entries whose id equals id[p] to id[q]. Costly.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuickFindUF</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] id;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuickFindUF</span><span class="params">(<span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        id = <span class="keyword">new</span> <span class="keyword">int</span>[N];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">            id[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">connected</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;<span class="keyword">return</span> id[p] == id[q]; &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> pid = id[p];</span><br><span class="line">        <span class="keyword">int</span> qid = idp[q];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; id.length; i++)</span><br><span class="line">            <span class="keyword">if</span> (id[i] == pid) id[i] = qid;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><table><thead><tr><th>algorithm</th><th>initialize</th><th>union</th><th>find</th></tr></thead><tbody><tr><td>quick-find</td><td>N</td><td>N</td><td>1</td></tr></tbody></table><p>N union commands on N object: quadratic time. Much too slow.</p><p>Quadratic algorithms don’t scale with technology.</p><h3 id="quick-union"><a href="#quick-union" class="headerlink" title="quick union"></a>quick union</h3><p>Data structure</p><ul><li>Integer array id[] of size N.</li><li>Interpretation: id[i] is parent of i.</li><li>Root of i is id[id[id[…id[i]…]]].</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0xbfl4c0kj30au06aaav.jpg" style="zoom:60%"><br></center><p>Each root represents the connected components.</p><p>Find: Check if <em>p</em> and <em>q</em> have the same root.</p><p>Union: To merge components containing <em>p</em> and <em>q</em>, set the id of p’s root to the id of q’s root.</p><p>(path compression)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QuickUnionUF</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span>[] id;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">QuickUnionUF</span><span class="params">(<span class="keyword">int</span> N)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        id = <span class="keyword">new</span> <span class="keyword">int</span>[N];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)id[i] = i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">root</span><span class="params">(<span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">while</span> (i != id[i])i = id[i];</span><br><span class="line">        <span class="keyword">return</span> i;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">connected</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> root(p) == root(q);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> i = root(p);</span><br><span class="line">        <span class="keyword">int</span> j = root(q);</span><br><span class="line">        id[i] = j;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Worst case:</p><table><thead><tr><th>algorithm</th><th>initialize</th><th>union</th><th>find</th></tr></thead><tbody><tr><td>Quick-union</td><td>N</td><td>N</td><td>N</td></tr></tbody></table><p>Quick-union defect</p><ul><li>Trees can get tall</li><li>Find too expensive (could be N array accesses).</li></ul><h3 id="improvements"><a href="#improvements" class="headerlink" title="improvements"></a>improvements</h3><h4 id="Improvement-1-weighting"><a href="#Improvement-1-weighting" class="headerlink" title="Improvement 1: weighting"></a>Improvement 1: weighting</h4><hr><p>Weighted quick-union</p><ul><li>Modify quick-union to avoid tall trees.</li><li>Keep track of size of each tree (number of objects).</li><li>Balance by linking root of smaller tree to root of larger tree.</li></ul><p>Data structure： Same as quick-union, but maintain extra array sz[i] to count number of objects in the tree rooted at i.</p><p>Find: Identical to quick-union. <code>return root(p) == root(q)</code></p><p>Union: Modify quick-union to:</p><ul><li>Link root of samller tree to root of larger tree.</li><li>Update the sz[] array.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> i = root(p);</span><br><span class="line">itn j = root(q);</span><br><span class="line"><span class="keyword">if</span> (i == j) <span class="keyword">return</span>;</span><br><span class="line"><span class="keyword">if</span> (sz[i] &lt; sz[j])&#123; id[i] = j; sz[j] += sz[i]; &#125;</span><br><span class="line"><span class="keyword">else</span>&#123; id[j] = i; sz[i] += sz[j]; &#125;</span><br></pre></td></tr></table></figure><hr><p>Proposition: Depth of any node x is at most  $lg N$</p><table><thead><tr><th>algorithm</th><th>initialize</th><th>union</th><th>find</th></tr></thead><tbody><tr><td>Weighted QU</td><td>N</td><td>lg N</td><td>Lg N</td></tr></tbody></table><h4 id="Improvement-2-path-compression"><a href="#Improvement-2-path-compression" class="headerlink" title="Improvement 2: path compression"></a>Improvement 2: path compression</h4><p>Quick union with path compression: Just after computing the root of p, set the id of each examined node to point to that root.</p><p>Two-pass implementation: add second loop to root() to set the id[] of each examined node to the root.</p><p>Simpler one-pass variant: Make every other node in path point to its grandparent (thereby halving path length).</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// variant</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">root</span><span class="params">(<span class="keyword">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (i != id[i])</span><br><span class="line">    &#123;</span><br><span class="line">        id[i] = id[id[i]]</span><br><span class="line">            i = id[i]</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> i;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Weighted QU + path compression: worst-case time is N + M lg* N</p><p>(lg * is an iterate function, plz refer to slide for more information)</p><h3 id="applications"><a href="#applications" class="headerlink" title="applications"></a>applications</h3><ul><li>Percolation</li><li>Games (Go, Hex)</li><li>Dynamic connectivity</li><li>Least common ancestor</li><li>Equivalence of finite state automata</li><li>Hoshen-Kopelman algorithm in physics</li><li>Hinley-Milner polymorphic type inference</li><li>Kruskal’s minimum spanning tree algorithm</li><li>Compiling equivalence statements in Fortran</li><li>Morphological attribute openings and closings</li><li><p>Matlab’s <code>bwlabel()</code> function in image processing</p></li><li><p>Subroutine of many other algorithms</p></li></ul><h3 id="Programming-Assignment-1"><a href="#Programming-Assignment-1" class="headerlink" title="Programming Assignment 1"></a>Programming Assignment 1</h3><p>Problem:</p><p><a href="http://coursera.cs.princeton.edu/algs4/assignments/percolation.html" target="_blank" rel="noopener">Programming Assignment 1</a></p><p>Code is on my Github page:</p><p><a href="https://github.com/Aden-Q/Algorithms-Part-I/tree/master/Percolation" target="_blank" rel="noopener">Percolation</a></p><p>Missing the optional task of running time analysis, but I don’t want to do it again because this task is somewhat discouraging for some beginners I think.</p><h2 id="Analysis-of-Algorithms"><a href="#Analysis-of-Algorithms" class="headerlink" title="Analysis of Algorithms"></a>Analysis of Algorithms</h2><h3 id="observations"><a href="#observations" class="headerlink" title="observations"></a>observations</h3><p>Analytic Engine</p><p>Reasons to analyze algorithms</p><ul><li>Predict performance</li><li>Compare algorithms</li><li>Provide guarantees</li><li>Understand theoretical basis</li></ul><p>Primary practical reason: avoid performance bugs.</p><p>Discrete Fourier transform</p><p>N-body simulation</p><p>Scientific method</p><ul><li>Observe</li><li>Hypothesize</li><li>Predict</li><li>Verify</li><li>Validate</li></ul><p>Principles</p><ul><li>Experiments must be reproducible</li><li>Hypotheses must be falsifiable</li></ul><p>3-sum problem</p><p>Standard plot on running time</p><p>Log-log scale strategy</p><p>Doubling hypothesis: run program, doubling the size of the input.</p><p>System independent effects</p><ul><li>Algorithm</li><li>Input data</li></ul><p>System dependent effects</p><ul><li>Hardware: CPU, memory, cache</li><li>Software: compiler, interpreter, garbage collector</li><li>System: operating system, network, other apps</li></ul><h3 id="mathematical-models"><a href="#mathematical-models" class="headerlink" title="mathematical models"></a>mathematical models</h3><p>Total running time: sum of cost * frequency for all operations</p><p>General concepts</p><p>1-sum problem</p><p>2-sum problem</p><p>tilde notation</p><p>Estimating a discrete sum</p><h3 id="order-of-growth-classification"><a href="#order-of-growth-classification" class="headerlink" title="order-of-growth classification"></a>order-of-growth classification</h3><p>$1,  log N, N, N lgN, N^2, N^3, 2^N$</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0xgesix2pj30xn0m511g.jpg" style="zoom:60%"><br></center><p>Recurence</p><p>Easy concepts</p><h3 id="theory-of-algorithms"><a href="#theory-of-algorithms" class="headerlink" title="theory of algorithms"></a>theory of algorithms</h3><p>Best case: Lower bound on cost</p><ul><li>Determined by “easiest” input</li><li>Provides a goal for all inputs</li></ul><p>Worst case: Upper bound on cost</p><ul><li>Determined by “most difficult” input</li><li>Provides a way to predict performance</li></ul><p>Average case: Expected cost for random input</p><ul><li>Need a model for “random” input</li><li>Provides a way to predict performance</li></ul><p>Actual data</p><ul><li>Need to understand input to effectively process it</li><li>Approach 1: design for the worst case</li><li>Approach 2: randomize, depend on probailistic guarantee</li></ul><p>Goals</p><ul><li>Establish “difficulty” of a problem</li><li>Develop “optimal” algorithms</li></ul><p>Approach</p><ul><li>Suppress details in analyze “to within a constant factor”</li><li>Eliminate variability in input model by focusing on the worst case</li></ul><p>Algorithm design approach</p><hr><p>Start</p><ul><li>Develop an algorithm</li><li>Prove a lower bound</li></ul><p>Gap?</p><ul><li>Lower the upper bound (discover a new algorithm)</li><li>Raise the lower bound (more difficult)</li></ul><h3 id="memory"><a href="#memory" class="headerlink" title="memory"></a>memory</h3><p>Bit</p><p>Byte</p><p>Megabyte (MB)</p><p>Gigabyte (GB)</p><p>Old machine: We used to assume a 32-bit machine with 4 byte pointers</p><p>Modern machine: We now assume a 64-bit machine with 8 byte pointers</p><p>Typical memory usage for objects in Java</p><ul><li>Object overhead: 16 bytes</li><li>Reference: 8 bytes</li><li>Padding: Each object uses a multiple of 8 bytes</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0xhbzceq9j310l0ekwl9.jpg" style="zoom:60%"><br></center><h1 id="Week-2"><a href="#Week-2" class="headerlink" title="Week 2"></a>Week 2</h1><h2 id="Stacks-and-Queues"><a href="#Stacks-and-Queues" class="headerlink" title="Stacks and Queues"></a>Stacks and Queues</h2><p>Fundamental data types.</p><ul><li>Value: collection of objects</li><li>Operations: insert, remove, iterate, test if empty</li><li>Intent is clear when we insert</li><li>Which item do we remove</li></ul><hr><p>Modular programming:</p><p>Seperate interface and implementation</p><p>Benefits.</p><ul><li>Client can’t know details of implementation</li><li>Implementation can’t know details of client needs</li><li>Design: creates modular, reusable libraries</li><li>Performance: useoptimized implementation where it matters</li></ul><h3 id="stacks"><a href="#stacks" class="headerlink" title="stacks"></a>stacks</h3><p>LIFO, examine the item most recently added.</p><p>push, pop</p><p>API.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StackOfStrings</span></span>&#123;</span><br><span class="line">    StackOfStrings()<span class="comment">// create an empty stack</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(String item)</span><span class="comment">//insert a new string onto stack</span></span></span><br><span class="line"><span class="function">    String <span class="title">pop</span><span class="params">()</span><span class="comment">// remove and return the string most recently added</span></span></span><br><span class="line"><span class="function">    <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span><span class="comment">// is the stack empty?</span></span></span><br><span class="line"><span class="function">    <span class="keyword">int</span> <span class="title">size</span><span class="params">()</span><span class="comment">// number of strings on the stack</span></span></span><br><span class="line"><span class="function">&#125;</span></span><br></pre></td></tr></table></figure><p>Linked-list representation </p><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// inner class</span></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span> </span>&#123;</span><br><span class="line">    String item;</span><br><span class="line">    Node next;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Pop:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcgy1g1a6m19n84j30fk0h6wh8.jpg" style="zoom:60%"><br></center><p>Push:</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1a6o6h045j30jr0lhdl9.jpg" style="zoom:60%"><br></center><p>Array implementation</p><hr><ul><li>Use array s[] to store N items on stack.</li><li>push(): add new item at s[N].</li><li>pop(): remove item from s[N-1].</li></ul><p>Defect: Stack overflows when N exceeds capacity.</p><p>Full implementation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FixedCapacityStackOfStrings</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> String[] s;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> N = <span class="number">0</span>;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FixedCapacityStackOfStrings</span><span class="params">(<span class="keyword">int</span> capacity)</span></span></span><br><span class="line"><span class="function">    </span>&#123; s = <span class="keyword">new</span> String[capacity]; &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123; <span class="keyword">return</span> N == <span class="number">0</span>; &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(String item)</span></span></span><br><span class="line"><span class="function">    </span>&#123; s[N++] = item; &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">pop</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123; <span class="keyword">return</span> s[--N]; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Stack considerations:</p><p>Overflow and underflow</p><ul><li>Underflow: throw exception if pop from an empty stack.</li><li>Overflow: use resizing array for array implementation.</li></ul><p>Null items: We allow null items to be inserted.</p><p>Loitering: Holding a reference to an object when it is no longer needed.</p><p>To avoid the problem caused by loitering, we need to remove the pointer and free the memory:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// the version avoids "loitering" garbage collector can reclaim memory only</span></span><br><span class="line"><span class="comment">// if no outstanding references</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> String <span class="title">pop</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  String item = s[--N];</span><br><span class="line">  s[N] = <span class="keyword">null</span>;</span><br><span class="line">  <span class="keyword">return</span> item;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="resizing-arrays"><a href="#resizing-arrays" class="headerlink" title="resizing arrays"></a>resizing arrays</h3><p>Problem. Requiring client to provide capacity does not implement API</p><p>First try:</p><ul><li>push(): increase size of array s[] by 1.</li><li>pop(): decrease size of array s[] by 1.</li></ul><p>Too expensive</p><ul><li>Need to copy all item to a new array.</li><li>Inserting first N items takes time proportional to 1+2+…+N</li></ul><hr><p>Repeated doubling: If the array is full, create a new array of twice the size, and copy items</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ResizingArrayStackOfStrings</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123; s = <span class="keyword">new</span> String[<span class="number">1</span>]; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(String item)</span> </span>&#123;</span><br><span class="line"><span class="keyword">if</span> (N == s.length) resize(<span class="number">2</span> * s.length);</span><br><span class="line">  s[N++] = item;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">resize</span><span class="params">(<span class="keyword">int</span> capacity)</span> </span>&#123;</span><br><span class="line">      String[] copy = <span class="keyword">new</span> String[capacity];</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">        copy[i] = s[i];</span><br><span class="line">      s = copy;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Efficient solution for shrinking an array: halve size of array s[] when array is <strong>one-quarter</strong> full.</p><p>Invariant: Array is between 25% and 100% full.</p><p>Amortized analysis: Average running time per operation over a worst-case sequence of operations.</p><p>Proposition: Starting from an empty stack, any sequence of M push and pop operations takes time proportional to M.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1a85oktmyj30nb0bqwhr.jpg" style="zoom:60%"><br></center><p>Tradeoffs:</p><p>Linked-list implementation</p><ul><li>Every operation takes constant time in the worst case.</li><li>Uses extra time and space to deal with the links.</li></ul><p>Resizing-array implementation.</p><ul><li>Every operation takes constant amortized time.</li><li>Less wasted space.</li></ul><h3 id="queues"><a href="#queues" class="headerlink" title="queues"></a>queues</h3><p>FIFO, examine the item least recently added.</p><p>enqueue, dequeue</p><p>API:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">QueueOfStrings</span> </span>&#123;</span><br><span class="line">    QueueOfStrings();<span class="comment">// create an empty queue</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">enqueue</span><span class="params">(String item)</span></span>;<span class="comment">// insert a new string onto queue</span></span><br><span class="line">    <span class="function">String <span class="title">dequeue</span><span class="params">()</span></span>;<span class="comment">// remove and return the string least recently added</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>;<span class="comment">// is the queue empty?</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;<span class="comment">// number of strings on the queue</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Linked-list representation</p><hr><p>Maintain pointer to first and last nodes in a linked list;</p><p>Insert/remove from opposite ends</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1a8en2iayj30vt0iutex.jpg" style="zoom:60%"><br></center><p>Enqueue:</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1a8gkxa8ij30i90jptdz.jpg" style="zoom:60%"><br></center><p>Array implementation of a queue</p><hr><ul><li>Use array q[] to store items in queue.</li><li>enqueue(): add new item at q[tail].</li><li>dequeue(): remove item from q[head].</li><li>Update head and tail modulo the capacity</li><li>Add resizing array.</li></ul><h3 id="generics"><a href="#generics" class="headerlink" title="generics"></a>generics</h3><p>Java generics</p><ul><li>Avoid casting in client.</li><li>Discover type mismatch errors at compile-time instead of run-time.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Stack&lt;Apple&gt; s = <span class="keyword">new</span> Stack&lt;Apple&gt;();</span><br><span class="line">Apple a = <span class="keyword">new</span> Apple();</span><br><span class="line">Orange b = <span class="keyword">new</span> Orange();</span><br><span class="line">s.push(a);</span><br><span class="line">s.push(b);<span class="comment">// compile-time error</span></span><br><span class="line">a = s.pop();</span><br></pre></td></tr></table></figure><p>Guilding principles: Welcome compile-time errors; avoid run-time errors.</p><p>Full implementation (Linked-list version):</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Stack</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> Node first = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">Item item;</span><br><span class="line">  Node next;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123; <span class="keyword">return</span> first == <span class="keyword">null</span>; &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(Item item)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    Node oldfirst = first;</span><br><span class="line">    first = <span class="keyword">new</span> Node();</span><br><span class="line">    first.item = item;</span><br><span class="line">    first.next = oldfirst;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> Item <span class="title">pop</span><span class="params">()</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    Item item = first.item;</span><br><span class="line">    first = first.next;</span><br><span class="line">    <span class="keyword">return</span> item;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Wrapper type.</p><ul><li>Each primitive type has a wrapper object type.</li><li>Ex: Integer is wrapper type for int.</li></ul><p>Autoboxing: Automatic case between a primitive type and its wrapper.</p><p>Syntactic sugar: Behind-the-scenes casting.</p><p>Bottom line: Client code can use generic stack for any type of data.</p><h3 id="iterators"><a href="#iterators" class="headerlink" title="iterators"></a>iterators</h3><p>Design challenge: Support iteration over stack items by client, without revealing the internal representation of the stack.</p><p>Java solution: Make stack implement the <strong>Iterable</strong> interface.</p><p>An <strong>Iterable</strong> has a method that returns an <strong>Iterator</strong>.</p><p>Iterable interface:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Iterable</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function">Iterator&lt;Item&gt; <span class="title">iterator</span><span class="params">()</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>An <strong>Iterator</strong> has methods <strong>hasNext()</strong> and <strong>next()</strong>.</p><p>Iterator interface:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Iterator</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function">Item <span class="title">next</span><span class="params">()</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span></span>;<span class="comment">// optional</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>“foreach” statement:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (String s : stack)</span><br><span class="line">StdOut.println(s);</span><br></pre></td></tr></table></figure><p>Equivalent code:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Iterator&lt;String&gt; i = stack.iterator();</span><br><span class="line"><span class="keyword">while</span>(i.hasNext())</span><br><span class="line">&#123;</span><br><span class="line">    String s = i.next();</span><br><span class="line">    StdOut.println(s);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Example:</p><p>Stack iterator: linked-list implementation</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Iterator;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Stack</span>&lt;<span class="title">Item</span>&gt; <span class="keyword">implements</span> <span class="title">Iterable</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterator&lt;Item&gt; <span class="title">iterator</span><span class="params">()</span></span>&#123; <span class="keyword">return</span> <span class="keyword">new</span> ListIterator(); &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">ListIterator</span> <span class="keyword">implements</span> <span class="title">Iterator</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class">    </span>&#123;</span><br><span class="line">  <span class="keyword">private</span> Node current = first;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">hasNext</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> current != <span class="keyword">null</span>; &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">remove</span><span class="params">()</span></span>&#123; <span class="comment">/* not supported */</span> &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> Item <span class="title">next</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    Item item = current.item;</span><br><span class="line">    current = current.next;</span><br><span class="line">    <span class="keyword">return</span> item;</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Bag API</p><hr><p>Main application: Adding items to a collection and iterating (when order doesn’t matter).</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Bag</span>&lt;<span class="title">Item</span>&gt; <span class="keyword">implements</span> <span class="title">Iterable</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">Bag();<span class="comment">// create an empty bag</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(Item x)</span></span>;<span class="comment">// insert a new item onto bag</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;<span class="comment">// number of items in bag</span></span><br><span class="line"><span class="function">Iterator&lt;Item&gt; <span class="title">iterator</span><span class="params">()</span></span>;<span class="comment">// iterator for all items in bag</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="applications-1"><a href="#applications-1" class="headerlink" title="applications"></a>applications</h3><p>Why not simply use Java collections library?</p><p><strong>“Performance”</strong></p><p>Lesson: Don’t use a library until you understand its API or you can tolerate the defect of the efficiency.</p><p>Stack applications:</p><ul><li>Parsing in a compiler.</li><li>Java virtual machine.</li><li>Undo in a word processor.</li><li>Back button in a Web browser.</li><li>PostScript language for printers</li><li>Implementing function calls in a compiler.</li></ul><p>Dijkstra’s two-stack algorithm:</p><ul><li>Value: push onto the value stack.</li><li>Operator: push onto the operator stack.</li><li>Left parenthesis: ignore.</li><li>Right parenthesis: pop operator and two values; push the result of applying that operator to those values onto the operand stack.</li></ul><h3 id="Programming-Assignment-2"><a href="#Programming-Assignment-2" class="headerlink" title="Programming Assignment 2"></a>Programming Assignment 2</h3><p>Problem:</p><p><a href="http://coursera.cs.princeton.edu/algs4/assignments/queues.html" target="_blank" rel="noopener">Programming Assignment 2</a></p><p>Code is on my Github page:</p><p><a href="https://github.com/Aden-Q/Algorithms-Part-I/tree/master/Deques-and-Randomized-Queues" target="_blank" rel="noopener">Deques and Randomized Queues</a></p><p>Missing bonus memory challenge task. (I think it’s easy)</p><h2 id="Elementary-Sorts"><a href="#Elementary-Sorts" class="headerlink" title="Elementary Sorts"></a>Elementary Sorts</h2><h3 id="rules-of-the-game"><a href="#rules-of-the-game" class="headerlink" title="rules of the game"></a>rules of the game</h3><p>Goal: Sort any type of data.</p><p>Q. How can sort() know how to compare data of type Double, String, and java.io.File without any information about the type of an item’s key?</p><p>Callback = reference to executable code.</p><ul><li>Client passes array of objects to sort() function.</li><li>The sort() function calls back object’s compareTo() method as needed.</li></ul><p>Comparable interface (built in to Java)</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparable</span>&lt;<span class="title">Item</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Item that)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Object implementation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">File</span> <span class="keyword">implements</span> <span class="title">Compareble</span>&lt;<span class="title">File</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">...</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(File b)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> +<span class="number">1</span>;</span><br><span class="line">  ...</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Sort implementation</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">  <span class="keyword">int</span> N = a.length;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> j = i; j &gt; <span class="number">0</span>; j--)</span><br><span class="line">          <span class="keyword">if</span> (a[j].compareTo(a[j-<span class="number">1</span>]) &lt; <span class="number">0</span>)</span><br><span class="line">              exch(a, j, j-<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Total order</p><hr><p>A total order is a binary relation ≤ that satisfies</p><ul><li>Antisymmetry: if v ≤ w and w ≤ v, then v = w.</li><li>Transitivity: if v ≤ w and w ≤ x, then v ≤ x.</li><li>Totality: either v ≤ w or w ≤ v or both.</li></ul><p>Comparable API</p><hr><p>implement compareTo() so that v.compareTo(w)</p><ul><li>Is a total order.</li><li>Returns a negative integer, zero, or positive integer if v is less than, equal to, or greater than w, repectively.</li><li>Throws an exception if incompatible types (or either is null).</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Date</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Date</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> month, day, year;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Date</span><span class="params">(<span class="keyword">int</span> m, <span class="keyword">int</span> d, <span class="keyword">int</span> y)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">  month = m;</span><br><span class="line">  day = dl</span><br><span class="line">  year = yl</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compareTo</span><span class="params">(Date that)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.year &lt; that.year)<span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.year &gt; that.year)<span class="keyword">return</span> +<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.month &lt; that.month)<span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">  <span class="keyword">if</span> (<span class="keyword">this</span>.month &gt; that.month)<span class="keyword">return</span> +<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.day &lt; that.day)<span class="keyword">return</span> -<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">this</span>.day &gt; that.day)<span class="keyword">return</span> +<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Two useful sorting abstractions</p><hr><p>Less: Is item v less than w?</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(Comparable v, Comparable w)</span></span></span><br><span class="line"><span class="function"></span>&#123;<span class="keyword">return</span> v.compareTo(w) &lt; <span class="number">0</span>; &#125;</span><br></pre></td></tr></table></figure><p>Exchange: Swap item in array a[] at index i with the one at index j.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(Comparable[] a, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Comparable swap = a[i];</span><br><span class="line">    a[i] = a[j];</span><br><span class="line">    a[j] = swap;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="selection-sort"><a href="#selection-sort" class="headerlink" title="selection sort"></a>selection sort</h3><p>In iteration i, find index min of smallest remaining entry.</p><p>Swap a[i] and a[min].</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1b1eimnf3j30rv08bjux.jpg" style="zoom:60%"><br></center> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Selection</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> N = a.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> min = i;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = i+<span class="number">1</span>; i &lt; N; j++)</span><br><span class="line">            <span class="keyword">if</span> (less(a[j], a[min]))</span><br><span class="line">          min = j;</span><br><span class="line">      exch(a, i, min)</span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(Comparable v, Comparable w)</span></span></span><br><span class="line"><span class="function">  </span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(Comparable[] a, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function">  </span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="insertion-sort"><a href="#insertion-sort" class="headerlink" title="insertion sort"></a>insertion sort</h3><p>In iteration i, swap a[i] with each larger entry to its left.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1b1mumo6sj30sj084ad5.jpg" style="zoom:60%"><br></center><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Insertion</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">      <span class="keyword">int</span> N = a.length;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">          <span class="keyword">for</span> (<span class="keyword">int</span> j = i; j &gt; <span class="number">0</span>; j--)</span><br><span class="line">              <span class="keyword">if</span> (less(a[j], a[j-<span class="number">1</span>]))</span><br><span class="line">              exch(a, j, j-<span class="number">1</span>);</span><br><span class="line">      <span class="keyword">else</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(Comparable v, Comparable w)</span></span></span><br><span class="line"><span class="function">  </span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(Comparable[] a, <span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function">  </span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Def: An inversion is a pair of keys that are out of order.</p><p>Def: An array is partially sorted if the number of inversions is ≤ cN.</p><p>Proposition: For partially-sorted arrays, insertion sort runs in linear time.</p><p>Pf: Number of exchanges equals the number of inversions.</p><h3 id="shellsort"><a href="#shellsort" class="headerlink" title="shellsort"></a>shellsort</h3><p>Idea: Move entries more than one position at a time by h-sorting the array.</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1b1zwsg9uj30ma065abq.jpg" style="zoom:60%"><br></center><p>How to h-sort an array? Insertion sort, with stride length h.</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1b27tqt6mj30st0mj10f.jpg" style="zoom:60%"><br></center><p>Useful in practice:</p><ul><li>Fast unless array size is huge.</li><li>Tiny, fixed footprint for code (used in embedded systems).</li><li>Hardware sort prototype.</li></ul><h3 id="shuffling"><a href="#shuffling" class="headerlink" title="shuffling"></a>shuffling</h3><p>Shuffle sort</p><ul><li>Generate a random real number for each array entry.</li><li>Sort the array.</li></ul><p>Proposition: Shuffle sort produces a uniformly random permutation of the input array, provided no duplicate values.</p><p>Goal: Rearrange array so that result is a uniformly random permutation in linear time.</p><p>Knuth shuffle</p><ul><li>In iteration i, pick integer r between 0 and i uniformly at random.</li><li>Swap a[i] and a[r].</li></ul><p>Proposition: Knuth shuffling algorithm produces a uniformly random permutation of the input array in linear time.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StdRandom</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">  ...</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">shuffle</span><span class="params">(Object[] a)</span></span></span><br><span class="line"><span class="function">  </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> N = a.length;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> r = StdRandom.uniform(i + <span class="number">1</span>);<span class="comment">// between 0 and i</span></span><br><span class="line">        exch(a, i, r);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>online poker: easily cracked</p><p>Bottom line: Shuffling a deck of cards is hard!</p><h3 id="convex-hull"><a href="#convex-hull" class="headerlink" title="convex hull"></a>convex hull</h3><p>The convex hull of a set of N points is the smallest perimeter fence enclosing the points.</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1b2pp0x4hj30ag098js9.jpg" style="zoom:60%"><br></center><p>Equivalent definitions:</p><ul><li>Smallest convex set containing all the points.</li><li>Smallest area convex polygon enclosing the points.</li><li>Convex polygon enclosing the points, whose vertices are points in set.</li></ul><p>Convex hull output: Sequence of vertices in counterclockwise order.</p><p>Convex hull application: motion planning</p><p>Robot motion planning: Find shortest path in the plane from s to t that avoids a polygonal obstacle.</p><p>Fact: Shortest path is either straight line from s to t or it is one of two polygonal chains of convex hull.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1b2v8xwxgj30jm09bgo7.jpg" style="zoom:60%"><br></center><p>Farthest pair problem: Given N points in the plane, find a pair of points with the largest Euclidean distance between them.</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1b2x5yyapj30au09tgmu.jpg" style="zoom:60%"><br></center><p>Graham scan:</p><ul><li>Choose point p with smallest y-coordinate.</li><li>Sort points by polar angle with p.</li><li>Consider points in order; discard unless it create a ccw turn.</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1b33pust5j30j20fdaci.jpg" style="zoom:60%"><br></center><p>Implementation:</p><p>Define a total order, comparing by y-coordinate.</p><p>Define a total order for each point p. (polar angle)</p><p>Computational geometry to determine counterclockwise for triple.</p><p>Mergesort to sort efficiently.</p><p>Implementing ccw:</p><p>CCW: Given three points a, b, and c, is a-&gt;b-&gt;c a counterclockwise turn? (is c to the left of the ray a-&gt;b)</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1b3a2cjzjj30b708e751.jpg" style="zoom:60%"><br></center><p>A good strategy involves computing areas (high school compitation knowledge)</p><p>To show respectations:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1b3eepjljj30qi06g42n.jpg" style="zoom:60%"><br></center><h1 id="Week-3"><a href="#Week-3" class="headerlink" title="Week 3"></a>Week 3</h1><h2 id="Mergesort"><a href="#Mergesort" class="headerlink" title="Mergesort"></a>Mergesort</h2><h3 id="mergesort"><a href="#mergesort" class="headerlink" title="mergesort"></a>mergesort</h3><p>Basic plan:</p><ul><li>Divide array into two halves.</li><li>Recursively sort each half.</li><li>Merge two halves.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(Comparable[] a, Comparable[] aux, <span class="keyword">int</span> lo, <span class="keyword">int</span> mid, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isSorted</span><span class="params">(a, lo, mid)</span></span>;<span class="comment">// precondition: a[lo...mid] sorted</span></span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isSorted</span><span class="params">(a, mid+<span class="number">1</span>, hi)</span></span>;<span class="comment">// precondition: a[mid+1...hi] sorted</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = lo; k &lt;= hi; k++)</span><br><span class="line">        aux[k] = a[k];</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> i = lo, j = mid+<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> k = lo; k &lt;= hi; k++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (i &gt; mid)a[k] = aux[j++];</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (j &gt; hi)a[k] = aux[i++];</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (less(aux[j], aux[i]))a[k] = aux[j++];</span><br><span class="line">        <span class="keyword">else</span>a[k] = aux[i++];</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isSorted</span><span class="params">(a, lo, hi)</span></span>;<span class="comment">// poscondition: a[lo...hi] sorted</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Assertion: Statement to test assumptions about your program.</p><ul><li>Helps detect logic bugs.</li><li>Documents code.</li></ul><p>Java assert statement: Throws exception unless boolean condition is true.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">assert</span> <span class="title">isSorted</span><span class="params">(a, lo, hi)</span></span>;</span><br></pre></td></tr></table></figure><p>Can enable or disable at runtime:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">java -ea MyProgram<span class="comment">// enable assertions</span></span><br><span class="line">java -da MyProgram<span class="comment">// disable assertions (default)</span></span><br></pre></td></tr></table></figure><p>Best practices: Use assertions to check internal invariants; assume assertions will be disabled in production code.</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1c6cuj9zyj30s009f77o.jpg" style="zoom:60%"><br></center><p>Recurrence relation</p><p>Proposition: Mergesort uses extra space proportional to N.</p><p>Pf: The array aux[] needs to be of size N for the last merge.</p><p> Some detailed improvements can be done. </p><h3 id="bottom-up-mergesort"><a href="#bottom-up-mergesort" class="headerlink" title="bottom-up mergesort"></a>bottom-up mergesort</h3><p>Basic plan:</p><ul><li>Pass through array, merging subarrays of size 1.</li><li>Repeat for subarrays of size 2, 4, 8, 16, ……</li></ul><p>Bottom line: No recursion needed!</p><p>Several passes.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1c6t3ncm3j30pu0ehgsz.jpg" style="zoom:60%"><br></center><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MergeBU</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Comparable[] aux;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">merge</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> mid, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function">    </span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> N = a.length;</span><br><span class="line">        aux = <span class="keyword">new</span> Comparable[N];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> sz = <span class="number">1</span>; sz &lt; N; sz = sz+sz)</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> lo = <span class="number">0</span>; lo &lt; M - sz; lo += sz+sz)</span><br><span class="line">                merge(a, lo, lo+sz-<span class="number">1</span>, Math.min(lo+sz+sz-<span class="number">1</span>, N-<span class="number">1</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>log N passes</p><h3 id="sorting-complexity"><a href="#sorting-complexity" class="headerlink" title="sorting complexity"></a>sorting complexity</h3><p>Model of computation: Allowable operations.</p><p>Cost model: Operation count(s).</p><p>Upper bound: Cost guarantee provided by some algorithm for X.</p><p>Lower bound: Proven limit on cost guarantee of all algorithms for X.</p><p>Optimal algorithm: Algorithm with best possible cost guarantee for X.</p><p>Decision tree: please refer to CLRS</p><p>Mergesort is optimal with respect to compares.</p><p>Mergesort is not optimal with respect to space usage.</p><p>Lower bound N log N may not hold if the algorithm has information about:</p><ul><li>The initial order of the input.</li><li>The distribution of key values.</li><li>The representation of the keys.</li></ul><p>Eg:</p><p>Partially-ordered arrays.</p><p>Duplicate keys.</p><p>Digital properties of keys.</p><h3 id="comparators"><a href="#comparators" class="headerlink" title="comparators"></a>comparators</h3><p>Comparable interface: sort using a type’s natural order.</p><p>Comparator interface: sort using an alternate order.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Comparator</span>&lt;<span class="title">Key</span>&gt;</span></span><br><span class="line"><span class="class"><span class="title">int</span> <span class="title">compare</span>(<span class="title">Key</span> <span class="title">v</span>, <span class="title">Key</span> <span class="title">w</span>)// <span class="title">compare</span> <span class="title">keys</span> <span class="title">v</span> <span class="title">and</span> <span class="title">w</span></span></span><br></pre></td></tr></table></figure><p>Required property: Must be a total order.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Student</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Comparator&lt;Student&gt; BY_NAME = <span class="keyword">new</span> ByName();</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Comparator&lt;Student&gt; BY_SECTION = <span class="keyword">new</span> BySection();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> section;</span><br><span class="line">    ...</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ByName</span> <span class="keyword">implements</span> <span class="title">Comparator</span>&lt;<span class="title">Student</span>&gt;</span></span><br><span class="line"><span class="class">    </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Student v, Student w)</span></span></span><br><span class="line"><span class="function">        </span>&#123; <span class="keyword">return</span> v.name.compareTo(w.name); &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">BySection</span> <span class="keyword">implements</span> <span class="title">Comparator</span>&lt;<span class="title">Student</span>&gt;</span></span><br><span class="line"><span class="class">    </span>&#123;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">compare</span><span class="params">(Student v, Student w)</span></span></span><br><span class="line"><span class="function">        </span>&#123; <span class="keyword">return</span> v.section - w.section; &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="stability"><a href="#stability" class="headerlink" title="stability"></a>stability</h3><p>Selection/Shell sort are not stable.</p><p>Insertion/Merge sort are stable.</p><p>Long-distance exchange may lead to problems.</p><p>Mergesort is stable because merge is stable.</p><h3 id="Programming-Assignment-3"><a href="#Programming-Assignment-3" class="headerlink" title="Programming Assignment 3"></a>Programming Assignment 3</h3><p>Problem:</p><p><a href="http://coursera.cs.princeton.edu/algs4/assignments/collinear.html" target="_blank" rel="noopener">Programming Assignment 3</a></p><p>Code is on my Github page:</p><p><a href="https://github.com/Aden-Q/Algorithms-Part-I/tree/master/Collinear" target="_blank" rel="noopener">Collinear</a></p><p>Failed some timing tests because HashMap is not allowed.</p><p>Got 92 out of 100.</p><h2 id="Quicksort"><a href="#Quicksort" class="headerlink" title="Quicksort"></a>Quicksort</h2><h3 id="quicksort"><a href="#quicksort" class="headerlink" title="quicksort"></a>quicksort</h3><p>Basic plan:</p><ul><li>Shuffle the array.</li><li>Partition.</li><li>Sort each piece recursively.</li></ul><p>Phase 1: Repeat until i and j pointers cross.</p><ul><li>Scan i from left to right so long as (a[i] &lt; a[lo])</li><li>Scan j from right to left so long as (a[j] &gt; a[lo])</li><li>Exchange a[i] with a[j]</li></ul><p>Phase 2: When pointers cross.</p><ul><li>Exchange a[lo] with a[j]</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i = lo, j = hi+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">while</span> (<span class="keyword">true</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">while</span> (less(a[++i], a[lo]))</span><br><span class="line">            <span class="keyword">if</span> (i == hi) <span class="keyword">break</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">while</span> (less(a[lo], a[--j]))</span><br><span class="line">            <span class="keyword">if</span> (j == lo) <span class="keyword">break</span>;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> (i &gt;= j) <span class="keyword">break</span>;</span><br><span class="line">        exch(a, i, j);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    exch(a, lo, j);</span><br><span class="line">    <span class="keyword">return</span> j;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Quick</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function">    </span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        StdRandom.shuffle(a);</span><br><span class="line">        sort(a, <span class="number">0</span>, a.length - <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (hi &lt;= lo)<span class="keyword">return</span>;</span><br><span class="line">        <span class="keyword">int</span> j = partition(a, lo, hi);</span><br><span class="line">        sort(a, lo, j-<span class="number">1</span>);</span><br><span class="line">        sort(a, j+<span class="number">1</span>, hi);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Details:</p><ul><li>Partitioning in-place: Can be done with extra memoy.</li><li>Terminating the loop: Testing whether the pointers cross is a bit trickier than it might seem.</li><li>Staying in bounds: The (j == lo) test is redundant because of the key, but (i == hi) test is not.</li><li><p>Preserving randomness: Shuffling is needed for performance guarantee.</p></li><li><p>Equal keys: When duplicates are present, it is bettuer to stop on keys equal to the partitioning item’s key.</p></li></ul><p>Best case: N log N</p><p>Worst case: $N^2$</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1d8shuq7hj30wn0ludp8.jpg" style="zoom:60%"><br></center><p>Approximate sum by an integral.</p><p>Proposition: Quicksort is an in-place sorting algorithm, not stable.</p><p>Pf:</p><ul><li>Partitioning: constant extra space.</li><li>Depth of recursion: logarithmic extra space (with high probability).</li></ul><p>Insertion sort small subarrays:</p><ul><li>Even quicksort has too much overhead for tiny subarrays.</li><li>Cutoff to insertion sort for around 10 items.</li><li>Note: could delay insertion sort until one pass at end.</li></ul><p>Practical improvements:</p><p>Insertion sort small subarrays:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (hi &lt;= lo + CUTOFF - <span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        Insertion.sort(a, lo, hi);</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">int</span> j = partition(a, lo, hi);</span><br><span class="line">    sort(a, lo, j-<span class="number">1</span>);</span><br><span class="line">    sort(a, j+<span class="number">1</span>, hi);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Median of sample:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">sort</span><span class="params">(Comparable[] a, <span class="keyword">int</span> lo, <span class="keyword">int</span> hi)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (hi &lt;= lo)<span class="keyword">return</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> m = medianOf3(a, lo, lo + (hi -lo)/<span class="number">2</span>, hi);</span><br><span class="line">    swap(a, lo, m);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">int</span> j = partition(a, lo, hi);</span><br><span class="line">    sort(a, lo, j-<span class="number">1</span>);</span><br><span class="line">    sort(a, j+<span class="number">1</span>, hi);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="selection"><a href="#selection" class="headerlink" title="selection"></a>selection</h3><p>Goal: Given an array of N items, find the kth largest.</p><p>Applications:</p><ul><li>Order statistics.</li><li>Find the “top k.”</li></ul><p>Quick-select:</p><hr><p>Partition array so that:</p><ul><li>Entry a[j] is in place.</li><li>No larger entry to the left of j.</li><li>No smaller entry to the right of j.</li></ul><p>Repeat in one subarray, depending on j; finished when j equals k.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Comparable <span class="title">select</span><span class="params">(Comparable[] a, <span class="keyword">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    StdRandom.shuffle(a);</span><br><span class="line">    <span class="keyword">int</span> lo = <span class="number">0</span>; hi = a.length - <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (hi &gt; lo)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> j = partition(a, lo, hi);</span><br><span class="line">        <span class="keyword">if</span> (j &lt; k) lo = j + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (j &gt; k)hi = j - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span><span class="keyword">return</span> a[k];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> a[k];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Proposition: Quick-select takes linear time on average.</p><p>Remard: Quadratic time in the worst case while random shuffle provides a probabilistic guarantee.</p><h3 id="duplicate-keys"><a href="#duplicate-keys" class="headerlink" title="duplicate keys"></a>duplicate keys</h3><p>Quicksort with duplicate keys: Algorithm goes quadratic unless partitioning stops on equal keys!</p><p>3-way partitioning:</p><p>Goal: Partition array into 3 parts so that:</p><ul><li>Entries between lt and gt equal to partition item v.</li><li>No larger entries to left of lt.</li><li>No smaller entries to right of gt.</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1d9kvv8aqj30ee06lt9f.jpg" style="zoom:60%"><br></center><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1d9nf4f8qj30f505m3z1.jpg" style="zoom:60%"><br></center><p>Bottom line: Randomized quicksort with 3-way partitioning reduces running time from linearithmic to linear in broad class of applications.</p><h3 id="system-sorts"><a href="#system-sorts" class="headerlink" title="system sorts"></a>system sorts</h3><p>Java system sorts:</p><p>Arrays.sort()</p><ul><li>Has different method for each primitive type.</li><li>Has a method for data types that implement Comparable.</li><li>Has a method that uses a Comparator.</li><li>Uses tuned quicksort for primitive types; tuned mergesort for objects.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.Arrays;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StringSort</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        String[] a = StdIn.readStrings();</span><br><span class="line">        Arrays.sort(a);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">            StdOut.println(a[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Choices:</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1da8hsgkuj30sc0h7jza.jpg" style="zoom:60%"><br></center><h1 id="Week-4"><a href="#Week-4" class="headerlink" title="Week 4"></a>Week 4</h1><h2 id="Priority-Queues"><a href="#Priority-Queues" class="headerlink" title="Priority Queues"></a>Priority Queues</h2><h3 id="API-and-elementary-implementations"><a href="#API-and-elementary-implementations" class="headerlink" title="API and elementary implementations"></a>API and elementary implementations</h3><p>Collections: Insert and delete items.</p><ul><li>Stack: Remove the item most recently added.</li><li>Queue: Remove the item least recently added.</li><li>Randomized queue: Remove a random item.</li><li>Priority queue: Remove the largest (or smallest) item.</li></ul><p>Priority queue API</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxPQ</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">MaxPQ();<span class="comment">// create an empty priority queue</span></span><br><span class="line">MaxPQ(Key[] a);<span class="comment">// create a priority with given keys</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insert</span><span class="params">(Key v)</span></span>;<span class="comment">// insert a key into the priority queue</span></span><br><span class="line"><span class="function">Key <span class="title">delMax</span><span class="params">()</span></span>;<span class="comment">// return and remove the largest key</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>;<span class="comment">// is the priority queue empty?</span></span><br><span class="line"><span class="function">Key <span class="title">max</span><span class="params">()</span></span>;<span class="comment">// return the largest key</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;<span class="comment">// number of entries in the priority queue</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Applications:</p><ul><li>Event-driven simulation</li><li>Numerical computation</li><li>Data compression</li><li>Graph searching</li><li>Number theory</li><li>Artificial intelligence</li><li>Statistics</li><li>Operating systems</li><li>Discrete optimization</li><li>Spam filtering</li></ul><p>Generalizes: stack, queue, randomized queue.</p><p>Unordered array implementation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UnorderedMaxPQ</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> Key[] pq;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> N;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">UnorderedMaxPQ</span><span class="params">(<span class="keyword">int</span> capacity)</span></span></span><br><span class="line"><span class="function"></span>&#123; pq = (Key[]) <span class="keyword">new</span> Comparable[capacity]; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> N == <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(Key x)</span></span></span><br><span class="line"><span class="function"></span>&#123; pq[N++] = x; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Key <span class="title">delMax</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> max = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; N; i++)</span><br><span class="line">    <span class="keyword">if</span> (less(max, i)) max = i;</span><br><span class="line">    exch(max, N-<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> pq[--N];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th>implementation</th><th>insert</th><th>delmax</th><th>max</th></tr></thead><tbody><tr><td>unordered array</td><td>1</td><td>N</td><td>N</td></tr><tr><td>ordered array</td><td>N</td><td>1</td><td>1</td></tr><tr><td>Goal</td><td>log N</td><td>log N</td><td>log N</td></tr></tbody></table><h3 id="binary-heaps"><a href="#binary-heaps" class="headerlink" title="binary heaps"></a>binary heaps</h3><p>Based on complete binary tree (Perfectly balanced, except for bottom level).</p><p>Binary heap: Array representation of a heap-ordered complete binary tree.</p><p>Heap-ordered binary tree:</p><ul><li>Keys in nodes.</li><li><p>Parent’s key no smaller than children’s key.</p><p>Array representation:</p></li><li><p>Indices start at 1. (Start at 0 causes a little trouble)</p></li><li>Take nodes in level order.</li><li>No explicit liniks needed!</li></ul><p>Proposition: Largest key is a[1], which is root of binary tree.</p><p>Proposition: Can use array indices to move through tree.</p><ul><li>Parent of node at k is at k/2.</li><li>Children of node at k are at 2k and 2k+1.</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1dnzpm3q4j30dw0dagom.jpg" style="zoom:60%"><br></center><p>Swim:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">swim</span><span class="params">(<span class="keyword">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (k &gt; <span class="number">1</span> &amp;&amp; less(k/<span class="number">2</span>, k))</span><br><span class="line">    &#123;</span><br><span class="line">        exch(k, k/<span class="number">2</span>);</span><br><span class="line">        k = k/<span class="number">2</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Insertion:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(Key x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    pq[++N] = x;</span><br><span class="line">    swim(N);<span class="comment">// swim means swim up</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1do64ok5pj30cb0h90wm.jpg" style="zoom:60%"><br></center><p>Sink:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">sink</span><span class="params">(<span class="keyword">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="number">2</span>*k &lt;= N)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> j = <span class="number">2</span>*k;</span><br><span class="line">        <span class="keyword">if</span> (j &lt; N &amp;&amp; less(j, j+<span class="number">1</span>)) j++;</span><br><span class="line">        <span class="keyword">if</span> (!less(k, j)) <span class="keyword">break</span>;</span><br><span class="line">        exch(k, j);</span><br><span class="line">        k = j;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Delete max:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Key <span class="title">delMax</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Key max = pq[<span class="number">1</span>];</span><br><span class="line">    exch(<span class="number">1</span>, N--);</span><br><span class="line">    sink(<span class="number">1</span>);</span><br><span class="line">    pq[N+<span class="number">1</span>] = <span class="keyword">null</span>;<span class="comment">// prevent loitering</span></span><br><span class="line">    <span class="keyword">return</span> max;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1dog1bzv3j30dv0hd0xg.jpg" style="zoom:60%"><br></center><p>Complete Java implementation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MaxPQ</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> Key[] pq;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> N;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">MaxPQ</span><span class="params">(<span class="keyword">int</span> capacity)</span></span></span><br><span class="line"><span class="function"></span>&#123; pq = (Key[]) <span class="keyword">new</span> Comparable[capacity+<span class="number">1</span>]; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> N == <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">insert</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delMax</span><span class="params">()</span></span>;</span><br><span class="line">&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">swim</span><span class="params">(<span class="keyword">int</span> k)</span></span>;</span><br><span class="line">&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="title">sink</span><span class="params">(<span class="keyword">int</span> k)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* as before */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">less</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> pq[i].compareTo(pq[j]) &lt; <span class="number">0</span>; &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">exch</span><span class="params">(<span class="keyword">int</span> i, <span class="keyword">int</span> j)</span></span></span><br><span class="line"><span class="function"></span>&#123; Key t = pq[i]; pq[i] = pq[j]; pq[j] = t; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Improvements: Fibonacci heap</p><p>Some considerations</p><hr><p>Immutability of keys:</p><ul><li>Assumption: client does not change keys while they’re on the PQ.</li><li>Best practice: use immutable keys.</li></ul><p>Underflow and overflow:</p><ul><li>Underflow: throw exception if deleting from empty PQ.</li><li>Overflow: add no-arg constructor and use resizing array.</li></ul><p>Minimum-oriented priority queue:</p><ul><li>Replace less() with greater().</li><li>Implement greater().</li></ul><p>Other operations:</p><ul><li>Remove an arbitrary item.</li><li>Change the priority of an item.</li></ul><p>Immutability:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Vector</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> N;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">double</span>[] data;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Vector</span><span class="params">(<span class="keyword">double</span>[] data)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.N = data.length;</span><br><span class="line">        <span class="keyword">this</span>.data = <span class="keyword">new</span> <span class="keyword">double</span>[N];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">            <span class="keyword">this</span>.data[i] = data[i];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Immutable: String, Integer, Double, Color, Vector, Transaction, Point2D.</p><p>Mutable: StringBuilder, Stack, Counter, Java array.</p><p>Advantages of immutability:</p><ul><li>Simplifies debugging.</li><li>Safer in presence of hostile code.</li><li>Simplifiers concurrent programming.</li><li>Safe to use as key in priority queue or symbol table.</li></ul><p>Disadvantage: Must create new object for each data type value.</p><h3 id="heapsort"><a href="#heapsort" class="headerlink" title="heapsort"></a>heapsort</h3><p>Basic plan for in-place sort:</p><ul><li>Create max-heap with all N keys.</li><li>Repeatedly remove the maximum key.</li></ul><p>Heap construction: Sink, bottom-up.</p><p>Build:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> k = N/<span class="number">2</span>; k &gt;= <span class="number">1</span>; k--)</span><br><span class="line">    sink(a, k, N);</span><br></pre></td></tr></table></figure><p>Sort:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (N &gt; <span class="number">1</span>)</span><br><span class="line">&#123;</span><br><span class="line">    exch(a, <span class="number">1</span>, N--);</span><br><span class="line">    sink(a, <span class="number">1</span>, N);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Bottom line: </p><ul><li>Inner loop longer than quicksort’s</li><li>Makes poor use of cache memory</li><li>Not stable</li></ul><h3 id="event-driven-simulation"><a href="#event-driven-simulation" class="headerlink" title="event-driven simulation"></a>event-driven simulation</h3><p>Molecular dynamics simulation of hard discs</p><hr><p>Goal. Simulate the motion of N moving particles that behave according to the laws of elastic collision.</p><p>Time-driven simulation: Judge collision with dt</p><p>Event-driven simulation: Maintain PQ of collision events, prioritized by time.</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1entk93myj30pa067tbf.jpg" style="zoom:60%"><br></center><p>Collision prediction: Given position, velocity, and radius of a particle, when will it collide next with a wall or another particle?</p><p>Collision resolution: If collision occurs, update colliding particle(s) according to laws of elastic collisions.</p><p>Difficult simulation, involving a lot of physics and math, or at least not easy.</p><h3 id="Programming-Assignment-4"><a href="#Programming-Assignment-4" class="headerlink" title="Programming Assignment 4"></a>Programming Assignment 4</h3><p>Problem:</p><p><a href="http://coursera.cs.princeton.edu/algs4/assignments/8puzzle.html" target="_blank" rel="noopener">Programming Assignment 4</a></p><p>Code is on my Github page:</p><p><a href="https://github.com/Aden-Q/Algorithms-Part-I/tree/master/8-Puzzle" target="_blank" rel="noopener">8 Puzzle</a></p><p>Failed some timing tests.</p><p>Got 96 out of 100.</p><h2 id="Symbol-Tables"><a href="#Symbol-Tables" class="headerlink" title="Symbol Tables"></a>Symbol Tables</h2><h3 id="API"><a href="#API" class="headerlink" title="API"></a>API</h3><p>Key-value pair abstraction:</p><ul><li>Insert a value with specified key.</li><li>Given a key, search for the corresponding value.</li></ul><p>Associative array abstraction: Associate one value with each key.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ST</span>&lt;<span class="title">Key</span>, <span class="title">Value</span>&gt; </span>&#123;</span><br><span class="line">    ST();<span class="comment">// create a symbol table</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(Key key, Value val)</span></span>;<span class="comment">// put key-value pair into the table (remove key from table if value is null)</span></span><br><span class="line">    <span class="function">Value <span class="title">get</span><span class="params">(Key key)</span></span>;<span class="comment">// value paired with key (null if key is absent)</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">delete</span><span class="params">(Key key)</span></span>;<span class="comment">// remove key (and its value) from table</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Key key)</span></span>;<span class="comment">// is there a value paired with key?</span></span><br><span class="line">    <span class="function"><span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>;<span class="comment">// is the table empty?</span></span><br><span class="line">    <span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;<span class="comment">// number of key-value pairs in the table</span></span><br><span class="line">    <span class="function">Iterable&lt;Key&gt; <span class="title">keys</span><span class="params">()</span></span>;<span class="comment">// all the keys in the table</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Convetions:</p><ul><li>Value are not null.</li><li>Method get() returns null if key not present.</li><li>Method put() overwrites old value with new value.</li></ul><p>Contains:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> get(key) != <span class="keyword">null</span>; &#125;</span><br></pre></td></tr></table></figure><p>Lazy delete:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; put(key, <span class="keyword">null</span>); &#125;</span><br></pre></td></tr></table></figure><p>Keys and values</p><hr><p>Value type: Any generic type.</p><p>Key type: several natural assumptions:</p><ul><li>Assume keys are Comparable, use compareTo().</li><li>Assume keys are any generic type, use equals() to test equality.</li><li>Assume keys are any generic type, use equals() to test equality; use hashCode() to scramble key.</li></ul><p>Best practices: Use immutable types for symbol table keys.</p><p>Equality test:</p><hr><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">Data</span> <span class="keyword">implements</span> <span class="title">Comparable</span>&lt;<span class="title">Date</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> month;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> day;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> year;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object y)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (y == <span class="keyword">this</span>)<span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (y == <span class="keyword">null</span>)<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (y.getClass() != <span class="keyword">this</span>.getClass())</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    </span><br><span class="line">    Date that = (Date) y;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.day != that.day)<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.month != that.month)<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.year != that.year)<span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="elementary-implementations"><a href="#elementary-implementations" class="headerlink" title="elementary implementations"></a>elementary implementations</h3><p>Sequential search in a linked list:</p><hr><p>Data structure: Maintain an (unordered) linked list of key-value pairs.</p><p>Search: Scan through all keys until find a match.</p><p>Insert: Scan through all keys until find a match; if no match add to front.</p><p>Binary search in an ordered array:</p><hr><p>Data structure: Maintain an ordered array of key-value pairs.</p><p>Rank helper function: How many keys &lt; k?</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Value <span class="title">get</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (isEmpty())<span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    <span class="keyword">int</span> i = rank(key);</span><br><span class="line">    <span class="keyword">if</span> (i &lt; N &amp;&amp; keys[i].compareTo(key) == <span class="number">0</span>)<span class="keyword">return</span> vals[i];</span><br><span class="line">    <span class="keyword">else</span><span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">rank</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> lo = <span class="number">0</span>; hi = N-<span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (lo &lt;= hi)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> mid = lo + (hi - lo) / <span class="number">2</span>;</span><br><span class="line">        <span class="keyword">int</span> cmp = key.compareTo(keys[mid]);</span><br><span class="line">        <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>) hi = mid - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>) lo = mid + <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span><span class="keyword">return</span> mid;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> lo;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1fnwacsmmj30wu0cpgqz.jpg" style="zoom:60%"><br></center><h3 id="ordered-operations"><a href="#ordered-operations" class="headerlink" title="ordered operations"></a>ordered operations</h3><p>API:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ST</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;, <span class="title">Value</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">ST();<span class="comment">// create an ordered symbol table</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">put</span><span class="params">(Key key, Value val)</span></span>;<span class="comment">// put key-value pair into the table (remove key from table if value is null)</span></span><br><span class="line"><span class="function">Value <span class="title">get</span><span class="params">(Key key)</span></span>;<span class="comment">// value paired with key (null if key is absent)</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">delete</span><span class="params">(Key key)</span></span>;<span class="comment">// remove key (and its value) from table</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Key key)</span></span>;<span class="comment">// is there a value paired with key?</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>;<span class="comment">// is the table empty?</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;<span class="comment">// number of key-value pairs</span></span><br><span class="line"><span class="function">Key <span class="title">min</span><span class="params">()</span></span>;<span class="comment">// smallest key</span></span><br><span class="line"><span class="function">Key <span class="title">max</span><span class="params">()</span></span>;<span class="comment">// largest key</span></span><br><span class="line"><span class="function">Key <span class="title">floor</span><span class="params">(Key key)</span></span>;<span class="comment">// smallest key less than or equal to key</span></span><br><span class="line"><span class="function">Key <span class="title">ceiling</span><span class="params">(Key key)</span></span>;<span class="comment">// smallest key greater than or equal to key</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">rank</span><span class="params">(Key key)</span></span>;<span class="comment">// number of keys less than key</span></span><br><span class="line"><span class="function">Key <span class="title">select</span><span class="params">(<span class="keyword">int</span> k)</span></span>;<span class="comment">// key of rank k</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteMin</span><span class="params">()</span></span>;<span class="comment">// delete smallest key</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">deleteMax</span><span class="params">()</span></span>;<span class="comment">// delete largest key</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">(Key lo, Key hi)</span></span>;<span class="comment">// number of keys in [lo..hi]</span></span><br><span class="line"><span class="function">Iterable&lt;Key&gt; <span class="title">keys</span><span class="params">(Key lo, Key hi)</span></span>;<span class="comment">// keys in [lo..hi], in sorted order</span></span><br><span class="line"><span class="function">Iterable&lt;Key&gt; <span class="title">keys</span><span class="params">()</span></span>;<span class="comment">// all keys in the table, in sorted order</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Binary-Search-Trees"><a href="#Binary-Search-Trees" class="headerlink" title="Binary Search Trees"></a>Binary Search Trees</h2><h3 id="BSTs"><a href="#BSTs" class="headerlink" title="BSTs"></a>BSTs</h3><p>Definition: A BST is binary tree in symmetric order.</p><p>A binary tree is either:</p><ul><li>Empty</li><li>Two disjoint binary trees (left and right).</li></ul><p>Symmetric order: Each node has a key, and every node’s key is: </p><ul><li>Larger than all keys in its left subtree.</li><li>Smaller than all keys in its right subtree.</li></ul><p>Java definition: A BST is a reference to a root Node.</p><p>A Node is comprised of four fields:</p><ul><li>A Key and a Value.</li><li>A reference to the left and right subtree.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Key key;</span><br><span class="line">    <span class="keyword">private</span> Value val;</span><br><span class="line">    <span class="keyword">private</span> Node left, right;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(Key key, Value val)</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.val = val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1fzf22o39j30fl0a4wh7.jpg" style="zoom:60%"><br></center><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BST</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;, <span class="title">Value</span>&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> Node root;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class"></span>&#123; <span class="comment">/* see previous slide */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(Key key, Value val)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* see later */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Value <span class="title">get</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* see later */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* see later */</span> &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> Iterable&lt;Key&gt; <span class="title">iterator</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="comment">/* see later */</span> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Search: If less, go left; if greater, go right; if equal, search hit.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Value <span class="title">get</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Node x = root;</span><br><span class="line">    <span class="keyword">while</span> (x != <span class="keyword">null</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> cmp = key.compareTo(x.key);</span><br><span class="line">        <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)x = x.left;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)x = x.right;</span><br><span class="line">        <span class="keyword">else</span><span class="keyword">return</span> x.val;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Insertion (concise but tricky recursive code):</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(Key key, Value val)</span></span></span><br><span class="line"><span class="function"></span>&#123; root = put(root, key, val); &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">put</span><span class="params">(Node x, Key key, Value val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="keyword">null</span>)<span class="keyword">return</span> <span class="keyword">new</span> Node(key, val);</span><br><span class="line">    <span class="keyword">int</span> cmp = key.compareTo(x.key);</span><br><span class="line">    <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)x.left = put(x.left, key, val);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)x.right = put(x.right, key, val);</span><br><span class="line">    <span class="keyword">else</span>x.val = val;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ordered-operations-1"><a href="#ordered-operations-1" class="headerlink" title="ordered operations"></a>ordered operations</h3><p>Minimum: Smallest key in table.</p><p>Maximum: Largest key in table.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1g00rztt2j30iu0a8gnd.jpg" style="zoom:60%"><br></center><p>Rank: How many keys &lt; k?</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">rank</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> rank(key, root); &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">rank</span><span class="params">(Key key, Node x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="keyword">null</span>)<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> cmp = key.compareTo(x.key);</span><br><span class="line">    <span class="keyword">if</span> (cmp &lt; <span class="number">0</span>)<span class="keyword">return</span> rank(key,x.left);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (cmp &gt; <span class="number">0</span>)<span class="keyword">return</span> <span class="number">1</span> + size(x.left) + rank(key, x.right);</span><br><span class="line">    <span class="keyword">else</span><span class="keyword">return</span> size(x.left);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Inorder traversal:</p><ul><li>Traverse left subtree.</li><li>Enqueue key.</li><li>Traverse right subtree.</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Iterable&lt;Key&gt; <span class="title">keys</span><span class="params">()</span></span>;</span><br><span class="line">&#123;</span><br><span class="line">    Queue&lt;Key&gt; q = <span class="keyword">new</span> Queue&lt;Key&gt;();</span><br><span class="line">    inorder(root, q);</span><br><span class="line">    <span class="keyword">return</span> q;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">inorder</span><span class="params">(Node x, Queue&lt;Key&gt; q)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="keyword">null</span>)<span class="keyword">return</span>;</span><br><span class="line">    inorder(x.left, q);</span><br><span class="line">    q.enqueue(x.key);</span><br><span class="line">    inorder(x.right, q);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="deletion"><a href="#deletion" class="headerlink" title="deletion"></a>deletion</h3><p>Lazy deletion:</p><ul><li>Set its value to null.</li><li>Leave key in tree to guide searches (but don’t consider it equal in search).</li></ul><p>Delete the minimum key:</p><ul><li>Go left until finding a node with a null left link.</li><li>Replace that node by its right link.</li><li>Update subtree counts.</li></ul><p>Else, Hibbard deletion, please refer to CLRS BST chapter for more details</p><h1 id="Week-5"><a href="#Week-5" class="headerlink" title="Week 5"></a>Week 5</h1><h2 id="Balanced-Search-Trees"><a href="#Balanced-Search-Trees" class="headerlink" title="Balanced Search Trees"></a>Balanced Search Trees</h2><h3 id="2-3-search-trees"><a href="#2-3-search-trees" class="headerlink" title="2-3 search trees"></a>2-3 search trees</h3><p>Allow 1 or 2 keys per node</p><ul><li>2-node: one key, two children</li><li>3-node: two keys, three children</li></ul><p>Perfect balance: Every path from root to null link has same length</p><p>Symmetric order: Inorder traversal yields keys in ascending order</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0yd3afksej30ka0bsgov.jpg" style="zoom:60%"><br></center><p>Search</p><ul><li>Compare search key against keys in node</li><li>Find interval containing search key</li><li>Follow associated link (recursively)</li></ul><p>Insert into a 2-node at bottom</p><ul><li>Search for key, as usual</li><li>Replace 2-node with 3-node</li></ul><p>Splitting a 4-node is a local transformation: constant number of operations</p><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g0yde48g5vj30nb0gdgs4.jpg" style="zoom:60%"><br></center><p>Invariants: Maintain symmetric order and perfect balance</p><p>Pf: Each transformation maintains symmetric order and perfect balance</p><p>Tree height: Always $lg N$</p><h3 id="red-black-BSTs"><a href="#red-black-BSTs" class="headerlink" title="red-black BSTs"></a>red-black BSTs</h3><p>Left-leaning RB tree</p><p>Idea:</p><ul><li>Represent 2-3 tree as a BST</li><li>Use “internal” left-leaning links as “glue” for 3-nodes</li></ul><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g0ydp9v9ckj30sj06wmzw.jpg" style="zoom:60%"><br></center><p>A BST such that:</p><ul><li>No node has two red links connected to it</li><li>Every path from root to null link has the same number of black links</li><li>Red links lean left</li></ul><p>2-3 tree and RB BST are coresponding as following:</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0ydtk0xlaj30ge0h478m.jpg" style="zoom:60%"><br></center><p>Search for red-black BST is the same as the general BST</p><p>Representation:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> RED = <span class="keyword">true</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">boolean</span> BLACK = <span class="keyword">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    Key key;</span><br><span class="line">    Value val;</span><br><span class="line">    Node left, right;</span><br><span class="line">    <span class="keyword">boolean</span> color;<span class="comment">// color of parent link</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">isRed</span><span class="params">(Node x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (x == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    <span class="keyword">return</span> x.color == RED;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Left rotation: Orient a (temporarily) right-leaning red link to lean left</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">rotateLedt</span><span class="params">(Node h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isRed</span><span class="params">(h.right)</span></span>;</span><br><span class="line">    Node x = h.right;</span><br><span class="line">    h.right = x.left;</span><br><span class="line">    x.left = h;</span><br><span class="line">    x.color = h.color;</span><br><span class="line">    h.color = RED;</span><br><span class="line">    <span class="keyword">return</span> x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Invariants: Maintains symmetric order and perfect black balance</p><p>Right rotation is similar.</p><hr><p>Color flip: Recolor to split a (temporary) 4-node</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">flipColors</span><span class="params">(Node h)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">assert</span> !isRed(h);</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isRed</span><span class="params">(h.left)</span></span>;</span><br><span class="line">    <span class="function"><span class="keyword">assert</span> <span class="title">isRed</span><span class="params">(h.right)</span></span>;</span><br><span class="line">    h.color = RED;</span><br><span class="line">    h.left.color = Black;</span><br><span class="line">    h.right.color = Black;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><p>Insertion in a LLRB tree</p><p>Basic strategy: Maintain 1-1 correspondence with 2-3 trees by applying elementary red-black BST operations</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0yebsxcraj30dz0esact.jpg" style="zoom:60%"><br></center><p>Warmup 1: Insert into a tree with exactly 1 node</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g0yeeyme4uj30ln0av795.jpg" style="zoom:60%"><br></center><p>Warmup 2: Insert into a tree with exactly 2 nodes (3 cases)</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0yej8db99j30ue0i1qc8.jpg" style="zoom:60%"><br></center><p>Case 2: Insert into a 3-node at the bottom</p><ul><li>Do standard BST insert; color new link red</li><li>Rotate to balance the 4-node (if needed)</li><li>Flip colors to pass red link up one level</li><li>Rotate to make lean left (if needed)</li><li>Repeat case 1 or case 2 up the tree (if needed)</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0yenl6vckj30vo0d8443.jpg" style="zoom:60%"><br></center><p>Java implementation</p><p>Reduce one case to another</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> Node <span class="title">put</span><span class="params">(Node h, Key key, Value val)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (h == <span class="keyword">null</span>) <span class="keyword">return</span> <span class="keyword">new</span> Node(key, val, RED);</span><br><span class="line">    <span class="keyword">int</span> cmp = key.compareTo(h.key);</span><br><span class="line">    <span class="keyword">if</span>(cmp &lt; <span class="number">0</span>) h.left = put(h.left, key, val);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span>(cmp &gt; <span class="number">0</span>) h.right = put(h.right, key, val);</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (cmp == <span class="number">0</span>) h.val = val;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (isRed(h.right) &amp;&amp; !isRed(h.left))h = rotateLeft(h;</span><br><span class="line">    <span class="keyword">if</span> (isRed(h.left) &amp;&amp; isRed(h.left.left))h = rotateRight(h);</span><br><span class="line">    <span class="keyword">if</span> (isRed(h.left) &amp;&amp; isRed(h.right))flipColors(h);</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> h;                                                              </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="B-trees-Bayer-McCreight-1972"><a href="#B-trees-Bayer-McCreight-1972" class="headerlink" title="B-trees (Bayer-McCreight, 1972)"></a>B-trees (Bayer-McCreight, 1972)</h3><p>File system model:</p><ul><li>Page: Contiguous block of data</li><li>Probe: First access to a page</li><li>Property: Time required for a probe is much larger than time to access data within a page</li><li>Cost model: Number of probes</li><li>Goal: Access data using minimum number of probes</li></ul><p>B-tree: Generalize 2-3 trees by allowing up to M-1 key-link pairs per node</p><ul><li>At least 2 key-link pairs at root</li><li>At least M/2 key-link pairs in other nodes</li><li>External nodes contain client keys</li><li>Internal nodes contain copies of keys to guide search</li></ul><p>Searching in a B-tree:</p><ul><li>Start at root</li><li>Find interval for search key and take corresponding link</li><li>Search terminates in external node</li></ul><p>Insertion in a B-tree:</p><ul><li>Search for new key</li><li>Insert at bottom</li><li>Split nodes with M key-link pairs on the way up the tree</li></ul><p>Red-black trees are widely used as system symbol tables</p><ul><li>Java: java.util.TreeMap, java.util.TreeSet</li><li>C++ STL: map, multimap, multiset</li><li>Linux kernel: completely fair scheduler, linux/rbtree.h</li><li>Emacs: conservative stack scanning</li></ul><p>B-tree variants: B+ tree, B* tree, B# tree, …</p><p>B-trees (and variants) are videly used for file systems and databases</p><ul><li>Windows: NTFS</li><li>Mac: HFS, HFS+</li><li>Linux: ReiserFS, XFS, Ext3FS, JFS</li><li>Databases: Oracle, DB2, Ingres, SQL, PostgreSQL</li></ul><h2 id="Geometric-Applications-of-BSTs"><a href="#Geometric-Applications-of-BSTs" class="headerlink" title="Geometric Applications of BSTs"></a>Geometric Applications of BSTs</h2><p>Applications: CAD, games, movies, virtual reality, databases, …</p><h3 id="1d-range-search"><a href="#1d-range-search" class="headerlink" title="1d range search"></a>1d range search</h3><ul><li>Insert key-value pair</li><li>Search for key k</li><li>Delete key k</li><li>Range search: find all keys between $k_1$ and $k_2$</li><li>Range count: number of keys between $k_1$ and $k_2$</li></ul><hr><p>Implementations:</p><table><thead><tr><th>data structure</th><th>insert</th><th>range count</th><th>range search</th></tr></thead><tbody><tr><td>unordered array</td><td>1</td><td>N</td><td>N</td></tr><tr><td>ordered array</td><td>N</td><td>log N</td><td>R + log N</td></tr><tr><td>goal</td><td>log N</td><td>log N</td><td>R + log N</td></tr></tbody></table><p>N = number of keys</p><p>R = number of keys that match</p><p>BST implementation:</p><p>Proposition: Running time proportional to log N.</p><p>Pf: Nodes examined = search path to lo + search path to hi.</p><h3 id="line-segment-intersection"><a href="#line-segment-intersection" class="headerlink" title="line segment intersection"></a>line segment intersection</h3><p>Orthogonal line segment intersection search</p><p>Quadratic algorithm: Check all pairs of line segments for intersection.</p><p>Nondegeneracy assumption: All x- and y- coordinates are distinct.</p><p>Sweep-line algorithm:</p><p>Sweep vertical line from left to right</p><ul><li>X-coordinates define events.</li><li>H-segment (left endpoint): insert y-coordinate into BST.</li><li>H-segment (right endpoint): remove y-coordinate from BST.</li><li>When hit a vertical line segment, do a 1-d search</li></ul><p>Proposition: The sweep-line algorithm takes time proportional to N log N + R to find all R intersections among N orthogonal line segments.</p><p>Pf.</p><ul><li>Put x-coordinates on a PQ (or sort).    N log N</li><li>Insert y-coordinates into BST  N log N</li><li>Delete y-coordinates from BST  N log N</li><li>Range searches in BST  N log N + R</li></ul><p>Bottom line: Sweep line reduces 2d orthogonal line segment intersection search to 1d range search</p><h3 id="kd-trees"><a href="#kd-trees" class="headerlink" title="kd trees"></a>kd trees</h3><p>Extension of ordered symbol-table to 2d keys</p><ul><li>Insert a 2d key</li><li>Delete a 2d key</li><li>Search for a 2d key</li><li>Range search: find all keys that lie in a 2d range</li><li>Range count: number of keys that lie in a 2d range</li></ul><p>Geometric interpretation:</p><ul><li>Keys are point in the plane</li><li>Find/count points in a given h-v rectangle</li></ul><hr><p>Grid implementation:</p><ul><li>Divide space into M-by-M grid of squares</li><li>Create list of points contained in each square</li><li>Use 2d array to directly index relevant square</li><li>Insert: add(x, y) to list for corresponding square</li><li>Range search: examine only squares that intersect 2d range query</li></ul><p>Space-time tradeoff</p><ul><li>Space: $M^2+N$</li><li>Time: 1 + $N/M^2$ per square examined, on average</li></ul><p>Choose grid square size to tune performance</p><ul><li>Too small: waste space</li><li>Too large: too many points per square</li></ul><p>It’s fast, simple solution for evenly-distributed points</p><p>Problem: Clustering a well-knwon phenomenon in geometric data</p><ul><li>Lists are too long, even though average length is short</li><li>Need data structure that adapts gracefully to data</li></ul><hr><p>2d tree construction</p><p>Recursively partition plane into two halfplanes.</p><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g13eil2g5ij30fc0itdib.jpg" style="zoom:60%"><br></center><p>Data structure: BST, but alternate using x- and y- coordinates as key.</p><ul><li>Search gives rectangle containing point</li><li>Insert further subdivides the plane</li></ul><p>Range search in a 2d tree</p><p>Goal: Find all points in a query axis-aligned rectangle.</p><ul><li>Check if point in node lies in given rectangle</li><li>Recursively search left/bottom (if any could fall in rectangle)</li><li>Recursively search right/top (if any could fall in rectangle)</li></ul><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g13et5rhmvj30xj0em0x2.jpg" style="zoom:60%"><br></center><p>Nearest neighbor search in a 2d tree</p><p>Goal: Find closest point to query point</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g13es1t253j30xm0ey0wn.jpg" style="zoom:60%"><br></center><ul><li>Check distance from point in node to query point</li><li>Recursively search left/bottom (if it could contain a closer point)</li><li>Recursively search right/top (if it could contain a closer point)</li><li>Organize method so that it begins by searching for query point</li></ul><hr><p>Kd tree</p><p>Recursively partition k-dimensional space into 2 halfspaces</p><p>Efficient, simple data structure for processing k-dimensional data</p><ul><li>Widely used</li><li>Apapts well to high-dimensional and clustered data</li><li>Discovered by an undergrad in an algorithms class!</li></ul><hr><p>N-body simulation</p><ul><li>Build 3d-tree with N particles sa nodes</li><li>Store center-of-mass of subtree in each node.</li><li>To compute total force acting on a particle, traverse tree, but stop as soon as distance from particle to subdivision is sufficiently large.</li></ul><h3 id="interval-search-trees"><a href="#interval-search-trees" class="headerlink" title="interval search trees"></a>interval search trees</h3><p>1d interval search: Data structure to hold set of (overlapping) intervals</p><ul><li>Insert an interval (lo, hi).</li><li>Search for an interval (lo, hi).</li><li>Delete an interval (lo, hi).</li><li>Interval intersection query: given an interval (lo, hi), find all intervals (or one interval) in data structure that intersects (lo, hi).</li></ul><p>API</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">IntervalST</span></span></span><br><span class="line"><span class="class">    <span class="title">IntervalST</span>()</span></span><br><span class="line"><span class="class">    <span class="title">void</span> <span class="title">put</span>(<span class="title">Key</span> <span class="title">lo</span>, <span class="title">Key</span> <span class="title">hi</span>, <span class="title">Value</span> <span class="title">val</span>)</span></span><br><span class="line"><span class="class">    <span class="title">Value</span> <span class="title">get</span>(<span class="title">Key</span> <span class="title">lo</span>, <span class="title">Key</span> <span class="title">hi</span>)</span></span><br><span class="line"><span class="class">    <span class="title">void</span> <span class="title">delete</span>(<span class="title">Key</span> <span class="title">lo</span>, <span class="title">Key</span> <span class="title">hi</span>)</span></span><br><span class="line"><span class="class">    <span class="title">Iterable</span>&lt;<span class="title">Value</span>&gt; <span class="title">intersects</span>(<span class="title">Key</span> <span class="title">lo</span>, <span class="title">Key</span> <span class="title">hi</span>)</span></span><br></pre></td></tr></table></figure><p>Interval search trees</p><p>Create BST, where each node stores an interval (lo, hi).</p><ul><li>Use left endpoint as BST key.</li><li>Store max endpoint in subtree rooted at node.</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g13friuhaaj30o90duq6b.jpg" style="zoom:60%"><br></center><p>To insert an interval (lo, hi):</p><ul><li>Insert into BST, using lo as the key.</li><li>Update max in each node on search path.</li></ul><p>To search for any one interval that intersects query interval (lo, hi):</p><ul><li>If interval in node intersects query interval, return it.</li><li>Else if left subtree is null, go right.</li><li>Else if max endpoint in left subtree is less than lo, go right.</li><li>Else go left.</li></ul><p>Case 1. If search goes right, then no intersection in left.</p><p>Case 2. If search goes left, then there is either an intersection in left subtree or no intersections in either</p><p>Pf. Suppose no intersection in left.</p><ul><li>Since went left, we have lo ≤ max.</li><li>Then for any interval (a,b) in right subtree of x, hi &lt; c ≤ a, no intersection in right.</li></ul><h3 id="rectangle-intersection"><a href="#rectangle-intersection" class="headerlink" title="rectangle intersection"></a>rectangle intersection</h3><p>Orthogonal rectangle intersection search</p><p>Goal: Find all intersections among a set of N orthogonal rectangles</p><p>Quadratic algorithm: Check all pairs of rectangles for intersection</p><p>Non-degeneracy assumption: All x- and y- coordinates are distinct.</p><p>Design-rule checking:</p><ul><li>Certain wires cannot intersect</li><li>Certain spacing needed between different types of wires</li><li>Debugging = orthogonal rectangle intersection search</li></ul><p>Sweep-line algorithm (similar to previous one)</p><ul><li>X-coordinates of left and right endpoints define events.</li><li>Maintain set of rectangles that intersect the sweep line in an interval search tree (using y-intervals of rectangle).</li><li>Left endpoint: interval search for y-interval of rectangle; insert y-interval.</li><li>Right endpoint: remove y-interval.</li></ul><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g13gi5ehrlj30vf0dojtf.jpg" style="zoom:60%"><br></center><p>Bottom line: Sweep line reduces 2d orthogonal rectangle intersection search to 1d interval search.</p><h3 id="Summary-Of-Geometric-Applications-of-BSTs"><a href="#Summary-Of-Geometric-Applications-of-BSTs" class="headerlink" title="Summary Of Geometric Applications of BSTs"></a>Summary Of Geometric Applications of BSTs</h3><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g13glc65gbj30we0pewlm.jpg" style="zoom:60%"><br></center><h3 id="Programming-Assignment-5"><a href="#Programming-Assignment-5" class="headerlink" title="Programming Assignment 5"></a>Programming Assignment 5</h3><p>Problem:</p><p><a href="http://coursera.cs.princeton.edu/algs4/assignments/kdtree.html" target="_blank" rel="noopener">Programming Assignment 5</a></p><p>Code is on my Github page:</p><p><a href="https://github.com/Aden-Q/Algorithms-Part-I/tree/master/Kd-tree" target="_blank" rel="noopener">Kdtree</a></p><p>Missing the optional task of running time analysis because it’s optional.</p><h1 id="Week-6"><a href="#Week-6" class="headerlink" title="Week 6"></a>Week 6</h1><h2 id="Hash-Tables"><a href="#Hash-Tables" class="headerlink" title="Hash Tables"></a>Hash Tables</h2><h3 id="hash-functions"><a href="#hash-functions" class="headerlink" title="hash functions"></a>hash functions</h3><p>Basic plan: save items in a key-indexed table (index is a function of the key).</p><p>Hash function: Method for computing array index from key.</p><p><code>hash(&quot;it&quot;) = 3</code></p><p>Issues:</p><ul><li>Computing the hash function.</li><li>Equality test.</li><li>Collision resolution.</li></ul><p>Classic space-time tradeoff.</p><ul><li>No space limitation: trivial hash function with key as index.</li><li>No time limitation: trivial collision resolution with sequential search.</li><li>Space and time limitations: hashing (the real world).</li></ul><p>Hash function</p><hr><p>Idealistic goal: Scramble the keys uniformly to produce a table index.</p><ul><li>Efficiently computable.</li><li>Each table index equally likely for each key.</li></ul><p>All Java classes inherit a method hashCode(), which returns a 32-bit int.</p><p>Default implementation: Memory address of x.</p><p>Some typicals in Java libraries:</p><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1g164xduhj30zg0mb11h.jpg" style="zoom:60%"><br></center><p> Hash for strings: Horner’s method</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">String</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> hash = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">char</span>[] s;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span></span></span><br><span class="line"><span class="function">    </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> h = hash;</span><br><span class="line">    <span class="keyword">if</span> (h != <span class="number">0</span>)<span class="keyword">return</span> h;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; length(); i++)</span><br><span class="line">    h = s[i] + (<span class="number">31</span> * h);</span><br><span class="line">    hash = h;</span><br><span class="line">    <span class="keyword">return</span> h;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Modular hashing</p><p>Hash code: A int between $-2^{32}$ and $2^{31}-1$</p><p>Hash function: An int between 0 and M-1 (for use as array index).</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// to be between 0 and M-1</span></span><br><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Key key)</span></span></span><br><span class="line"><span class="function"></span>&#123; <span class="keyword">return</span> (key.hashCode() &amp; <span class="number">0x7fffffff</span>) % M; &#125;</span><br></pre></td></tr></table></figure><p>Assumption</p><p>Uniform hashing assumption: Each key is equally likely to hash to an integer between 0 and M-1.</p><h3 id="seperate-chaining"><a href="#seperate-chaining" class="headerlink" title="seperate chaining"></a>seperate chaining</h3><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1g1ngvns8j30kx0f4whb.jpg" style="zoom:60%"><br></center><p>Typical choice of M: near N / 5</p><h3 id="linear-probing"><a href="#linear-probing" class="headerlink" title="linear probing"></a>linear probing</h3><p>Open addressing (IBM 1953): When a new key collides, find next empty slot, and put it there.</p><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1g1v6g6iaj30dr0gbgnk.jpg" style="zoom:60%"><br></center><p>Hash: Map key to integer i between 0 and M-1.</p><p>Insert: Put at table index i if free; if not try i+1, i+2, etc.</p><p>Search: Search table index i; if occupied but no match, try i+1, i+2, etc.</p><p>Note: Array size M must be greater than number of key-value pairs N.</p><h3 id="context"><a href="#context" class="headerlink" title="context"></a>context</h3><p>Algorithmic complexity attack.</p><p>One-way hash function: “Hard” to find a key that will hash to a desired value.</p><p>Separate chaining vs. linear probing</p><hr><p>Separate chaining:</p><ul><li>Easier to implement delete.</li><li>Performance degrades gracefully.</li><li>Clustering less sensitive to poorly-designed hash function.</li></ul><p>Linear probing:</p><ul><li>Less wasted space.</li><li>Better cache performance.</li></ul><p>Variations:</p><ul><li>Two-probe hashing</li><li>Double hashing</li><li>Cuckoo hashing</li><li>And so on…</li></ul><h2 id="Symbol-Table-Applications"><a href="#Symbol-Table-Applications" class="headerlink" title="Symbol Table Applications"></a>Symbol Table Applications</h2><h3 id="sets"><a href="#sets" class="headerlink" title="sets"></a>sets</h3><p>Mathematical set: A collection of distinct keys.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SET</span>&lt;<span class="title">Key</span> <span class="keyword">extends</span> <span class="title">Comparable</span>&lt;<span class="title">Key</span>&gt;&gt;</span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">SET();<span class="comment">// create an empty set</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(Key key)</span></span>;<span class="comment">// add the key to the set</span></span><br><span class="line"><span class="function"><span class="keyword">boolean</span> <span class="title">contains</span><span class="params">(Key key)</span></span>;<span class="comment">// is the key in the set?</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">remove</span><span class="params">(Key key)</span></span>;<span class="comment">// remove the key from the set</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">size</span><span class="params">()</span></span>;<span class="comment">// return the number of keys in the set</span></span><br><span class="line"><span class="function">Iterator&lt;Key&gt; <span class="title">iterator</span><span class="params">()</span></span>;<span class="comment">// iterator through keys in the set</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Exception filter:</p><ul><li>Read in a list of words from one file.</li><li>Print out all words from standard input that are { in, not in } the list.</li></ul><h3 id="dictionary-clients"><a href="#dictionary-clients" class="headerlink" title="dictionary clients"></a>dictionary clients</h3><p>Dictionary lookup.</p><h3 id="indexing-clients"><a href="#indexing-clients" class="headerlink" title="indexing clients"></a>indexing clients</h3><p>File indexing</p><hr><p>Goal: Given a list of files specified, create an index so that you can efficiently find all files containing a given query string.</p><p>Key: String.</p><p>Value: Set of files.</p><p>Concordance</p><hr><p>Goal: Preprocess a text corpus to support concordance queries: given a word, find all occurrences with their immediate contexts.</p><h3 id="sparse-vectors"><a href="#sparse-vectors" class="headerlink" title="sparse vectors"></a>sparse vectors</h3><center><br><img src="https://ws1.sinaimg.cn/large/006tKfTcly1g1g3ffe3xzj30hw086jta.jpg" style="zoom:60%"><br></center><p>Problem: Sparse matrix-vector multiplication.</p><p>Vector representations</p><hr><p>1 D array representation:</p><ul><li>Constant time access to elements.</li><li>Space proportional to N.</li></ul><center><br><img src="https://ws3.sinaimg.cn/large/006tKfTcly1g1g3gd9fznj30u103qwfy.jpg" style="zoom:60%"><br></center><p>Symbol table representation:</p><ul><li>Key = index, value = entry.</li><li>Efficient iterator.</li><li>Space proportional to number of nonzeros.</li></ul><center><br><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g1g3ge1nh0j30fp05nwf9.jpg" style="zoom:60%"><br></center><p>Sparse matrix representation: Each row of matrix is a sparse vector.</p><ul><li>Efficient access to elements.</li><li>Space proportional to number of nonzeros (plus N).</li></ul><center><br><img src="https://ws4.sinaimg.cn/large/006tKfTcly1g1g3m3lj45j30ek0c2ad6.jpg" style="zoom:60%"><br></center><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">SparseVector[] a = <span class="keyword">new</span> SparseVector[N];</span><br><span class="line"><span class="keyword">double</span>[] x = <span class="keyword">new</span> <span class="keyword">double</span>[N];</span><br><span class="line"><span class="keyword">double</span>[] b = <span class="keyword">new</span> <span class="keyword">double</span>[N];</span><br><span class="line">...</span><br><span class="line"><span class="comment">// Initialize a[] and x[]</span></span><br><span class="line">...</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; N; i++)</span><br><span class="line">    b[i] = a[i].dot(x);</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Princeton Algorithm course on coursera. Part 1&lt;/p&gt;
    
    </summary>
    
      <category term="Note" scheme="http://yoursite.com/categories/Note/"/>
    
    
      <category term="Programming" scheme="http://yoursite.com/tags/Programming/"/>
    
      <category term="Java" scheme="http://yoursite.com/tags/Java/"/>
    
  </entry>
  
</feed>
